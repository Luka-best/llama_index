{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1acacc45",
   "metadata": {},
   "source": [
    "#uncomment to install llama-index, make sure it is above 0.10.x\n",
    "## TODO :\n",
    "Once the llama-index pip installable package is ready, implement the **models = NVIDIARerank.get_available_models()** , it is not implemnted right now !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983aa69",
   "metadata": {},
   "source": [
    "## establish the reranker class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0e0b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.nvidia_rerank import NVIDIARerank\n",
    "rerank=NVIDIARerank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76caf73e",
   "metadata": {},
   "source": [
    "## we can set top_n like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "493a15f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "## setting top_n\n",
    "rerank.top_n=2\n",
    "print(rerank.top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d21ecf",
   "metadata": {},
   "source": [
    "## Switching to nim backend , otherwise the default will be API Catalog's as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72bf369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nim\n"
     ]
    }
   ],
   "source": [
    "from llama_index.postprocessor.nvidia_rerank import NVIDIARerank\n",
    "\n",
    "rerank.mode(type_mode=\"nim\", base_url=\"http://localhost:1976/v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6d016",
   "metadata": {},
   "source": [
    "## load some toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cad18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.data_structs import Node\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "query = \"which way should i go?\"\n",
    "passages = [\n",
    "    \"two roads diverged in a yellow wood, and sorry i could not travel both and be one traveler, long i stood and looked down one as far as i could to where it bent in the undergrowth;\",\n",
    "    \"then took the other, as just as fair, and having perhaps the better claim because it was grassy and wanted wear, though as for that the passing there had worn them really about the same,\",\n",
    "    \"and both that morning equally lay in leaves no step had trodden black. oh, i marked the first for another day! yet knowing how way leads on to way i doubted if i should ever come back.\",\n",
    "    \"i shall be telling this with a sigh somewhere ages and ages hense: two roads diverged in a wood, and i, i took the one less traveled by, and that has made all the difference.\"\n",
    "]\n",
    "\n",
    "nodes = [\n",
    "    NodeWithScore(node=Node(text=passages[0]), score=0.7),\n",
    "    NodeWithScore(node=Node(text=passages[1]), score=0.8),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856aa72e",
   "metadata": {},
   "source": [
    "## validate with NVreranker works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e478e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='94b57b89-3aa7-4483-88bd-5082f263e3a9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='then took the other, as just as fair, and having perhaps the better claim because it was grassy and wanted wear, though as for that the passing there had worn them really about the same,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8),\n",
       " NodeWithScore(node=TextNode(id_='73074d0c-67ee-46b7-b99d-1c091e0e3295', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='two roads diverged in a yellow wood, and sorry i could not travel both and be one traveler, long i stood and looked down one as far as i could to where it bent in the undergrowth;', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.postprocessor.nvidia_rerank import NVIDIARerank\n",
    "rerank.postprocess_nodes(nodes, query_str=query )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f3008",
   "metadata": {},
   "source": [
    "## switch to APICatalog , for that we need to set the NVIDIA_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc268603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NVAPI Key (starts with nvapi-):  ······································································\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "## API Key can be found by going to NVIDIA NGC -> AI Foundation Models -> (some model) -> Get API Code or similar.\n",
    "## 10K free queries to any endpoint (which is a lot actually).\n",
    "\n",
    "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "    nvapi_key=os.environ[\"NVIDIA_API_KEY\"] \n",
    "\n",
    "else:\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6308fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalog\n"
     ]
    }
   ],
   "source": [
    "rerank.mode(type_mode=\"catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a3d644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='94b57b89-3aa7-4483-88bd-5082f263e3a9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='then took the other, as just as fair, and having perhaps the better claim because it was grassy and wanted wear, though as for that the passing there had worn them really about the same,', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8),\n",
       " NodeWithScore(node=TextNode(id_='73074d0c-67ee-46b7-b99d-1c091e0e3295', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='two roads diverged in a yellow wood, and sorry i could not travel both and be one traveler, long i stood and looked down one as far as i could to where it bent in the undergrowth;', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.postprocessor.nvidia_rerank import NVIDIARerank\n",
    "rerank.postprocess_nodes(nodes, query_str=query )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98362fb3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7525d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec266a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b355d05",
   "metadata": {},
   "source": [
    "## Validate how Cohere does this in llama-index integration \n",
    "reference url : https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/postprocessor/llama-index-postprocessor-cohere-rerank/llama_index/postprocessor/cohere_rerank/base.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204ee49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668270ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308615a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d54e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank.mode(type_mode=\"catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024c9e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580eff87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
