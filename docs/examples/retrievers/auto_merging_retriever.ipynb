{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5325ac27-38ea-47aa-afef-be4ec4f8f4b9",
   "metadata": {},
   "source": [
    "# Auto Merging Retriever\n",
    "\n",
    "In this notebook, we showcase our `AutoMergingRetriever`, which looks at a set of leaf nodes and recursively \"merges\" subsets of leaf nodes that reference a parent node beyond a given threshold. This allows us to consolidate potentially disparate, smaller contexts into a larger context that might help synthesis.\n",
    "\n",
    "You can define this hierarchy yourself over a set of documents, or you can make use of our brand-new text parser: a RecursiveNodeParser that takes in a candidate set of documents and outputs an entire hierarchy of nodes, from \"coarse-to-fine\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1316ac-84ca-41d0-80f9-d4ef758e653c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80372299-ab32-4ddd-9b88-05c877120c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-26 20:54:41--  https://arxiv.org/pdf/2307.09288.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 128.84.21.199\n",
      "Connecting to arxiv.org (arxiv.org)|128.84.21.199|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13661300 (13M) [application/pdf]\n",
      "Saving to: ‘data/llama2.pdf’\n",
      "\n",
      "data/llama2.pdf     100%[===================>]  13.03M  31.9KB/s    in 4m 44s  \n",
      "\n",
      "2023-08-26 20:59:27 (47.0 KB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9c5d99-bd0e-4b26-b816-9f5ad29df3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_hub.file.pdf.base import PDFReader\n",
    "from llama_hub.file.unstructured.base import UnstructuredReader\n",
    "from llama_hub.file.deepdoctection.base import DeepDoctectionReader\n",
    "from llama_hub.file.pdf_miner.base import PDFMinerReader\n",
    "from llama_index import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60b6c024-0963-4315-8e6c-12cce16e3090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepdoctection in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (0.26)\n",
      "Requirement already satisfied: timm in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (0.9.5)\n",
      "Collecting pdfminer\n",
      "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (1.23.5)\n",
      "Requirement already satisfied: termcolor>=1.1 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (23.1)\n",
      "Requirement already satisfied: jsonlines==3.0.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (3.0.0)\n",
      "Requirement already satisfied: networkx>=2.7.1 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.11.2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (6.6.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (0.9.0)\n",
      "Requirement already satisfied: catalogue==2.0.7 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (2.0.7)\n",
      "Requirement already satisfied: pyzmq>=16 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (25.0.2)\n",
      "Requirement already satisfied: pypdf2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (3.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.12.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (0.14.1)\n",
      "Requirement already satisfied: tqdm==4.64.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (4.64.0)\n",
      "Requirement already satisfied: opencv-python==4.5.4.60 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (4.5.4.60)\n",
      "Requirement already satisfied: mock==4.0.3 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (4.0.3)\n",
      "Requirement already satisfied: pyyaml==6.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from deepdoctection) (6.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from jsonlines==3.0.0->deepdoctection) (23.1.0)\n",
      "Requirement already satisfied: safetensors in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from timm) (0.3.3)\n",
      "Requirement already satisfied: torchvision in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from timm) (0.15.2)\n",
      "Requirement already satisfied: torch>=1.7 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from timm) (2.0.1)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.18.0-cp35-abi3-macosx_10_9_universal2.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.12.0->deepdoctection) (4.7.1)\n",
      "Requirement already satisfied: requests in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.12.0->deepdoctection) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.12.0->deepdoctection) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.12.0->deepdoctection) (2023.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from importlib-metadata>=4.11.2->deepdoctection) (3.15.0)\n",
      "Requirement already satisfied: sympy in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from torch>=1.7->timm) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.12.0->deepdoctection) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.12.0->deepdoctection) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.12.0->deepdoctection) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.12.0->deepdoctection) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
      "Building wheels for collected packages: pdfminer\n",
      "  Building wheel for pdfminer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140099 sha256=2dabaf17d728054ec22d8192870dc4992b88377dc5692513d2f75acede0e1d65\n",
      "  Stored in directory: /Users/jerryliu/Library/Caches/pip/wheels/b6/02/c9/adcd788c3ed26716f0be0d92c19daeec173ab822641de69fc0\n",
      "Successfully built pdfminer\n",
      "Installing collected packages: pycryptodome, pdfminer\n",
      "Successfully installed pdfminer-20191125 pycryptodome-3.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deepdoctection timm pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "723f1f02-2157-4166-b013-90e627c76530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDFReader = download_loader(\"PDFReader\")\n",
    "loader = PDFReader()\n",
    "docs0 = loader.load_data(file=Path('./data/llama2.pdf'))\n",
    "\n",
    "# loader = UnstructuredReader()\n",
    "# docs = loader.load_data(file=Path('./data/llama2.pdf'))\n",
    "\n",
    "# loader = DeepDoctectionReader()\n",
    "# docs = loader.load_data(file=Path('./data/llama2.pdf'))\n",
    "\n",
    "# loader = PDFMinerReader()\n",
    "# docs = loader.load_data(file=Path('./data/llama2.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a75c4217-ab50-417f-a8ed-3b746a9956c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch docs together\n",
    "from llama_index import Document\n",
    "\n",
    "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0917f609-874c-400a-af92-abaebac679d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader = SimpleDirectoryReader(input_files=[\"../data/paul_graham/paul_graham_essay.txt\"])\n",
    "# docs = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724fe6f1-80e1-4ac5-bd99-8b9b8d15bddd",
   "metadata": {},
   "source": [
    "## Parse Chunk Hierarchy from Text, Load into Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45e783f5-a323-4f51-ae9a-4b71b00e5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import RecursiveNodeParser, SimpleNodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c3947df-25c2-4254-a3d4-381d136f3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to parse nodes\n",
    "\n",
    "node_parser = RecursiveNodeParser.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2162b309-dfc5-484b-a31c-24f705316f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9b5bc9b-389d-47db-a41c-3eb5b3d38ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7299ca7e-09b6-432f-a277-aae9eca0522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.schema import NodeRelationship\n",
    "def get_leaf_nodes(nodes: List) -> List:\n",
    "    \"\"\"Get leaf nodes.\"\"\"\n",
    "    leaf_nodes = []\n",
    "    for node in nodes:\n",
    "        if NodeRelationship.CHILD not in node.relationships:\n",
    "            leaf_nodes.append(node)\n",
    "    return leaf_nodes\n",
    "\n",
    "\n",
    "def get_non_leaf_nodes(nodes: List) -> List:\n",
    "    \"\"\"Get non_leaf nodes.\"\"\"\n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "    leaf_node_ids = {n.node_id for n in leaf_nodes}\n",
    "\n",
    "    non_leaf_nodes = []\n",
    "    for node in nodes:\n",
    "        if node.node_id not in leaf_node_ids:\n",
    "            non_leaf_nodes.append(node)\n",
    "    return non_leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "faeb37a8-aea9-4ee8-b6c0-3b2f188d244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes = get_leaf_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c33b5a8-4d9f-481e-8616-fc8717900159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15a6fcb0-e098-4695-b549-c4ff46c26c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2):\n",
    "#     print(leaf_nodes[i].get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ec940-8af7-45f5-9994-919d57583c24",
   "metadata": {},
   "source": [
    "### Load into Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "27c8f2cd-3e04-4feb-937b-b9ee33e1c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define storage context\n",
    "from llama_index.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.storage import StorageContext\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=docstore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "827ece8e-7a4b-4ee1-8ee2-3433d7f2072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load index into vector index\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "base_index = VectorStoreIndex(leaf_nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d84c19-c9ac-4294-a000-264c3c02427b",
   "metadata": {},
   "source": [
    "## Define Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e61682a0-dd3c-400b-8734-35d5d0a98252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers.auto_merging_retriever import AutoMergingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f96fd0bc-c6c0-4073-a692-d1803cf4289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "retriever = AutoMergingRetriever(\n",
    "    base_retriever,\n",
    "    storage_context,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "62f655cd-4195-4398-80e5-5aa561982d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Filling in node. Node id: 3b256786-958e-4626-9a02-ca9d00aace53> Node text: andusethedataforsupervisedfine-tuninginthesame\n",
      "manner as described in Section 3.1.An example can ...\n",
      "\n",
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 7d852fbe-3928-4ff1-9be9-8f80075d0102.\n",
      "> Parent node text: We also ask the annotators to avoid negative user experience\n",
      "categories (see Appendix A.5.2).The ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query_str = \"What were some lessons learned from red-teaming?\"\n",
    "query_str = \"Can you tell me about the key concepts for safety finetuning\"\n",
    "# query_str = \"Give me details on how safety violations were measured for Llama 2\"\n",
    "\n",
    "nodes = retriever.retrieve(query_str)\n",
    "base_nodes = base_retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f8019cb-6a76-473a-b24c-c96208fa64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node = docstore.get_document('fb24e04e-9544-4659-bf82-1c90d5540b7e')\n",
    "# print(node.get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "77eabc56-2009-4504-8832-b6d857bd43a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0d482b22-fd38-476b-821f-0c77564815c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** dec3035d-a5b6-4edd-acd1-5745499380c1<br>**Similarity:** 0.8706509346624604<br>**Text:** we describe our approach to safety fine-tuning, including safety categories, annotation\n",
       "guidelines,andthetechniquesweusetomitigatesafetyrisks.Weemployaprocesssimilartothegeneral\n",
       "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.Specifically,<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 05d93601-1b11-4892-be36-f8507d8eb600<br>**Similarity:** 0.862506098281326<br>**Text:** we use the following techniques in safety fine-tuning:\n",
       "1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\n",
       "tions that are then included in the general supervised fine-tuning process (Section 3.1).This teaches\n",
       "themodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\n",
       "high-quality human preference data annotation.2.Safety RLHF : Subsequently,<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** cbc408f8-1fa2-4653-81d3-7e66d1b688f2<br>**Similarity:** 0.8459963570749429<br>**Text:** 7\n",
       "3 Fine-tuning 8\n",
       "3.1 Supervised Fine-Tuning (SFT) .9\n",
       "3.2 Reinforcement Learning with Human Feedback (RLHF) .9\n",
       "3.3 System Message for Multi-Turn Consistency .16\n",
       "3.4 RLHF Results .17\n",
       "4 Safety 20\n",
       "4.1 Safety in Pretraining .20\n",
       "4.2 Safety Fine-Tuning .23\n",
       "4.3 Red Teaming .28\n",
       "4.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 2fd5840f-0c57-46c5-9ba5-ade16d3c7322<br>**Similarity:** 0.831324881683882<br>**Text:** thispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\n",
       "LLM safety.We hope that this openness will enable the community to reproduce fine-tuned LLMs and\n",
       "continue to improve the safety of those models, paving the way for more responsible development of LLMs.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 7d852fbe-3928-4ff1-9be9-8f80075d0102<br>**Similarity:** 0.8248377708758811<br>**Text:** We also ask the annotators to avoid negative user experience\n",
       "categories (see Appendix A.5.2).The guidelines are meant to be a general guide for the model and are\n",
       "iteratively refined and revised to include newly identified risks.4.2.2 Safety Supervised Fine-Tuning\n",
       "InaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\n",
       "ofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\n",
       "manner as described in Section 3.1.An example can be found in Table 5.The annotators are instructed to initially come up with prompts that they think could potentially induce\n",
       "themodel toexhibit unsafebehavior, i.e.perform redteaming, asdefined bythe guidelines.Subsequently,\n",
       "annotators are tasked with crafting a safe and helpful response that the model should produce.4.2.3 Safety RLHF\n",
       "Weobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\n",
       "insupervisedfine-tuning.Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\n",
       "explainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation.Inparticular,when\n",
       "the model outputs safe responses, they are often more detailed than what the average annotator writes.Therefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\n",
       "teachthemodelhowtowritemorenuancedresponses.ComprehensivetuningwithRLHFhastheadded\n",
       "benefit that it may make the model more robust to jailbreak attempts (Bai et al. 2022a).WeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\n",
       "writeapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\n",
       "theprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines.Wethenusethehuman\n",
       "preference data to train a safety reward model (see Section 3.2.2),<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e4dd58db-4b12-49dc-b42f-8a0ee746f5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** dec3035d-a5b6-4edd-acd1-5745499380c1<br>**Similarity:** 0.8706509346624604<br>**Text:** we describe our approach to safety fine-tuning, including safety categories, annotation\n",
       "guidelines,andthetechniquesweusetomitigatesafetyrisks.Weemployaprocesssimilartothegeneral\n",
       "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.Specifically,<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 05d93601-1b11-4892-be36-f8507d8eb600<br>**Similarity:** 0.862506098281326<br>**Text:** we use the following techniques in safety fine-tuning:\n",
       "1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\n",
       "tions that are then included in the general supervised fine-tuning process (Section 3.1).This teaches\n",
       "themodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\n",
       "high-quality human preference data annotation.2.Safety RLHF : Subsequently,<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** cbc408f8-1fa2-4653-81d3-7e66d1b688f2<br>**Similarity:** 0.8459963570749429<br>**Text:** 7\n",
       "3 Fine-tuning 8\n",
       "3.1 Supervised Fine-Tuning (SFT) .9\n",
       "3.2 Reinforcement Learning with Human Feedback (RLHF) .9\n",
       "3.3 System Message for Multi-Turn Consistency .16\n",
       "3.4 RLHF Results .17\n",
       "4 Safety 20\n",
       "4.1 Safety in Pretraining .20\n",
       "4.2 Safety Fine-Tuning .23\n",
       "4.3 Red Teaming .28\n",
       "4.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 2fd5840f-0c57-46c5-9ba5-ade16d3c7322<br>**Similarity:** 0.831324881683882<br>**Text:** thispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\n",
       "LLM safety.We hope that this openness will enable the community to reproduce fine-tuned LLMs and\n",
       "continue to improve the safety of those models, paving the way for more responsible development of LLMs.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 1f0dac7d-1b36-4a84-aa00-f172415b8460<br>**Similarity:** 0.8265816530219178<br>**Text:** We also ask the annotators to avoid negative user experience\n",
       "categories (see Appendix A.5.2).The guidelines are meant to be a general guide for the model and are\n",
       "iteratively refined and revised to include newly identified risks.4.2.2 Safety Supervised Fine-Tuning\n",
       "InaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\n",
       "ofsafemodelresponsesfromtrainedannotators,<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** eaa3d730-968c-4bd6-9521-1452ddcac01f<br>**Similarity:** 0.8230938887298445<br>**Text:** 3 Safety RLHF\n",
       "Weobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\n",
       "insupervisedfine-tuning.Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\n",
       "explainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation.Inparticular,when\n",
       "the model outputs safe responses,<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for node in base_nodes:\n",
    "    display_source_node(node, source_length=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f62e2c-4def-402e-8904-47f34d12c2fb",
   "metadata": {},
   "source": [
    "## Plug it into Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5d3ce9ec-f6cd-475b-94fa-3e8df81ab824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f106e1bb-58bc-48bf-a46b-e527339f83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "base_query_engine = RetrieverQueryEngine.from_args(base_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "94a85854-ca04-41ed-9f44-b6dce1e513e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Filling in node. Node id: 3b256786-958e-4626-9a02-ca9d00aace53> Node text: andusethedataforsupervisedfine-tuninginthesame\n",
      "manner as described in Section 3.1.An example can ...\n",
      "\n",
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 7d852fbe-3928-4ff1-9be9-8f80075d0102.\n",
      "> Parent node text: We also ask the annotators to avoid negative user experience\n",
      "categories (see Appendix A.5.2).The ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8b334b7b-fcb8-4057-a418-b8d8c425ad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key concepts for safety fine-tuning include supervised safety fine-tuning and safety RLHF (Reinforcement Learning with Human Feedback). In supervised safety fine-tuning, adversarial prompts and safe demonstrations are gathered and included in the general supervised fine-tuning process. This helps the model align with safety guidelines even before RLHF. Safety RLHF involves collecting human preference data by having annotators write prompts that they believe can elicit unsafe behavior. Multiple model responses are compared, and the safest response is selected according to a set of guidelines. This data is then used to train a safety reward model. These concepts are aimed at mitigating safety risks and improving the safety of language models.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1c38a124-5279-4a43-a2fe-ed2cbce9bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response = base_query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5c2910e5-1a45-4de5-8035-5b5a47125d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key concepts for safety fine-tuning include supervised safety fine-tuning and safety RLHF (Reinforcement Learning with Human Feedback). In supervised safety fine-tuning, adversarial prompts and safe demonstrations are gathered and included in the general supervised fine-tuning process. This helps the model align with safety guidelines even before RLHF. Safety RLHF involves observing and generalizing from safe demonstrations in supervised fine-tuning. The model learns to write detailed safe responses, address safety concerns, explain sensitive topics, and provide additional helpful information. These concepts aim to mitigate safety risks and improve the safety of language models.\n"
     ]
    }
   ],
   "source": [
    "print(str(base_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c834e3-ecd9-43cd-b661-e9380076abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autogenerate some questions \n",
    "question_gen_query = (\n",
    "    \"You are a Teacher/ Professor. Your task is to setup \"\n",
    "    \"a quiz/examination. Using the provided context from a \"\n",
    "    \"report on the new Llama 2 model, formulate \"\n",
    "    \"a single question that captures an important fact from the \"\n",
    "    \"context. Restrict the question to the context information provided.\"\n",
    ")\n",
    "dataset_generator = DatasetGenerator.from_documents(\n",
    "    docs,\n",
    "    question_gen_query=question_gen_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d786e-25b6-4cc6-a89c-5c4fdc3195a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try 8 questions\n",
    "questions = dataset_generator.generate_questions_from_nodes(num=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a8d24-8274-47df-ad1a-0a96cb9a9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "\n",
    "ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": [query_str],\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "result = evaluate(ds, [answer_relevancy, faithfulness])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
