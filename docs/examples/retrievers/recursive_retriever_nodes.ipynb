{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025f3e20-aec9-491c-8c90-234aed406a25",
   "metadata": {},
   "source": [
    "# Recursive Retriever + Node References\n",
    "\n",
    "This guide shows how you can use recursive retrieval to traverse node relationships and fetch nodes based on \"references\".\n",
    "\n",
    "Node references are a powerful concept. When you first perform retrieval, you may want to retrieve the reference as opposed to the raw text. You can have multiple references point to the same node.\n",
    "\n",
    "In this guide we explore some different usages of node references:\n",
    "- **Chunk references**: Different chunk sizes referring to a bigger chunk\n",
    "- **Metadata references**: Summaries + Generated Questions referring to a bigger chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f38de-e79a-4ce2-ad4e-2c70afc33f34",
   "metadata": {},
   "source": [
    "## Load Data + Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb829ef-b54b-4095-a832-6d1d115aa645",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd97455-5ff3-43ee-8222-f496ec234dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_hub.file.pdf.base import PDFReader\n",
    "from llama_index.response.notebook_utils import display_source_node\n",
    "from llama_index.retrievers import RecursiveRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07c0e42-1ae8-4267-9355-6bb75323f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFReader()\n",
    "docs0 = loader.load_data(file=Path(\"./data/llama2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493e5492-a6ae-4e3e-aa23-274c0605b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2abcd3-6cae-49dd-8719-9b738d000652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.schema import IndexNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b997ae-9260-4ae7-af2f-0f8d38625d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0cda44b0-fd27-4255-9aa7-08d358635772",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes = node_parser.get_nodes_from_documents(docs)\n",
    "# set node ids to be a constant\n",
    "for idx, node in enumerate(base_nodes):\n",
    "    node.id_ = f\"node-{idx}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3102d7de-d94c-428b-b2df-d37565d4f717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 : Open Foundation and Fine-Tuned Chat Models\n",
      "Hugo Touvron∗Louis Martin†Kevin Stone†\n",
      "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
      "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
      "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
      "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
      "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
      "Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
      "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
      "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
      "Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
      "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov Thomas Scialom∗\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.Our fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases.Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "ourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\n",
      "source models.We provide a detailed description of our approach to fine-tuning and safety\n",
      "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
      "contribute to the responsible development of LLMs.∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
      "†Second author\n",
      "Contributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\n",
      "\n",
      "Contents\n",
      "1 Introduction 3\n",
      "2 Pretraining 5\n",
      "2.1 Pretraining Data .............................................5\n",
      "2.2 Training Details .............................................5\n",
      "2.3 Llama 2 Pretrained Model Evaluation ................................7\n",
      "3 Fine-tuning 8\n",
      "3.1 Supervised Fine-Tuning (SFT) .....................................9\n",
      "3.2 Reinforcement Learning with Human Feedback (RLHF) .....................9\n",
      "3.3 System Message for Multi-Turn Consistency .............................16\n",
      "3.4 RLHF Results ..............................................17\n",
      "4 Safety 20\n",
      "4.1 Safety in Pretraining ..........................................20\n",
      "4.2 Safety Fine-Tuning ...........................................23\n",
      "4.3 Red Teaming ........\n"
     ]
    }
   ],
   "source": [
    "print(base_nodes[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aeacfed8-ccaf-41fb-aed6-5cca437c8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ebab2-fc46-41ea-8a92-9148994d793f",
   "metadata": {},
   "source": [
    "## Baseline Retriever\n",
    "\n",
    "Define a baseline retriever that simply fetches the top-k raw text nodes by embedding similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "704fb3da-710e-4ad9-b630-565911917f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index = VectorStoreIndex(base_nodes)\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "160c339b-601a-486b-9e17-dd6cc9f133ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievals = base_retriever.retrieve(\"Can you tell me about the key concepts for safety finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "632610f3-c8f2-440a-ab27-5ca7d65f882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-22<br>**Similarity:** 0.8320946364637798<br>**Text:** Wethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\n",
       "safetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\n",
       "provide additional information if possible.We also ask the annotators to avoid negative user experience\n",
       "categories (see Appendix A.5.2).The guidelines are meant to be a general guide for the model and are\n",
       "iteratively refined and revised to include newly identified risks.4.2.2 Safety Supervised Fine-Tuning\n",
       "InaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\n",
       "ofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\n",
       "manner as described in Section 3.1.An example can be found in Table 5.The annotators are instructed to initially come up with prompts that they think could potentially induce\n",
       "themodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines.Subsequently,\n",
       "annotators are tasked with crafting a safe and helpful response that the model should produce.4.2.3 Safety RLHF\n",
       "Weobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\n",
       "insupervisedfine-tuning.Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\n",
       "explainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation.Inparticular,when\n",
       "the model outputs safe responses, they are often more detailed than what the average annotator writes.Therefore, after gathering only a few thousan...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** node-18<br>**Similarity:** 0.7975705212073063<br>**Text:** Next,wedescribe\n",
       "theprocessofoursafetyalignment(Section4.2),explaininghowwecollectedsafety-relatedannotationsand\n",
       "utilizedSFTandRLHF,andpresentexperimentalresults.Then,wediscusstheredteamingweperformedto\n",
       "furtherunderstandandimprovemodelsafety(Section4.3).Finally,wepresentquantitativesafetyevaluations\n",
       "ofLlama 2-Chat (Section 4.4).We also share a model card in the Appendix, in Table 52.4.1 Safety in Pretraining\n",
       "It is important to understand what is in the pretraining data both to increase transparency and to shed\n",
       "lightonrootcausesofpotentialdownstreamissues,suchaspotentialbiases.Thiscaninformwhat,ifany,\n",
       "downstream mitigations to consider, and help guide appropriate model use.In this section, we analyze the\n",
       "pretraining datafor distributionsof languages,demographic representations,and toxicity.Wealso present\n",
       "the results of testing the pretrained models on existing safety benchmarks.Steps Taken to Pretrain Responsibly.We followed Meta’s standard privacy and legal review processes for\n",
       "each dataset used in training.We did not use any Meta user data in training.We excluded data from certain\n",
       "sitesknowntocontainahighvolumeofpersonalinformationaboutprivateindividuals.Wemadeabest\n",
       "effort to train our models efficiently to reduce the carbon footprint of pretraining (Section 2.2.1).Sharing our\n",
       "modelsbroadlywillreducetheneedforotherstotrainsimilarmodels.Noadditionalfilteringwasconducted\n",
       "onthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\n",
       "speechclassif...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n in retrievals:\n",
    "    display_source_node(n, source_length=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96dd8a01-1cae-4614-beab-5b5e0434fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_base = RetrieverQueryEngine.from_args(\n",
    "    base_retriever,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82ae66ff-7d12-45c8-9b1a-adb20bd3c7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key concepts for safety fine-tuning include addressing immediate safety concerns, explaining potential risks to the user, and providing additional information if possible. The guidelines for safety fine-tuning are meant to be a general guide for the model and are iteratively refined and revised to include newly identified risks. Safety fine-tuning can be done through supervised fine-tuning, where prompts and demonstrations of safe model responses are gathered from trained annotators, or through reinforcement learning from human feedback (RLHF), where human preference data is collected to train a safety reward model. The goal of safety fine-tuning is to make the model more robust to unsafe behavior and improve its safety performance without negatively impacting its helpfulness.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_base.query(\"Can you tell me about the key concepts for safety finetuning\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5431df3-d255-4492-bce4-bbebde6f2306",
   "metadata": {},
   "source": [
    "## Chunk References: Smaller Child Chunks Referring to Bigger Parent Chunk\n",
    "\n",
    "In this usage example, we show how to build a graph of smaller chunks pointing to bigger parent chunks.\n",
    "\n",
    "During query-time, we retrieve smaller chunks, but we follow references to bigger chunks. This allows us to have more context for synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "49c784d8-71e6-42bc-84d9-a2aea4217b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_chunk_sizes = [128, 256, 512]\n",
    "sub_node_parsers = [\n",
    "    SimpleNodeParser.from_defaults(chunk_size=c) for c in sub_chunk_sizes\n",
    "]\n",
    "\n",
    "all_nodes = []\n",
    "for base_node in base_nodes:\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    base_inode = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(base_inode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d614088-b122-40ad-811a-29cc0c2a295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a44ef2d5-0342-4073-831f-f35dd6f04dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_chunk = VectorStoreIndex(all_nodes, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c06af99f-02be-4055-a6ea-3071ffe8fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c7c5e43-45b5-42d6-afc5-cb81ed3cb211",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e9f7bcb-5442-4d2d-a7eb-814b68ebb45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: da1a039d-78e3-4df4-80a8-1e7e63b517e5\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id da1a039d-78e3-4df4-80a8-1e7e63b517e5: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91<br>**Similarity:** 1.0<br>**Text:** 22\n",
       "\n",
       "TruthfulQA ↑ToxiGen ↓\n",
       "MPT7B 29.13 22.32\n",
       "30B 35.25 22.61\n",
       "Falcon7B 25.95 14.53\n",
       "40B 40.39 23.44\n",
       "Llama 17B 27.42 23.00\n",
       "13B 41.74 23.08\n",
       "33B 44.19 22.57\n",
       "65B 48.71 21.77\n",
       "Llama 27B 33.29 21.25\n",
       "13B 41.86 26.10\n",
       "34B 43.45 21.19\n",
       "70B 50.18 24.60\n",
       "Table 11: Evaluation of pretrained LLMs on automatic safety benchmarks.For TruthfulQA, we present the\n",
       "percentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter).ForToxiGen,we\n",
       "present the percentage of toxic generations (the smaller, the better).Benchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\n",
       "patternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\n",
       "onpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments.Further\n",
       "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
       "in which a system may be deployed.For this, it may be necessary to test beyond the groups available in\n",
       "theBOLDdataset(race,religion,andgender).AsLLMsareintegratedanddeployed,welookforwardto\n",
       "continuing research that will amplify their potential for positive impact on these important social issues.4.2 Safety Fine-Tuning\n",
       "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
       "guidelines,andthetechniquesweusetomitigatesafetyrisks.Weemployaprocesssimilartothegeneral\n",
       "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.Specifically, we use the following techniques in safety fine-tuning:\n",
       "1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\n",
       "tions that are then included in the general supervised fine-tuning process (Section 3.1).This teaches\n",
       "themodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\n",
       "high-quality human preference data annotation.2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Se...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** da1a039d-78e3-4df4-80a8-1e7e63b517e5<br>**Similarity:** 1.0<br>**Text:** Wethendefinebestpracticesforsafeandhelpfulmodelresponses: themodelshouldfirstaddressimmediate\n",
       "safetyconcernsifapplicable,thenaddressthepromptbyexplainingthepotentialriskstotheuser,andfinally\n",
       "provide additional information if possible.We also ask the annotators to avoid negative user experience\n",
       "categories (see Appendix A.5.2).The guidelines are meant to be a general guide for the model and are\n",
       "iteratively refined and revised to include newly identified risks.4.2.2 Safety Supervised Fine-Tuning\n",
       "InaccordancewiththeestablishedguidelinesfromSection4.2.1,wegatherpromptsanddemonstrations\n",
       "ofsafemodelresponsesfromtrainedannotators,andusethedataforsupervisedfine-tuninginthesame\n",
       "manner as described in Section 3.1.An example can be found in Table 5.The annotators are instructed to initially come up with prompts that they think could potentially induce\n",
       "themodel toexhibit unsafebehavior, i.e.,perform redteaming, asdefined bythe guidelines.Subsequently,\n",
       "annotators are tasked with crafting a safe and helpful response that the model should produce.4.2.3 Safety RLHF\n",
       "Weobserveearlyinthedevelopmentof Llama 2-Chat thatitisabletogeneralizefromthesafedemonstrations\n",
       "insupervisedfine-tuning.Themodelquicklylearnstowritedetailedsaferesponses,addresssafetyconcerns,\n",
       "explainwhythetopicmightbesensitive,andprovideadditionalhelpfulinformation.Inparticular,when\n",
       "the model outputs safe responses, they are often more detailed than what the average annotator writes.Therefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\n",
       "teachthemodelhowtowritemorenuancedresponses.ComprehensivetuningwithRLHFhastheadded\n",
       "benefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).WeconductRLHFbyfirstcollectinghumanpreferencedataforsafetysimilartoSection3.2.2: annotators\n",
       "writeapromptthattheybelievecanelicitunsafebehavior,andthencomparemultiplemodelresponsesto\n",
       "theprompts,selectingtheresponsethatissafestaccordingtoasetofguidelines.Wethenusethehu...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever_chunk.retrieve(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "411f26ad-d13b-4858-938e-efcfa899e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_chunk = RetrieverQueryEngine.from_args(\n",
    "    retriever_chunk,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd98366-0d5f-4d04-87cd-b811990b7485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: da1a039d-78e3-4df4-80a8-1e7e63b517e5\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id da1a039d-78e3-4df4-80a8-1e7e63b517e5: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0mThe key concepts for safety fine-tuning include supervised safety fine-tuning, safety RLHF (Reinforcement Learning from Human Feedback), and safety context distillation. In supervised safety fine-tuning, adversarial prompts and safe demonstrations are gathered and included in the fine-tuning process to align the model with safety guidelines. Safety RLHF involves training a safety-specific reward model and gathering challenging adversarial prompts to optimize the model's safety through rejection sampling and PPO (Proximal Policy Optimization) optimization. Safety context distillation refines the RLHF pipeline by generating safer model responses using a safety preprompt and fine-tuning the model on these safer responses. These techniques aim to mitigate safety risks and improve the model's alignment with safety guidelines.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_chunk.query(\"Can you tell me about the key concepts for safety finetuning\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc7379-c077-40b7-ba4e-f47f80def0c7",
   "metadata": {},
   "source": [
    "## Metadata References: Summaries + Generated Questions referring to a bigger chunk\n",
    "\n",
    "In this usage example, we show how to define additional context that references the source node.\n",
    "\n",
    "This additional context includes summaries as well as generated questions.\n",
    "\n",
    "During query-time, we retrieve smaller chunks, but we follow references to bigger chunks. This allows us to have more context for synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24e40c5e-4868-487f-aaf4-f333aa4bda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.schema import IndexNode\n",
    "from llama_index.node_parser.extractors import (\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    MetadataExtractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c5d6f87-790e-4b82-abb2-cc6944678b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_extractor = MetadataExtractor(\n",
    "    extractors=[\n",
    "        SummaryExtractor(summaries=[\"self\"], show_progress=True),\n",
    "        QuestionsAnsweredExtractor(questions=5, show_progress=True)\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c706c-940e-499d-b742-eaf09a230b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run metadata extractor across base nodes, get back dictionaries\n",
    "metadata_dicts = metadata_extractor.extract(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2873327d-420a-4778-a83b-6fdf7aa21bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache metadata dicts\n",
    "def save_metadata_dicts(path):\n",
    "    with open(path, \"w\") as fp:\n",
    "        for m in metadata_dicts:\n",
    "            fp.write(json.dumps(m) + \"\\n\")\n",
    "\n",
    "\n",
    "def load_metadata_dicts(path):\n",
    "    with open(path, \"r\") as fp:\n",
    "        metadata_dicts = [json.loads(l) for l in fp.readlines()]\n",
    "        return metadata_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e318efb2-9afa-4414-b37f-71738d73d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metadata_dicts(\"data/llama2_metadata_dicts.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4edce99f-8a96-4539-95e7-62aeeabb2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dicts = load_metadata_dicts(\"data/llama2_metadata_dicts.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f18d2109-5fcb-4fd5-b147-23897fed8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all nodes consists of source nodes, along with metadata \n",
    "all_nodes = base_nodes\n",
    "for idx, d in enumerate(metadata_dicts):\n",
    "    inode_q = IndexNode(text=d[\"questions_this_excerpt_can_answer\"], index_id=base_nodes[idx].node_id)\n",
    "    inode_s = IndexNode(text=d[\"section_summary\"], index_id=base_nodes[idx].node_id)\n",
    "    all_nodes.extend([inode_q, inode_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f90ada6-0969-40cc-a4ec-3579b4900cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22abc768-83d5-41d0-84f0-533899c76894",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load index into vector index\n",
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "\n",
    "vector_index_metadata = VectorStoreIndex(all_nodes, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d53938a-1322-41b1-ad11-169b13b9805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_metadata = vector_index_metadata.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37ae791f-c183-4ad4-9a3a-253288ded5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_metadata = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_metadata},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cd85685-19eb-44cc-ad27-1d163eaddad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: fac454e2-85e7-4fbe-92d3-8378cf7d91c4\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id fac454e2-85e7-4fbe-92d3-8378cf7d91c4: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91<br>**Similarity:** 1.0<br>**Text:** 22\n",
       "\n",
       "TruthfulQA ↑ToxiGen ↓\n",
       "MPT7B 29.13 22.32\n",
       "30B 35.25 22.61\n",
       "Falcon7B 25.95 14.53\n",
       "40B 40.39 23.44\n",
       "Llama 17B 27.42 23.00\n",
       "13B 41.74 23.08\n",
       "33B 44.19 22.57\n",
       "65B 48.71 21.77\n",
       "Llama 27B 33.29 21.25\n",
       "13B 41.86 26.10\n",
       "34B 43.45 21.19\n",
       "70B 50.18 24.60\n",
       "Table 11: Evaluation of pretrained LLMs on automatic safety benchmarks.For TruthfulQA, we present the\n",
       "percentageofgenerationsthatarebothtruthfulandinformative(thehigherthebetter).ForToxiGen,we\n",
       "present the percentage of toxic generations (the smaller, the better).Benchmarks give a summary view ofmodel capabilities and behaviors that allow us to understand general\n",
       "patternsinthemodel,buttheydonotprovideafullycomprehensiveviewoftheimpactthemodelmayhave\n",
       "onpeopleorreal-worldoutcomes;thatwouldrequirestudyofend-to-endproductdeployments.Further\n",
       "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
       "in which a system may be deployed.For this, it may be necessary to test beyond the groups available in\n",
       "theBOLDdataset(race,religion,andgender).AsLLMsareintegratedanddeployed,welookforwardto\n",
       "continuing research that will amplify their potential for positive impact on these important social issues.4.2 Safety Fine-Tuning\n",
       "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
       "guidelines,andthetechniquesweusetomitigatesafetyrisks.Weemployaprocesssimilartothegeneral\n",
       "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.Specifically, we use the following techniques in safety fine-tuning:\n",
       "1.Supervised Safety Fine-Tuning : We initialize by gathering adversarial prompts and safe demonstra-\n",
       "tions that are then included in the general supervised fine-tuning process (Section 3.1).This teaches\n",
       "themodeltoalignwithoursafetyguidelinesevenbeforeRLHF,andthuslaysthefoundationfor\n",
       "high-quality human preference data annotation.2.Safety RLHF : Subsequently, we integrate safety in the general RLHF pipeline described in Se...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** fac454e2-85e7-4fbe-92d3-8378cf7d91c4<br>**Similarity:** 1.0<br>**Text:** In each case, we took the overall lessons as a guide\n",
       "to helpfurther modelsafetytraining, and specificallytook data fromthese exercisesformodel fine-tuning,\n",
       "model feedback training, and as a signal for other safety model training.Multiple additionalrounds ofred teaming wereperformed over severalmonths tomeasure the robustness\n",
       "of each new model as it was released internally.We defined the robustness of a model, γ, with respect to\n",
       "a red teaming exercise executed by a set of experts as the average number of created prompts that would\n",
       "triggeraviolatingresponsefromthemodelperpersonperhour.Asanexample,onour7Bmodel,wehadan\n",
       "evolution of γ: 1.8→0.45over several red teaming iterations and model refinements.Robustness will likely\n",
       "continue to improve with additional red teaming efforts.Another magnitude that we tracked as new models\n",
       "were produced was the percentage of prompts triggering violating responses discovered in the previous red\n",
       "teaming exercises that were mitigated in a given new candidate release.On average, we had a 90% rejection\n",
       "rate model over model.4.4 Safety Evaluation of Llama 2-Chat\n",
       "SafetyHumanEvaluation.Wecollectedroughly2,000adversarialpromptsforhumanevaluationaccording\n",
       "to the safety categories in Section 4.2.1, in which 1,351 prompts are single-turn and 623 are multi-turn.Examples of evaluation prompts and responses can be found in Appendix A.4.6.We then asked raters to judge models for safety violations on a five-point Likert scale with the following\n",
       "definitions:\n",
       "•5- No safety violations and very helpful\n",
       "•4- No safety violations and only minor non-safety issues\n",
       "•3- No safety violations but not helpful or other major non-safety issues\n",
       "•2- Mild or moderate safety violations\n",
       "29\n",
       "\n",
       "(a)Overall violation percentage.(b)Overall safety and helpfulness mean rating.Figure17: Overallsafetymeasures.Left: Llama 2-Chat haslowviolationpercentageoverallacrossmodel\n",
       "sizes.Right: Llama 2-Chat has high safety and helpfulness mean rating overall across model sizes.It is\n",
       "importan...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever_metadata.retrieve(\n",
    "    \"Can you tell me about the key concepts for safety finetuning\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5285854a-69a6-4bc4-a2a5-1004cc790a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_metadata = RetrieverQueryEngine.from_args(\n",
    "    retriever_metadata,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e0ada5c-9a83-4517-bbb7-899d4415d68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mRetrieving with query id None: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id 70a1c9f7-8cbc-41bf-9203-6e3ea8ef4a91: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: fac454e2-85e7-4fbe-92d3-8378cf7d91c4\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id fac454e2-85e7-4fbe-92d3-8378cf7d91c4: Can you tell me about the key concepts for safety finetuning\n",
      "\u001b[0mThe key concepts for safety fine-tuning include supervised safety fine-tuning, safety RLHF (Reinforcement Learning from Human Feedback), safety context distillation, safety categories, and annotation guidelines. Supervised safety fine-tuning involves gathering adversarial prompts and safe demonstrations to align the model with safety guidelines. Safety RLHF integrates safety into the RLHF pipeline by training a safety-specific reward model and gathering challenging adversarial prompts. Safety context distillation refines the RLHF pipeline by generating safer model responses through prefixing prompts with a safety preprompt. The safety categories considered are illicit and criminal activities, hateful and harmful activities, and unqualified advice. The annotation guidelines help create adversarial prompts along the dimensions of risk categories and attack vectors.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_metadata.query(\"Can you tell me about the key concepts for safety finetuning\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973bdca-d179-47d6-bd96-2631b36e1d94",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We evalate how well our recursive retrieval + node reference methods work. We evaluate both chunk references as well as metadata references. We use embedding similarity lookup to retrieve the reference nodes.\n",
    "\n",
    "We compare both methods against a baseline retriever where we fetch the raw nodes directly.\n",
    "\n",
    "In terms of metrics, we evaluate using both hit-rate and MRR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a30b7-2eb2-4eae-b0b9-1d4ec26ac915",
   "metadata": {},
   "source": [
    "### Dataset Generation\n",
    "\n",
    "We first generate a dataset of questions from the set of text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fe8ae8a-a2b2-4515-bcff-1145e14ede3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import (\n",
    "    generate_qa_embedding_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eef1b43d-996b-4b0a-becb-1cec08d9f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 231/231 [18:52<00:00,  4.90s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = generate_qa_embedding_pairs(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd3e2507-9157-48a5-909b-18eeb9ec01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.save_json(\"data/llama2_questions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "611f07af-2006-4158-8dc6-59d11a269c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "eval_dataset = EmbeddingQAFinetuneDataset.from_json(\"data/llama2_questions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31ac1eb4-6bec-49ab-be7e-695e435fdcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generalize into eval functions\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(\n",
    "    dataset,\n",
    "    retriever,\n",
    "    verbose=False,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        \n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_id = relevant_docs[query_id][0]\n",
    "\n",
    "        for tmp in retrieved_nodes:\n",
    "            print(f\"NODE: {tmp.node.node_id}\")\n",
    "            print(tmp.node.get_content())\n",
    "\n",
    "        print(f'EXPECTED NODE: {expected_id}')\n",
    "        print(corpus[expected_id])\n",
    "        raise Exception\n",
    "\n",
    "        rank = None\n",
    "        for idx, id in enumerate(retrieved_ids):\n",
    "            if id == expected_id:\n",
    "                rank = idx + 1\n",
    "                break\n",
    "        \n",
    "        is_hit = rank is not None  # assume 1 relevant doc\n",
    "        mrr = 0 if rank is None else 1/rank\n",
    "\n",
    "        eval_result = {\n",
    "            \"is_hit\": is_hit,\n",
    "            \"mrr\": mrr,\n",
    "            \"retrieved\": retrieved_ids,\n",
    "            \"expected\": expected_id,\n",
    "            \"query\": query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "\n",
    "        # TMP\n",
    "        break\n",
    "\n",
    "\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4782a6-f3da-453f-93be-7683ed15b508",
   "metadata": {},
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87798866-11bc-4f7f-b8aa-0a023309492f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set vector retriever similarity top k to higher\n",
    "top_k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6d142c6-0374-43ec-af31-e02d246bd815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/507 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mRetrieving with query id None: What are the key contributions of the Llama 2 project in the field of large language models (LLMs)?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/507 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: 99e47b53-2b09-4074-bc5f-139f2f7d1f32\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id 99e47b53-2b09-4074-bc5f-139f2f7d1f32: What are the key contributions of the Llama 2 project in the field of large language models (LLMs)?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: b4a06d94-5c60-49fe-a151-86b38ad284b8\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id b4a06d94-5c60-49fe-a151-86b38ad284b8: What are the key contributions of the Llama 2 project in the field of large language models (LLMs)?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mRetrieved node with id, entering: 672479a2-6821-42c6-9bfa-daf4d251f9d7\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mRetrieving with query id 672479a2-6821-42c6-9bfa-daf4d251f9d7: What are the key contributions of the Llama 2 project in the field of large language models (LLMs)?\n",
      "\u001b[0mNODE: 99e47b53-2b09-4074-bc5f-139f2f7d1f32\n",
      "Llama 2 : Open Foundation and Fine-Tuned Chat Models\n",
      "Hugo Touvron∗Louis Martin†Kevin Stone†\n",
      "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
      "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
      "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
      "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
      "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
      "Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
      "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
      "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
      "Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
      "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov Thomas Scialom∗\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.Our fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases.Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "ourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\n",
      "source models.We provide a detailed description of our approach to fine-tuning and safety\n",
      "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
      "contribute to the responsible development of LLMs.∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
      "†Second author\n",
      "Contributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\n",
      "\n",
      "Contents\n",
      "1 Introduction 3\n",
      "2 Pretraining 5\n",
      "2.1 Pretraining Data .............................................5\n",
      "2.2 Training Details .............................................5\n",
      "2.3 Llama 2 Pretrained Model Evaluation ................................7\n",
      "3 Fine-tuning 8\n",
      "3.1 Supervised Fine-Tuning (SFT) .....................................9\n",
      "3.2 Reinforcement Learning with Human Feedback (RLHF) .....................9\n",
      "3.3 System Message for Multi-Turn Consistency .............................16\n",
      "3.4 RLHF Results ..............................................17\n",
      "4 Safety 20\n",
      "4.1 Safety in Pretraining ..........................................20\n",
      "4.2 Safety Fine-Tuning ...........................................23\n",
      "4.3 Red Teaming ........\n",
      "NODE: b4a06d94-5c60-49fe-a151-86b38ad284b8\n",
      "7 Conclusion\n",
      "Inthisstudy,wehaveintroduced Llama 2,anewfamilyofpretrainedandfine-tunedmodelswithscales\n",
      "of7billionto70billionparameters.Thesemodelshavedemonstratedtheircompetitivenesswithexisting\n",
      "open-source chat models, as well as competency that is equivalent to some proprietary models on evaluation\n",
      "setsweexamined,althoughtheystilllagbehindothermodelslikeGPT-4.Wemeticulouslyelaboratedonthe\n",
      "methodsandtechniquesappliedinachievingourmodels,withaheavyemphasisontheiralignmentwiththe\n",
      "principlesofhelpfulnessandsafety.Tocontributemoresignificantlytosocietyandfosterthepaceofresearch,\n",
      "wehaveresponsiblyopenedaccessto Llama 2 andLlama 2-Chat .Aspartofourongoingcommitmentto\n",
      "transparency and safety, we plan to make further improvements to Llama 2-Chat in future work.36\n",
      "\n",
      "References\n",
      "Daron Acemoglu and Pascual Restrepo.Artificial intelligence, automation, and work.In The economics of\n",
      "artificial intelligence: An agenda , pages 197–236.University of Chicago Press, 2018.Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai.Gqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023.Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru,\n",
      "Merouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune,\n",
      "Baptiste Pannier, and Guilherme Penedo.Falcon-40B: an open large language model with state-of-the-art\n",
      "performance.2023.\n",
      "NODE: 672479a2-6821-42c6-9bfa-daf4d251f9d7\n",
      "Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\n",
      "followed by alignment with human preferences via techniques such as Reinforcement Learning with Human\n",
      "Feedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\n",
      "limited the development of LLMs to a few players.There have been public releases of pretrained LLMs\n",
      "(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\n",
      "match the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\n",
      "(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed “product” LLMs, such\n",
      "asChatGPT,BARD,andClaude.TheseclosedproductLLMsareheavilyfine-tunedtoalignwithhuman\n",
      "preferences, which greatly enhances their usability and safety.This step can require significant costs in\n",
      "computeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\n",
      "the community to advance AI alignment research.In this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\n",
      "Llama 2-Chat , at scales up to 70B parameters.On the series of helpfulness and safety benchmarks we tested,\n",
      "Llama 2-Chat models generally perform better than existing open-source models.They also appear to\n",
      "be on par with some of the closed-source models, at least on the human evaluations we performed (see\n",
      "Figures1and3).Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-specificdata\n",
      "annotation and tuning, as well as conducting red-teaming and employing iterative evaluations.Additionally,\n",
      "thispapercontributesathoroughdescriptionofourfine-tuningmethodologyandapproachtoimproving\n",
      "LLM safety.We hope that this openness will enable the community to reproduce fine-tuned LLMs and\n",
      "continue to improve the safety of those models, paving the way for more responsible development of LLMs.Wealsosharenovelobservationswemadeduringthedevelopmentof Llama 2 andLlama 2-Chat ,suchas\n",
      "the emergence of tool usage and temporal organization of knowledge.3\n",
      "\n",
      "Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\n",
      "source models.Human raters judged model generations for safety violations across ~2,000 adversarial\n",
      "prompts consisting of both single and multi-turn prompts.More details can be found in Section 4.4.It is\n",
      "importanttocaveatthesesafetyresultswiththeinherentbiasofLLMevaluationsduetolimitationsofthe\n",
      "promptset,subjectivityofthereviewguidelines,andsubjectivityofindividualraters.Additionally,these\n",
      "safety evaluations are performed using content standards that are likely to be biased towards the Llama\n",
      "2-Chatmodels.We are releasing the following models to the general public for research and commercial use‡:\n",
      "1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata.Wealso\n",
      "increasedthesizeofthepretrainingcorpusby40%,doubledthecontextlengthofthemodel,and\n",
      "adoptedgrouped-queryattention(Ainslieetal.,2023).Wearereleasingvariantsof Llama 2 with\n",
      "7B,13B,and70Bparameters.Wehavealsotrained34Bvariants,whichwereportoninthispaper\n",
      "but are not releasing.§\n",
      "2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases.We release\n",
      "variants of this model with 7B, 13B, and 70B parameters as well.WebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety.LikeallLLMs,\n",
      "Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\n",
      "Solaimanet al.,2023).Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\n",
      "all scenarios.Therefore, before deploying any applications of Llama 2-Chat , developers should perform\n",
      "safetytestingand tuningtailoredtotheirspecificapplicationsofthemodel.\n",
      "EXPECTED NODE: 99576cc4-20a8-4785-bac7-927b08916aca\n",
      "Llama 2 : Open Foundation and Fine-Tuned Chat Models\n",
      "Hugo Touvron∗Louis Martin†Kevin Stone†\n",
      "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
      "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
      "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
      "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
      "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
      "Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
      "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
      "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
      "Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
      "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov Thomas Scialom∗\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.Our fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases.Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "ourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\n",
      "source models.We provide a detailed description of our approach to fine-tuning and safety\n",
      "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
      "contribute to the responsible development of LLMs.∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
      "†Second author\n",
      "Contributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\n",
      "\n",
      "Contents\n",
      "1 Introduction 3\n",
      "2 Pretraining 5\n",
      "2.1 Pretraining Data .............................................5\n",
      "2.2 Training Details .............................................5\n",
      "2.3 Llama 2 Pretrained Model Evaluation ................................7\n",
      "3 Fine-tuning 8\n",
      "3.1 Supervised Fine-Tuning (SFT) .....................................9\n",
      "3.2 Reinforcement Learning with Human Feedback (RLHF) .....................9\n",
      "3.3 System Message for Multi-Turn Consistency .............................16\n",
      "3.4 RLHF Results ..............................................17\n",
      "4 Safety 20\n",
      "4.1 Safety in Pretraining ..........................................20\n",
      "4.2 Safety Fine-Tuning ...........................................23\n",
      "4.3 Red Teaming ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m vector_retriever_chunk \u001b[38;5;241m=\u001b[39m vector_index_chunk\u001b[38;5;241m.\u001b[39mas_retriever(similarity_top_k\u001b[38;5;241m=\u001b[39mtop_k)\n\u001b[1;32m      2\u001b[0m retriever_chunk \u001b[38;5;241m=\u001b[39m RecursiveRetriever(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     retriever_dict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m\"\u001b[39m: vector_retriever_chunk},\n\u001b[1;32m      5\u001b[0m     node_dict\u001b[38;5;241m=\u001b[39mall_nodes_dict,\n\u001b[1;32m      6\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m )   \n\u001b[0;32m----> 8\u001b[0m results_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever_chunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 26\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, retriever, verbose)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEXPECTED NODE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(corpus[expected_id])\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m\n\u001b[1;32m     28\u001b[0m rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(retrieved_ids):\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=top_k)\n",
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")   \n",
    "results_chunk = evaluate(eval_dataset, retriever_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3245ab44-4ee7-4621-af1d-0029f2f2df73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'is_hit': False, 'mrr': 0, 'retrieved': ['99e47b53-2b09-4074-bc5f-139f2f7d1f32', 'b4a06d94-5c60-49fe-a151-86b38ad284b8', '672479a2-6821-42c6-9bfa-daf4d251f9d7'], 'expected': '99576cc4-20a8-4785-bac7-927b08916aca', 'query': 'acc2dc60-0789-4870-943a-bcc36ff81fdd'}]\n"
     ]
    }
   ],
   "source": [
    "print(results_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "34ccbc0e-8230-4772-b3cb-fb7d94035237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_chunk_df = pd.DataFrame(results_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61923bd2-7234-411d-9968-ff75c99367d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_chunk = results_chunk_df[\"is_hit\"].mean()\n",
    "hit_rate_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae448fe7-3a66-45a6-8e8e-6ed3950e61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_metadata = vector_index_chunk.as_retriever(similarity_top_k=top_k)\n",
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_metadata},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")  \n",
    "\n",
    "evaluate(eval_dataset, retriever_metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
