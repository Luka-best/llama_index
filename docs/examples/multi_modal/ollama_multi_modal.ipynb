{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e3af8d-a850-49bd-9b0b-707b29ee320e",
   "metadata": {},
   "source": [
    "# Multimodal Ollama\n",
    "\n",
    "This notebook shows you how to use our Ollama multimodal integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8d5f34-7131-4470-879f-480c60f55250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.multi_modal_llms import OllamaMultiModal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac7cff1-f4ce-4b1e-b5f1-8b62fc2e4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_model = OllamaMultiModal(model=\"llava\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427443b3-0c26-4e52-ab5d-82e63839428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.multi_modal_llms.generic_utils import load_image_urls\n",
    "\n",
    "image_urls = [\n",
    "    # \"https://www.visualcapitalist.com/wp-content/uploads/2023/10/US_Mortgage_Rate_Surge-Sept-11-1.jpg\",\n",
    "    # \"https://www.sportsnet.ca/wp-content/uploads/2023/11/CP1688996471-1040x572.jpg\",\n",
    "    \"https://res.cloudinary.com/hello-tickets/image/upload/c_limit,f_auto,q_auto,w_1920/v1640835927/o3pfl41q7m5bj8jardk0.jpg\",\n",
    "    # \"https://www.cleverfiles.com/howto/wp-content/uploads/2018/03/minion.jpg\",\n",
    "]\n",
    "\n",
    "image_documents = load_image_urls(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ebffbe-be55-48fc-9cc9-305654c9e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_response = mm_model.complete(\n",
    "    prompt=\"Tell me more about this image\",\n",
    "    image_documents=image_documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509de1e2-319d-4f30-81ce-212a9a9025e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image appears to be of a person holding what looks like an object in their hand. It's not clear what the object is, but it could be a piece of paper or a small electronic device. The person is facing away from the camera, so we don't have any information about their appearance. There are no visible texts or distinctive markings on the object that would provide further context. If you have more information about this image or if there's something specific you'd like to know, please let me know and I can try to help you with that! \n"
     ]
    }
   ],
   "source": [
    "print(str(complete_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483b3222-11ee-4ab1-9e3c-f223e55aa7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image you've provided appears to be a photograph of a person sitting on a surface with a bright light source in front of them, creating a strong backlight. The subject is wearing what looks like a black top and their face is partially obscured by the lighting conditions, which might suggest they are wearing sunglasses or looking away from the camera.\n",
      "\n",
      "The lighting setup gives a sense of dramatic effect to the image, with the bright light source causing the surrounding area to be in shadow. This type of lighting can create interesting contrasts and textures in photography, often used to emphasize certain elements of an image or to give it a particular mood or atmosphere.\n",
      "\n",
      "Without more context or information about the photograph, it's difficult to provide further details about the setting, the subject, or the intention behind the shot. "
     ]
    }
   ],
   "source": [
    "response_gen = mm_model.stream_complete(\n",
    "    prompt=\"Tell me more about this image\",\n",
    "    image_documents=image_documents,\n",
    ")\n",
    "for r in response_gen:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3203ce-4a43-44e2-b70b-17df390d9dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama: [{'role': 'user', 'content': 'Tell me more about this image', 'images': [<_io.BytesIO object at 0x2914b1b20>]}]\n",
      "{'model': 'llava', 'created_at': '2024-02-03T18:42:05.9808Z', 'message': {'role': 'assistant', 'content': ' This image shows a pair of legs wearing black pants and white socks. The person is also wearing shoes, but the type or brand is not clearly visible. The background appears to be a simple, neutral setting that does not provide any additional context or information about the location or activity taking place. There are no texts or distinct objects in the image that provide more details. The photo seems to have been taken casually, possibly for personal use or as part of an informal photoshoot session. '}, 'done': True, 'total_duration': 3326739583, 'prompt_eval_count': 14, 'prompt_eval_duration': 492488000, 'eval_count': 100, 'eval_duration': 2818813000}\n"
     ]
    }
   ],
   "source": [
    "# chat\n",
    "from llama_index.llms import ChatMessage, MessageRole\n",
    "\n",
    "\n",
    "image_bytes_io = [d.resolve_image() for d in image_documents]\n",
    "\n",
    "chat_response = mm_model.chat([\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=\"Tell me more about this image\",\n",
    "        additional_kwargs={\"images\": image_bytes_io}\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1839bc6-3b02-4ff3-a0c4-dad3e7f995a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant:  This image shows a pair of legs wearing black pants and white socks. The person is also wearing shoes, but the type or brand is not clearly visible. The background appears to be a simple, neutral setting that does not provide any additional context or information about the location or activity taking place. There are no texts or distinct objects in the image that provide more details. The photo seems to have been taken casually, possibly for personal use or as part of an informal photoshoot session. \n"
     ]
    }
   ],
   "source": [
    "print(str(chat_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977f1d6a-bde2-41be-8229-684f21f44014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is an image of a person standing and looking to the side. The individual appears to be wearing casual clothing, including what seems to be a t-shirt or a similar top. Due to the angle and composition of the photo, it's difficult to provide more specific details about the person's appearance or surroundings. "
     ]
    }
   ],
   "source": [
    "# stream chat\n",
    "from llama_index.llms import ChatMessage, MessageRole\n",
    "\n",
    "\n",
    "image_bytes_io = [d.resolve_image() for d in image_documents]\n",
    "\n",
    "chat_gen = mm_model.stream_chat([\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=\"Tell me more about this image\",\n",
    "        additional_kwargs={\"images\": image_bytes_io}\n",
    "    )\n",
    "])\n",
    "for r in chat_gen:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77780433-131e-462d-b560-ce35ad654379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
