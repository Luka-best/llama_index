{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "917b5345-2958-444f-a81f-6c3ae328912e",
   "metadata": {},
   "source": [
    "# Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge\n",
    "\n",
    "There has been recent research that demonstrated GPT-4's ability to closely align to human judges when evaluating LLM generated texts (e.g., see [[1]](https://arxiv.org/abs/2306.05685), [[2]](https://arxiv.org/abs/2303.16634)). In this notebook, we demonstrate how to use the `llama_index` library to distill knowledge from GPT-4 to GPT-3.5 so that the smaller GPT-3.5 becomes closer to GPT-4 performance; and by proxy, closer to human judges.\n",
    "\n",
    "To do so, we take the following steps:\n",
    "\n",
    "1. Generate datasets: `train` and `test`\n",
    "2. Perform knowledge distillation (using `train`)\n",
    "3. Evaluate the distilled model  on `test`\n",
    "\n",
    "More specifically, we will use `CorrectnessEvaluator` as our LLM Judge in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2263c-dd38-45f6-8f00-9955b93d51ea",
   "metadata": {},
   "source": [
    "```\n",
    "IMO the easiest evaluator to fine-tune for is probably the correctness metric. generate \"ground-truth dataset\" of question + ground-truth context -> ground-truth answer, and then use GPT-4 as the correctness evaluator to compare predicted answer from RAG vs. ground-truth answer, and fine-tune to 3.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8deb07-ed32-4284-b943-e63867e26288",
   "metadata": {},
   "source": [
    "## 0 Prompt Templates & Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f7df9-a048-43aa-b862-290e832ea631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HUGGING_FACE_TOKEN = os.getenv(\"HUGGING_FACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99afd212-38b0-492c-91ea-a810e126ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "    \"QUESTION_GEN\": (\n",
    "        \"You are a Teacher/ Professor. Your task is to setup \"\n",
    "        \"a quiz/examination. Using the provided context, formulate \"\n",
    "        \"a single question that captures an important fact from the \"\n",
    "        \"context. Restrict the question to the context information provided.\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7031c-9da8-4116-969a-b1180a0fc118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# define jupyter display function\n",
    "def display_eval_df(question, source, answer_a, answer_b, result) -> None:\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Question\": question,\n",
    "            \"Source\": source,\n",
    "            \"Model A\": answer_a[\"model\"],\n",
    "            \"Answer A\": answer_a[\"text\"],\n",
    "            \"Model B\": answer_b[\"model\"],\n",
    "            \"Answer B\": answer_b[\"text\"],\n",
    "            \"Score\": result.score,\n",
    "            \"Judgement\": result.feedback,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"300px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Answer A\", \"Answer B\"]\n",
    "    )\n",
    "    display(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89edf1-b359-4370-8b1e-fad279508c68",
   "metadata": {},
   "source": [
    "## 1 Generate datasets: `train` and `test`\n",
    "\n",
    "As mentioned before the LLM Judge we will be using is the `CorrectnessEvaluator`. What this means then is that we'll need to generate some ground-truth data from which our Judge can assert whether or not the provided response is indeed correct.\n",
    "\n",
    "So, the LLM Judge will get a `<query, generated-answer, ground-truth-answer>`, and it will output a correctness score between 0 and 1 (higher is better).\n",
    "\n",
    "We will handle getting `<query, ground-truth-answer>` separately from `<generated-answer>`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e884e6-70af-426b-be62-d064f497d0c6",
   "metadata": {},
   "source": [
    "### Generate `<query, ground-truth-answer>`\n",
    "\n",
    "We're going to turn a set of Wikipedia pages into `Documents` and define a `DatasetGenerator` on top of them to generate our `queries` and `ground-truth-answers`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebbecc4-543d-41d8-ae96-5f729e7e8a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff858baa-5ae1-4dda-8407-6d23237b6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia pages\n",
    "from llama_index.readers import WikipediaReader\n",
    "\n",
    "cities = [\n",
    "    \"San Francisco\",\n",
    "    \"Toronto\",\n",
    "    \"New York\",\n",
    "    \"Vancouver\",\n",
    "    \"Montreal\",\n",
    "]\n",
    "\n",
    "documents = WikipediaReader().load_data(\n",
    "    pages=[f\"History of {x}\" for x in cities]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667f6ed-145b-41f3-92d2-be36aa1e47e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate questions against chunks\n",
    "from llama_index.evaluation import DatasetGenerator\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "# set context for llm provider\n",
    "gpt_35_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
    ")\n",
    "\n",
    "# instantiate a DatasetGenerator\n",
    "dataset_generator = DatasetGenerator.from_documents(\n",
    "    documents,\n",
    "    question_gen_query=PROMPTS[\"QUESTION_GEN\"],\n",
    "    service_context=gpt_35_context,\n",
    "    show_progress=True,\n",
    "    num_questions_per_chunk=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f8b72-3337-4a2a-929c-87083bbf7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce06f6-1e85-4694-a4ac-9b4d465ed9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 59/59 [00:02<00:00, 26.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.00s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.03s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.86s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.40s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.85s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "qrd = dataset_generator.generate_dataset_from_nodes(num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e2f82-29b7-41cc-8f23-ae254f873031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for future\n",
    "qrd.save_json(\"qrd.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3081043-629c-45ac-8d8f-193281f9f47e",
   "metadata": {},
   "source": [
    "### Create `generated-answers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f08da0-27c0-4805-8c99-fad7041b3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.indices.vector_store.retrievers import VectorIndexRetriever\n",
    "\n",
    "# Create vector index\n",
    "the_index = VectorStoreIndex.from_documents(documents=documents)\n",
    "\n",
    "# Create the retriver on this index\n",
    "the_retriever = VectorIndexRetriever(\n",
    "    index=the_index,\n",
    "    similarity_top_k=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d6f7f-7067-48a8-ae8f-5619dc18d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine.retriever_query_engine import (\n",
    "    RetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.llms import HuggingFaceInferenceAPI\n",
    "from llama_index.llm_predictor import LLMPredictor\n",
    "\n",
    "llm = HuggingFaceInferenceAPI(\n",
    "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    context_window=2048,  # to use refine\n",
    "    token=HUGGING_FACE_TOKEN,\n",
    ")\n",
    "context = ServiceContext.from_defaults(llm_predictor=LLMPredictor(llm=llm))\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=the_retriever, service_context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb345deb-d34e-4b48-9f72-ef108ad3afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:13<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "dataset = []\n",
    "num_train_questions = int(0.65 * len(qrd.qr_pairs))\n",
    "for q, a in tqdm.tqdm(qrd.qr_pairs[:num_train_questions]):\n",
    "    # data for this q\n",
    "    data_entry = {\"question\": q, \"reference\": a}\n",
    "    response = query_engine.query(q)\n",
    "    response_struct = {}\n",
    "    response_struct[\"model\"] = \"llama-2\"\n",
    "    response_struct[\"text\"] = str(response)\n",
    "    response_struct[\"context\"] = (\n",
    "        response.source_nodes[0].node.text[:1000] + \"...\"\n",
    "    )\n",
    "\n",
    "    data_entry[\"response_data\"] = response_struct\n",
    "    dataset.append(data_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf90efb-a6e8-4766-9cad-5f4289692790",
   "metadata": {},
   "source": [
    "### Generate Answers From GPT-4 Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8bbcf-6bc6-4a6c-a778-d43c6896fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the gpt-4 judge\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.callbacks import OpenAIFineTuningHandler\n",
    "from llama_index.callbacks import CallbackManager\n",
    "from llama_index.evaluation import CorrectnessEvaluator\n",
    "\n",
    "# NOTE: this finetuning_handler will collect 2x chat_histories for\n",
    "# each query: one for original, and another for flipped\n",
    "finetuning_handler = OpenAIFineTuningHandler()\n",
    "callback_manager = CallbackManager([finetuning_handler])\n",
    "gpt_4_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    callback_manager=callback_manager,\n",
    ")\n",
    "\n",
    "gpt4_judge = CorrectnessEvaluator(service_context=gpt_4_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225358e-e898-4f32-a99b-47a67941f715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [04:11<00:00,  6.62s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# for `training`\n",
    "for data_entry in tqdm.tqdm(dataset):\n",
    "    eval_result = await gpt4_judge.aevaluate(\n",
    "        query=data_entry[\"question\"],\n",
    "        response=data_entry[\"response_data\"][\"text\"],\n",
    "        context=data_entry[\"response_data\"][\"context\"],\n",
    "        reference=data_entry[\"reference\"],\n",
    "    )\n",
    "\n",
    "    # save final result\n",
    "    judgement = {}\n",
    "    judgement[\"llm\"] = \"gpt_4\"\n",
    "    judgement[\"score\"] = eval_result.score\n",
    "    judgement[\"text\"] = eval_result.response\n",
    "    data_entry[\"evaluations\"] = [judgement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ed14f-2209-4fbb-86cf-2fa69aa1fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 38 examples to correction_finetuning_events.jsonl\n"
     ]
    }
   ],
   "source": [
    "finetuning_handler.save_finetuning_events(\"correction_finetuning_events.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0437508-aa43-478b-81a4-6aeecbf6d19c",
   "metadata": {},
   "source": [
    "## Fine-tuning GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb90eb9e-aad3-4bce-a9b5-c2343c4e3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import OpenAIFinetuneEngine\n",
    "\n",
    "finetune_engine = OpenAIFinetuneEngine(\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"correction_finetuning_events.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6b392-8932-4eda-93eb-911513be3cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 38\n",
      "First example:\n",
      "{'role': 'system', 'content': '\\nYou are an expert evaluation system for a question answering chatbot.\\n\\nYou are given the following information:\\n- a user query,\\n- a reference answer, and\\n- a generated answer.\\n\\nYour job is to judge the relevance and correctness of the generated answer.\\nOutput a single score that represents a holistic evaluation.\\nYou must return your response in a line with only the score.\\nDo not return answers in any other format.\\nOn a separate line provide your reasoning for the score as well.\\n\\nFollow these guidelines for scoring:\\n- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\\n- If the generated answer is not relevant to the user query, you should give a score of 1.\\n- If the generated answer is relevant but contains mistakes, you should give a score between 2 and 3.\\n- If the generated answer is relevant and fully correct, you should give a score between 4 and 5.\\n\\nExample Response:\\n4.0\\nThe generated answer has the exact same metrics as the reference answer,     but it is not as concise.\\n\\n'}\n",
      "{'role': 'user', 'content': '\\n## User Query\\nQuestion: What event in 1906 had a significant impact on the city of San Francisco?\\n\\n## Reference Answer\\nThe great earthquake and fire in 1906 had a significant impact on the city of San Francisco.\\n\\n## Generated Answer\\n1906 earthquake and fire had a significant impact on the city of San Francisco, leading to the eviction of cemeteries to the nearby town of Colma, California.\\n'}\n",
      "{'role': 'assistant', 'content': '4.5\\nThe generated answer is relevant and correct. It not only mentions the 1906 earthquake and fire, but also provides additional information about the impact of the event. However, the additional information was not asked for in the user query, hence the slight deduction.'}\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 325, 742\n",
      "mean / median: 477.05263157894734, 472.5\n",
      "p5 / p95: 347.4, 625.9000000000001\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 19, 112\n",
      "mean / median: 56.026315789473685, 54.0\n",
      "p5 / p95: 28.4, 85.9\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
      "Dataset has ~18128 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~54384 tokens\n",
      "As of August 22, 2023, fine-tuning gpt-3.5-turbo is $0.008 / 1K Tokens.\n",
      "This means your total cost for training will be $0.14502400000000001 per epoch.\n"
     ]
    }
   ],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0234b-040d-44f6-901b-38e6eb241644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-mecbP0ruMxHEqOAsnF7eCydF at 0x2aa3ae660> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-mecbP0ruMxHEqOAsnF7eCydF\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1698790732,\n",
       "  \"finished_at\": 1698791412,\n",
       "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:llamaindex::8FrXRqaU\",\n",
       "  \"organization_id\": \"org-1ZDAvajC6v2ZtAP9hLEIsXRz\",\n",
       "  \"result_files\": [\n",
       "    \"file-dHUwbAvZK0NKi466LBMy6HB1\"\n",
       "  ],\n",
       "  \"status\": \"succeeded\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-ge2lmJw8Illb0tjagxG4LqCd\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": 3\n",
       "  },\n",
       "  \"trained_tokens\": 54156,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_engine.get_current_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f324ca-b984-4c56-99f2-ee8de2554aab",
   "metadata": {},
   "source": [
    "## LLM Judgements "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab42c1-2e42-4f33-b199-cf67be86ac89",
   "metadata": {},
   "source": [
    "First let's prepare our `test` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6db08a-da63-4f0f-b148-16ed089ca585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:06<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = []\n",
    "for q, a in tqdm.tqdm(qrd_pairs[num_train_questions:]):\n",
    "    # data for this q\n",
    "    data_entry = {\"question\": q, \"reference\": a}\n",
    "    response = query_engine.query(q)\n",
    "    response_struct = {}\n",
    "    response_struct[\"model\"] = \"llama-2\"\n",
    "    response_struct[\"text\"] = str(response)\n",
    "    response_struct[\"context\"] = (\n",
    "        response.source_nodes[0].node.text[:1000] + \"...\"\n",
    "    )\n",
    "\n",
    "    data_entry[\"response_data\"] = response_struct\n",
    "    test_dataset.append(data_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8fc74-c6aa-4759-8904-7655ecfd9bb7",
   "metadata": {},
   "source": [
    "Now, let's predict on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e535a-bd3a-4664-943a-1bf3ff02a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [02:12<00:00,  6.31s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# for `test`\n",
    "for data_entry in tqdm.tqdm(test_dataset):\n",
    "    eval_result = await gpt4_judge.aevaluate(\n",
    "        query=data_entry[\"question\"],\n",
    "        response=data_entry[\"response_data\"][\"text\"],\n",
    "        context=data_entry[\"response_data\"][\"context\"],\n",
    "        reference=data_entry[\"reference\"],\n",
    "    )\n",
    "\n",
    "    # save final result\n",
    "    judgement = {}\n",
    "    judgement[\"llm\"] = \"gpt_4\"\n",
    "    judgement[\"score\"] = eval_result.score\n",
    "    judgement[\"text\"] = eval_result.response\n",
    "    data_entry[\"evaluations\"] = [judgement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b1bd7-beac-429b-b105-147df9efaa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_llm = finetune_engine.get_finetuned_model()\n",
    "ft_context = ServiceContext.from_defaults(\n",
    "    llm=ft_llm,\n",
    ")\n",
    "ft_gpt_3p5_judge = CorrectnessEvaluator(service_context=ft_context)\n",
    "\n",
    "# a non-fine-tuned judge\n",
    "gpt_3p5_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\")\n",
    ")\n",
    "gpt_3p5_judge = CorrectnessEvaluator(service_context=gpt_3p5_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d2661-3d06-42c6-9a99-86616ca4a31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:20<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.evaluation import EvaluationResult\n",
    "\n",
    "# predicting on training set for now just to get rest of pipeline established\n",
    "for data_entry in tqdm.tqdm(test_dataset):\n",
    "    eval_result = await ft_gpt_3p5_judge.aevaluate(\n",
    "        query=data_entry[\"question\"],\n",
    "        response=data_entry[\"response_data\"][\"text\"],\n",
    "        context=data_entry[\"response_data\"][\"context\"],\n",
    "        reference=data_entry[\"reference\"],\n",
    "    )\n",
    "\n",
    "    # save final result\n",
    "    judgement = {}\n",
    "    judgement[\"llm\"] = \"ft_gpt_3p5\"\n",
    "    judgement[\"score\"] = eval_result.score\n",
    "    judgement[\"text\"] = eval_result.response\n",
    "    data_entry[\"evaluations\"] += [judgement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6616b-ea0a-44c4-8749-68e64e0ebbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:41<00:00,  1.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# predicting on training set for now just to get rest of pipeline established\n",
    "for data_entry in tqdm.tqdm(test_dataset):\n",
    "    eval_result = await gpt_3p5_judge.aevaluate(\n",
    "        query=data_entry[\"question\"],\n",
    "        response=data_entry[\"response_data\"][\"text\"],\n",
    "        context=data_entry[\"response_data\"][\"context\"],\n",
    "        reference=data_entry[\"reference\"],\n",
    "    )\n",
    "\n",
    "    # save final result\n",
    "    judgement = {}\n",
    "    judgement[\"llm\"] = \"gpt_3p5\"\n",
    "    judgement[\"score\"] = eval_result.score\n",
    "    judgement[\"text\"] = eval_result.response\n",
    "    data_entry[\"evaluations\"] += [judgement]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302591be-4eac-4b1a-a8d5-0940516a990e",
   "metadata": {},
   "source": [
    "## Evaluation the LLM Judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5f971-488a-469b-b240-bf2b15d530f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_FMT_STR = (\n",
    "    \"{model}\\n\"\n",
    "    \"-----------------\\n\"\n",
    "    \"Number of obs.: {total_obs}\\n\"\n",
    "    \"Correlation with GPT-4: {corr}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612ee7b-f065-49fe-80ad-344fda9ff6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "scores = {\"gpt_4\": [], \"gpt_3p5\": [], \"ft_gpt_3p5\": []}\n",
    "for ix, d in enumerate(test_dataset):\n",
    "    for e in d[\"evaluations\"]:\n",
    "        scores[e[\"llm\"]].append(e[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61637486-4df2-419f-9973-d449e18efcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 w/ fine-tuning\n",
      "-----------------\n",
      "Number of obs.: 21\n",
      "Correlation with GPT-4: 0.6901319161879755\n",
      "\n",
      "\n",
      "\n",
      "GPT-3.5 w/out fine-tuning\n",
      "-----------------\n",
      "Number of obs.: 21\n",
      "Correlation with GPT-4: 0.7103381407680267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numpy conversion\n",
    "np_scores_gpt_4 = np.array(scores[\"gpt_4\"])\n",
    "np_scores_gpt_3p5 = np.array(scores[\"gpt_3p5\"])\n",
    "np_scores_ft_gpt_3p5 = np.array(scores[\"ft_gpt_3p5\"])\n",
    "\n",
    "# correlations\n",
    "corr_ft = np.corrcoef(np_scores_gpt_4, np_scores_ft_gpt_3p5)[0, 1]\n",
    "corr_no_ft = np.corrcoef(np_scores_gpt_4, np_scores_gpt_3p5)[0, 1]\n",
    "\n",
    "print(\n",
    "    REPORT_FMT_STR.format(\n",
    "        model=\"GPT-3.5 w/ fine-tuning\",\n",
    "        total_obs=np_scores_gpt_4.shape[0],\n",
    "        corr=corr_ft,\n",
    "    )\n",
    ")\n",
    "print(\"\\n\")\n",
    "print(\n",
    "    REPORT_FMT_STR.format(\n",
    "        model=\"GPT-3.5 w/out fine-tuning\",\n",
    "        total_obs=np_scores_gpt_4.shape[0],\n",
    "        corr=corr_no_ft,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_3.10",
   "language": "python",
   "name": "llama_index_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
