{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722c13cc-a78a-4037-859e-48c538d00d9b",
   "metadata": {},
   "source": [
    "# Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge\n",
    "\n",
    "There has been recent research that demonstrated GPT-4's ability to closely align to human judges when evaluating LLM generated texts (e.g., see [[1]](https://arxiv.org/abs/2306.05685), [[2]](https://arxiv.org/abs/2303.16634)). In this notebook, we demonstrate how to use the `llama_index` library to distill knowledge from GPT-4 to GPT-3.5 so that the smaller GPT-3.5 becomes closer to GPT-4 performance; and by proxy, closer to human judges.\n",
    "\n",
    "To do so, we take the following steps:\n",
    "\n",
    "1. Generate datasets: `train` and `test`\n",
    "2. Perform knowledge distillation (using `train`)\n",
    "3. Evaluate the distilled model  on `test`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8deb07-ed32-4284-b943-e63867e26288",
   "metadata": {},
   "source": [
    "## 0 Prompt Templates & Asyncio Event Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99afd212-38b0-492c-91ea-a810e126ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "    \"QUESTION_GEN\": (\n",
    "        \"You are a Teacher/ Professor. Your task is to setup \"\n",
    "        \"a quiz/examination. Using the provided context, formulate \"\n",
    "        \"a single question that captures an important fact from the \"\n",
    "        \"context. Restrict the question to the context information provided.\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d02e20-6618-40e9-8db7-11fb3e965a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89edf1-b359-4370-8b1e-fad279508c68",
   "metadata": {},
   "source": [
    "## 1 Generate datasets: `train` and `test`\n",
    "\n",
    "We should not lose sight on the ultimate goal here, which is to build an LLM judge that closely matches to human judges when evaluating LLM-generated texts. The work we need to do in this step, therefore, is to build a set of generated texts that our LLM judges will judge. More specifically, we will follow the \"pairwise comparison\" evaluation design pattern, where one text generation is passed to an LLM judge that is subsequently prompted to assign a score between 0 and 1 (higher is better).\n",
    "\n",
    "To generate a varied set of texts we'll use the following LLM text-generators:\n",
    "1. HuggingFace: Vicuna-13B\n",
    "2. HuggingFace: Mistral-7B\n",
    "3. HuggingFace: Falcon-7B\n",
    "\n",
    "The generation task we ask of each of these models will be to generate an abstractive answer to question when provided relevant context (i.e., RAG)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66486ab-38cf-4ed6-bef4-6fe9deee0590",
   "metadata": {},
   "source": [
    "### Using `DatasetGenerator` to build `train` and `test`\n",
    "\n",
    "The specific procedure we will use here involves generating questions against a set of chunks of a given `Document`. With the `<question, chunk>` pairs in hand, (for which we can merely treat as a \"simulated\" retrieval), we pass this information to the three LLM generators and prompt them each to generate an answer.\n",
    "\n",
    "Hang tight, we're almost there (sort of). Since we want to distill GPT-4 abilities for this task to GPT-3.5, we now need to generate GPT-4 judgements on the generated answers. To do this, we will pass the `<question, answer A, answer B>` (where `A` and `B` represent answers from any two of the LLM text-generators) as context to the GPT-4 judge and prompt it to decide the better answer of the two.\n",
    "\n",
    "With all of that we can now build a `dataset` that looks like the one below.\n",
    "| question | context-answer-A-answer-B | gpt-4-evaluation |\n",
    "|----------|---------------------------|------------------|\n",
    "| ...      | ...                       | ...              |\n",
    "\n",
    "And finally, to get `train` and `test` we will simply randomly shuffle `dataset` and split it using a 70/30 ratio. (Phew!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc60af-2ef8-43b6-8b24-f46adc223d03",
   "metadata": {},
   "source": [
    "With all that out of the way, let's spring into action. First, we will download the reference pdf document and create the set of questions against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536754e6-666f-4c43-82b0-d81c9281ed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 20.7M  100 20.7M    0     0   619k      0  0:00:34  0:00:34 --:--:--  648k  441k      0  0:00:48  0:00:02  0:00:46  441k     0   611k      0  0:00:34  0:00:24  0:00:10  635k616k      0  0:00:34  0:00:32  0:00:02  632k\n"
     ]
    }
   ],
   "source": [
    "# Download the pdf document — Uncomment the line of code below\n",
    "# !curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter03.pdf --output IPCC_AR6_WGII_Chapter03.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc37cea-c9d2-4807-ab45-69f8b38db639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from llama_index import SimpleDirectoryReader, ServiceContext\n",
    "\n",
    "# load a document\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"IPCC_AR6_WGII_Chapter03.pdf\"]\n",
    ").load_data()\n",
    "\n",
    "# Shuffle the documents\n",
    "random.seed(42)\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e10603-a0e0-4c87-a4d5-fdf8f1ca0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate questions against chunks\n",
    "from llama_index.evaluation import DatasetGenerator\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# set context for llm provider\n",
    "gpt_35_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
    ")\n",
    "\n",
    "# instantiate a DatasetGenerator\n",
    "dataset_generator = DatasetGenerator.from_documents(\n",
    "    documents,\n",
    "    question_gen_query=PROMPTS[\"QUESTION_GEN\"],\n",
    "    service_context=gpt_35_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e2276-92dc-48c3-8cd0-583655ab7ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some approaches used to assess ecological responses to multiple climate-induced drivers?\n",
      "Question: What is the projected decline in marine animal biomass with warming under SSP1-2.6 and SSP5-8.5 by 2080-2099 relative to 1995-2014?\n",
      "Question: What is the projected impact of tropicalisation on species richness at local to regional scales?\n",
      "What are the two Shared Socioeconomic Pathways (SSPs) under which the ensemble projections of global changes in phytoplankton phenology were made?\n",
      "Question: According to the context information, what is the title of the paper published in 2017 that provides biogeochemical protocols and diagnostics for the CMIP6 Ocean Model Intercomparison Project (OMIP)?\n"
     ]
    }
   ],
   "source": [
    "# use DatasetGenerator to create questions from nodes\n",
    "questions = dataset_generator.generate_questions_from_nodes(num=100)\n",
    "\n",
    "# let's take a look at a few of these\n",
    "for q in questions[:5]:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201d9cb-4746-4c71-8728-55e56cb8b76f",
   "metadata": {},
   "source": [
    "Now that we have the questions, the next step is to generate answers using the three LLM text-generators: Vicuna, Mistral, and Falcon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc71805-896d-4bbe-9053-495426a26a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.indices.vector_store.retrievers import VectorIndexRetriever\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents=documents)\n",
    "\n",
    "retriever = VectorIndexRetriever(  # what embeddings are being used?\n",
    "    index=index,\n",
    "    node_ids=list(index.index_struct.nodes_dict.values()),\n",
    "    similarity_top_k=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84331853-ac29-49ca-85c1-e874d26e5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine.retriever_query_engine import (\n",
    "    RetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.llms import Replicate, OpenAI\n",
    "\n",
    "# define our llm-generators (RAGs)\n",
    "\n",
    "# Vicuna\n",
    "vicuna_context = ServiceContext.from_defaults(\n",
    "    llm=Replicate(\n",
    "        model=\"replicate/vicuna-13b:6282abe6a492de4145d7bb601023762212f9ddbbe78278bd6771c8b3b2f2a13b\",\n",
    "        temperature=0.3,\n",
    "        context_window=2048,  # to use refine\n",
    "    )\n",
    ")\n",
    "\n",
    "vicuna_query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=retriever, service_context=vicuna_context\n",
    ")\n",
    "\n",
    "# define our llm judges (also student/teacher models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f9b77-db2d-43ce-b2d4-12a4bc2defcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ServiceContext(llm_predictor=LLMPredictor(system_prompt=None, query_wrapper_prompt=None), prompt_helper=PromptHelper(context_window=2048, num_output=256, chunk_overlap_ratio=0.1, chunk_size_limit=None, separator=' '), embed_model=OpenAIEmbedding(model_name='text-embedding-ada-002', embed_batch_size=10, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x16279af50>, deployment_name=None, additional_kwargs={}, api_key='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', api_type='open_ai', api_base='https://api.openai.com/v1', api_version=''), node_parser=SimpleNodeParser(text_splitter=SentenceSplitter(chunk_size=1024, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?', chunking_tokenizer_fn=<function split_by_sentence_tokenizer.<locals>.split at 0x107e3d900>, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x16279af50>, tokenizer=functools.partial(<bound method Encoding.encode of <Encoding 'gpt2'>>, allowed_special='all')), include_metadata=True, include_prev_next_rel=True, metadata_extractor=None, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x16279af50>), llama_logger=<llama_index.logger.base.LlamaLogger object at 0x16279bca0>, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x16279af50>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vicuna_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345cf8b-572e-4e6e-9e1b-40b6a30a79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vicuna_query_engine.query(questions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3d2a7-a108-4c09-a666-0d05f1dc1b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: What is the projected decline in marine animal biomass with warming under SSP1-2.6 and SSP5-8.5 by 2080-2099 relative to 1995-2014?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3a487-53fc-4ff6-8447-a59d0b58f087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='\\u200b', source_nodes=[NodeWithScore(node=TextNode(id_='d4e0bc38-a614-4463-a808-0a51923ed54d', embedding=None, metadata={'page_label': '446', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='dd617b75-f8ef-478e-a4cc-e0d44fcbaaaa', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '446', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}, hash='7bab188793a5813eb45b7cd57170de4469734f90aa82b1530b37521ec2dfc3e9'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f75150d0-c493-4ec6-8149-a4a04a7e75bd', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '446', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}, hash='dba5548dd2fc08ba7df8984d813c79dbc367ce732d3e1819800b868a7f770cf3')}, hash='402ade5489b10a61bc5409d2842ea92d80f37853167966a320bdd16e334bf831', text='The new CMIP6 ESM ensemble projects \\na decline in global zooplankton biomass by −3.9\\xa0 ±\\xa0 8.2% (very \\nlikely range) and −9.0\\xa0 ±\\xa0 8.9% in the period 2081–2100 relative to \\n1995–2014 under SSP1-2.6 and SSP5-8.5, respectively (Figure\\xa03.21d; \\nKwiatkowski et\\xa0 al., 2020), thus reinforcing the SROCC assessment \\nalbeit with greater inter-model uncertainties.\\nUsing an ensemble of global-scale marine ecosystem and fisheries \\nmodels (Fish-MIP) (Tittensor et\\xa0 al., 2018) with the CMIP5 ESM \\nensemble, SROCC concludes that projected ocean warming and \\ndecreased phytoplankton production and biomass will reduce global \\nmarine animal biomass during the 21st\\xa0century (medium confidence). \\nThe simulated declines (with very likely range) are −3.5\\xa0±\\xa04.8% and \\n−14.0\\xa0 ±\\xa0 14.6% under RCP2.6 and RCP8.5, respectively, by 2080–\\n2099 relative to 1995–2014 (SROCC Section\\xa0 5.2.3; Bindoff et\\xa0 al., \\n2019a; Lotze et\\xa0al., 2019)6. Updated Fish-MIP simulations with CMIP6 \\n(Figure\\xa03.21g,h,i) confirm the projected decline in total marine animal \\nbiomass in the 21st\\xa0century (Tittensor et\\xa0al., 2021). The simulated Observed ecological regime shifts\\nand their drivers in the oceans\\n960 1970 1980 1990 2000 2010Regime 2Current state Critical threshold\\nRegime 1\\n2,5005,0007,50010,000Shift in magnitude and extent of abrupt community shifts\\nin the global ocean(a)\\n0Shock\\n(b)\\nFigure\\xa03.19 | \\xa0Observed ecological regime shifts and their drivers in the oceans.\\n(a) A conceptual representation of ecosystem resilience and regime shifts. Shift \\nfrom Regime 1 to Regime 2 can be triggered by either a large shock (i.e., an abrupt \\nenvironmental transition) or gradual internal or external change that erodes the dominant \\nbalancing feedbacks, reducing ecosystem resilience (indicated by the shallower dotted line, \\nrelative to the deeper ‘valley’ reflecting higher resilience). (Based on Biggs et\\xa0al., 2018).\\n(b) The sum of the magnitude and extent of the abrupt community shifts that has been \\nestimated at each geographic cell in the global ocean during 1960–2014, calculated as \\nthe ratio of the amplitude of the change in a particular\\xa0year to the average magnitude \\nof the change over the entire time series (thus, is dimensionless). (Based on Beaugrand \\net\\xa0al., 2019).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8954753077473956), NodeWithScore(node=TextNode(id_='c28f54af-8820-45bf-a3e4-f526960bd287', embedding=None, metadata={'page_label': '382', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='59b51ef1-ccb7-4ee3-b870-662bc944b33f', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '382', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}, hash='b2f873d085ef5e0e4cce2b8497077cb206d312c6043989dfc1a6bf387f7ec826'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='40963eb0-8c85-4d5b-969c-c774a3ef148a', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '382', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}, hash='8e056cf273a408d8fe6a0b516dd13e01a619d779ad5937abcc3ae770a162f0ea'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='45acf7d3-4405-4188-a99d-610d7f814c7a', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '382', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}, hash='fe8ad638a3afdb71dbe66804e1a7a8df22ecfb627aa7805e17bd41a26478bd15')}, hash='33a5601d3dcc1f438169db9235ea25629545baf8422b2f04a6eebd0dcece37c1', text='{3.4.2.1, 3.4.2.3, 3.4.2.5, 3.4.4}Escalating impacts of climate change on marine life will further \\nalter biomass of marine animals (medium confidence), the \\ntiming of seasonal ecological events (medium confidence) \\nand the geographic ranges of coastal and ocean taxa (medium \\nconfidence), disrupting life cycles (medium confidence), \\nfood webs (medium confidence) and ecological connectivity \\nthroughout the water column (medium confidence). Multiple \\nlines of evidence suggest that climate-change responses are very \\nlikely to amplify up marine food webs over large regions of the ocean. \\nModest projected declines in global phytoplankton biomass translate \\ninto larger declines of total animal biomass (by 2080–2099 relative \\nto 1995–2014) ranging from (mean\\xa0±\\xa0 very likely range) −5.7\\xa0±\\xa04.1% \\nto −15.5\\xa0±\\xa08.5% under SSP1-2.6 and SSP5-8.5, respectively (medium \\nconfidence). Projected declines in upper-ocean nutrient concentrations, \\nlikely associated with increases in stratification, will reduce carbon \\nexport flux to the mesopelagic and deep-sea ecosystems (medium \\nconfidence). This will lead to a decline in the biomass of abyssal meio- \\nand macrofauna (by 2081–2100 relative to 1995–2014) by −9.8% and \\n−13.0% under SSP1-2.6 and SSP5-8.5, respectively (limited evidence). \\nBy 2100, 18.8\\xa0±\\xa019.0% to 38.9\\xa0±\\xa09.4% of the ocean will very likely \\nundergo a change of more than 20 d (advances and delays) in the \\nstart of the phytoplankton growth period under SSP1-2.6 and SSP5-\\n8.5, respectively (low confidence). This altered timing increases the risk \\nof temporal mismatches between plankton blooms and fish spawning \\nseasons (medium to high confidence) and increases the risk of fish-\\nrecruitment failure for species with restricted spawning locations, \\nespecially in mid-to-high latitudes of the Northern Hemisphere (low \\nconfidence). Projected range shifts among marine species (medium \\nconfidence) suggest extirpations and strongly decreasing tropical \\nbiodiversity. At higher latitudes, range expansions will drive increased \\nhomogenisation of biodiversity. The projected loss of biodiversity \\nultimately threatens marine ecosystem resilience (medium to high \\nconfidence), with subsequent effects on service provisioning (medium \\nto high confidence). {3.2.2.3, 3.4.2.10, 3.4.3.1–3.4.3.5, 3.5, WGI AR6 \\nSection\\xa02.3.4.2.3}\\nRisks from sea level rise for coastal ecosystems and people \\nare very likely to increase tenfold well before 2100 without \\nadaptation and mitigation action as agreed by Parties to the Paris \\nAgreement (very high confidence). Sea level rise under emission \\nscenarios that do not limit warming to 1.5°C will increase the risk of \\ncoastal erosion and submergence of coastal land (high confidence), \\nloss of coastal habitat and ecosystems (high confidence) and worsen \\nsalinisation of groundwater (high confidence), compromising coastal \\necosystems and livelihoods (high confidence). Under SSP1-2.6, \\nmost coral reefs (very high confidence), mangroves (likely, medium \\nconfidence) and salt marshes (likely, medium confidence) will be \\nunable to keep up with sea level rise by 2050, with ecological impacts \\nescalating rapidly beyond 2050, especially for scenarios coupling high \\nemissions with aggressive coastal development (very high confidence). \\nResultant decreases in natural shoreline protection will place \\nincreasing numbers of people at risk (very high confidence). The ability \\nto adapt to current coastal impacts, cope with future coastal risks and \\nprevent further acceleration of sea level rise beyond 2050 depends on \\nimmediate implementation of mitigation and adaptation actions (very \\nhigh confidence).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8952227615825511)], metadata={'d4e0bc38-a614-4463-a808-0a51923ed54d': {'page_label': '446', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}, 'c28f54af-8820-45bf-a3e4-f526960bd287': {'page_label': '382', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42937500-a709-4556-aac2-0e5929f66e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our dataset, and split into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb16d0-15b1-45f3-96b0-3b51574d1626",
   "metadata": {},
   "source": [
    "## 2 Perform knowledge distillation\n",
    "\n",
    "Okay, it's now time to distill some knowledge from GPT-4 to GPT-3.5 To do this, we will make use of `OpenAIFinetuneEngine` class of `llama_index`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_3.10",
   "language": "python",
   "name": "llama_index_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
