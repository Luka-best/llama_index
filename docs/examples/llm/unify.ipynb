{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unify\n",
    "Unify is a platform that offers dynamic routing of queries to the most appropriate endpoint served by different providers like OpenAI, MistralAI, Perplexity AI, Together AI and more. It offers single sign on access with one api key to access all the different providers supported by the [platform](https://unify.ai/hub).\n",
    "\n",
    "When using models through the Unify API endpoint, you get:,\n",
    "- Single sign-on with all providers.\n",
    "- Dynamic routing to the best provider for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install LlamaIndex ðŸ¦™ and the Unify integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-unify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "- Get your Unify API Key from the [Unify console](https://console.unify.ai/)\n",
    "- Set the `UNIFY_API_KEY` environment variable to the API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"UNIFY_API_KEY\"] = \"<YOUR API KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `complete` with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=\"  It's difficult to give an exact number of companies that serve chat model endpoints as it constantly changes due to various factors such as market demand, technological advancements, and new entrants in the field. However, there are numerous companies that offer chatbot development and deployment services, and many of them provide pre-built chat models that can be integrated into various platforms.\\n\\nHere are some of the popular companies that offer chatbot development services and pre-built chat models:\\n\\n1. Dialogflow (formerly known as API.ai) - Dialogflow is a Google-owned company that provides a platform for building conversational interfaces. It offers a wide range of pre-built chat models and integrations with popular messaging platforms.\\n2. IBM Watson Assistant - IBM Watson Assistant is a cloud-based AI platform that allows businesses to create and deploy conversational AI solutions. It provides a range of pre-built chat models and integrations with popular messaging platforms.\\n3. Microsoft Bot Framework - Microsoft Bot Framework is a set of tools and resources for building conversational AI solutions. It provides pre-built chat models and integrations with popular messaging platforms like Microsoft Teams, Slack, and Skype.\\n4. Amazon Lex - Amazon Lex is a service provided by Amazon Web Services (AWS) that allows businesses to build conversational AI solutions. It provides pre-built chat models and integrations with popular messaging platforms.\\n5. Rasa - Rasa is an open-source conversational AI platform that allows businesses to build and deploy chatbots. It provides pre-built chat models and integrations with popular messaging platforms.\\n6. ManyChat - ManyChat is a popular chatbot development platform that provides pre-built chat models and integrations with popular messaging platforms like Facebook Messenger, WhatsApp, and SMS.\\n7. Tars - Tars is a chatbot development platform that provides pre-built chat models and integrations with popular messaging platforms. It also offers a drag-and-drop interface for building custom chatbot flows.\\n8. MobileMonkey - MobileMonkey is a chatbot development platform that provides pre-built chat models and integrations with popular messaging platforms like Facebook Messenger, WhatsApp, and SMS.\\n9. BotStar - BotStar is a chatbot development platform that provides pre-built chat models and\", additional_kwargs={}, raw={'id': 'chatcmpl-124c27709ae445f3a496c060f038e009', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"  It's difficult to give an exact number of companies that serve chat model endpoints as it constantly changes due to various factors such as market demand, technological advancements, and new entrants in the field. However, there are numerous companies that offer chatbot development and deployment services, and many of them provide pre-built chat models that can be integrated into various platforms.\\n\\nHere are some of the popular companies that offer chatbot development services and pre-built chat models:\\n\\n1. Dialogflow (formerly known as API.ai) - Dialogflow is a Google-owned company that provides a platform for building conversational interfaces. It offers a wide range of pre-built chat models and integrations with popular messaging platforms.\\n2. IBM Watson Assistant - IBM Watson Assistant is a cloud-based AI platform that allows businesses to create and deploy conversational AI solutions. It provides a range of pre-built chat models and integrations with popular messaging platforms.\\n3. Microsoft Bot Framework - Microsoft Bot Framework is a set of tools and resources for building conversational AI solutions. It provides pre-built chat models and integrations with popular messaging platforms like Microsoft Teams, Slack, and Skype.\\n4. Amazon Lex - Amazon Lex is a service provided by Amazon Web Services (AWS) that allows businesses to build conversational AI solutions. It provides pre-built chat models and integrations with popular messaging platforms.\\n5. Rasa - Rasa is an open-source conversational AI platform that allows businesses to build and deploy chatbots. It provides pre-built chat models and integrations with popular messaging platforms.\\n6. ManyChat - ManyChat is a popular chatbot development platform that provides pre-built chat models and integrations with popular messaging platforms like Facebook Messenger, WhatsApp, and SMS.\\n7. Tars - Tars is a chatbot development platform that provides pre-built chat models and integrations with popular messaging platforms. It also offers a drag-and-drop interface for building custom chatbot flows.\\n8. MobileMonkey - MobileMonkey is a chatbot development platform that provides pre-built chat models and integrations with popular messaging platforms like Facebook Messenger, WhatsApp, and SMS.\\n9. BotStar - BotStar is a chatbot development platform that provides pre-built chat models and\", role='assistant', function_call=None, tool_calls=None, name=None))], 'created': 1710429905, 'model': 'llama-2-70b-chat@deepinfra', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=512, prompt_tokens=18, total_tokens=530, cost=0.0004734)}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.unify import Unify\n",
    "llm = Unify(model=\"llama-2-70b-chat@deepinfra\")\n",
    "llm.complete(\"How many companies serve chat model endpoints?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of using Unify is that through a single api key, you can access endpoints from different providers like Perplexity, Together AI, OctoAI and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Together AI response: \n",
      "   I'm called Llama because I'm a machine learning model, and my creators wanted to give me a unique and memorable name. They chose the name Llama because it's a nod to the animal of the same name, which is known for its intelligence, social behavior, and ability to communicate with humans.\n",
      "\n",
      "While I'm not a goat, I am a computer program designed to simulate conversation and answer questions to the best of my ability. My name is meant to evoke the idea of a friendly, intelligent creature that can help people communicate and learn.\n",
      "\n",
      "So, while I may not be a goat, I'm still a helpful and friendly AI assistant, and I'm here to assist you with any questions or tasks you may have!\n",
      "Anyscale response: \n",
      "   Both goat and llama are good names, but they have different connotations and associations.\n",
      "\n",
      "Goat is a more general term that can refer to any member of the Bovidae family, including both male and female goats. It's a simple and straightforward name that is easily recognizable and understandable.\n",
      "\n",
      "Llama, on the other hand, specifically refers to the South American relative of the camel, known for its long neck and ears, and its ability to spit when threatened. It's a more specific and unique name that is often associated with a particular image or idea.\n",
      "\n",
      "Ultimately, whether goat or llama is a better name depends on the context and the intended meaning. If you're referring to a generic member of the Bovidae family, goat might be a better choice. If you're referring to a specific animal with the characteristics I mentioned above, llama might be a better choice.\n"
     ]
    }
   ],
   "source": [
    "llm_together = Unify(model=\"llama-2-70b-chat@together-ai\")\n",
    "print(\"Together AI response: \\n\", llm_together.complete(\"Why are you called llama, isn't it a goat or something?\"))\n",
    "\n",
    "llm_anyscale = Unify(model=\"llama-2-70b-chat@anyscale\")\n",
    "print(\"Anyscale response: \\n\", llm_anyscale.complete(\"Isn't goat a better name than llama?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming and Dynamic routing\n",
    "You may also want to use `mixtral-8x7b-instruct-v0.1` with the fastest output speed, and are not concerned with which provider you are using. Unify's dynamic routing gets this data from our live benchmarks and routes you to the provider that is performing better than the rest at that instant.\n",
    "\n",
    "You can see how to configure dynamic routing [here](https://unify.ai/docs/hub/concepts/runtime_routing.html#how-to-use-it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Unify(model=\"mixtral-8x7b-instruct-v0.1@tks-per-sec\")\n",
    "response = llm.stream_complete(\"Why is mixtral so competitive with bigger models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and provider used were:  mixtral-8x7b-instruct-v0.1@fireworks-ai\n"
     ]
    }
   ],
   "source": [
    "for r in response:\n",
    "    print(r.delta, end=\"\")\n",
    "print(\"Model and provider used were: \", r.raw['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async and cost based routing\n",
    "You can also run this asynchronously, and may want to optimize for cost. If you need to run large volumes of data through some models, and need it by tomorrow, and want to optimize for cost and aren't interested too much in speed, but want to save on input costs. Unify's dynamic router can be used for this too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Synchronous (sync) code and asynchronous (async) code are two different ways to write code that allow you to control the flow of execution in a program.\n",
      "\n",
      "Synchronous code is executed in a sequential manner, meaning that each statement is executed one after the other, and the program waits for the current statement to complete before moving on to the next one. This is useful when you want to ensure that the code is executed in a specific order, and you need to wait for the result of one operation before proceeding to the next. However, if one of the operations takes a long time to complete, the entire program will be blocked and unresponsive until the operation is finished.\n",
      "\n",
      "Asynchronous code, on the other hand, allows you to execute multiple operations concurrently, without blocking the execution of other code. This is achieved by allowing the program to continue executing other statements while waiting for the result of an asynchronous operation. Asynchronous code is typically used when you have operations that take a long time to complete, such as network requests, file I/O, or other time-consuming tasks.\n",
      "\n",
      "In summary, the main difference between sync and async code is that sync code is executed sequentially, one statement at a time, while async code allows for concurrent execution of multiple operations, without blocking the program.\n",
      "Model and provider used were:  mixtral-8x7b-instruct-v0.1@deepinfra\n"
     ]
    }
   ],
   "source": [
    "llm = Unify(model=\"mixtral-8x7b-instruct-v0.1@input-cost\")\n",
    "response = await llm.acomplete(\"What is the difference between sync and async code?\")\n",
    "print(response)\n",
    "print(\"Model and provider used were: \", response.raw['model'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
