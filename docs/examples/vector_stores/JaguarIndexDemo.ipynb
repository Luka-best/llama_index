{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a004a3-d197-4a59-b63d-886faaf83ab8",
   "metadata": {},
   "source": [
    "# Jaguar Vector Store\n",
    "\n",
    "This document demonstrates llama_index working with Jaguar vector store.\n",
    "\n",
    "1) It is a distributed vector database that can store large number of vectors.\n",
    "2) The ZeroMove feature of JaguarDB enables instant horizontal scalability.\n",
    "3) It works with multimodal data including vector embeddings, text, images, videos, PDFs, audio, time series, and geospatial data. \n",
    "4) The all-master architecture allows both parallel reads and writes.\n",
    "5) Its anomaly detection capabilities can distinguish outliers in the dataset.\n",
    "6) The RAG support can combine LLMs and proprietary and real-time data.\n",
    "7) Sharing of metadata across multiple vector indexes improves data consistency.\n",
    "8) Distance metrics include Euclidean, Cosine, InnerProduct, Manhatten, Chebyshev, Hamming, Jeccard, and Minkowski.\n",
    "9) Similarity search can be performed with time cutoff and time decay effects.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "There are two requirements for running the examples in this file.\n",
    "\n",
    "You must install and set up the JaguarDB server and its HTTP gateway server. \n",
    "Please refer to the instructions:\n",
    "\n",
    "    http://www.jaguardb.com\n",
    "\n",
    "You must install packages llama-index and jaguardb-http-client.\n",
    "\n",
    "    !pip install -U llama-index\n",
    "    !pip install -U jaguardb-http-client\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d162991-b128-4451-94a9-8ca363cbf4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index.vector_stores.jaguar import JaguarVectorStore\n",
    "from jaguardb_http_client.JaguarHttpClient import JaguarHttpClient\n",
    "\n",
    "### instantiate a jaguar vector store client object\n",
    "url = \"http://127.0.0.1:8080/fwww/\"\n",
    "pod = \"vdb\"\n",
    "store = \"llamaindex_jaguar_store\"\n",
    "vector_index = \"v\"\n",
    "# vector_type = \"cosine_fraction_float\"\n",
    "vector_type = \"cosine_fraction_short\"  # half memory usage\n",
    "# vector_type = \"cosine_fraction_byte\"\n",
    "vector_dimension = 1536  # per OpenAIEmbedding model\n",
    "jaguarstore = JaguarVectorStore(\n",
    "    pod,\n",
    "    store,\n",
    "    vector_index,\n",
    "    vector_type,\n",
    "    vector_dimension,\n",
    "    url,\n",
    ")\n",
    "\n",
    "### connect to jaguar server\n",
    "jaguarstore.login()\n",
    "\n",
    "### create a vector index store\n",
    "\"\"\"\n",
    "Create a vector with vector index 'v' and 'v:text' with size 1024 bytes\n",
    "to hold text and metadata author and category\n",
    "\"\"\"\n",
    "metadata_str = \"author char(32), category char(16)\"\n",
    "text_size = 1024\n",
    "jaguarstore.create(metadata_str, text_size)\n",
    "\n",
    "### load paul gram example documents\n",
    "documents = SimpleDirectoryReader(\"../data/paul_graham/\").load_data()\n",
    "\n",
    "### make a storage context using our vector store\n",
    "storage_context = StorageContext.from_defaults(vector_store=jaguarstore)\n",
    "\n",
    "### have a service context using the openai embedding model\n",
    "embed_model = OpenAIEmbedding()\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "\n",
    "### make an index with the documents,storage context, and service context\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, service_context=service_context\n",
    ")\n",
    "\n",
    "### print number of documents in jaguar vector store\n",
    "num = jaguarstore.count()\n",
    "print(f\"There are {num} documents in jaguar vector store\")\n",
    "\n",
    "### get the query engine and ask it some questions\n",
    "query_engine = index.as_query_engine()\n",
    "q = \"What did the author do growing up?\"\n",
    "print(f\"Question: {q}\")\n",
    "response = query_engine.query(q)\n",
    "print(f\"Answer: {str(response)}\")\n",
    "\n",
    "q = \"What did the author do after his time at Viaweb?\"\n",
    "print(f\"Question: {q}\")\n",
    "response = query_engine.query(q)\n",
    "print(f\"Answer: {str(response)}\")\n",
    "\n",
    "### remove all the data in the vector store if you want\n",
    "jaguarstore.clear()\n",
    "\n",
    "### delete the whole vector in the database if you want\n",
    "jaguarstore.drop()\n",
    "\n",
    "### disconnect from jaguar server and cleanup resources\n",
    "jaguarstore.logout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
