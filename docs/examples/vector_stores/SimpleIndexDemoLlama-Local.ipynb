{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c48213d-6e6a-4c10-838a-2a7c710c3a05",
   "metadata": {},
   "source": [
    "# Local Llama2 + VectorStoreIndex\n",
    "\n",
    "This notebook walks through the proper setup to use llama-2 with LlamaIndex locally. Note that you need a decent GPU to run this notebook, ideally an A100 with at least 40GB of memory.\n",
    "\n",
    "Specifically, we look at using a vector store index."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91f09a23",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e14011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (0.7.17)\n",
      "Requirement already satisfied: ipywidgets in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (8.1.0)\n",
      "Requirement already satisfied: tiktoken in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: dataclasses-json in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (0.5.9)\n",
      "Requirement already satisfied: langchain>=0.0.218 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (0.0.247)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.15 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (2.0.19)\n",
      "Requirement already satisfied: numpy in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (1.25.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (8.2.2)\n",
      "Requirement already satisfied: openai>=0.26.4 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (0.27.8)\n",
      "Requirement already satisfied: pandas in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (2.0.3)\n",
      "Requirement already satisfied: urllib3<2 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (1.26.16)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (2023.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (4.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (4.12.2)\n",
      "Requirement already satisfied: nest-asyncio in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from llama-index) (1.5.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipywidgets) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: backcall in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from langchain>=0.0.218->llama-index) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from langchain>=0.0.218->llama-index) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from langchain>=0.0.218->llama-index) (4.0.2)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from langchain>=0.0.218->llama-index) (0.0.15)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from langchain>=0.0.218->llama-index) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from langchain>=0.0.218->llama-index) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from langchain>=0.0.218->llama-index) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from langchain>=0.0.218->llama-index) (2.31.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index) (3.20.1)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index) (1.5.1)\n",
      "Requirement already satisfied: tqdm in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from sqlalchemy>=2.0.15->llama-index) (2.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index) (1.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from beautifulsoup4->llama-index) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from pandas->llama-index) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from pandas->llama-index) (2023.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from tiktoken->llama-index) (2023.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (23.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.0.218->llama-index) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.0.218->llama-index) (2023.7.22)\n",
      "Requirement already satisfied: executing>=1.2.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /workspace/Connectors/ChatDemo/backend/.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50d3b817-b70e-4667-be4f-d3a0fe4bd119",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073233e",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Please sign in to HF hub with an account that has access to the llama2 models, using `huggingface-cli login` in your console. For more details, please see: https://ai.meta.com/resources/models-and-libraries/llama-downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690a6918-7c75-4f95-9ccc-d2c4a1fe00d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be92665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpjthvjme0\n",
      "Created a temporary directory at /tmp/tmpjthvjme0\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpjthvjme0/_remote_module_non_scriptable.py\n",
      "Writing /tmp/tmpjthvjme0/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af241956b8244d9b9626a57acf97d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "from llama_index.prompts.prompts import SimpleInputPrompt\n",
    "\n",
    "# Model names (make sure you have access on HF)\n",
    "LLAMA2_7B = \"meta-llama/Llama-2-7b-hf\"\n",
    "LLAMA2_7B_CHAT = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "LLAMA2_13B = \"meta-llama/Llama-2-13b-hf\"\n",
    "LLAMA2_13B_CHAT = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "LLAMA2_70B = \"meta-llama/Llama-2-70b-hf\"\n",
    "LLAMA2_70B_CHAT = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "\n",
    "selected_model = LLAMA2_13B_CHAT\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an AI assistant that answers questions in a friendly manner, based on the given source documents. Here are some rules you always follow:\n",
    "- Generate human readable output, avoid creating output with gibberish text.\n",
    "- Generate only the requested output, don't include any other language before or after the requested output.\n",
    "- Never say thank you, that you are are happy to help, that you are an AI agent, etc. Just answer directly.\n",
    "- Generate professional language typically used in business documents in North America.\n",
    "- Never generate offensive or foul language.\n",
    "\"\"\"\n",
    "\n",
    "query_wrapper_prompt = SimpleInputPrompt(\"### Question:\\n{query_str}\\n\\n### Answer:\")\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=2048,\n",
    "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=selected_model,\n",
    "    model_name=selected_model,\n",
    "    device_map=\"auto\",\n",
    "    # change these settings below depending on your GPU\n",
    "    model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d1691e-544b-454f-825b-5ee12f7faa8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"../../../examples/paul_graham_essay/data\"\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad144ee7-96da-4dd6-be00-fd6cf0c78e58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6caf93b-6345-4c65-a346-a95b0f1746c4",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85466fdf-93f3-4cb1-a5f9-0056a8245a6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdda1b2c-ae46-47cf-91d7-3153e8d0473b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Growing up, the author wrote short stories, programmed on an IBM 1401, and eventually convinced his father to buy him a TRS-80 microcomputer. He wrote simple games, a program to predict how high his model rockets would fly, and a word processor. He studied philosophy in college, but eventually switched to AI. He wrote essays and published them online, and worked on spam filters and painting. He also hosted dinners for a group of friends every Thursday night and bought a building in Cambridge.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24935a47",
   "metadata": {},
   "source": [
    "### Streaming Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446406f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At Interleaf, a group of people worked on projects for customers. One of the employees told the narrator about a new thing called HTML, which was a derivative of SGML. The narrator left Interleaf to go back to RISD and did freelance work for the group that did projects for customers. Later, the narrator and a college friend started a new company called Viaweb, which was a web app that allowed users to build stores through the browser. They got seed funding and recruited two programmers to help them build the software. They opened for business in January 1996 with 6 stores."
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(streaming=True)\n",
    "response = query_engine.query(\"What happened at interleaf?\")\n",
    "for token in response.response_gen:\n",
    "    print(token, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
