{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6537c4",
   "metadata": {},
   "source": [
    "# Response Evaluator\n",
    "\n",
    "In this example we are going to test the `ResponseEvaluator` on a vector index and tree index. The data is extracted from the [New York City](https://en.wikipedia.org/wiki/New_York_City) wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8304f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9080b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring logger to INFO level\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0b2364-4806-4656-81e7-3f6e4b910b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import (\n",
    "    TreeIndex,\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    Response,\n",
    ")\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.evaluation import ResponseEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe66f2a",
   "metadata": {},
   "source": [
    "Using GPT-4 here for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b98f89-d5b8-4d29-92f6-ad76d5060e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpt-4\n",
    "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)\n",
    "\n",
    "evaluator_gpt4 = ResponseEvaluator(service_context=service_context_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1298bbb4-c99e-431e-93ef-eb32c0a2fc2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./test_wiki_data/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca06a5b-8a15-40b4-8c7f-dae5407c674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 3 chunks\n",
      "> Building index from nodes: 3 chunks\n"
     ]
    }
   ],
   "source": [
    "# create tree index\n",
    "tree_index = TreeIndex.from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f0e53f-77a6-40d5-94ae-3f81b01af75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector index\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents, service_context=ServiceContext.from_defaults(chunk_size=512)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af730b2e-6949-4865-b7af-bb2bc60a9173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define jupyter display function\n",
    "\n",
    "\n",
    "def display_eval_df(response: Response, eval_result: str) -> None:\n",
    "    if response.source_nodes == []:\n",
    "        print(\"no response!\")\n",
    "        return\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Response\": str(response),\n",
    "            \"Source\": response.source_nodes[0].node.text[:1000] + \"...\",\n",
    "            \"Evaluation Result\": eval_result,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Response\", \"Source\"]\n",
    "    )\n",
    "    display(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f486d",
   "metadata": {},
   "source": [
    "To run evaluations you can call the `.evaluate()` function on the `Response` object return from the query to run the evaluations. Lets evaluate the outputs of both the tree_index and vector_index to see if there is any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c9ebfe-b1b6-4f4e-9278-174346de8c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = tree_index.as_query_engine()\n",
    "response_tree = query_engine.query(\n",
    "    \"What battles took place in New York City in the American Revolution?\"\n",
    ")\n",
    "eval_result = evaluator_gpt4.evaluate(response_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db9d00bc-8428-4a08-b48e-248ad7570923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no response!\n"
     ]
    }
   ],
   "source": [
    "display_eval_df(response_tree, eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "180a5d2e-9286-477b-9cd0-a5976d18d845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine()\n",
    "response_vector = query_engine.query(\n",
    "    \"What battles took place in New York City in the American Revolution?\"\n",
    ")\n",
    "eval_result = evaluator_gpt4.evaluate(response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c764b8b3-69b1-4ac8-b88b-3f9e204b8bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8ceaf_row0_col0, #T_8ceaf_row0_col1 {\n",
       "  inline-size: 600px;\n",
       "  overflow-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8ceaf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8ceaf_level0_col0\" class=\"col_heading level0 col0\" >Response</th>\n",
       "      <th id=\"T_8ceaf_level0_col1\" class=\"col_heading level0 col1\" >Source</th>\n",
       "      <th id=\"T_8ceaf_level0_col2\" class=\"col_heading level0 col2\" >Evaluation Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8ceaf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8ceaf_row0_col0\" class=\"data row0 col0\" >\n",
       "The Battle of Long Island, which was the largest battle of the American Revolutionary War, took place in August 1776 within the modern-day borough of Brooklyn. The only attempt at a peaceful solution to the war took place at the Conference House on Staten Island between American delegates, including Benjamin Franklin, and British general Lord Howe on September 11, 1776.</td>\n",
       "      <td id=\"T_8ceaf_row0_col1\" class=\"data row0 col1\" >enslaved few or several people. Others were hired out to work at labor. Slavery became integrally tied to New York's economy through the labor of slaves throughout the port, and the banking and shipping industries trading with the American South. During construction in Foley Square in the 1990s, the African Burying Ground was discovered; the cemetery included 10,000 to 20,000 of graves of colonial-era Africans, some enslaved and some free.The 1735 trial and acquittal in Manhattan of John Peter Zenger, who had been accused of seditious libel after criticizing colonial governor William Cosby, helped to establish the freedom of the press in North America. In 1754, Columbia University was founded under charter by King George II as King's College in Lower Manhattan.\n",
       "\n",
       "\n",
       "=== American Revolution ===\n",
       "\n",
       "The Stamp Act Congress met in New York in October 1765, as the Sons of Liberty organization emerged in the city and skirmished over the next ten years with British troops stationed there. The Battl...</td>\n",
       "      <td id=\"T_8ceaf_row0_col2\" class=\"data row0 col2\" >YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2490543d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_eval_df(response_vector, eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50895fe4",
   "metadata": {},
   "source": [
    "## Benchmark on Generated Question\n",
    "\n",
    "Now lets generate a few more questions so that we have more to evaluate with and run a small benchmark. In practic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90a8cd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.indices.service_context:chunk_size_limit is deprecated, please specify chunk_size instead\n",
      "chunk_size_limit is deprecated, please specify chunk_size instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is the population of New York City as of 2020?',\n",
       " 'Which borough of New York City has the highest population?',\n",
       " 'What is the economic significance of New York City?',\n",
       " 'How did New York City get its name?',\n",
       " 'What is the significance of the Statue of Liberty in New York City?']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.evaluation import DatasetGenerator\n",
    "\n",
    "question_generator = DatasetGenerator.from_documents(documents)\n",
    "eval_questions = question_generator.generate_questions_from_nodes(5)\n",
    "\n",
    "eval_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "810ee913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "def evaluate_query_engine(query_engine, questions):\n",
    "    c = [query_engine.aquery(q) for q in questions]\n",
    "    results = asyncio.run(asyncio.gather(*c))\n",
    "    print(\"finished query\")\n",
    "\n",
    "    total_correct = 0\n",
    "    for r in results:\n",
    "        # evaluate with gpt 4\n",
    "        eval_result = 1 if evaluator_gpt4.evaluate(r) == \"YES\" else 0\n",
    "        total_correct += eval_result\n",
    "\n",
    "    return total_correct, len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7ca4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=681 request_id=f587e4f416ad0d995a4400bc0a3be400 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=681 request_id=f587e4f416ad0d995a4400bc0a3be400 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1128 request_id=9af1677bef53dc66d8824900c8958b27 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1128 request_id=9af1677bef53dc66d8824900c8958b27 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2529 request_id=a58de27cf52038d452c2df03dd9251cb response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2529 request_id=a58de27cf52038d452c2df03dd9251cb response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=3697 request_id=431e660bf0414265427e4a9728ac9d49 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=3697 request_id=431e660bf0414265427e4a9728ac9d49 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=4373 request_id=7950dfcc95958d4f77f42f894a95f814 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=4373 request_id=7950dfcc95958d4f77f42f894a95f814 response_code=200\n",
      "finished query\n",
      "score: 4/5\n"
     ]
    }
   ],
   "source": [
    "vector_query_engine = vector_index.as_query_engine()\n",
    "correct, total = evaluate_query_engine(vector_query_engine, eval_questions[:5])\n",
    "\n",
    "print(f\"score: {correct}/{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "983503e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [1]/[1]\n",
      ">[Level 1] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [2]/[2]\n",
      ">[Level 1] Selected node: [2]/[2]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [3]/[3]\n",
      ">[Level 0] Selected node: [3]/[3]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [5]/[5]\n",
      ">[Level 1] Selected node: [5]/[5]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [4]/[4]\n",
      ">[Level 1] Selected node: [4]/[4]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [2]/[2]\n",
      ">[Level 0] Selected node: [2]/[2]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [6]/[6]\n",
      ">[Level 1] Selected node: [6]/[6]\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=986 request_id=61f22f53224cc69e668a3cd0a0481e55 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=986 request_id=61f22f53224cc69e668a3cd0a0481e55 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1856 request_id=1a8bda32900f3479b502478a05e393fb response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1856 request_id=1a8bda32900f3479b502478a05e393fb response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2182 request_id=028285e91044f7a6aa3f6111a2939d64 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2182 request_id=028285e91044f7a6aa3f6111a2939d64 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2263 request_id=48b050e0379258a500502520b062f4f1 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2263 request_id=48b050e0379258a500502520b062f4f1 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=9699 request_id=df7b807d143c1d89fbdd62cdd8874add response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=9699 request_id=df7b807d143c1d89fbdd62cdd8874add response_code=200\n",
      "finished query\n",
      "score: 2/5\n"
     ]
    }
   ],
   "source": [
    "tree_query_engine = tree_index.as_query_engine()\n",
    "correct, total = evaluate_query_engine(tree_query_engine, eval_questions[:5])\n",
    "\n",
    "print(f\"score: {correct}/{total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
