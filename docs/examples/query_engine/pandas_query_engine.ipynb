{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8329aae0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/examples/query_engine/pandas_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e45f9b60-cd6b-4c15-958f-1feca5438128",
   "metadata": {},
   "source": [
    "# Pandas Query Engine\n",
    "\n",
    "This guide shows you how to use our `PandasQueryEngine`: convert natural language to Pandas python code using LLMs.\n",
    "\n",
    "The input to the `PandasQueryEngine` is a Pandas dataframe, and the output is a response. The LLM infers dataframe operations to perform in order to retrieve the result.\n",
    "\n",
    "**NOTE**: We have measures in PandasQueryEngine to enforce safety and prevent arbitrary code execution. For instance, no execution of private/dunder methods, and access to a restricted set of globals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a0f96",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119eb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.query_engine import PandasQueryEngine\n",
    "\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ece7d73-0f67-4ff5-95e5-249a25bd118c",
   "metadata": {},
   "source": [
    "## Let's start on a Toy DataFrame\n",
    "\n",
    "Here let's load a very simple dataframe containing city and population pairs, and run the `PandasQueryEngine` on it.\n",
    "\n",
    "By setting `verbose=True` we can see the intermediate generated instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1484fe58-4853-4a76-bffc-435a9cce3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on some sample data\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"city\": [\"Toronto\", \"Tokyo\", \"Berlin\"],\n",
    "        \"population\": [2930000, 13960000, 3645000],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fea2edb-b3d4-4313-a656-d6edb00d93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = PandasQueryEngine(df=df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451836bc-b073-4838-8ab8-3def7d2c4d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df['city'][df['population'].idxmax()]\n",
      "```\n",
      "> Pandas Output: Tokyo\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the city with the highest population?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4253d4c3-f3e5-4779-bcd1-2e6e2818305f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Tokyo</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e10b7da-b355-49b2-9f80-f17541d4f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['city'][df['population'].idxmax()]\n"
     ]
    }
   ],
   "source": [
    "# get pandas python instructions\n",
    "print(response.metadata[\"pandas_instruction_str\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1de5eaf3-6129-47b1-b630-faf9138a04c5",
   "metadata": {},
   "source": [
    "## Analyzing the Titanic Dataset\n",
    "\n",
    "The Titanic dataset is one of the most popular tabular datasets in introductory machine learning\n",
    "Source: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e84f82e",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc2e1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-13 10:23:43--  https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/csv/titanic_train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 57726 (56K) [text/plain]\n",
      "Saving to: â€˜titanic_train.csvâ€™\n",
      "\n",
      "titanic_train.csv   100%[===================>]  56.37K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-01-13 10:23:44 (2.96 MB/s) - â€˜titanic_train.csvâ€™ saved [57726/57726]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/csv/titanic_train.csv' -O 'titanic_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809f18c8-e38b-449e-b5ee-c2ea700f8698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1758de-6310-4ed5-ae02-2dbf50d2c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = PandasQueryEngine(df=df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9dd658d-b62c-4e3b-aee9-0a06f57de032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "> Pandas Instructions:\n",
      "```\n",
      "df['survived'].corr(df['age'])\n",
      "```\n",
      "> Pandas Output: -0.07722109457217755\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the correlation between survival and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60474389-341b-4187-87b2-83811546dcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>-0.07722109457217755</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af999a1f-fea6-4734-82e6-4450f1a06a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['survived'].corr(df['age'])\n"
     ]
    }
   ],
   "source": [
    "# get pandas python instructions\n",
    "print(response.metadata[\"pandas_instruction_str\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1896e6d8-9324-4ea8-a903-bcbd94c5fb4b",
   "metadata": {},
   "source": [
    "## Additional Steps\n",
    "\n",
    "### Analyzing / Modifying prompts\n",
    "\n",
    "Let's look at the prompts! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a4a924d-315a-48e5-a404-f029c8962fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "{df_str}\n",
      "\n",
      "Follow these instructions:\n",
      "{instruction_str}\n",
      "Query: {query_str}\n",
      "\n",
      "Expression:\n"
     ]
    }
   ],
   "source": [
    "query_engine = PandasQueryEngine(df=df, verbose=True)\n",
    "prompts = query_engine.get_prompts()\n",
    "print(prompts[\"pandas_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c561301-3cfe-4d61-86e3-9d43847534f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'response_synthesis_prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_synthesis_prompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtemplate)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'response_synthesis_prompt'"
     ]
    }
   ],
   "source": [
    "print(prompts[\"response_synthesis_prompt\"].template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f95796-2044-4ff4-829c-9c4ff21f924f",
   "metadata": {},
   "source": [
    "This is the instruction string (that you can customize by passing in `instruction_str` on initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0fb52-685e-438b-890a-a88c2cb83292",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = \"\"\"\\\n",
    "1. Convert the query to executable Python code using Pandas.\n",
    "2. The final line of code should be a Python expression that can be called with the `eval()` function.\n",
    "3. The code should represent a solution to the query.\n",
    "4. PRINT ONLY THE EXPRESSION.\n",
    "5. Do not quote the expression.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30b563-ba0d-445f-83e9-46a8f480a83a",
   "metadata": {},
   "source": [
    "You can update it as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0118dfb-80e2-40d2-88dc-b8f6c62d786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = PromptTemplate(\"\"\"\\\n",
    "You are working with a pandas dataframe in Python.\n",
    "The name of the dataframe is `df`.\n",
    "This is the result of `print(df.head())`:\n",
    "{df_str}\n",
    "\n",
    "Follow these instructions:\n",
    "{instruction_str}\n",
    "Query: {query_str}\n",
    "\n",
    "Expression: \"\"\")\n",
    "\n",
    "query_engine.update_prompts({\"pandas_prompt\": new_prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c78a8e-d3ff-4c0e-b8c3-7fc79de83839",
   "metadata": {},
   "source": [
    "### Implementing Query Engine using Query Pipeline Syntax\n",
    "\n",
    "Here we show you how to construct the Pandas Query Engine using our Query Pipeline syntax and the prompt components above. This gives you a greater overview of the underlying components.\n",
    "\n",
    "TODO: move this to separate notebook under pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "662a7e43-dbc3-45c9-8fa0-15b18a897f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_pipeline import QueryPipeline as QP, Link\n",
    "from llama_index.query_engine.pandas import PandasInstructionParser\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53e642-afca-485e-91fd-43c220ea741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_prompt = prompts[\"pandas_prompt\"].partial(\n",
    "    instruction_str=instruction_str,\n",
    "    df_str=df.head(5)\n",
    ")\n",
    "response_synthesis_prompt = prompts[\"response_synthesis_prompt\"].partial(\n",
    "    \n",
    ")\n",
    "pandas_output_parser = PandasInstructionParser(df)\n",
    "\n",
    "\n",
    "qp = QueryPipeline(modules={\n",
    "    \"pandas_prompt\": pandas_prompt,\n",
    "    \"llm1\": llm,\n",
    "    \"pandas_output_parser\": pandas_output_parser,\n",
    "    \"response_synthesis_prompt\": response_synthesis_prompt,    \n",
    "})\n",
    "qp.add_chain([\"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "qp.add_links(\n",
    "    Link(\"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instruction\"),\n",
    "    Link(\"pandas_output_parser\", \"response_synthesis_prompt\", dest_key=\"pandas_output\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2975330-665f-4a09-bbc1-61276091aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qp.run(query_str=\"What is the correlation between survival and age?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
