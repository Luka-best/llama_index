{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645ef724-bba9-4d9d-89b0-a470dbfb1713",
   "metadata": {},
   "source": [
    "# Building a Router from Scratch\n",
    "\n",
    "In this tutorial, we show you how to build an LLM-powered router module that can route a user query to submodules.\n",
    "\n",
    "Routers are a simple but effective form of automated decision making that can allowing you to perform dynamic retrieval/querying over your data.\n",
    "\n",
    "In LlamaIndex, this is abstracted away with our [Router Modules](https://gpt-index.readthedocs.io/en/latest/core_modules/query_modules/router/root.html).\n",
    "\n",
    "To build a router, we'll walk through the following steps:\n",
    "- Crafting an initial prompt to select a set of choices\n",
    "- Enforcing structured output (for text completion endpoints)\n",
    "- Try integrating with a native function calling endpoint.\n",
    "\n",
    "And then we'll plug this into a RAG pipeline to dynamically make decisions on QA vs. summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b2770-a695-48dc-88e8-371cf0a7d7d0",
   "metadata": {},
   "source": [
    "## 1. Setup a Basic Router Prompt\n",
    "\n",
    "At its core, a router is a module that takes in a set of choices. Given a user query, it \"selects\" a relevant choice.\n",
    "\n",
    "For simplicity, we'll start with the choices as a set of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219698e6-0413-4bfa-bbbe-92a8ea38507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import PromptTemplate\n",
    "\n",
    "choices = [\n",
    "    \"Useful for questions related to apples\", \n",
    "    \"Useful for questions related to oranges\"\n",
    "]\n",
    "\n",
    "choices_str = \"\\n\\n\".join(choices)\n",
    "\n",
    "router_prompt0 = PromptTemplate(\n",
    "    \"Some choices are given below. It is provided in a numbered \"\n",
    "    \"list (1 to {num_choices}), \"\n",
    "    \"where each item in the list corresponds to a summary.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_list}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Using only the choices above and not prior knowledge, return the top choices \"\n",
    "    \"(no more than {max_outputs}, but only select what is needed) that \"\n",
    "    \"are most relevant to the question: '{query_str}'\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe20cf42-8f36-4b65-a4c2-3f0bd6895383",
   "metadata": {},
   "source": [
    "Let's try this prompt on a set of toy questions and see what the output brings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929a238e-1271-4a18-9f3c-da8a9cd9b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8367510f-91e5-4509-a228-4becdb222edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_prompt(query_str):\n",
    "    fmt_prompt = router_prompt0.format(\n",
    "        num_choices=len(choices),\n",
    "        max_outputs=2,\n",
    "        context_list=choices_str,\n",
    "        query_str=query_str\n",
    "    )\n",
    "    return fmt_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c8fc9c-5fdc-4ab6-90c5-f36031420d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"Can you tell me more about the amount of Vitamin C in apples\"\n",
    "fmt_prompt = get_formatted_prompt(query_str)\n",
    "response = llm.complete(fmt_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47800333-92ea-4cb3-8e11-2d795a635fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Useful for questions related to apples\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c111863-ea12-409c-9777-d3d387126601",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What are the health benefits of eating orange peels?\"\n",
    "fmt_prompt = get_formatted_prompt(query_str)\n",
    "response = llm.complete(fmt_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc70519-1805-4899-a4d4-a22cd49847c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful for questions related to oranges\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100f6664-3bef-4f5a-89e8-6c66a5d687b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"Can you tell me more about the amount of Vitamin C in apples and oranges.\"\n",
    "fmt_prompt = get_formatted_prompt(query_str)\n",
    "response = llm.complete(fmt_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1548044f-a0cd-4b3e-8678-4e49a97acdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Useful for questions related to apples\n",
      "2. Useful for questions related to oranges\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39f574-af06-495a-83e0-50866aca9caf",
   "metadata": {},
   "source": [
    "**Observation**: While the response corresopnds to the correct choice, it is hard to parse into a structured output. For instance, the second query doesn't even return a number corresponding to the choice (while the first and third queries do). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4cfd8-a515-4613-9f43-92563c14c846",
   "metadata": {},
   "source": [
    "## 2. A Router Prompt that can generate structured outputs\n",
    "\n",
    "Therefore the next step is to try to prompt the model to output a more structured representation (JSON). \n",
    "\n",
    "We define an output parser class (`RouterOutputParser`). This output parser will be responsible for both formatting the prompt and also parsing the result into a structured object (an `Answer`).\n",
    "\n",
    "We then apply the `format` and `parse` methods of the output parser around the LLM call using the router prompt to generate a structured output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e2fb0-aa18-45c1-a8fe-0ff7124eddc1",
   "metadata": {},
   "source": [
    "### 2.a Import Answer Class\n",
    "\n",
    "We load in the Answer class from our codebase. It's a very simple dataclass with two fields: `choice` and `reason`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd0b6408-da38-494e-be00-d2ab0f1a9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import fields\n",
    "from pydantic import BaseModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ecea17b-bbf8-4a33-9252-dc53c74cbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Answer(BaseModel):\n",
    "    choice: int\n",
    "    reason: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fa49cf5-b892-4834-a783-0f107cbafcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Answer\",\n",
      "  \"type\": \"object\",\n",
      "  \"properties\": {\n",
      "    \"choice\": {\n",
      "      \"title\": \"Choice\",\n",
      "      \"type\": \"integer\"\n",
      "    },\n",
      "    \"reason\": {\n",
      "      \"title\": \"Reason\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"choice\",\n",
      "    \"reason\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(Answer.schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e23bc5-0fc1-4da5-b5bc-4220f205d0e1",
   "metadata": {},
   "source": [
    "### 2.b Define Router Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585a9a25-0e9f-4da0-aa80-562fd0bb17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.types import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "166b80df-5736-432c-b49b-03f7450ed524",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT_STR = \"\"\"The output should be formatted as a JSON instance that conforms to \n",
    "the JSON schema below. \n",
    "\n",
    "Here is the output schema:\n",
    "{\n",
    "  \"type\": \"array\",\n",
    "  \"items\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"choice\": {\n",
    "        \"type\": \"integer\"\n",
    "      },\n",
    "      \"reason\": {\n",
    "        \"type\": \"string\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\n",
    "      \"choice\",\n",
    "      \"reason\"\n",
    "    ],\n",
    "    \"additionalProperties\": false\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a089d844-e989-44ea-9908-846bc6e7d584",
   "metadata": {},
   "source": [
    "If we want to put `FORMAT_STR` as part of an f-string as part of a prompt template, then we'll need to escape the curly braces so that they don't get treated as template variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74614e7a-2314-4702-8918-47cd4ec378bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _escape_curly_braces(input_string: str) -> str:\n",
    "    # Replace '{' with '{{' and '}' with '}}' to escape curly braces\n",
    "    escaped_string = input_string.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    return escaped_string\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657b5d2-ac58-46bd-a3c2-bd0021788814",
   "metadata": {},
   "source": [
    "We now define a simple parsing function to extract out the JSON string from the LLM response (by searching for square brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3c0c59-f72a-4003-b850-58bd81b5bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _marshal_output_to_json(output: str) -> str:\n",
    "    output = output.strip()\n",
    "    left = output.find(\"[\")\n",
    "    right = output.find(\"]\")\n",
    "    output = output[left : right + 1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d8db4d-475a-4fbf-8025-b2eae468b028",
   "metadata": {},
   "source": [
    "We put these together in our `RouterOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c04a83fe-624e-48fd-9dc3-f4aa85fb335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class RouterOutputParser(BaseOutputParser):\n",
    "    def parse(self, output: str) -> List[Answer]:\n",
    "        \"\"\"Parse string.\"\"\"\n",
    "        json_output = _marshal_output_to_json(output)\n",
    "        json_dicts = json.loads(json_output)\n",
    "        answers = [Answer.from_dict(json_dict) for json_dict in json_dicts]\n",
    "        return answers\n",
    "\n",
    "    def format(self, prompt_template: str) -> str:\n",
    "        return prompt_template + \"\\n\\n\" + _escape_curly_braces(FORMAT_STR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c20c8fe-9f73-41a7-9760-b2559d475769",
   "metadata": {},
   "source": [
    "### 2.c Give it a Try\n",
    "\n",
    "We create a function called `route_query` that will take in the output parser, llm, and prompt template and output a structured answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46126685-a108-4404-9307-73de5f51a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = RouterOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e67dfd6-42a0-4818-8642-6999748843bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RouterOutputParser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroute_query\u001b[39m(\n\u001b[1;32m      4\u001b[0m     query_str: \u001b[38;5;28mstr\u001b[39m, \n\u001b[1;32m      5\u001b[0m     choices: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m----> 6\u001b[0m     output_parser: \u001b[43mRouterOutputParser\u001b[49m\n\u001b[1;32m      7\u001b[0m ):\n\u001b[1;32m      8\u001b[0m     choices_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(choices)\n\u001b[1;32m     10\u001b[0m     fmt_base_prompt \u001b[38;5;241m=\u001b[39m router_prompt0\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     11\u001b[0m         num_choices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(choices),\n\u001b[1;32m     12\u001b[0m         max_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(choices),\n\u001b[1;32m     13\u001b[0m         context_list\u001b[38;5;241m=\u001b[39mchoices_str,\n\u001b[1;32m     14\u001b[0m         query_str\u001b[38;5;241m=\u001b[39mquery_str\n\u001b[1;32m     15\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RouterOutputParser' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def route_query(\n",
    "    query_str: str, \n",
    "    choices: List[str],\n",
    "    output_parser: RouterOutputParser\n",
    "):\n",
    "    choices_str = \"\\n\\n\".join(choices)\n",
    "    \n",
    "    fmt_base_prompt = router_prompt0.format(\n",
    "        num_choices=len(choices),\n",
    "        max_outputs=len(choices),\n",
    "        context_list=choices_str,\n",
    "        query_str=query_str\n",
    "    )\n",
    "    fmt_json_prompt = output_parser.format(fmt_base_prompt)\n",
    "    \n",
    "    raw_output = llm.complete(fmt_json_prompt)\n",
    "    parsed = output_parser.parse(str(raw_output))\n",
    "\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c0b4b-336e-4550-a4b6-950a141f1b57",
   "metadata": {},
   "source": [
    "## 3. Perform Routing with a Function Calling Endpoint\n",
    "\n",
    "In the previous section, we showed how to build a router with a text completion endpoint. This includes formatting the prompt to encourage the model output structured JSON, and a parse function to load in JSON.\n",
    "\n",
    "This process can feel a bit messy. Function calling endpoints (e.g. OpenAI) abstract away this complexity by allowing the model to natively output structured functions. This obviates the need to manually prompt + parse the outputs. \n",
    "\n",
    "LlamaIndex offers an abstraction called a `PydanticProgram` that integrates with a function endpoint to produce a structured Pydantic object. We integrate with OpenAI and Guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb461a-5c64-4efe-b36b-f02bef414e9e",
   "metadata": {},
   "source": [
    "We redefine our `Answer` class with annotations, as well as an `Answers` class containing a list of answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a62bb36-b64f-4900-a89c-ddfc39afbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    \"Represents a single choice with a reason.\"\"\"\n",
    "    choice: int\n",
    "    reason: str\n",
    "\n",
    "class Answers(BaseModel):\n",
    "    \"\"\"Represents a list of answers.\"\"\"\n",
    "    answers: List[Answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c32cc480-4d10-4a67-90f0-ee8cc002a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Answers',\n",
       " 'description': 'Represents a list of answers.',\n",
       " 'type': 'object',\n",
       " 'properties': {'answers': {'title': 'Answers',\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/Answer'}}},\n",
       " 'required': ['answers'],\n",
       " 'definitions': {'Answer': {'title': 'Answer',\n",
       "   'description': 'Represents a choice.',\n",
       "   'type': 'object',\n",
       "   'properties': {'choice': {'title': 'Choice', 'type': 'integer'},\n",
       "    'reason': {'title': 'Reason', 'type': 'string'}},\n",
       "   'required': ['choice', 'reason']}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Answers.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c65d01c-b56e-49ae-89c6-268d29bb25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.program import OpenAIPydanticProgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d6f7879-b3f6-4f65-94df-e2ac2edc0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt1 = router_prompt0.partial_format(\n",
    "    num_choices=len(choices),\n",
    "    max_outputs=len(choices),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acae0e8c-442e-43f5-9753-bd1afff12ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "program = OpenAIPydanticProgram.from_defaults(\n",
    "    output_cls=Answers,\n",
    "    prompt=router_prompt1,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a44e079d-545c-4a75-abc2-409e8fd5c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function call: Answers with args: {\n",
      "  \"answers\": [\n",
      "    {\n",
      "      \"choice\": 2,\n",
      "      \"reason\": \"Useful for questions related to oranges\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query_str = \"What are the health benefits of eating orange peels?\"\n",
    "output = program(\n",
    "    context_list=choices_str,\n",
    "    query_str=query_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d914bf0e-a1ec-49cf-adfd-3636c536908e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answers(answers=[Answer(choice=2, reason='Useful for questions related to oranges')])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1e1ce-6075-4655-9c6c-3882806da483",
   "metadata": {},
   "source": [
    "## 4. Plug Router Module as part of a RAG pipeline\n",
    "\n",
    "In this section we'll put the router module to use in a RAG pipeline. We'll use it to dynamically decide whether to perform question-answering or summarization. Question-answering is performed through vector index retrieval, while summarization is performed through our summary index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf6b37-31de-4c23-9e85-9cbfb732b591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
