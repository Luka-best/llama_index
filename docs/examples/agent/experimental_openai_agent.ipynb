{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build your own OpenAI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e",
   "metadata": {
    "tags": []
   },
   "source": [
    "With the [new OpenAI API](https://openai.com/blog/function-calling-and-other-api-updates) that supports function calling, it's never been easier to build your own agent!\n",
    "\n",
    "In this notebook tutorial, we showcase how to write your own OpenAI agent in **under 50 lines of code**! It is minimal, yet feature complete (with ability to carry on a conversation and use tools)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initial Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f",
   "metadata": {},
   "source": [
    "Let's start by importing some simple building blocks.  \n",
    "\n",
    "The main thing we need is:\n",
    "1. the OpenAI API (using our own `llama_index` LLM class)\n",
    "2. a place to keep conversation history \n",
    "3. a definition for tools that our agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d47283b-025e-4874-88ed-76245b22f82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Sequence, List\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms import OpenAI, ChatMessage\n",
    "from llama_index.tools import BaseTool, FunctionTool\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "load_dotenv(\"../../../.env\")\n",
    "assert (key := os.getenv(\"OPENAI_API_KEY\")); openai.api_key = key\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe08eb1-e638-4c00-9103-5c305bfacccf",
   "metadata": {},
   "source": [
    "Let's define some very simple calculator tools for our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd3c4a6-f3e0-46f9-ad3b-7ba57d1bc992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfcfb78b-7d4f-48d9-8d4c-ffcded23e7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d30b8-6405-4187-a9ed-6146dcc42167",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Our (Slightly Better) `OpenAIAgent` Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ca3fd-6711-4c0c-a853-d868dd14b484",
   "metadata": {},
   "source": [
    "We provide a (slightly better) `OpenAIAgent` implementation in LlamaIndex, which you can directly use as follows.  \n",
    "\n",
    "In comparison to the simplified version above:\n",
    "* it implements the `BaseChatEngine` and `BaseQueryEngine` interface, so you can more seamlessly use it in the LlamaIndex framework. \n",
    "* it supports multiple function calls per conversation turn\n",
    "* it supports streaming\n",
    "* it supports async endpoints\n",
    "* it supports callback and tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ab3938-1138-43ea-b085-f430b42f5377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.agent.experimental_openai_agent import (\n",
    "    ExperimentalOpenAIAgent, ChatStreamHandler\n",
    ")\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d852ece7-e5a1-4368-9d59-c7014e0b5b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "agent = OpenAIAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\n",
    "csh = ChatStreamHandler(llm)\n",
    "exp_agent = ExperimentalOpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool],\n",
    "    llm=llm,\n",
    "    stream_handler=csh,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89daf1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a random name: \"Elijah\"\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Tell me a random name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a00c606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name \"Elijah\" spelled backwards is \"hjaile\".\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Now tell me that name backwards.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce34cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 3\n",
      "}\n",
      "Got output: 363\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: add with args: {\n",
      "  \"a\": 363,\n",
      "  \"b\": 42\n",
      "}\n",
      "Got output: 405\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "response = exp_agent.chat(\"What is (121 * 3) + 42?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500cbee4",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fd1cad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 3\n",
      "}\n",
      "Got output: 363\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: add with args: {\n",
      "  \"a\": 363,\n",
      "  \"b\": 42\n",
      "}\n",
      "Got output: 405\n",
      "========================\n",
      "(121 * 3) + 42 is equal to 405.\n"
     ]
    }
   ],
   "source": [
    "response = exp_agent.chat(\"What is (121 * 3) + 42?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "538bf32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolOutput(content='363', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 121, 'b': 3}}, raw_output=363), ToolOutput(content='405', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 363, 'b': 42}}, raw_output=405)]\n"
     ]
    }
   ],
   "source": [
    "# inspect sources\n",
    "print(response.sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33983c",
   "metadata": {},
   "source": [
    "### Async Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d1fc974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 3\n",
      "}\n",
      "Got output: 363\n",
      "========================\n",
      "121 multiplied by 3 is equal to 363.\n"
     ]
    }
   ],
   "source": [
    "response = await exp_agent.achat(\"What is 121 * 3?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae035cb",
   "metadata": {},
   "source": [
    "### Streaming Chat\n",
    "Here, every LLM response is returned as a generator. You can stream every incremental step, or only the last response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14217fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 2\n",
      "}\n",
      "Got output: 242\n",
      "========================\n",
      "The answer to 121 multiplied by 2 is 242.\n",
      "\n",
      "Once upon a time, in a cozy little village, there was a group of 242 mice who lived harmoniously in a charming mouse hole. These mice were not your ordinary mice; they were known for their intelligence and resourcefulness.\n",
      "\n",
      "The leader of the mouse group was a wise and courageous mouse named Milo. Milo was admired by all the mice for his ability to solve problems and lead the group through any challenge they faced. Under his guidance, the mice formed a tight-knit community, working together to ensure their survival and happiness.\n",
      "\n",
      "Every day, the mice would venture out of their mouse hole in search of food and adventure. They would scurry through fields, climb trees, and explore every nook and cranny of their village. Despite their small size, the mice were determined and fearless, always ready to overcome any obstacle that came their way.\n",
      "\n",
      "One day, a severe drought struck the village, causing a shortage of food for both the mice and the other animals. The mice knew they had to find a solution to feed their community. Milo called for a meeting and shared his plan with the group.\n",
      "\n",
      "Using their collective intelligence, the mice devised a plan to gather food from the nearby farms without being noticed by the humans. They would work in teams, carefully navigating through the fields and collecting grains, seeds, and vegetables to sustain their community.\n",
      "\n",
      "Each night, the mice would set out on their mission, using their agility and stealth to avoid detection. They would carry small portions of food back to their mouse hole, ensuring that everyone had enough to eat. The mice worked tirelessly, never giving up despite the challenges they faced.\n",
      "\n",
      "As the days went by, the mice's efforts paid off. The village mice not only managed to feed themselves but also shared their surplus with other animals in need. Their selflessness and determination inspired the entire village, and soon, other animals joined forces to support the mice in their mission.\n",
      "\n",
      "The mice became a symbol of unity and resilience, showing that even the smallest creatures can make a significant impact when they work together. Their story spread far and wide, inspiring other communities to come together and face their own challenges head-on.\n",
      "\n",
      "And so, the group of 242 mice became legends in their village, forever remembered for their bravery, intelligence, and unwavering spirit. Their story serves as a reminder that no matter how small we may be, we can achieve great things when we work together towards a common goal."
     ]
    }
   ],
   "source": [
    "response = agent.stream_chat(\n",
    "    \"What is 121 * 2? Once you have the answer, use that number to write a story about a group of mice.\"\n",
    ")\n",
    "\n",
    "response_gen = response.response_gen\n",
    "\n",
    "for token in response_gen:\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac119f",
   "metadata": {},
   "source": [
    "### Async Streaming Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33ea069f-819b-4ec1-a93c-fcbaacb362a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: add with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 8\n",
      "}\n",
      "Got output: 129\n",
      "========================\n",
      "The answer to 121 plus 8 is 129.\n",
      "\n",
      "Once upon a time, in a lush green meadow, there was a group of 129 mice who lived in perfect harmony. These mice were known for their adventurous spirit and their love for exploration.\n",
      "\n",
      "The leader of the mouse group was a wise and charismatic mouse named Oliver. Oliver was respected by all the mice for his knowledge and ability to guide the group through any challenge they encountered. Under his leadership, the mice formed a close-knit community, always looking out for one another.\n",
      "\n",
      "Every day, the mice would embark on exciting expeditions, venturing into the unknown corners of the meadow. They would scurry through tall grasses, climb trees, and navigate through intricate tunnels, always eager to discover new places and treasures.\n",
      "\n",
      "One sunny morning, as the mice were exploring a dense thicket, they stumbled upon a hidden treasure chest. The chest was filled with sparkling jewels, golden coins, and precious artifacts. The mice were amazed by the sight and knew they had stumbled upon something extraordinary.\n",
      "\n",
      "Oliver called for a meeting and proposed a plan to share the treasure among all the mice. He believed that the treasure should be used to improve the lives of the entire mouse community. The mice agreed, and together they devised a fair distribution system.\n",
      "\n",
      "Each mouse was assigned a specific task to contribute to the well-being of the group. Some mice became expert foragers, gathering food and supplies for everyone. Others used their nimble paws to build cozy nests and shelters. Some mice took on the role of educators, teaching the younger ones valuable skills and knowledge.\n",
      "\n",
      "With the newfound wealth, the mice were able to create a thriving community. They built a grand mouse mansion, complete with multiple levels and intricate tunnels. The mice enjoyed a life of comfort and security, always grateful for the treasure that had brought them together.\n",
      "\n",
      "But the mice didn't keep all the treasure to themselves. They also used a portion of it to help other animals in need. They established a charity fund to provide food and shelter for those less fortunate, spreading kindness and compassion throughout the meadow.\n",
      "\n",
      "Word of the generous and resourceful mice spread far and wide. Other animals were inspired by their actions and began working together to create a harmonious and supportive community. The mice became ambassadors of unity and cooperation, showing that even the smallest creatures can make a big difference when they come together.\n",
      "\n",
      "And so, the group of 129 mice lived happily ever after, their story serving as a reminder that unity, kindness, and shared resources can create a world where everyone thrives."
     ]
    }
   ],
   "source": [
    "response = await agent.astream_chat(\n",
    "    \"What is 121 + 8? Once you have the answer, use that number to write a story about a group of mice.\"\n",
    ")\n",
    "\n",
    "response_gen = response.response_gen\n",
    "\n",
    "for token in response_gen:\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe399c5-6d07-4926-b701-b612efd56b30",
   "metadata": {},
   "source": [
    "### Agent with Personality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47c034-f948-4604-a8d8-828b617ea245",
   "metadata": {},
   "source": [
    "You can specify a system prompt to give the agent additional instruction or personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef36d1e-c26e-4b07-b3d0-3b7f314a45f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.prompts.system import SHAKESPEARE_WRITING_ASSISTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7fa46-1173-42f2-885c-0cc28df1cd2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    system_prompt=SHAKESPEARE_WRITING_ASSISTANT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4841778-7008-4b61-afcc-995b6b64e91a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = agent.chat(\"Hi\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a83768-1203-4485-a346-2fa78089afb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = agent.chat(\"Tell me a story\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c322b-bf5d-4140-9dcf-341062a4151b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
