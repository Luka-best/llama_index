{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build your own OpenAI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e",
   "metadata": {
    "tags": []
   },
   "source": [
    "With the [new OpenAI API](https://openai.com/blog/function-calling-and-other-api-updates) that supports function calling, it's never been easier to build your own agent!\n",
    "\n",
    "In this notebook tutorial, we showcase how to write your own OpenAI agent in **under 50 lines of code**! It is minimal, yet feature complete (with ability to carry on a conversation and use tools)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initial Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f",
   "metadata": {},
   "source": [
    "Let's start by importing some simple building blocks.  \n",
    "\n",
    "The main thing we need is:\n",
    "1. the OpenAI API (using our own `llama_index` LLM class)\n",
    "2. a place to keep conversation history \n",
    "3. a definition for tools that our agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47283b-025e-4874-88ed-76245b22f82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import logging\n",
    "from typing import Sequence, List\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms import OpenAI, ChatMessage\n",
    "from llama_index.tools import BaseTool, FunctionTool\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "level = logging.WARNING\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=level)\n",
    "logger.setLevel(level)\n",
    "logging.getLogger(\"llama_index\").setLevel(level)\n",
    "logging.getLogger(\"asyncio\").setLevel(level)\n",
    "\n",
    "load_dotenv(\"../../../.env\")\n",
    "assert (key := os.getenv(\"OPENAI_API_KEY\")); openai.api_key = key\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe08eb1-e638-4c00-9103-5c305bfacccf",
   "metadata": {},
   "source": [
    "Let's define some very simple calculator tools for our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3c4a6-f3e0-46f9-ad3b-7ba57d1bc992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcfb78b-7d4f-48d9-8d4c-ffcded23e7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d30b8-6405-4187-a9ed-6146dcc42167",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Our (Slightly Better) `OpenAIAgent` Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ca3fd-6711-4c0c-a853-d868dd14b484",
   "metadata": {},
   "source": [
    "We provide a (slightly better) `OpenAIAgent` implementation in LlamaIndex, which you can directly use as follows.  \n",
    "\n",
    "In comparison to the simplified version above:\n",
    "* it implements the `BaseChatEngine` and `BaseQueryEngine` interface, so you can more seamlessly use it in the LlamaIndex framework. \n",
    "* it supports multiple function calls per conversation turn\n",
    "* it supports streaming\n",
    "* it supports async endpoints\n",
    "* it supports callback and tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab3938-1138-43ea-b085-f430b42f5377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.agent.experimental_openai_agent import (\n",
    "    ExperimentalOpenAIAgent\n",
    ")\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852ece7-e5a1-4368-9d59-c7014e0b5b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "agent = OpenAIAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\n",
    "exp_agent = ExperimentalOpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89daf1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(agent.chat(\"Tell me a random name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(agent.chat(\"Now tell me that name backwards.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce34cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = exp_agent.chat(\"What is (121 * 3) + 42?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500cbee4",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = exp_agent.chat(\"What is (121 * 3) + 42?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bf32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect sources\n",
    "print(response.sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33983c",
   "metadata": {},
   "source": [
    "### Async Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await exp_agent.achat(\"What is 121 * 3?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae035cb",
   "metadata": {},
   "source": [
    "### Streaming Chat\n",
    "Here, every LLM response is returned as a generator. You can stream every incremental step, or only the last response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dca9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.experimental_openai_agent import logger as _logger\n",
    "assert logging.getLogger(\"llama_index.agent.experimental_openai_agent\") is _logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e5a951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 2\n",
      "}\n",
      "Got output: 242\n",
      "========================\n",
      "In a world of whiskers and tiny paws,\n",
      "There lived a group of mice, without a cause.\n",
      "With fur so soft and eyes so bright,\n",
      "They scurried and played, day and night.\n",
      "\n",
      "Two hundred and forty-two, their number strong,\n",
      "They danced and frolicked, a joyful throng.\n",
      "Through fields of wheat and meadows green,\n",
      "They explored the world, a sight unseen.\n",
      "\n",
      "With nimble feet and curious minds,\n",
      "They ventured far, leaving no trace behind.\n",
      "In search of cheese and crumbs to eat,\n",
      "They braved the darkness, their hearts replete.\n",
      "\n",
      "Each mouse unique, with its own tale,\n",
      "From timid to bold, they would prevail.\n",
      "They built their nests in hidden nooks,\n",
      "Safe from predators, with secret looks.\n",
      "\n",
      "Their tiny voices, a chorus of glee,\n",
      "Echoed through the night, wild and free.\n",
      "They sang of friendship and unity,\n",
      "A testament to their community.\n",
      "\n",
      "Oh, the tales they wove, of daring feats,\n",
      "Of narrow escapes and stolen treats.\n",
      "With each passing day, their bond grew strong,\n",
      "A family of mice, where they belong.\n",
      "\n",
      "So let us celebrate these creatures small,\n",
      "With hearts so big, they conquer all.\n",
      "Two hundred and forty-two, their legacy,\n",
      "A reminder of the power of unity."
     ]
    }
   ],
   "source": [
    "response = agent.stream_chat(\n",
    "    \"What is 121 * 2? Once you have the answer, use that number to write a poem about a group of mice.\"\n",
    ")\n",
    "\n",
    "response_gen = response.response_gen\n",
    "\n",
    "for ix, token in enumerate(response_gen):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14217fb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 2\n",
      "}\n",
      "Got output: 242\n",
      "========================\n",
      "In a world of whiskers and tiny paws,\n",
      "A group of mice scurried without pause.\n",
      "With hearts so brave and spirits so free,\n",
      "They embarked on adventures, a sight to see.\n",
      "\n",
      "Two hundred and forty-two, their number strong,\n",
      "They journeyed together, a lively throng.\n",
      "Through fields and forests, they would roam,\n",
      "Exploring the world, finding a home.\n",
      "\n",
      "In meadows of green and flowers so bright,\n",
      "They danced and played, day and night.\n",
      "Their tiny footsteps left trails in the dew,\n",
      "As they chased dreams that were bold and true.\n",
      "\n",
      "With curiosity as their guiding light,\n",
      "They discovered wonders, hidden from sight.\n",
      "From secret tunnels to hidden nooks,\n",
      "They explored every corner, like curious books.\n",
      "\n",
      "Each mouse unique, with its own tale,\n",
      "From timid whispers to adventures on a grand scale.\n",
      "They shared laughter and tears, joys and fears,\n",
      "Creating memories that would last for years.\n",
      "\n",
      "Two hundred and forty-two, a family so tight,\n",
      "They faced challenges with all their might.\n",
      "Through thick and thin, they stood as one,\n",
      "Supporting each other, until the day was done.\n",
      "\n",
      "And as the moon shone upon their path,\n",
      "They celebrated life, with a joyful laugh.\n",
      "For in their unity, they found their strength,\n",
      "A bond that would endure, at any length.\n",
      "\n",
      "So let us raise a toast to these mice,\n",
      "With hearts so pure and full of spice.\n",
      "Two hundred and forty-two, a number divine,\n",
      "A group of mice, forever intertwined."
     ]
    }
   ],
   "source": [
    "response = exp_agent.stream_chat(\n",
    "    \"What is 121 * 2? Once you have the answer, use that number to write a poem about a group of mice.\"\n",
    ")\n",
    "\n",
    "response_gen = response.response_gen\n",
    "\n",
    "for ix, token in enumerate(response_gen):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac119f",
   "metadata": {},
   "source": [
    "### Async Streaming Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2c4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea069f-819b-4ec1-a93c-fcbaacb362a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.chat_engine.types:awrite response to hist\n",
      "WARNING:llama_index.chat_engine.types:delta: \n",
      "WARNING:llama_index.chat_engine.types:msg: assistant: \n",
      "WARNING:llama_index.chat_engine.types:delta: \n",
      "WARNING:llama_index.chat_engine.types:msg: assistant: \n",
      "WARNING:llama_index.chat_engine.types:delta: \n",
      "WARNING:llama_index.chat_engine.types:msg: assistant: \n",
      "WARNING:llama_index.chat_engine.types:delta: \n",
      "WARNING:llama_index.chat_engine.types:msg: assistant: \n"
     ]
    }
   ],
   "source": [
    "response = await exp_agent.astream_chat(\n",
    "    \"What is 121 * 2 + 8? Once you have the answer, use that number to write a limerick about a group of mice.\"\n",
    ")\n",
    "\n",
    "response_gen = response.response_gen\n",
    "\n",
    "for token in response_gen:\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe399c5-6d07-4926-b701-b612efd56b30",
   "metadata": {},
   "source": [
    "### Agent with Personality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47c034-f948-4604-a8d8-828b617ea245",
   "metadata": {},
   "source": [
    "You can specify a system prompt to give the agent additional instruction or personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef36d1e-c26e-4b07-b3d0-3b7f314a45f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.prompts.system import SHAKESPEARE_WRITING_ASSISTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7fa46-1173-42f2-885c-0cc28df1cd2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    system_prompt=SHAKESPEARE_WRITING_ASSISTANT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4841778-7008-4b61-afcc-995b6b64e91a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = agent.chat(\"Hi\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a83768-1203-4485-a346-2fa78089afb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = agent.chat(\"Tell me a story\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c322b-bf5d-4140-9dcf-341062a4151b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
