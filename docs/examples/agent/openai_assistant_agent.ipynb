{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {},
   "source": [
    "# OpenAI Assistant Agent\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This shows you how to use our agent abstractions built on top of the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc",
   "metadata": {},
   "source": [
    "## Simple Agent (no external tools)\n",
    "\n",
    "Here we show a simple example with the built-in code interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f",
   "metadata": {},
   "source": [
    "Let's start by importing some simple building blocks.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41101795",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f856af7-2f11-446a-9aef-21d68ddf2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAssistantAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b6fe26-0bdd-44ab-a887-9525dbc85f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantAgent.from_new(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    openai_tools=[{\"type\": \"code_interpreter\"}],\n",
    "    instructions_prefix=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40da2dd6-0872-4179-bbc1-33dfbb6c2b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_ctzN0ZY3JUWETHhYxI3DiFSo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._thread_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0433d6-d662-4d9c-a087-d2052269c4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_SoUGr1TrDXi0DnnpSr8IvRSW', assistant_id='asst_NVZU7Lw5ANydjbyAo9IZ1TEZ', content=[MessageContentText(text=Text(annotations=[], value='Certainly! To solve the equation \\\\( 3x + 11 = 14 \\\\), you would subtract 11 from both sides of the equation to isolate the term with \\\\( x \\\\), which gives you \\\\( 3x = 3 \\\\). Then, you would divide both sides by 3 to solve for \\\\( x \\\\), which gives \\\\( x = 1 \\\\).\\n\\nSo, the solution to the equation \\\\( 3x + 11 = 14 \\\\) is \\\\( x = 1 \\\\).'), type='text')], created_at=1699342119, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_a5F7i662WjPfs0ZoGOo4cAtT', thread_id='thread_ctzN0ZY3JUWETHhYxI3DiFSo'), ThreadMessage(id='msg_IdL880TyzZ83Cp1FkWc1UdLv', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1699342114, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_ctzN0ZY3JUWETHhYxI3DiFSo')], object='list', first_id='msg_SoUGr1TrDXi0DnnpSr8IvRSW', last_id='msg_IdL880TyzZ83Cp1FkWc1UdLv', has_more=False)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI need to solve the equation `3x + 11 = 14`. Can you help me?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/callbacks/utils.py:39\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_assistant_agent.py:292\u001b[0m, in \u001b[0;36mOpenAIAssistantAgent.chat\u001b[0;34m(self, message, chat_history, function_call)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     function_call: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentChatResponse:\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    289\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mAGENT_STEP,\n\u001b[1;32m    290\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mMESSAGES: [message]},\n\u001b[1;32m    291\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 292\u001b[0m         chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatResponseMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWAIT\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[1;32m    296\u001b[0m         e\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: chat_response})\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_assistant_agent.py:264\u001b[0m, in \u001b[0;36mOpenAIAssistantAgent._chat\u001b[0;34m(self, message, chat_history, function_call, mode)\u001b[0m\n\u001b[1;32m    259\u001b[0m raw_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mlist(\n\u001b[1;32m    260\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_id,\n\u001b[1;32m    261\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m )\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mprint\u001b[39m(raw_messages)\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m\n\u001b[1;32m    265\u001b[0m messages \u001b[38;5;241m=\u001b[39m from_openai_thread_messages(raw_messages)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# get most recent message content\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"I need to solve the equation `3x + 11 = 14`. Can you help me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bfaa306-245a-43e3-bcd4-f5ad8611aa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to the equation \\(3x + 11 = 14\\) is \\(x = 1\\).\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8a07e-b18d-4ab2-be61-9f5b835aface",
   "metadata": {},
   "source": [
    "## Assistant with Query Engine Tools\n",
    "\n",
    "Here we showcase the function calling capabilities of the OpenAIAssistantAgent by integrating it with our query engine tools over different documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c55f5f-fc22-4e85-b539-fbbe1fd93ac2",
   "metadata": {},
   "source": [
    "### 1. Setup: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355abef5-85c2-4a2c-8b6f-3a6c2d520807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAssistantAgent\n",
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d02c34-d5d6-4318-824f-1ae20fc5d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/lyft\"\n",
    "    )\n",
    "    lyft_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/uber\"\n",
    "    )\n",
    "    uber_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b43c5eb8-a98b-4f17-877b-f66b7d8715ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1880483 (1.8M) [application/octet-stream]\n",
      "Saving to: ‘data/10k/uber_2021.pdf’\n",
      "\n",
      "data/10k/uber_2021. 100%[===================>]   1.79M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2023-11-07 00:20:08 (24.3 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]\n",
      "\n",
      "--2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1440303 (1.4M) [application/octet-stream]\n",
      "Saving to: ‘data/10k/lyft_2021.pdf’\n",
      "\n",
      "data/10k/lyft_2021. 100%[===================>]   1.37M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2023-11-07 00:20:09 (22.2 MB/s) - ‘data/10k/lyft_2021.pdf’ saved [1440303/1440303]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/10k/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf' -O 'data/10k/lyft_2021.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d79f4f2-bc1d-4aff-b51e-0f05e4de2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not index_loaded:\n",
    "    # load data\n",
    "    lyft_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/lyft_2021.pdf\"]\n",
    "    ).load_data()\n",
    "    uber_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/uber_2021.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
    "    uber_index = VectorStoreIndex.from_documents(uber_docs)\n",
    "\n",
    "    # persist index\n",
    "    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\n",
    "    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df845e8-8932-4a51-ad0a-db0e6533fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ed3f3b-cf01-4958-ba53-e5448e487c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Lyft financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Uber financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd18ac7-5b5b-4093-8882-30ab93fa9d16",
   "metadata": {},
   "source": [
    "### 2. Let's Try it Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e76a5a96-c299-4565-bc1a-8b4f4ca4b455",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OpenAIAssistantAgent.from_new() got an unexpected keyword argument 'run_retrieve_sleep_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIAssistantAgent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSEC Analyst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a QA assistant designed to analyze sec filings.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_engine_tools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstructions_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlease address the user as Jerry.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_retrieve_sleep_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: OpenAIAssistantAgent.from_new() got an unexpected keyword argument 'run_retrieve_sleep_time'"
     ]
    }
   ],
   "source": [
    "agent = OpenAIAssistantAgent.from_new(\n",
    "    name=\"SEC Analyst\",\n",
    "    instructions=\"You are a QA assistant designed to analyze sec filings.\",\n",
    "    tools=query_engine_tools,\n",
    "    instructions_prefix=\"Please address the user as Jerry.\",\n",
    "    verbose=True,\n",
    "    run_retrieve_sleep_time=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b30b508-3f2e-47e6-b79c-57333fe37e88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Run failed with status failed.\nError: LastError(code='rate_limit_exceeded', message=\"We're currently processing too many requests - please try again later.\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat was Lyft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms revenue growth in 2021?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/callbacks/utils.py:39\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_assistant_agent.py:339\u001b[0m, in \u001b[0;36mchat\u001b[0;34m(self, message, chat_history, function_call)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_achat\u001b[39m(\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    331\u001b[0m     message: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    334\u001b[0m     mode: ChatResponseMode \u001b[38;5;241m=\u001b[39m ChatResponseMode\u001b[38;5;241m.\u001b[39mWAIT,\n\u001b[1;32m    335\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AGENT_CHAT_RESPONSE_TYPE:\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync chat not implemented\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     message: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    342\u001b[0m     chat_history: Optional[List[ChatMessage]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    343\u001b[0m     function_call: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    344\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentChatResponse:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    346\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mAGENT_STEP,\n\u001b[1;32m    347\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mMESSAGES: [message]},\n\u001b[1;32m    348\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    349\u001b[0m         chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat(\n\u001b[1;32m    350\u001b[0m             message, chat_history, function_call, mode\u001b[38;5;241m=\u001b[39mChatResponseMode\u001b[38;5;241m.\u001b[39mWAIT\n\u001b[1;32m    351\u001b[0m         )\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_assistant_agent.py:309\u001b[0m, in \u001b[0;36m_chat\u001b[0;34m(self, message, chat_history, function_call, mode)\u001b[0m\n\u001b[1;32m    305\u001b[0m     messages \u001b[38;5;241m=\u001b[39m from_openai_thread_messages(raw_messages)\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m messages[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat\u001b[39m(\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    310\u001b[0m     message: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    311\u001b[0m     chat_history: Optional[List[ChatMessage]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    312\u001b[0m     function_call: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    313\u001b[0m     mode: ChatResponseMode \u001b[38;5;241m=\u001b[39m ChatResponseMode\u001b[38;5;241m.\u001b[39mWAIT,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AGENT_CHAT_RESPONSE_TYPE:\n\u001b[1;32m    315\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Main chat interface.\"\"\"\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# TODO: since chat interface doesn't expose additional kwargs\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# we can't pass in file_ids per message\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_assistant_agent.py:282\u001b[0m, in \u001b[0;36mrun_assistant\u001b[0;34m(self, instructions_prefix)\u001b[0m\n\u001b[1;32m    279\u001b[0m sources \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m run\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueued\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_action\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 282\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mretrieve(\n\u001b[1;32m    283\u001b[0m         thread_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_id,\n\u001b[1;32m    284\u001b[0m         run_id\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_action\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    287\u001b[0m         cur_tool_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_function_calling(run)\n",
      "\u001b[0;31mValueError\u001b[0m: Run failed with status failed.\nError: LastError(code='rate_limit_exceeded', message=\"We're currently processing too many requests - please try again later.\")"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What was Lyft's revenue growth in 2021?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0783a8db-5546-472a-8376-6d2774dba45a",
   "metadata": {},
   "source": [
    "## Assistant with Built-In Retrieval\n",
    "\n",
    "Let's test the assistant by having it use the built-in OpenAI Retrieval tool over a user-uploaded file.\n",
    "\n",
    "Here, we upload and pass in the file during assistant-creation time. \n",
    "\n",
    "The other option is you can upload/pass the file-id in for a message in a given thread with `upload_files` and `add_message`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac4421f-ca9e-4d9f-91e1-10e1fb1119e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAssistantAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304c5c23-930c-4aed-8e0b-84a6e5c36138",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantAgent.from_new(\n",
    "    name=\"SEC Analyst\",\n",
    "    instructions=\"You are a QA assistant designed to analyze sec filings.\",\n",
    "    openai_tools=[{\"type\": \"retrieval\"}],\n",
    "    instructions_prefix=\"Please address the user as Jerry.\",\n",
    "    files=[\"data/10k/lyft_2021.pdf\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6845f8e9-ca2c-4bd1-a31a-dc58b47c585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"What was Lyft's revenue growth in 2021?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a93a9d-cc97-49c4-8a12-de710edc2fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyft's revenue increased by $843.6 million or 36% in 2021 as compared to the previous year【7†source】.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ac4d5-6c07-4df4-8dfc-258d376ef694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
