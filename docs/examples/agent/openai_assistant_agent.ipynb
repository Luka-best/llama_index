{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {},
   "source": [
    "# OpenAI Assistant Agent\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This shows you how to use our agent abstractions built on top of the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc",
   "metadata": {},
   "source": [
    "## Initial Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f",
   "metadata": {},
   "source": [
    "Let's start by importing some simple building blocks.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41101795",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f856af7-2f11-446a-9aef-21d68ddf2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAssistantAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b6fe26-0bdd-44ab-a887-9525dbc85f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantAgent.from_new(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    openai_tools=[{\"type\": \"code_interpreter\"}],\n",
    "    instructions_prefix=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40da2dd6-0872-4179-bbc1-33dfbb6c2b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_tv79OZgYTyrkBdVssJT6qUnZ'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._thread_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ba6844-5c1f-4f29-8d01-5ad48904375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_5nreRbfh68wEzNUgW4GSiXxP', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1699315600, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_kxFIsH2G10l4tG25HtpaewSk')], object='list', first_id='msg_5nreRbfh68wEzNUgW4GSiXxP', last_id='msg_5nreRbfh68wEzNUgW4GSiXxP', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI()\n",
    "# messages = client.beta.threads.messages.list(\n",
    "#   thread_id=\"thread_kxFIsH2G10l4tG25HtpaewSk\"\n",
    "# )\n",
    "# print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70dac88-aaeb-4e58-96a9-dc9e662faef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = client.beta.threads.runs.create(\n",
    "#   thread_id=agent._thread_id,\n",
    "#   assistant_id=agent._assistant.id,\n",
    "#   instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06449701-60d0-420c-932e-1131026e66ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_XgGS3UUs667uAcLMbANU1xCj', assistant_id='asst_apFjJVO63opijCHAxSgL32l2', cancelled_at=None, completed_at=None, created_at=1699316140, expires_at=None, failed_at=1699316151, file_ids=[], instructions='Please address the user as Jane Doe. The user has a premium account.', last_error=LastError(code='rate_limit_exceeded', message=\"We're currently processing too many requests - please try again later.\"), metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1699316140, status='failed', thread_id='thread_tv79OZgYTyrkBdVssJT6qUnZ', tools=[ToolAssistantToolsCode(type='code_interpreter')])\n"
     ]
    }
   ],
   "source": [
    "# run = client.beta.threads.runs.retrieve(\n",
    "#   thread_id=agent._thread_id,\n",
    "#   run_id=run.id\n",
    "# )\n",
    "# print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f0433d6-d662-4d9c-a087-d2052269c4e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Run failed with status failed.\nError: LastError(code='rate_limit_exceeded', message=\"We're currently processing too many requests - please try again later.\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI need to solve the equation `3x + 11 = 14`. Can you help me?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/callbacks/utils.py:39\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_assistant_agent.py:224\u001b[0m, in \u001b[0;36mOpenAIAssistantAgent.chat\u001b[0;34m(self, message, chat_history, function_call)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     function_call: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentChatResponse:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    221\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mAGENT_STEP,\n\u001b[1;32m    222\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mMESSAGES: [message]},\n\u001b[1;32m    223\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 224\u001b[0m         chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatResponseMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWAIT\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[1;32m    228\u001b[0m         e\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: chat_response})\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_assistant_agent.py:192\u001b[0m, in \u001b[0;36mOpenAIAssistantAgent._chat\u001b[0;34m(self, message, chat_history, function_call, mode)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Main chat interface.\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m added_message_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_message(message)\n\u001b[0;32m--> 192\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_assistant\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstructions_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_instructions_prefix\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m raw_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mlist(\n\u001b[1;32m    196\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_id\n\u001b[1;32m    197\u001b[0m )\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mprint\u001b[39m(raw_messages)\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_assistant_agent.py:163\u001b[0m, in \u001b[0;36mOpenAIAssistantAgent.run_assistant\u001b[0;34m(self, instructions_prefix)\u001b[0m\n\u001b[1;32m    157\u001b[0m instructions_prefix \u001b[38;5;241m=\u001b[39m instructions_prefix \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instructions_prefix\n\u001b[1;32m    158\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    159\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_id,\n\u001b[1;32m    160\u001b[0m     assistant_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assistant\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    161\u001b[0m     instructions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instructions_prefix\n\u001b[1;32m    162\u001b[0m )\n\u001b[0;32m--> 163\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_assistant_agent.py:177\u001b[0m, in \u001b[0;36mOpenAIAssistantAgent.retrieve_response\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m    175\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_retrieve_sleep_time)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun failed with status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mlast_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\n",
      "\u001b[0;31mValueError\u001b[0m: Run failed with status failed.\nError: LastError(code='rate_limit_exceeded', message=\"We're currently processing too many requests - please try again later.\")"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"I need to solve the equation `3x + 11 = 14`. Can you help me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfaa306-245a-43e3-bcd4-f5ad8611aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
