{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034e355d-83a0-4bd2-877e-0f493c5f713d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OpenAI Agent Query Planning\n",
    "In this demo, we explore adding a `QueryPlanTool` to an `OpenAIAgent`. This effectively enables the agent\n",
    "to do advanced query planning, all through a single tool! \n",
    "\n",
    "The `QueryPlanTool` is designed to work well with the OpenAI Function API. The tool takes in a set of other tools as input.\n",
    "The tool function signature contains of a QueryPlan Pydantic object, which can in turn contain a DAG of QueryNode objects defining a compute graph.\n",
    "The agent is responsible for defining this graph through the function signature when calling the tool. The tool itself executes the DAG over any corresponding tools.\n",
    "\n",
    "In this setting we use a familiar example: Uber 10Q filings in March, June, and September of 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fdc69e-4c3a-4b4a-babf-3733a0ba2d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # uncomment to turn on logging\n",
    "# import logging\n",
    "# import sys\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c225e522-1ebd-436f-9c47-8738eb513880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1e705a-36f2-4272-8f98-7f3785e76e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, LLMPredictor, ServiceContext, GPTVectorStoreIndex\n",
    "from llama_index.response.pprint_utils import pprint_response\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35364259-f1c3-4df0-b8c9-79e0afca7436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=-1, streaming=True))\n",
    "# llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", streaming=True))\n",
    "llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\", streaming=True))\n",
    "llm_predictor_gpt4 = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\", streaming=True))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "service_context_gpt4 = ServiceContext.from_defaults(llm_predictor=llm_predictor_gpt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7113434-0e41-46b6-a74e-284ce211fd38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d036819a-754e-460b-8734-8af7071287e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "march_2022 = SimpleDirectoryReader(input_files=[\"../data/10q/uber_10q_march_2022.pdf\"]).load_data()\n",
    "june_2022 = SimpleDirectoryReader(input_files=[\"../data/10q/uber_10q_june_2022.pdf\"]).load_data()\n",
    "sept_2022 = SimpleDirectoryReader(input_files=[\"../data/10q/uber_10q_sept_2022.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd541b68-c67f-4cbf-b579-5437d48e5b8f",
   "metadata": {},
   "source": [
    "# Build indices\n",
    "\n",
    "We build a vector index / query engine over each of the documents (March, June, September)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6c3178-6aab-4fdc-99f6-c820661e7a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "march_index = GPTVectorStoreIndex.from_documents(march_2022)\n",
    "june_index = GPTVectorStoreIndex.from_documents(june_2022)\n",
    "sept_index = GPTVectorStoreIndex.from_documents(sept_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af29f86-9a18-4b8e-af38-8ddc24b550e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "march_engine = march_index.as_query_engine(similarity_top_k=3, service_context=service_context)\n",
    "june_engine = june_index.as_query_engine(similarity_top_k=3, service_context=service_context)\n",
    "sept_engine = sept_index.as_query_engine(similarity_top_k=3, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6471ed-5645-4bb0-b8db-1b964ff7cd23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OpenAI Function Agent with a Query Plan Tool\n",
    "\n",
    "Use OpenAIAgent, built on top of the OpenAI tool use interface.\n",
    "\n",
    "Feed it our QueryPlanTool, which is a Tool that takes in other tools. And the agent to generate a query plan DAG over these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a89972cc-f7b8-4ebd-9c39-935e8a3671ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "query_tool_sept = QueryEngineTool.from_defaults(\n",
    "    query_engine=sept_engine,\n",
    "    name=\"sept_2022\",\n",
    "    description=f\"Provides information about Uber quarterly financials ending September 2022\",\n",
    ")\n",
    "query_tool_june = QueryEngineTool.from_defaults(\n",
    "    query_engine=june_engine,\n",
    "    name=\"june_2022\",\n",
    "    description=f\"Provides information about Uber quarterly financials ending June 2022\",\n",
    ")\n",
    "query_tool_march = QueryEngineTool.from_defaults(\n",
    "    query_engine=march_engine,\n",
    "    name=\"march_2022\",\n",
    "    description=f\"Provides information about Uber quarterly financials ending March 2022\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ae6d0bd-bd85-4f99-8363-96e203156933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define query plan tool\n",
    "from llama_index.tools import QueryPlanTool\n",
    "# from llama_index.tools.query_plan_v2 import QueryPlanTool\n",
    "from llama_index import ResponseSynthesizer\n",
    "\n",
    "response_synthesizer = ResponseSynthesizer.from_args(\n",
    "    service_context=service_context\n",
    ")\n",
    "query_plan_tool = QueryPlanTool.from_defaults(\n",
    "    query_engine_tools=[query_tool_sept, query_tool_june, query_tool_march],\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "320e8bde-6afc-4896-94bf-7a186f94fa49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'query_plan_tool',\n",
       " 'description': '        This is a query plan tool that takes in a list of tools and executes a query plan over these tools to answer a query. The query plan is a DAG of query nodes.\\n\\nGiven a list of tool names and the query plan schema, you can choose to generate a query plan to answer a question.\\n\\nThe tool names and descriptions are as follows:\\n\\n\\n\\n        Tool Name: sept_2022\\nTool Description: Provides information about Uber quarterly financials ending September 2022 \\n\\nTool Name: june_2022\\nTool Description: Provides information about Uber quarterly financials ending June 2022 \\n\\nTool Name: march_2022\\nTool Description: Provides information about Uber quarterly financials ending March 2022 \\n        ',\n",
       " 'parameters': {'title': 'QueryPlan',\n",
       "  'description': \"Query plan.\\n\\nContains a list of QueryNode objects (which is a recursive object).\\nOut of the list of QueryNode objects, one of them must be the root node.\\nThe root node is the one that isn't a dependency of any other node.\",\n",
       "  'type': 'object',\n",
       "  'properties': {'nodes': {'title': 'Nodes',\n",
       "    'description': 'The original question we are asking.',\n",
       "    'type': 'array',\n",
       "    'items': {'$ref': '#/definitions/QueryNode'}}},\n",
       "  'required': ['nodes'],\n",
       "  'definitions': {'QueryNode': {'title': 'QueryNode',\n",
       "    'description': 'Query node.\\n\\nA query node represents a query (query_str) that must be answered.\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\n(child_nodes).\\nThe tool_name and child_nodes fields are mutually exclusive.',\n",
       "    'type': 'object',\n",
       "    'properties': {'id': {'title': 'Id',\n",
       "      'description': 'ID of the query node.',\n",
       "      'type': 'integer'},\n",
       "     'query_str': {'title': 'Query Str',\n",
       "      'description': 'Question we are asking. This is the query string that will be executed. ',\n",
       "      'type': 'string'},\n",
       "     'tool_name': {'title': 'Tool Name',\n",
       "      'description': 'Name of the tool to execute the `query_str`.',\n",
       "      'type': 'string'},\n",
       "     'dependencies': {'title': 'Dependencies',\n",
       "      'description': 'List of sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if there are no sub-questions to be specified, in which case `tool_name` is specified.',\n",
       "      'type': 'array',\n",
       "      'items': {'type': 'integer'}}},\n",
       "    'required': ['id', 'query_str']}}}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_plan_tool.metadata.to_openai_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6466d4bf-59bd-4916-bf28-c1eb71a0a650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.selectors.llm_selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [query_plan_tool],\n",
    "    max_function_calls=10,\n",
    "    llm=ChatOpenAI(temperature=0, model_name=\"gpt-4-0613\"),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb85a5-8539-4218-b337-521ba77771a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = agent.query(\"What were the risk factors in sept 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4778a8b-c2de-494c-b825-d0fe3c1d4aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.tools.query_plan import QueryPlan\n",
    "\n",
    "query_plan = QueryPlan(**{\n",
    "  \"root\": {\n",
    "    \"query_str\": \"risk factors\",\n",
    "    \"tool_name\": \"sept_2022\",\n",
    "    \"child_nodes\": []\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f056a81-cf16-4c05-aa3b-4439f2dc808d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'QueryPlan',\n",
       " 'description': 'Query plan.\\n\\nContains the root QueryNode (which is a recursive object).\\nThe root node should contain the original query string to be executed.\\n\\nExample query plan in JSON format:\\n\\n```json\\n{\\n    \"root\": {\\n        \"query_str\": \"Compare the demographics of France and Italy.\",\\n        \"child_nodes\": [\\n            {\\n                \"query_str\": \"What are the demographics of France?\",\\n                \"tool_name\": \"france_demographics\",\\n                \"child_nodes\": []\\n            },\\n            {\\n                \"query_str\": \"What are the demographics of Italy?\",\\n                \"tool_name\": \"italy_demographics\",\\n                \"child_nodes\": []\\n            }\\n        ]\\n    }\\n}\\n```',\n",
       " 'type': 'object',\n",
       " 'properties': {'root': {'title': 'Root',\n",
       "   'description': 'Root node of the query plan. Should contain the original query string to be executed.',\n",
       "   'allOf': [{'$ref': '#/definitions/QueryNode'}]}},\n",
       " 'required': ['root'],\n",
       " 'definitions': {'QueryNode': {'title': 'QueryNode',\n",
       "   'description': 'Query node.\\n\\nA query node represents a query (query_str) that must be answered.\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\n(child_nodes).\\nThe tool_name and child_nodes fields are mutually exclusive.',\n",
       "   'type': 'object',\n",
       "   'properties': {'query_str': {'title': 'Query Str',\n",
       "     'description': 'Question we are asking. This is the query string that will be executed. We will either provide a tool to execute the query, or a list of child nodes containing sub-questions that will be executed first, and the results of which will be used as context to execute the current query string.',\n",
       "     'type': 'string'},\n",
       "    'tool_name': {'title': 'Tool Name',\n",
       "     'description': 'Name of the tool to execute the `query_str`.',\n",
       "     'type': 'string'},\n",
       "    'child_nodes': {'title': 'Child Nodes',\n",
       "     'description': 'List of child nodes representing sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if `tool_name` is specified.',\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/QueryNode'}}},\n",
       "   'required': ['query_str', 'child_nodes']}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QueryPlan.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "feeb0afc-96c8-4be5-839c-ce8a64fb9e71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: query_plan_tool with args: {\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"query_str\": \"What is Uber's revenue for March 2022?\",\n",
      "      \"tool_name\": \"march_2022\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"query_str\": \"What is Uber's revenue for June 2022?\",\n",
      "      \"tool_name\": \"june_2022\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"query_str\": \"What is Uber's revenue for September 2022?\",\n",
      "      \"tool_name\": \"sept_2022\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"query_str\": \"Analyze Uber revenue growth in March, June, and September\",\n",
      "      \"tool_name\": \"revenue_growth_analyzer\",\n",
      "      \"dependencies\": [1, 2, 3]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 4, \"query_str\": \"Analyze Uber revenue growth in March, June, and September\", \"tool_name\": \"revenue_growth_analyzer\", \"dependencies\": [1, 2, 3]}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mExecuting 3 child nodes\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 1, \"query_str\": \"What is Uber's revenue for March 2022?\", \"tool_name\": \"march_2022\", \"dependencies\": []}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSelected Tool: ToolMetadata(description='Provides information about Uber quarterly financials ending March 2022', name='march_2022', fn_schema=None)\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuted query, got response.\n",
      "Query: What is Uber's revenue for March 2022?\n",
      "Response: Uber's revenue for March 2022 was $6.854 billion.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 2, \"query_str\": \"What is Uber's revenue for June 2022?\", \"tool_name\": \"june_2022\", \"dependencies\": []}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSelected Tool: ToolMetadata(description='Provides information about Uber quarterly financials ending June 2022', name='june_2022', fn_schema=None)\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuted query, got response.\n",
      "Query: What is Uber's revenue for June 2022?\n",
      "Response: Uber's revenue for June 2022 cannot be determined from the provided information. However, the revenue for the three months ended June 30, 2022, was $8,073 million.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 3, \"query_str\": \"What is Uber's revenue for September 2022?\", \"tool_name\": \"sept_2022\", \"dependencies\": []}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSelected Tool: ToolMetadata(description='Provides information about Uber quarterly financials ending September 2022', name='sept_2022', fn_schema=None)\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuted query, got response.\n",
      "Query: What is Uber's revenue for September 2022?\n",
      "Response: Uber's revenue for the three months ended September 30, 2022, was $8.343 billion.\n",
      "\u001b[0mGot output: Based on the provided context information, we can analyze Uber's revenue growth as follows:\n",
      "\n",
      "- In March 2022, Uber's revenue was $6.854 billion.\n",
      "- For the three months ended June 30, 2022, Uber's revenue was $8,073 million (or $8.073 billion). However, we do not have the specific revenue for June 2022.\n",
      "- For the three months ended September 30, 2022, Uber's revenue was $8.343 billion.\n",
      "\n",
      "From this information, we can observe that Uber's revenue has been growing between the periods mentioned. The revenue increased from $6.854 billion in March 2022 to $8.073 billion for the three months ended June 2022, and further increased to $8.343 billion for the three months ended September 2022. However, we cannot provide a month-by-month analysis for June and September as the specific monthly revenue figures are not available.\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"Analyze Uber revenue growth in March, June, and September\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53bfd23d-cbb8-40ce-8bb7-feb3001398dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context information, we can analyze Uber's revenue growth for the three-month periods ending in March, June, and September.\n",
      "\n",
      "1. For the three months ended March 31, 2022, Uber's revenue was $6.854 billion.\n",
      "2. For the three months ended June 30, 2022, Uber's revenue was $8.073 billion.\n",
      "3. For the three months ended September 30, 2022, Uber's revenue was $8.343 billion.\n",
      "\n",
      "To analyze the growth, we can compare the revenue figures for each period:\n",
      "\n",
      "- From March to June, Uber's revenue increased by $1.219 billion ($8.073 billion - $6.854 billion), which represents a growth of approximately 17.8% (($1.219 billion / $6.854 billion) * 100).\n",
      "- From June to September, Uber's revenue increased by $0.270 billion ($8.343 billion - $8.073 billion), which represents a growth of approximately 3.3% (($0.270 billion / $8.073 billion) * 100).\n",
      "\n",
      "In summary, Uber experienced significant revenue growth of 17.8% between the three-month periods ending in March and June, followed by a smaller growth of 3.3% between the periods ending in June and September.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5bae0b65-59f5-4b5b-b5a7-1d8c5c4aa308",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: query_plan_tool with args: {\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"query_str\": \"What were the risk factors for Uber in March 2022?\",\n",
      "      \"tool_name\": \"march_2022\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"query_str\": \"What were the risk factors for Uber in June 2022?\",\n",
      "      \"tool_name\": \"june_2022\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"query_str\": \"What were the risk factors for Uber in September 2022?\",\n",
      "      \"tool_name\": \"sept_2022\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"query_str\": \"Analyze changes in risk factors in March, June, and September for Uber\",\n",
      "      \"tool_name\": \"risk_factor_analysis_tool\",\n",
      "      \"dependencies\": [1, 2, 3]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 4, \"query_str\": \"Analyze changes in risk factors in March, June, and September for Uber\", \"tool_name\": \"risk_factor_analysis_tool\", \"dependencies\": [1, 2, 3]}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mExecuting 3 child nodes\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 1, \"query_str\": \"What were the risk factors for Uber in March 2022?\", \"tool_name\": \"march_2022\", \"dependencies\": []}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSelected Tool: ToolMetadata(description='Provides information about Uber quarterly financials ending March 2022', name='march_2022', fn_schema=None)\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuted query, got response.\n",
      "Query: What were the risk factors for Uber in March 2022?\n",
      "Response: In March 2022, the risk factors for Uber included:\n",
      "\n",
      "1. The impact of the COVID-19 pandemic on their business, operations, and financial results, including uncertainties related to the severity and duration of the outbreak, future waves or resurgences, virus variants, vaccine administration and efficacy, and government actions.\n",
      "\n",
      "2. The potential classification of Drivers as employees, workers, or quasi-employees, which could lead to increased costs and legal challenges in various jurisdictions.\n",
      "\n",
      "3. Driver supply constraints, with consumer demand for Mobility recovering faster than driver availability, which could be impacted by concerns regarding the COVID-19 pandemic.\n",
      "\n",
      "4. Regulatory obstacles and legal risks in various jurisdictions, including proposals that could restrict or limit Uber's operations, increase operating costs, and decrease the number of platform users.\n",
      "\n",
      "5. The impact of existing or new laws and regulations on Uber's business, including potential exposure to substantial liability and increased expenses to comply with such laws and regulations.\n",
      "\n",
      "6. The potential impact of laws, regulations, or governmental actions seeking to curb air pollution or emissions on Uber's business, as a substantial portion of their business involves vehicles that run on fossil fuels.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 2, \"query_str\": \"What were the risk factors for Uber in June 2022?\", \"tool_name\": \"june_2022\", \"dependencies\": []}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSelected Tool: ToolMetadata(description='Provides information about Uber quarterly financials ending June 2022', name='june_2022', fn_schema=None)\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuted query, got response.\n",
      "Query: What were the risk factors for Uber in June 2022?\n",
      "Response: In June 2022, some of the risk factors for Uber included:\n",
      "\n",
      "1. The impact of the COVID-19 pandemic on their business operations, financial results, and future prospects. The extent of the impact depended on future developments such as outbreaks or variants of the virus, vaccine administration and efficacy, impact on capital and financial markets, governmental or regulatory orders, and potential permanent changes to end-users' behavior.\n",
      "\n",
      "2. Slowing growth rates, particularly for their ridesharing products. Achieving profitability depended on factors such as growing supply and demand on their platform, increasing user activity, expanding their business, competing with competitors' products and offerings, developing new products and technologies, and maintaining a positive brand perception.\n",
      "\n",
      "3. A significant percentage of their Gross Bookings came from trips in large metropolitan areas and trips to and from airports. Any negative impact on their operations in these areas or their ability to provide trips to and from airports could adversely affect their financial results and future prospects.\n",
      "\n",
      "4. The company's susceptibility to economic, social, weather, and regulatory conditions in large metropolitan areas where they derived a significant portion of their Mobility Gross Bookings.\n",
      "\n",
      "5. The need to adapt to recently adopted and not-yet-adopted accounting pronouncements, which could potentially impact their consolidated financial statements.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 3, \"query_str\": \"What were the risk factors for Uber in September 2022?\", \"tool_name\": \"sept_2022\", \"dependencies\": []}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSelected Tool: ToolMetadata(description='Provides information about Uber quarterly financials ending September 2022', name='sept_2022', fn_schema=None)\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuted query, got response.\n",
      "Query: What were the risk factors for Uber in September 2022?\n",
      "Response: In September 2022, some of the risk factors for Uber included:\n",
      "\n",
      "1. Criminal activity and safety incidents involving drivers, consumers, or third parties using their platform, which could lead to negative publicity, liability claims, and increased operating costs.\n",
      "2. Public reporting or disclosure of safety information, which could adversely impact their business and financial results.\n",
      "3. Substantial investments in new offerings and technologies, which are inherently risky and may not yield expected benefits.\n",
      "4. The need to successfully introduce new or upgraded products, offerings, or features for drivers, consumers, merchants, shippers, and carriers to retain and attract users to their platform.\n",
      "5. Economic conditions affecting the number of drivers, merchants, and carriers on their platform, as well as consumer demand for their services.\n",
      "6. Increases in fuel, food, labor, energy, and other costs due to inflation and other factors, which could adversely affect their operating results.\n",
      "7. Dependencies on third parties, which could create vulnerabilities in their network and operations.\n",
      "\u001b[0mGot output: From the context information provided, we can analyze the changes in risk factors for Uber in March, June, and September as follows:\n",
      "\n",
      "1. COVID-19 Pandemic Impact: The impact of the COVID-19 pandemic on Uber's business operations and financial results remains a consistent risk factor throughout the three periods. However, the focus shifts from the severity and duration of the outbreak in March to the potential permanent changes to end-users' behavior in June and September.\n",
      "\n",
      "2. Regulatory and Legal Risks: The potential classification of drivers as employees and the impact of existing or new laws and regulations on Uber's business remain constant risk factors throughout the three periods. However, the focus on laws and regulations seeking to curb air pollution or emissions in March is not explicitly mentioned in June and September.\n",
      "\n",
      "3. Driver Supply and Demand: Driver supply constraints are mentioned as a risk factor in March, while slowing growth rates and the need to grow supply and demand on their platform are highlighted in June. In September, economic conditions affecting the number of drivers, merchants, and carriers on their platform are mentioned as a risk factor.\n",
      "\n",
      "4. New Offerings and Technologies: The need to successfully introduce new or upgraded products, offerings, or features is mentioned as a risk factor in September, while substantial investments in new offerings and technologies are highlighted in June.\n",
      "\n",
      "5. Geographical Concentration: The risk associated with a significant percentage of their Gross Bookings coming from trips in large metropolitan areas and trips to and from airports is mentioned in June, while the susceptibility to economic, social, weather, and regulatory conditions in large metropolitan areas is highlighted in September.\n",
      "\n",
      "6. Safety and Security: Criminal activity and safety incidents involving drivers, consumers, or third parties using their platform, as well as public reporting or disclosure of safety information, are mentioned as risk factors in September but not in March or June.\n",
      "\n",
      "7. Dependencies on Third Parties: The risk of dependencies on third parties creating vulnerabilities in their network and operations is mentioned in September but not in March or June.\n",
      "\n",
      "In summary, while some risk factors remain consistent throughout the three periods, such as the impact of the COVID-19 pandemic and regulatory and legal risks, other risk factors evolve or emerge, such as safety and security concerns, dependencies on third parties, and the need to introduce new offerings and technologies.\n",
      "========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:29:07 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '667', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249323', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '162ms', 'x-request-id': '97cdcfdf6434e133e0f32d1e27c9691a', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da24c82be162338-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:29:08 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '50', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249323', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '162ms', 'x-request-id': '15ad0db83a27d000bb3a6400983565b4', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da24c8d98992338-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:29:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '49', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249323', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '162ms', 'x-request-id': '0f1ecbb4675bc884bcf1a89708eb0192', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da24c9aed042338-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:29:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '33', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249323', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '162ms', 'x-request-id': 'faade9408f466c797541d5bace1b9bae', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da24cb50bd32338-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:29:23 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '52', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249323', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '162ms', 'x-request-id': '8390b00a7d17e094f74c64f6c924989a', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da24ce7da142338-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"Analyze changes in risk factors in march, june, and september for Uber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01703941-f016-47d3-9cf9-fefac0fb54e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd52c07-0e46-4edd-8201-caa72b25ae1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = agent.query(\"Analyze both Uber revenue growth and risk factors over march, june, and september\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c47e41be-d61c-4992-b1c7-e038e1860d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context information, we can analyze Uber's revenue growth for the three-month periods ending in March, June, and September.\n",
      "\n",
      "1. For the three months ended March 31, 2022, Uber's revenue was $6.854 billion.\n",
      "2. For the three months ended June 30, 2022, Uber's revenue was $8.073 billion.\n",
      "3. For the three months ended September 30, 2022, Uber's revenue was $8.343 billion.\n",
      "\n",
      "To analyze the growth, we can compare the revenue figures for each period:\n",
      "\n",
      "- From March to June, Uber's revenue increased by $1.219 billion ($8.073 billion - $6.854 billion), which represents a growth of approximately 17.8% (($1.219 billion / $6.854 billion) * 100).\n",
      "- From June to September, Uber's revenue increased by $0.270 billion ($8.343 billion - $8.073 billion), which represents a growth of approximately 3.3% (($0.270 billion / $8.073 billion) * 100).\n",
      "\n",
      "In summary, Uber experienced significant revenue growth of 17.8% between the three-month periods ending in March and June, followed by a smaller growth of 3.3% between the periods ending in June and September.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba9d02e4-4c5c-47d2-8cf4-62bcc967e6f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: query_plan_tool with args: {\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"query_str\": \"What is Uber's revenue growth and risk factors in March 2022?\",\n",
      "      \"tool_name\": \"march_2022\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"query_str\": \"What is Uber's revenue growth and risk factors in September 2022?\",\n",
      "      \"tool_name\": \"sept_2022\",\n",
      "      \"dependencies\": []\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"query_str\": \"Compare and contrast the revenue growth and risk factors of Uber in March 2022 and September 2022.\",\n",
      "      \"tool_name\": \"comparison_tool\",\n",
      "      \"dependencies\": [1, 2]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 3, \"query_str\": \"Compare and contrast the revenue growth and risk factors of Uber in March 2022 and September 2022.\", \"tool_name\": \"comparison_tool\", \"dependencies\": [1, 2]}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mExecuting 2 child nodes\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 1, \"query_str\": \"What is Uber's revenue growth and risk factors in March 2022?\", \"tool_name\": \"march_2022\", \"dependencies\": []}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSelected Tool: ToolMetadata(description='Provides information about Uber quarterly financials ending March 2022', name='march_2022', fn_schema=None)\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuted query, got response.\n",
      "Query: What is Uber's revenue growth and risk factors in March 2022?\n",
      "Response: In March 2022, Uber's revenue was $6.9 billion, up 136% year-over-year. The revenue growth outpaced Gross Bookings growth primarily due to a $1.5 billion increase in their Freight business, a favorable impact of $200 million due to a change in the accounting model for their UK Mobility business, and a favorable comparative impact to the same period in 2021.\n",
      "\n",
      "Some significant risk factors for Uber in March 2022 include the ongoing COVID-19 pandemic, which has created uncertainty around the world and impacted their Mobility offerings. The extent of the pandemic's impact on their business and financial results depends on future developments, such as the duration of the outbreak, vaccine adoption and efficacy, the impact on capital and financial markets, and any permanent changes to end-users' behavior.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuting node {\"id\": 2, \"query_str\": \"What is Uber's revenue growth and risk factors in September 2022?\", \"tool_name\": \"sept_2022\", \"dependencies\": []}\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSelected Tool: ToolMetadata(description='Provides information about Uber quarterly financials ending September 2022', name='sept_2022', fn_schema=None)\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mExecuted query, got response.\n",
      "Query: What is Uber's revenue growth and risk factors in September 2022?\n",
      "Response: In September 2022, Uber's revenue was $8.3 billion, up 72% year-over-year. The revenue growth outpaced Gross Bookings growth primarily due to a $1.3 billion increase in their Freight business, primarily due to the acquisition of Transplace during the fourth quarter of 2021, and the net favorable impact to Mobility revenue of $1.1 billion as a result of business model changes in the UK.\n",
      "\n",
      "Some risk factors for Uber in September 2022 include the ongoing impact of COVID-19 on market and economic conditions, driver supply constraints, and potential changes in governmental restrictions. These factors may continue to have an adverse impact on Uber's business and operations.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:12:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '37', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249591', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '98ms', 'x-request-id': 'ef73f1d46b5007414e36fcb7e18ac8e3', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da233cf6d2e171a-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got output: In March 2022, Uber's revenue growth was 136% year-over-year, reaching $6.9 billion. The growth was primarily driven by a $1.5 billion increase in their Freight business, a $200 million favorable impact due to a change in the accounting model for their UK Mobility business, and a favorable comparative impact to the same period in 2021. The main risk factor during this period was the ongoing COVID-19 pandemic, which created uncertainty and impacted their Mobility offerings.\n",
      "\n",
      "In September 2022, Uber's revenue growth was 72% year-over-year, amounting to $8.3 billion. The growth was mainly due to a $1.3 billion increase in their Freight business, primarily from the acquisition of Transplace during the fourth quarter of 2021, and a net favorable impact to Mobility revenue of $1.1 billion as a result of business model changes in the UK. The risk factors during this period included the ongoing impact of COVID-19 on market and economic conditions, driver supply constraints, and potential changes in governmental restrictions.\n",
      "\n",
      "In summary, while both periods experienced significant revenue growth, the growth rate was higher in March 2022 compared to September 2022. The risk factors in both periods were primarily related to the ongoing COVID-19 pandemic, but September 2022 also faced additional risks such as driver supply constraints and potential changes in governmental restrictions.\n",
      "========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:12:16 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '83', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249591', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '98ms', 'x-request-id': 'e53ef1850c85fd26b97fd961a1a81af9', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da233d6bb2f171a-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:12:18 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '76', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249590', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '98ms', 'x-request-id': '3525b7c47d3ae8c57fe02f1b5cc705d0', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da233e42e50171a-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:12:22 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '68', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249590', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '98ms', 'x-request-id': '51c4a4df86d3aadab6bfff91da622c11', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da233fe2f71171a-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:12:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '57', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249591', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '98ms', 'x-request-id': 'babb25b3fbbfc7e332e125d968730d1e', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da234310d15171a-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "The server had an error while processing your request. Sorry about that! {\n  \"error\": {\n    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:12:47 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '45', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249591', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '98ms', 'x-request-id': 'b29becea593744a1cee1609cd4aad9c5', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da23495e893171a-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFirst look at Uber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms revenue growth and risk factors in March, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthen revenue growth and risk factors in September, and then compare and contrast the two documents?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/indices/query/base.py:23\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     22\u001b[0m     str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 23\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_agent.py:155\u001b[0m, in \u001b[0;36mBaseOpenAIAgent._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RESPONSE_TYPE:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatMessageHistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/llama_index/agent/openai_agent.py:109\u001b[0m, in \u001b[0;36mBaseOpenAIAgent.chat\u001b[0;34m(self, message, chat_history)\u001b[0m\n\u001b[1;32m    106\u001b[0m n_function_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# send function call & output back to get another response\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m ai_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctions\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m chat_history\u001b[38;5;241m.\u001b[39madd_message(ai_message)\n\u001b[1;32m    113\u001b[0m function_call \u001b[38;5;241m=\u001b[39m ai_message\u001b[38;5;241m.\u001b[39madditional_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:245\u001b[0m, in \u001b[0;36mBaseChatModel.predict_messages\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     _stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(stop)\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:195\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    190\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    194\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 195\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:95\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     94\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     96\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n\u001b[1;32m     97\u001b[0m generations \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39mgenerations \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:87\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m     92\u001b[0m     ]\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     94\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 88\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m     92\u001b[0m     ]\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     94\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/langchain/chat_models/openai.py:354\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m     message \u001b[38;5;241m=\u001b[39m _convert_dict_to_message(\n\u001b[1;32m    347\u001b[0m         {\n\u001b[1;32m    348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: inner_completion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m         }\n\u001b[1;32m    352\u001b[0m     )\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[ChatGeneration(message\u001b[38;5;241m=\u001b[39mmessage)])\n\u001b[0;32m--> 354\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/langchain/chat_models/openai.py:302\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/langchain/chat_models/openai.py:300\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m~/Programming/gpt_index/.venv/lib/python3.10/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAPIError\u001b[0m: The server had an error while processing your request. Sorry about that! {\n  \"error\": {\n    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 20 Jun 2023 07:12:47 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'llamaindex', 'openai-processing-ms': '45', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249591', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '98ms', 'x-request-id': 'b29becea593744a1cee1609cd4aad9c5', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da23495e893171a-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"First look at Uber's revenue growth and risk factors in March, \" +\n",
    "    \"then revenue growth and risk factors in September, and then compare and contrast the two documents?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f6f3c-e5ac-401b-925a-7a6cce0620bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb580ce-b9f8-4cec-af16-58d0c13f7446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
