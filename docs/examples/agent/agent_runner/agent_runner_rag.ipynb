{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aaf39be-eca2-4f26-b469-0499a1b52648",
   "metadata": {},
   "source": [
    "# Controllable Agents for RAG\n",
    "\n",
    "Adding agentic capabilities on top of your RAG pipeline can allow you to reason over much more complex questions.\n",
    "\n",
    "But a big pain point for agents is the **lack of steerability/transparency**. An agent may tackle a user query through chain-of-thought/planning, which requires repeated calls to an LLM. During this process it can be hard to inspect what's going on, or stop/correct execution in the middle.\n",
    "\n",
    "This notebook shows you how to use our brand-new lower-level agent API, which allows controllable step-wise execution, on top of a RAG pipeline.\n",
    "\n",
    "We showcase this over Wikipedia documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd57f6-3804-48b4-b53a-9815a6dfc48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575832d2-292b-4a31-93ba-d4d6ae731880",
   "metadata": {},
   "source": [
    "## Setup Data\n",
    "\n",
    "Here we load a simple dataset of different cities from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949ab8a9-c664-496f-ac6a-9085383f113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SummaryIndex,\n",
    "    SimpleKeywordTableIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    ")\n",
    "from llama_index.schema import IndexNode\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3502864b-4880-47b2-af6a-9931e62aa268",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles = [\n",
    "    \"Toronto\",\n",
    "    \"Seattle\",\n",
    "    \"Chicago\",\n",
    "    \"Boston\",\n",
    "    \"Houston\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ac67685-bbb7-403c-82f9-6aad600dde4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "for title in wiki_titles:\n",
    "    response = requests.get(\n",
    "        \"https://en.wikipedia.org/w/api.php\",\n",
    "        params={\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"titles\": title,\n",
    "            \"prop\": \"extracts\",\n",
    "            # 'exintro': True,\n",
    "            \"explaintext\": True,\n",
    "        },\n",
    "    ).json()\n",
    "    page = next(iter(response[\"query\"][\"pages\"].values()))\n",
    "    wiki_text = page[\"extract\"]\n",
    "\n",
    "    data_path = Path(\"data\")\n",
    "    if not data_path.exists():\n",
    "        Path.mkdir(data_path)\n",
    "\n",
    "    with open(data_path / f\"{title}.txt\", \"w\") as fp:\n",
    "        fp.write(wiki_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10da881c-c1b0-4613-a114-ec12b8e8449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all wiki documents\n",
    "city_docs = {}\n",
    "for wiki_title in wiki_titles:\n",
    "    city_docs[wiki_title] = SimpleDirectoryReader(\n",
    "        input_files=[f\"data/{wiki_title}.txt\"]\n",
    "    ).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f6c4f-723a-4cea-a6ba-b2aac3df7ec3",
   "metadata": {},
   "source": [
    "Define LLM + Service Context + Callback Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a98c988-ae17-40b2-b13d-b19a38df44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99b113-c40b-4aba-a721-3229778a063f",
   "metadata": {},
   "source": [
    "## Setup Agent\n",
    "\n",
    "In this section we define our tools and setup the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add97ea0-6eb6-48bb-b785-93c56f872531",
   "metadata": {},
   "source": [
    "### Define Toolset\n",
    "\n",
    "Each tool here corresponds to a simple top-k RAG pipeline over a single document / Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38609b7-8030-4929-8a79-615fbc6d673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index import load_index_from_storage, StorageContext\n",
    "from llama_index.node_parser import SentenceSplitter\n",
    "import os\n",
    "\n",
    "node_parser = SentenceSplitter()\n",
    "\n",
    "# Build agents dictionary\n",
    "query_engine_tools = []\n",
    "\n",
    "for idx, wiki_title in enumerate(wiki_titles):\n",
    "    nodes = node_parser.get_nodes_from_documents(city_docs[wiki_title])\n",
    "    all_nodes.extend(nodes)\n",
    "\n",
    "    if not os.path.exists(f\"./data/{wiki_title}\"):\n",
    "        # build vector index\n",
    "        vector_index = VectorStoreIndex(nodes, service_context=service_context)\n",
    "        vector_index.storage_context.persist(\n",
    "            persist_dir=f\"./data/{wiki_title}\"\n",
    "        )\n",
    "    else:\n",
    "        vector_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=f\"./data/{wiki_title}\"),\n",
    "            service_context=service_context,\n",
    "        )\n",
    "    # define query engines\n",
    "    vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "    # define tools\n",
    "    query_engine_tools.append(\n",
    "        QueryEngineTool(\n",
    "            query_engine=vector_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"vector_tool\",\n",
    "                description=(\n",
    "                    \"Useful for questions related to specific aspects of\"\n",
    "                    f\" {wiki_title} (e.g. the history, arts and culture,\"\n",
    "                    \" sports, demographics, or more).\"\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3e2f2-065c-4aea-87fa-5ddb7d6ac883",
   "metadata": {},
   "source": [
    "### Setup OpenAI Agent\n",
    "\n",
    "We setup an OpenAI Agent through its components: an AgentRunner as well as an `OpenAIAgentWorker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1452368b-9f3a-4da6-8c5e-11266250f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.executor.base import AgentRunner\n",
    "from llama_index.agent.openai.step import OpenAIAgentWorker\n",
    "\n",
    "openai_step_engine = OpenAIAgentWorker.from_tools(tools, llm=llm, verbose=True)\n",
    "agent = AgentRunner(openai_step_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea26dd-7cc7-498c-bacc-caf87a34d1e6",
   "metadata": {},
   "source": [
    "## Run Some Queries\n",
    "\n",
    "We now demonstrate the capabilities of our step-wise agent framework. \n",
    "\n",
    "We show how it can handle complex queries, both e2e as well as step by step. \n",
    "\n",
    "We can then show how we can steer the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe41cdb-1107-443e-8c79-f06d95fb9621",
   "metadata": {},
   "source": [
    "### Out of the box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f206ddc-6767-419f-a3c1-9db98b84e774",
   "metadata": {},
   "source": [
    "response = agent.chat(\n",
    "    \"Tell me about the demographics of Houston, and compare that with the demographics of Chicago\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4edd555-b183-4b47-9a14-6c1ceb12b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82983fbd-15ce-4620-aceb-d61cd8765597",
   "metadata": {},
   "source": [
    "### Test Step-Wise Execution\n",
    "\n",
    "We now break this query down into steps. We first create a task object from the user query.\n",
    "\n",
    "We can then start running through steps - or even interjecting our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371476b4-8b53-4276-ad45-af227bfb3226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start task\n",
    "task = agent.create_task(\n",
    "    \"Tell me about the demographics of Houston, and compare that with the demographics of Chicago?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7973a99-27a4-4b61-a9a6-e69528fbd0bf",
   "metadata": {},
   "source": [
    "This returns a `Task` object, which contains the `input`, additional state in `extra_state`, and other fields.\n",
    "\n",
    "Now let's try executing a single step of this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8fcfb7-b8d8-44c1-b623-5d19f95f0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_output = agent.run_step(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a5eae-cbb2-46a7-80a9-6f8d877c5fae",
   "metadata": {},
   "source": [
    "When we inspect the logs and the output, we see that the first part was executed - the demographics of Houston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eaaebe-2b64-48fd-80b6-58d7e3a4ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_output = agent.run_step(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d9b929-4f49-4d62-b4fb-a0b4c6e68f9a",
   "metadata": {},
   "source": [
    "If you wanted to pause execution now, you can - you can take the intermediate results without completing the agent flow!\n",
    "\n",
    "**NOTE**: The `memory` of the agent (`agent.memory`) isn't modified until the task is complete and committed - so if you pause now, the memory won't be committed.\n",
    "\n",
    "But wait. You can also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80ee79-844c-495c-8bfd-7af67955d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display final response\n",
    "print(step_output.is_last)\n",
    "step_output.output.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb21c5-5d65-4a09-950f-ae1027daa90f",
   "metadata": {},
   "source": [
    "### Inspect Steps / Tasks\n",
    "\n",
    "We can inspect current and previous tasks and steps.\n",
    "\n",
    "This gives you greater transparency into what the agent has processed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab070ec-14a5-46ca-9901-a7da670c1f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = agent.list_tasks()\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5137ac-301c-4799-aba7-75145b976791",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tasks[0]\n",
    "steps = agent.list_completed_steps(task()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_logan",
   "language": "python",
   "name": "llama_index_logan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
