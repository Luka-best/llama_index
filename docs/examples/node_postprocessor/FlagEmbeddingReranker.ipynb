{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9c30403",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/node_postprocessor/SentenceTransformerRerank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f531c-303c-4d19-9a6a-1259def23c07",
   "metadata": {},
   "source": [
    "Rerank can speed up an LLM query without sacrificing accuracy (and in fact, probably improving it). It does so by pruning away irrelevant nodes from the context."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d21a258",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65114dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c7d2f-ad2f-4d42-8d05-7441f7d344d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "caee0963",
   "metadata": {},
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb92e6-f1e2-4ba5-9ccb-d69a2c959197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd38ae-0821-465d-b422-80fd9901213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext, set_global_service_context\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "ctx = ServiceContext.from_defaults(embed_model=\"local\")\n",
    "set_global_service_context(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f4a1c6-7320-4252-89ff-81e15a8eadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build index\n",
    "index = VectorStoreIndex.from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f21b3c-43c6-4fde-b60f-e464ee3e435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor import FlagEmbeddingReranker\n",
    "\n",
    "rerank = FlagEmbeddingReranker(model=\"BAAI/bge-reranker-large\", top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027f9c4-044e-48f5-8231-820e91fab20d",
   "metadata": {},
   "source": [
    "First, we try with reranking. We time the query to see how long it takes to process the output from the retrieved context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51abb86b-43c3-49ad-b262-311b8159fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d20ab-cd91-4bc4-ba64-170f23fdadfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10, node_postprocessors=[rerank]\n",
    ")\n",
    "\n",
    "now = time()\n",
    "response = query_engine.query(\n",
    "    \"Which grad schools did the author apply for and why?\",\n",
    ")\n",
    "print(f\"Elapsed: {round(time() - now, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f98ac-df41-445f-a050-66d4a193a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb808169-b7bb-4ed7-9bf0-c3091afbaf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.get_formatted_sources(length=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de93bda-09f1-44cf-87ee-0b249758a28d",
   "metadata": {},
   "source": [
    "Next, we try without rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f975d-69db-470c-9388-5736b1ca6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=10)\n",
    "\n",
    "\n",
    "now = time()\n",
    "response = query_engine.query(\n",
    "    \"Which grad schools did the author apply for and why?\",\n",
    ")\n",
    "\n",
    "print(f\"Elapsed: {round(time() - now, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a57135-9944-4154-a100-22c80cc94a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2da74-ec2b-4f8f-90fb-9b0685ded447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.get_formatted_sources(length=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858826fa-d9a9-45b6-be57-3ec7f25704ce",
   "metadata": {},
   "source": [
    "As we can see, the query engine with reranking produced a much more concise output in much lower time (6s v.s. 10s). While both responses were essentially correct, the query engine without reranking included a lot of irrelevant information - a phenomenon we could attribute to \"pollution of the context window\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
