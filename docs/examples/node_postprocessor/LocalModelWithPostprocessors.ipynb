{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f768fd2-6721-4f0f-95ab-6c1726c4e02a",
   "metadata": {},
   "source": [
    "One usage of postprocessors is to be able to develop with local LLM models, which are very slow on large context lengths.\n",
    "\n",
    "Here we see an example of using a reranker and an optimizer which reduces the node length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5c7d2f-ad2f-4d42-8d05-7441f7d344d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fcb92e6-f1e2-4ba5-9ccb-d69a2c959197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"../data/paul_graham\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a037f-d139-4cb5-a49a-66b6a1945a54",
   "metadata": {},
   "source": [
    "We set the service context to use the local:cpu llm predictor and set it to be the global default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbd38ae-0821-465d-b422-80fd9901213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonch/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "llama.cpp: loading model from /home/jonch/.cache/llama_index/models/llama-2-13b/ggml-model-q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 9132.71 MB (+ 1608.00 MB per state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM metadata: context_window=4096 num_output=256 is_chat_model=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: kv self size  = 3200.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext, set_global_service_context\n",
    "\n",
    "ctx = ServiceContext.from_defaults(embed_model=\"local\", llm_predictor=\"local\")\n",
    "set_global_service_context(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f4a1c6-7320-4252-89ff-81e15a8eadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build index\n",
    "index = VectorStoreIndex.from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f21b3c-43c6-4fde-b60f-e464ee3e435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import (\n",
    "    SentenceTransformerRerank,\n",
    "    SentenceEmbeddingOptimizer,\n",
    ")\n",
    "\n",
    "rerank = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", top_n=2\n",
    ")\n",
    "optimizer = SentenceEmbeddingOptimizer(\n",
    "    embed_model=ctx.embed_model, percentile_cutoff=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655f975d-69db-470c-9388-5736b1ca6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10, node_postprocessors=[rerank, optimizer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf96cfd-f7e9-44c4-855b-9ef548c237f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1375.62 ms\n",
      "llama_print_timings:      sample time =    91.30 ms /   127 runs   (    0.72 ms per token,  1391.00 tokens per second)\n",
      "llama_print_timings: prompt eval time = 47405.29 ms /   256 tokens (  185.18 ms per token,     5.40 tokens per second)\n",
      "llama_print_timings:        eval time = 30955.60 ms /   126 runs   (  245.68 ms per token,     4.07 tokens per second)\n",
      "llama_print_timings:       total time = 78855.56 ms\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Why did the author think his choice of art schools would be good?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a57135-9944-4154-a100-22c80cc94a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my understanding, the author thought that attending Accademia di Belli Arti in Florence would be a good choice because:\n",
      "1. It is the oldest art school, which suggests a long history of teaching and producing successful artists.\n",
      "2. The faculty and students had a \"nicest people\" reputation, which could provide a supportive and nurturing environment for the author's artistic growth.\n",
      "3. The arrangement between the faculty and students, where no teaching or learning was required, might allow the author to focus solely on creating art without feeling pressured by academic expectations.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d2da74-ec2b-4f8f-90fb-9b0685ded447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: 937751f7-721f-423e-8c24-c645c09370db): The students and faculty in the painting department at the Accademia were the nicest people you could imagine, but they had long since arrived at an arrangement whereby the students wouldn't require the faculty to teach anything, and in return the faculty wouldn't require the students to learn anything. I applied to two: RISD in the US, and the Accademia di Belli Arti in Florence, which, because it was the oldest art school, I imagined would be good. Meanwhile I was applying to art scho...\n",
      "\n",
      "> Source (Doc id: d192ceb7-7881-4ced-abb5-f9276150988a): Art galleries didn't want to be online, and still don't, not the fancy ones. Idelle Weber was a painter, one of the early photorealists, and I'd taken her painting class at Harvard. (The painting on the cover of this book, ANSI Common Lisp, is one that I painted around this time.) She liked to paint on big, square canvases, 4 to 5 feet on a s...\n"
     ]
    }
   ],
   "source": [
    "print(response.get_formatted_sources(length=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d423dc1-ffcd-441a-917e-25d0110a732e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
