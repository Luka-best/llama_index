{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23cf319b",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/WeaviateIndex_metadata_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
   "metadata": {},
   "source": [
    "# Vespa Vector Store demo\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5508d8ac",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-vespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index pyvespa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
   "metadata": {},
   "source": [
    "#### Setting up API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ad68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eccceb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
   "metadata": {},
   "source": [
    "#### Load documents, build the VectorStoreIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2bcc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.vespa import VespaVectorStore\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a41a70d",
   "metadata": {},
   "source": [
    "## Defining some sample data\n",
    "\n",
    "Let's insert some documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df6b6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"The Shawshank Redemption\",\n",
    "        metadata={\n",
    "            \"author\": \"Stephen King\",\n",
    "            \"theme\": \"Friendship\",\n",
    "            \"year\": 1994,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Godfather\",\n",
    "        metadata={\n",
    "            \"director\": \"Francis Ford Coppola\",\n",
    "            \"theme\": \"Mafia\",\n",
    "            \"year\": 1972,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Inception\",\n",
    "        metadata={\n",
    "            \"director\": \"Christopher Nolan\",\n",
    "            \"theme\": \"Fiction\",\n",
    "            \"year\": 2010,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"To Kill a Mockingbird\",\n",
    "        metadata={\n",
    "            \"author\": \"Harper Lee\",\n",
    "            \"theme\": \"Mafia\",\n",
    "            \"year\": 1960,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"1984\",\n",
    "        metadata={\n",
    "            \"author\": \"George Orwell\",\n",
    "            \"theme\": \"Totalitarianism\",\n",
    "            \"year\": 1949,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Great Gatsby\",\n",
    "        metadata={\n",
    "            \"author\": \"F. Scott Fitzgerald\",\n",
    "            \"theme\": \"The American Dream\",\n",
    "            \"year\": 1925,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Harry Potter and the Sorcerer's Stone\",\n",
    "        metadata={\n",
    "            \"author\": \"J.K. Rowling\",\n",
    "            \"theme\": \"Fiction\",\n",
    "            \"year\": 1997,\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9e71f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mVespaVectorStore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mapplication_package\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvespa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpackage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mApplicationPackage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mApplicationPackage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hybridsearch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'doc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'string'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'metadata'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'string'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'string'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'enable-bm25'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'embedding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensor<float>(x[384])'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'input text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'embed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'attribute'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHNSW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'angular'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mFieldSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'metadata'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mRankProfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bm25'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bm25sum'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bm25sum'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bm25(text)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'query(q)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensor<float>(x[384])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRankProfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'semantic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'closeness(field, embedding)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'query(q)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensor<float>(x[384])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRankProfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fusion'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'closeness(field, embedding)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bm25'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalPhaseRanking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'reciprocal_rank_fusion(bm25sum, closeness(field, embedding))'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'query(q)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensor<float>(x[384])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQueryProfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQueryProfileType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnamespace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdefault_schema_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'doc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdeployment_target\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'local'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mport\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8080\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0membeddings_outside_vespa\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mgroupname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtenant\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mapplication\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mkey_location\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mkey_content\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mauth_client_token_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Vespa vector store.\n",
      "\n",
      "Can be initialized in several ways:\n",
      "1. (Default) Initialize Vespa vector store with default hybrid template and local (docker) deployment.\n",
      "2. Initialize by providing an application package created in pyvespa (can be deployed locally or to Vespa cloud).\n",
      "3. Initialize from previously deployed Vespa application by providing URL. (Local or cloud deployment).\n",
      "\n",
      "The application must be set up with the following fields:\n",
      "- id: Document id\n",
      "- text: Text field\n",
      "- embedding: Field to store embedding vectors.\n",
      "- metadata: Metadata field (all metadata will be stored here)\n",
      "\n",
      "The application must be set up with the following rank profiles:\n",
      "- bm25: For text search\n",
      "- semantic: For semantic search\n",
      "- fusion: For semantic hybrid search\n",
      "\n",
      "When creating a VectorStoreIndex from VespaVectorStore, the index will add documents to the Vespa application.\n",
      "Be ware that the Vespa container will be reused if not deleted between deployments, to avoid data duplication.\n",
      "During query time, the index queries the Vespa application to get the top k most relevant hits.\n",
      "\n",
      "Args:\n",
      "        application_package (ApplicationPackage): Application package\n",
      "        deployment_target (str): Deployment target, either `local` or `cloud`\n",
      "        port (int): Port that Vespa application will run on. Only applicable if deployment_target is `local`\n",
      "        default_schema_name (str): Schema name in Vespa application\n",
      "        namespace (str): Namespace in Vespa application\n",
      "        embeddings_outside_vespa (bool): Whether embeddings are created outside Vespa, or not.\n",
      "        url (Optional[str]): URL of deployed Vespa application.\n",
      "        groupname (Optional[str]): Group name in Vespa application, only applicable in `streaming` mode, see https://pyvespa.readthedocs.io/en/latest/examples/scaling-personal-ai-assistants-with-streaming-mode-cloud.html#A-summary-of-Vespa-streaming-mode\n",
      "        tenant (Optional[str]): Tenant for Vespa application. Applicable only if deployment_target is `cloud`\n",
      "        key_location (Optional[str]): Location of the control plane key used for signing HTTP requests to the Vespa Cloud.\n",
      "        key_content (Optional[str]): Content of the control plane key used for signing HTTP requests to the Vespa Cloud. Use only when key file is not available.\n",
      "        auth_client_token_id (Optional[str]): Use token based data plane authentication. This is the token name configured in the Vespa Cloud Console. This is used to configure Vespa services.xml. The token is given read and write permissions.\n",
      "        kwargs (Any): Additional kwargs for Vespa application\n",
      "\n",
      "Examples:\n",
      "    `pip install llama-index-vector-stores-vespa`\n",
      "\n",
      "    ```python\n",
      "    from llama_index.core import VectorStoreIndex\n",
      "    from llama_index.vector_stores.vespa import VespaVectorStore\n",
      "\n",
      "    vector_store = VespaVectorStore()\n",
      "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
      "    index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
      "    retriever = index.as_retriever()\n",
      "    retriever.retrieve(\"Who directed inception?\")\n",
      "\n",
      "    ```\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\thoma\\documents\\repos\\llama_index\\llama-index-integrations\\vector_stores\\llama-index-vector-stores-vespa\\llama_index\\vector_stores\\vespa\\base.py\n",
      "\u001b[1;31mType:\u001b[0m           _ProtocolMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?VespaVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe4378",
   "metadata": {},
   "source": [
    "### Initilizing the VespaVectorStore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be7d09",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- Explain template used\n",
    "- Option to define your own application package\n",
    "- Option to use own embedding model (also outside), but must then change template\n",
    "- Link to pyvespa documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b0b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.vespa.base:Using default hybrid template. Please make sure that the Vespa application is set up with the correct schema and rank profile.\n",
      "Using default hybrid template. Please make sure that the Vespa application is set up with the correct schema and rank profile.\n",
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Waiting for configuration server, 10/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 10/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 15/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 20/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 25/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 30/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 35/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 40/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Application is up!\n",
      "Finished deployment.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "vector_store = VespaVectorStore()\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d2528e",
   "metadata": {},
   "source": [
    "## As retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a71818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.vespa.base:Query: VectorStoreQuery(query_embedding=None, similarity_top_k=2, doc_ids=None, node_ids=[], query_str='Who directed inception?', output_fields=None, embedding_field=None, mode=<VectorStoreQueryMode.DEFAULT: 'default'>, alpha=None, filters=None, mmr_threshold=None, sparse_top_k=None, hybrid_top_k=None)\n",
      "Query: VectorStoreQuery(query_embedding=None, similarity_top_k=2, doc_ids=None, node_ids=[], query_str='Who directed inception?', output_fields=None, embedding_field=None, mode=<VectorStoreQueryMode.DEFAULT: 'default'>, alpha=None, filters=None, mmr_threshold=None, sparse_top_k=None, hybrid_top_k=None)\n",
      "INFO:llama_index.vector_stores.vespa.base:Vespa Query body:\n",
      " {'hits': 2, 'ranking.profile': 'bm25', 'query': 'Who directed inception?', 'tracelevel': 9, 'yql': 'select * from sources * where userQuery()'}\n",
      "Vespa Query body:\n",
      " {'hits': 2, 'ranking.profile': 'bm25', 'query': 'Who directed inception?', 'tracelevel': 9, 'yql': 'select * from sources * where userQuery()'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='c9d6c88f-e4e1-4ea1-9ad7-1dd6754351a0', embedding=None, metadata={'director': 'Christopher Nolan', 'theme': 'Fiction', 'year': 2010}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=2.3017175961610485)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = index.as_retriever(vector_store_query_mode=\"default\")\n",
    "retriever.retrieve(\"Who directed inception?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfe83ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.vespa.base:Query: VectorStoreQuery(query_embedding=None, similarity_top_k=2, doc_ids=None, node_ids=[], query_str='Who directed inception?', output_fields=None, embedding_field=None, mode=<VectorStoreQueryMode.SEMANTIC_HYBRID: 'semantic_hybrid'>, alpha=None, filters=None, mmr_threshold=None, sparse_top_k=None, hybrid_top_k=None)\n",
      "Query: VectorStoreQuery(query_embedding=None, similarity_top_k=2, doc_ids=None, node_ids=[], query_str='Who directed inception?', output_fields=None, embedding_field=None, mode=<VectorStoreQueryMode.SEMANTIC_HYBRID: 'semantic_hybrid'>, alpha=None, filters=None, mmr_threshold=None, sparse_top_k=None, hybrid_top_k=None)\n",
      "WARNING:llama_index.vector_stores.vespa.base:Embedding field not provided. Using default embedding field embedding\n",
      "Embedding field not provided. Using default embedding field embedding\n",
      "INFO:llama_index.vector_stores.vespa.base:Vespa Query body:\n",
      " {'hits': 2, 'ranking.profile': 'fusion', 'query': 'Who directed inception?', 'tracelevel': 9, 'yql': 'select * from sources * where rank({targetHits:10}nearestNeighbor(embedding,q), userQuery()) limit 2', 'input.query(q)': 'embed(Who directed inception?)'}\n",
      "Vespa Query body:\n",
      " {'hits': 2, 'ranking.profile': 'fusion', 'query': 'Who directed inception?', 'tracelevel': 9, 'yql': 'select * from sources * where rank({targetHits:10}nearestNeighbor(embedding,q), userQuery()) limit 2', 'input.query(q)': 'embed(Who directed inception?)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='c9d6c88f-e4e1-4ea1-9ad7-1dd6754351a0', embedding=None, metadata={'director': 'Christopher Nolan', 'theme': 'Fiction', 'year': 2010}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.03278688524590164),\n",
       " NodeWithScore(node=TextNode(id_='830e48de-cef2-4d5c-a03a-dd59e2a0b418', embedding=None, metadata={'author': 'George Orwell', 'theme': 'Totalitarianism', 'year': 1949}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.03225806451612903)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = index.as_retriever(vector_store_query_mode=\"semantic_hybrid\")\n",
    "retriever.retrieve(\"Who directed inception?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa36e8",
   "metadata": {},
   "source": [
    "### As query engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1bd18f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.vespa.base:Query: VectorStoreQuery(query_embedding=None, similarity_top_k=2, doc_ids=None, node_ids=[], query_str='Who directed inception?', output_fields=None, embedding_field=None, mode=<VectorStoreQueryMode.DEFAULT: 'default'>, alpha=None, filters=None, mmr_threshold=None, sparse_top_k=None, hybrid_top_k=None)\n",
      "Query: VectorStoreQuery(query_embedding=None, similarity_top_k=2, doc_ids=None, node_ids=[], query_str='Who directed inception?', output_fields=None, embedding_field=None, mode=<VectorStoreQueryMode.DEFAULT: 'default'>, alpha=None, filters=None, mmr_threshold=None, sparse_top_k=None, hybrid_top_k=None)\n",
      "INFO:llama_index.vector_stores.vespa.base:Vespa Query body:\n",
      " {'hits': 2, 'ranking.profile': 'bm25', 'query': 'Who directed inception?', 'tracelevel': 9, 'yql': 'select * from sources * where userQuery()'}\n",
      "Vespa Query body:\n",
      " {'hits': 2, 'ranking.profile': 'bm25', 'query': 'Who directed inception?', 'tracelevel': 9, 'yql': 'select * from sources * where userQuery()'}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='Christopher Nolan', source_nodes=[NodeWithScore(node=TextNode(id_='c9d6c88f-e4e1-4ea1-9ad7-1dd6754351a0', embedding=None, metadata={'director': 'Christopher Nolan', 'theme': 'Fiction', 'year': 2010}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=2.3017175961610485)], metadata={'c9d6c88f-e4e1-4ea1-9ad7-1dd6754351a0': {'director': 'Christopher Nolan', 'theme': 'Fiction', 'year': 2010}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "query_engine.query(\"Who directed inception?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0663ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.vespa.base:Query: VectorStoreQuery(query_embedding=None, similarity_top_k=2, doc_ids=None, node_ids=[], query_str='Harry Potter?', output_fields=None, embedding_field=None, mode=<VectorStoreQueryMode.DEFAULT: 'default'>, alpha=None, filters=MetadataFilters(filters=[MetadataFilter(key='theme', value='Fiction', operator=<FilterOperator.EQ: '=='>), MetadataFilter(key='year', value=1997, operator=<FilterOperator.GT: '>'>)], condition=<FilterCondition.OR: 'or'>), mmr_threshold=None, sparse_top_k=None, hybrid_top_k=None)\n",
      "Query: VectorStoreQuery(query_embedding=None, similarity_top_k=2, doc_ids=None, node_ids=[], query_str='Harry Potter?', output_fields=None, embedding_field=None, mode=<VectorStoreQueryMode.DEFAULT: 'default'>, alpha=None, filters=MetadataFilters(filters=[MetadataFilter(key='theme', value='Fiction', operator=<FilterOperator.EQ: '=='>), MetadataFilter(key='year', value=1997, operator=<FilterOperator.GT: '>'>)], condition=<FilterCondition.OR: 'or'>), mmr_threshold=None, sparse_top_k=None, hybrid_top_k=None)\n",
      "WARNING:llama_index.vector_stores.vespa.base:Filter support not implemented yet. Will be ignored.\n",
      "Filter support not implemented yet. Will be ignored.\n",
      "INFO:llama_index.vector_stores.vespa.base:Vespa Query body:\n",
      " {'hits': 2, 'ranking.profile': 'bm25', 'query': 'Harry Potter?', 'tracelevel': 9, 'yql': 'select * from sources * where userQuery()'}\n",
      "Vespa Query body:\n",
      " {'hits': 2, 'ranking.profile': 'bm25', 'query': 'Harry Potter?', 'tracelevel': 9, 'yql': 'select * from sources * where userQuery()'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='180bb151-3eb8-4bb5-92be-5a7753c23fb7', embedding=None, metadata={'author': 'J.K. Rowling', 'theme': 'Fiction', 'year': 1997}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=2.1663224434456927)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    FilterOperator,\n",
    "    FilterCondition,\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    ")\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"theme\", value=\"Fiction\"),\n",
    "        MetadataFilter(key=\"year\", value=1997, operator=FilterOperator.GT),\n",
    "    ],\n",
    "    condition=FilterCondition.OR,\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(filters=filters)\n",
    "retriever.retrieve(\"Harry Potter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9bc14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
