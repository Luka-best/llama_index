{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfdaff2-6478-4fc7-a717-c56cb5b8b1c2",
   "metadata": {},
   "source": [
    "# Defining a Custom Property Graph Retriever\n",
    "\n",
    "This guide shows you how to define a custom retriever against a property graph.\n",
    "\n",
    "It is more involved than using our out-of-the-box graph retrievers, but allows you to have granular control over the retrieval process so that it's better tailored for your application. \n",
    "\n",
    "We show you how to define an advanced retrieval flow by directly leveraging the property graph store. We'll execute both vector search and text-to-cypher retrieval, and then combine the results through a reranking module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bcf776-7e25-4f3b-9cf7-edd954cede01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index \n",
    "%pip install llama-index-graph-stores-neo4j\n",
    "%pip install llama-index-postprocessor-cohere-rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159b260-0061-4323-897f-f12e261da235",
   "metadata": {},
   "source": [
    "## Setup and Build the Property Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6389fe2a-6573-4847-a7ca-756b3f94d34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d0d28-d20a-4378-8f3b-2f0ed776d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dc1433-c1e6-4a77-9c3b-2b4e52bae23d",
   "metadata": {},
   "source": [
    "#### Load Paul Graham Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57333740-ec57-42d6-ae60-8fc3fa58c504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1685f988-9d8f-4ac7-bf90-822430c01414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183f0ce-ae84-41cb-bcfa-3f81705e24e8",
   "metadata": {},
   "source": [
    "#### Define Default LLMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06478af-01bc-43ed-aabc-30d193d6482a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21fe301-b239-4e47-b4e6-cfd9560c394f",
   "metadata": {},
   "source": [
    "#### Setup Neo4j\n",
    "\n",
    "To launch Neo4j locally, first ensure you have docker installed. Then, you can launch the database with the following docker command\n",
    "\n",
    "```\n",
    "docker run \\\n",
    "    -p 7474:7474 -p 7687:7687 \\\n",
    "    -v $PWD/data:/data -v $PWD/plugins:/plugins \\\n",
    "    --name neo4j-apoc \\\n",
    "    -e NEO4J_apoc_export_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
    "    -e NEO4JLABS_PLUGINS=\\[\\\"apoc\\\"\\] \\\n",
    "    neo4j:latest\n",
    "\n",
    "```\n",
    "From here, you can open the db at http://localhost:7474/. On this page, you will be asked to sign in. Use the default username/password of neo4j and neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe4d640-afdc-434c-af06-c66b6fb27bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j.neo4j_property_graph import Neo4jPGStore\n",
    "\n",
    "graph_store = Neo4jPGStore(\n",
    "    username=\"neo4j\",\n",
    "    password=\"llamaindex\",\n",
    "    url=\"bolt://localhost:7687\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a33a72-323a-4462-9d91-a2ae6ff04f9f",
   "metadata": {},
   "source": [
    "#### Build the Property Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67f2faf0-e079-4f1f-97d7-65a0cd64eabb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.40it/s]\n",
      "Extracting paths from text: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:09<00:00,  2.24it/s]\n",
      "Extracting implicit paths: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 7394.99it/s]\n",
      "Generating embeddings: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Generating embeddings: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  8.82it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PropertyGraphIndex\n\u001b[0;32m----> 3\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mPropertyGraphIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperty_graph_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index_forks/llama_index_logan/llama-index-core/llama_index/core/indices/base.py:145\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[0;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, service_context, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     docstore\u001b[38;5;241m.\u001b[39mset_document_hash(doc\u001b[38;5;241m.\u001b[39mget_doc_id(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[1;32m    138\u001b[0m nodes \u001b[38;5;241m=\u001b[39m run_transformations(\n\u001b[1;32m    139\u001b[0m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     transformations,\n\u001b[1;32m    141\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    143\u001b[0m )\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index_forks/llama_index_logan/llama-index-core/llama_index/core/indices/property_graph/base.py:133\u001b[0m, in \u001b[0;36mPropertyGraphIndex.__init__\u001b[0;34m(self, nodes, llm, kg_extractors, property_graph_store, vector_store, use_async, embed_model, embed_kg_nodes, callback_manager, transformations, storage_context, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index_forks/llama_index_logan/llama-index-core/llama_index/core/indices/base.py:94\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m---> 94\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[0;32m~/Programming/gpt_index_forks/llama_index_logan/llama-index-core/llama_index/core/indices/base.py:212\u001b[0m, in \u001b[0;36mBaseIndex.build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build the index from nodes.\"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_docstore\u001b[38;5;241m.\u001b[39madd_documents(nodes, allow_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index_forks/llama_index_logan/llama-index-core/llama_index/core/indices/property_graph/base.py:302\u001b[0m, in \u001b[0;36mPropertyGraphIndex._build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_index_from_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes: Optional[Sequence[BaseNode]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m IndexLPG:\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build index from nodes.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_insert_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;66;03m# this isn't really used or needed\u001b[39;00m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IndexLPG()\n",
      "File \u001b[0;32m~/Programming/gpt_index_forks/llama_index_logan/llama-index-core/llama_index/core/indices/property_graph/base.py:277\u001b[0m, in \u001b[0;36mPropertyGraphIndex._insert_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# refresh schema if needed\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperty_graph_store\u001b[38;5;241m.\u001b[39msupports_structured_queries:\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperty_graph_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nodes\n",
      "File \u001b[0;32m~/Programming/gpt_index_forks/llama_index_logan/llama-index-integrations/graph_stores/llama-index-graph-stores-neo4j/llama_index/graph_stores/neo4j/neo4j_property_graph.py:728\u001b[0m, in \u001b[0;36mNeo4jPGStore.get_schema\u001b[0;34m(self, refresh)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m, refresh: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m refresh:\n\u001b[0;32m--> 728\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_schema\n",
      "File \u001b[0;32m~/Programming/gpt_index_forks/llama_index_logan/llama-index-integrations/graph_stores/llama-index-graph-stores-neo4j/llama_index/graph_stores/neo4j/neo4j_property_graph.py:165\u001b[0m, in \u001b[0;36mNeo4jPGStore.refresh_schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrefresh_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     node_properties \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    159\u001b[0m         el[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_query(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m     ]\n\u001b[0;32m--> 165\u001b[0m     rel_properties \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    166\u001b[0m         el[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_query(\n\u001b[1;32m    168\u001b[0m             rel_properties_query, param_map\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXCLUDED_LABELS\u001b[39m\u001b[38;5;124m\"\u001b[39m: EXCLUDED_RELS}\n\u001b[1;32m    169\u001b[0m         )\n\u001b[1;32m    170\u001b[0m     ]\n\u001b[1;32m    171\u001b[0m     relationships \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    172\u001b[0m         el[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_query(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    177\u001b[0m     ]\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# Get constraints & indexes\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097923a-4cd9-4c82-9a88-4f89144e06c9",
   "metadata": {},
   "source": [
    "## Define Custom Retriever\n",
    "\n",
    "Now we define a custom retriever by subclassing `CustomPGRetriever`. \n",
    "\n",
    "#### 1. Initialization \n",
    "We initialize two pre-existing property graph retrievers: the `VectorContextRetriever` and the `TextToCypherRetriever`, as well as the cohere reranker.\n",
    "\n",
    "#### 2. Define `custom_retrieve`\n",
    "\n",
    "We then define the `custom_retrieve` function. It passes nodes through the two retrievers and gets back a final ranked list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69a555b-4029-4b74-9c96-6da617f651aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import (\n",
    "    CustomPGRetriever, \n",
    "    VectorContextRetriever, \n",
    "    TextToCypherRetriever\n",
    ")\n",
    "from llama_index.core.graph_stores import PropertyGraphStore\n",
    "from llama_index.core.vector_stores.types import VectorStore\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "\n",
    "from typing import Optional, Any, Union\n",
    "\n",
    "\n",
    "class MyCustomRetriever(CustomPGRetriever):\n",
    "    \"\"\"Custom retriever with cohere reranking.\"\"\"\n",
    "\n",
    "    def init(\n",
    "        self,\n",
    "        graph_store: PropertyGraphStore,\n",
    "        ## vector context retriever params\n",
    "        include_text: bool = True,\n",
    "        embed_model: Optional[BaseEmbedding] = None,\n",
    "        vector_store: Optional[VectorStore] = None,\n",
    "        similarity_top_k: int = 4,\n",
    "        path_depth: int = 1,\n",
    "        ## text-to-cypher params\n",
    "        llm: Optional[LLM] = None,\n",
    "        text_to_cypher_template: Optional[Union[PromptTemplate, str]] = None,\n",
    "        ## cohere reranker params \n",
    "        cohere_api_key: Optional[str] = None,\n",
    "        cohere_top_n: int = 2,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Uses any kwargs passed in from class constructor.\"\"\"\n",
    "        \n",
    "        self.vector_retriever = VectorContextRetriever(\n",
    "            graph_store,\n",
    "            include_text=include_text,\n",
    "            embed_model=embed_model,\n",
    "            vector_store=vector_store,\n",
    "            similarity_top_k=similarity_top_k,\n",
    "            path_depth=path_depth\n",
    "        )\n",
    "        \n",
    "        self.cypher_retriever = TextToCypherRetriever(\n",
    "            graph_store,\n",
    "            llm=llm,\n",
    "            text_to_cypher_template=text_to_cypher_template\n",
    "            ## NOTE: you can attach other parameters here if you'd like \n",
    "        )\n",
    "        \n",
    "        self.reranker = CohereRerank(api_key=cohere_api_key, top_n=cohere_top_n)\n",
    "\n",
    "    def custom_retrieve(self, query_str: str) -> str:\n",
    "        \"\"\"Define custom retriever with reranking.\"\"\" \n",
    "        nodes_1 = self.vector_retriever.retrieve(query_str)\n",
    "        nodes_2 = self.cypher_retriever.retrieve(query_str)\n",
    "        reranked_nodes = self.reranker.postprocess_nodes(nodes_1 + nodes_2)\n",
    "        \n",
    "        \n",
    "        ## TMP: please change\n",
    "        final_text = \"\\n\\n\".join([n.get_content(metadata_mode=\"llm\") for n in reranked_nodes])\n",
    "        \n",
    "        return final_text\n",
    "        \n",
    "\n",
    "    # optional async method\n",
    "    # async def acustom_retrieve(self, query_str: str) -> str:\n",
    "    #     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7ad0b-f170-40e8-b9bd-76deb5b42bdc",
   "metadata": {},
   "source": [
    "## Test out the Custom Retriever\n",
    "\n",
    "Now let's initialize and test out the custom retriever against our data! \n",
    "\n",
    "To build a full RAG pipeline, we use the `RetrieverQueryEngine` to combine our retriever with the LLM synthesis module - this is also used under the hood for the property graph index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346d827-9fd8-42bf-8bc9-548f23da68fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_retriever = MyCustomRetriever(\n",
    "    index.property_graph_store,\n",
    "    include_text=True,\n",
    "    vector_store=index.vector_store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af69b34-184a-457a-9e98-d32b103ac0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    custom_retriever,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9e150-b02f-4819-becf-b68375558fce",
   "metadata": {},
   "source": [
    "#### Try out a 'baseline'\n",
    "\n",
    "We compare against a baseline retriever that's the vector context only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963306cc-3fb2-4a7d-9f1f-c8e6f66747c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = VectorContextRetriever(index.graph_store, include_text=True)\n",
    "base_query_engine = index.as_query_engine(\n",
    "    sub_retrievers=[base_retriever]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e5bda-b11d-4544-adb9-ebed298fe070",
   "metadata": {},
   "source": [
    "### Try out some Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950e8b7-91db-4153-8528-47a8b91d77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine.query(\"What happened at Interleaf and Viaweb?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50271c-1d42-434f-a541-909d731bff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_query_engine.query(\"What happened at Interleaf and Viaweb?\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_logan",
   "language": "python",
   "name": "llama_index_logan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
