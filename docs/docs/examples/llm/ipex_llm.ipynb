{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPEX-LLM \n",
    "\n",
    "> [IPEX-LLM](https://github.com/intel-analytics/ipex-llm/) is a PyTorch library for running LLM on Intel CPU and GPU (e.g., local PC with iGPU, discrete GPU such as Arc, Flex and Max) with very low latenc. This PR adds ipex-llm integrations to LlamaIndex as a new integration package.\n",
    "\n",
    "This example goes over how to use LlamaIndex to interact with IPEX-LLM for text generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-ipex-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U transformers==4.37.0 tokenizers==0.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/shane-llamaindex/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00, 18.13it/s]\n",
      "2024-03-28 02:09:21,774 - INFO - Converting the current model to sym_int4 format......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tokenizer: /mnt/disk1/models/zephyr-7b-alpha\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ipex_llm import IpexLLM\n",
    "\n",
    "llm = IpexLLM(\n",
    "    model_name=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
    "    tokenizer_name=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
    "    context_window=512,\n",
    "    max_new_tokens=128,\n",
    "    generate_kwargs={\"temperature\": 0.7, \"do_sample\": False},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/shane-llamaindex/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In a land far, far away, \n",
      "\n",
      "Lived a young girl named Lily, \n",
      "\n",
      "Who had a dream to chase every day. \n",
      "\n",
      "Lily loved to read, write, and draw, \n",
      "\n",
      "She'd spend hours in her room, \n",
      "\n",
      "Creating stories, characters, and worlds, \n",
      "\n",
      "That only she knew. \n",
      "\n",
      "One day, Lily's teacher said, \n",
      "\n",
      "\"Lily, you're a talented writer, \n",
      "\n",
      "But you need to work on your grammar, \n",
      "\n",
      "And your spelling, and your\n"
     ]
    }
   ],
   "source": [
    "completion_response = llm.complete(\"Once upon a time, \")\n",
    "print(completion_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shane-llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
