{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Execution of Same Event Example\n",
    "\n",
    "In this example, we'll demonstrate how to use the workflow functionality to achieve similar capabilities while allowing parallel execution of multiple events of the same type.  \n",
    "By setting the `num_workers` parameter in `@step` decorator, we can control the number of steps executed simultaneously, enabling efficient parallel processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Installing Dependencies\n",
    "\n",
    "First, we need to install the necessary dependencies:\n",
    "\n",
    "* LlamaIndex core for most functionalities\n",
    "* llama-index-utils-workflow for workflow capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-core llama-index-utils-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing Required Libraries\n",
    "After installing the dependencies, we can import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from llama_index.core.workflow import (\n",
    "    step,\n",
    "    Context,\n",
    "    Workflow,\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will create a workflow that can process multiple data items in parallel. By using the `@step(num_workers=N)` decorator, we can limit the number of steps executed simultaneously, thus controlling the level of parallelism. This approach is particularly suitable for scenarios that require processing similar tasks while managing resource usage.  \n",
    "For example, you can execute multiple sub-queries at once, but please note that num_workers cannot be set without limits. It depends on  your workload or token limits.\n",
    "#Defining Event Types\n",
    "We'll define two event types: one for input events to be processed in parallel, and another for processing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelEvent(Event):\n",
    "    data: str\n",
    "\n",
    "\n",
    "class ResultEvent(Event):\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating the Parallel Workflow\n",
    "Now, we'll create a ParallelWorkflow class that includes three main steps:\n",
    "\n",
    "- start: Initialize and send multiple parallel events\n",
    "- process_data: Process data in parallel\n",
    "- combine_results: Collect and merge all processing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class ParallelWorkflow(Workflow):\n",
    "    @step(pass_context=True)\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> ParallelEvent:\n",
    "        data_list = [\"A\", \"B\", \"C\"]\n",
    "        ctx.data[\"num_to_collect\"] = len(data_list)\n",
    "        for item in data_list:\n",
    "            self.send_event(ParallelEvent(data=item))\n",
    "        return None\n",
    "\n",
    "    @step(num_workers=3)\n",
    "    async def process_data(self, ev: ParallelEvent) -> ResultEvent:\n",
    "        # Simulate some time-consuming processing\n",
    "        await asyncio.sleep(random.randint(1, 2))\n",
    "        result = f\"Processed: {ev.data}\"\n",
    "        print(f\"Completed processing: {ev.data}\")\n",
    "        return ResultEvent(result=result)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def combine_results(\n",
    "        self, ctx: Context, ev: ResultEvent\n",
    "    ) -> StopEvent | None:\n",
    "        num_to_collect = ctx.data[\"num_to_collect\"]\n",
    "        results = ctx.collect_events(ev, [ResultEvent] * num_to_collect)\n",
    "        if results is None:\n",
    "            return None\n",
    "\n",
    "        combined_result = \", \".join([event.result for event in results])\n",
    "        return StopEvent(result=combined_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workflow:\n",
    "\n",
    "- The start method initializes and sends multiple ParallelEvents.\n",
    "- The process_data method uses the @step(num_workers=3) decorator to limit the number of simultaneously executing workers to 3.\n",
    "- The combine_results method collects all processing results and merges them.\n",
    "\n",
    "#Running the Workflow\n",
    "Finally, we can create a main function to run our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing: A\n",
      "Completed processing: C\n",
      "Completed processing: B\n",
      "Workflow result: Processed: A, Processed: C, Processed: B\n",
      "Time taken: 2.0068275928497314 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "workflow = ParallelWorkflow()\n",
    "\n",
    "start_time = time.time()\n",
    "result = await workflow.run()\n",
    "end_time = time.time()\n",
    "print(f\"Workflow result: {result}\")\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Note\n",
    "\n",
    "- Processing occurs in parallel, handling 3 items at a time, and only takes 2 seconds. Without setting num_workers, it would take 3 to 6 seconds.\n",
    "- The order of the completed results may differ from the input order, depending on the completion time of the tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how to implement controlled parallel processing in a workflow. By setting num_workers, we can control the degree of parallelism, which is very useful for scenarios that need to balance performance and resource usage."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
