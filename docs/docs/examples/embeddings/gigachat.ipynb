{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjI-RDp0UGVb"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index-embeddings-gigachat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "KDZcSr5XUS1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.gigachat import GigaChatEmbedding\n",
        "\n",
        "gigachat_embedding = GigaChatEmbedding(\n",
        "    auth_data=\"your-auth-data\", scope=\"your-scope\" # Set scope 'GIGACHAT_API_PERS' for personal use or 'GIGACHAT_API_CORP' for corporate use.\n",
        ")\n",
        "\n",
        "queries_embedding = gigachat_embedding._get_query_embeddings(\n",
        "    [\"This is a passage!\", \"This is another passage\"]\n",
        ")\n",
        "print(pass_embedding)\n",
        "\n",
        "text_embedding = gigachat_embedding._get_text_embedding(\"Where is blue?\")\n",
        "print(text_embedding)"
      ],
      "metadata": {
        "id": "gLDpHv6XUUvb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}