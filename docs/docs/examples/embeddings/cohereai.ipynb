{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/embeddings/cohereai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CohereAI Embeddings\n",
    "\n",
    "Cohere Embed is the first embedding model that natively supports float, int8 and binary embeddings. \n",
    "\n",
    "1. v3 models support all embedding types while v2 models support only `float` embedding type.\n",
    "2. The default `embedding_type` is `float` with `LlamaIndex`. You can customize it for v3 models using parameter `embedding_type`.\n",
    "\n",
    "In this notebook, we will demonstrate using `Cohere Embeddings` with different `models`, `input_types` and `embedding_types`.\n",
    "\n",
    "Refer to their [main blog post](https://txt.cohere.com/int8-binary-embeddings/) for more details on Cohere int8 & binary Embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-litellm\n",
    "%pip install llama-index-embeddings-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilise with your api key\n",
    "import os\n",
    "\n",
    "cohere_api_key = \"YOUR COHERE API KEY\"\n",
    "os.environ[\"COHERE_API_KEY\"] = cohere_api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With latest `embed-english-v3.0` embeddings.\n",
    "\n",
    "- input_type=\"search_document\": Use this for texts (documents) you want to store in your vector database\n",
    "\n",
    "- input_type=\"search_query\": Use this for search queries to find the most relevant documents in your vector database\n",
    "\n",
    "The default `embedding_type` is `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "\n",
    "# with input_typ='search_query'\n",
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model_name=\"embed-english-v3.0\",\n",
    "    input_type=\"search_query\",\n",
    ")\n",
    "\n",
    "embeddings = embed_model.get_text_embedding(\"Hello CohereAI!\")\n",
    "\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with input_type = 'search_document'\n",
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model_name=\"embed-english-v3.0\",\n",
    "    input_type=\"search_document\",\n",
    ")\n",
    "\n",
    "embeddings = embed_model.get_text_embedding(\"Hello CohereAI!\")\n",
    "\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's check With `int8` embedding_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model_name=\"embed-english-v3.0\",\n",
    "    input_type=\"search_query\",\n",
    "    embedding_type=\"int8\",\n",
    ")\n",
    "\n",
    "embeddings = embed_model.get_text_embedding(\"Hello CohereAI!\")\n",
    "\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With `binary` embedding_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model_name=\"embed-english-v3.0\",\n",
    "    input_type=\"search_query\",\n",
    "    embedding_type=\"binary\",\n",
    ")\n",
    "\n",
    "embeddings = embed_model.get_text_embedding(\"Hello CohereAI!\")\n",
    "\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With old `embed-english-v2.0` embeddings.\n",
    "\n",
    "v2 models support by default `float` embedding_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=cohere_api_key, model_name=\"embed-english-v2.0\"\n",
    ")\n",
    "\n",
    "embeddings = embed_model.get_text_embedding(\"Hello CohereAI!\")\n",
    "\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now with latest `embed-english-v3.0` embeddings, \n",
    "\n",
    "let's use \n",
    "1. input_type=`search_document` to build index\n",
    "2. input_type=`search_query` to retrive relevant context.\n",
    "\n",
    "We will experiment with `int8` embedding_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build index with input_type = 'search_document'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Cohere(model=\"command-nightly\", api_key=cohere_api_key)\n",
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model_name=\"embed-english-v3.0\",\n",
    "    input_type=\"search_document\",\n",
    "    embedding_type=\"int8\",\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build retriever with input_type = 'search_query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model_name=\"embed-english-v3.0\",\n",
    "    input_type=\"search_query\",\n",
    "    embedding_type=\"int8\",\n",
    ")\n",
    "\n",
    "search_query_retriever = index.as_retriever()\n",
    "\n",
    "search_query_retrieved_nodes = search_query_retriever.retrieve(\n",
    "    \"What happened in the summer of 1995?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in search_query_retrieved_nodes:\n",
    "    display_source_node(n, source_length=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anthropic_env",
   "language": "python",
   "name": "anthropic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "64bcadabe4cd61f3d117ba0da9d14bf2f8e35582ff79e821f2e71056f2723d1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
