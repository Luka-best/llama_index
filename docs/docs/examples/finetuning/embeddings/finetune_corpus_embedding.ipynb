{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning corpus embeddings using NUDGE\n",
    "[NUDGE](https://www.arxiv.org/abs/2409.02343) is a novel simple and lightweight fine-tuning method that boosts accuracy when retrieving text using semantic similarity with pre-trained embedding models. NUDGE directly modifies the embeddings of data records to maximize the similarity between training queries and their ground-truth answers. NUDGE does so non-parametrically. Non-parametric means that NUDGE does not modify model parameters to generate better embeddings, as fine-tuning the embedding model, or training adaptors would. Instead, NUDGE directly changes the embeddings themselves. Compared with fine-tuning the pre-trained model and training adaptors, NUDGE provides 3.3x and 4.3x higher increase in accuracy and runs 200x and 3x faster, respectively. [Here](https://data-people-group.github.io/blogs/2024/09/05/nudge/) is a blog post on NUDGE, and [here](https://www.arxiv.org/abs/2409.02343) is the paper with more details.\n",
    "\n",
    "We demonstrate NUDGE's effectiveness on a commonly used Information Retrieval benchmark called Scifact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the scifact benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /usr/local/lib/python3.10/dist-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.4.0 available.\n",
      "PyTorch version 2.4.0 available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.finetuning import EmbeddingQAFinetuneDataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "def load_hf_dataset(dataset_name):\n",
    "    hf_dataset_name = f\"sepz/{dataset_name}_ft\"\n",
    "    corpus = load_dataset(hf_dataset_name, \"data_records\", split=\"train\")\n",
    "\n",
    "    queries_train = load_dataset(hf_dataset_name, \"qs\", split=\"train\")\n",
    "    queries_validation = load_dataset(hf_dataset_name, \"qs\", split=\"dev\")\n",
    "    queries_test = load_dataset(hf_dataset_name, \"qs\", split=\"test\")\n",
    "\n",
    "    qrels_train = load_dataset(hf_dataset_name, \"qs_rel\", split=\"train\")\n",
    "    qrels_validation = load_dataset(hf_dataset_name, \"qs_rel\", split=\"dev\")\n",
    "    qrels_test = load_dataset(hf_dataset_name, \"qs_rel\", split=\"test\")\n",
    "\n",
    "    corpus = {\n",
    "        str(corpus[i][\"record_id\"]): corpus[i][\"text\"] for i in range(len(corpus))\n",
    "    }\n",
    "\n",
    "    queries_train = {\n",
    "        str(queries_train[i][\"q_id\"]): queries_train[i][\"input\"]\n",
    "        for i in range(len(queries_train))\n",
    "    }\n",
    "    queries_validation = {str(r[\"q_id\"]): r[\"input\"] for r in queries_validation}\n",
    "    queries_test = {str(r[\"q_id\"]): r[\"input\"] for r in queries_test}\n",
    "\n",
    "    qrels_train = (\n",
    "        qrels_train.to_pandas().groupby(\"q_id\")[\"record_id\"].apply(list).to_dict()\n",
    "    )\n",
    "    qrels_validation = (\n",
    "        qrels_validation.to_pandas().groupby(\"q_id\")[\"record_id\"].apply(list).to_dict()\n",
    "    )\n",
    "    qrels_test = (\n",
    "        qrels_test.to_pandas().groupby(\"q_id\")[\"record_id\"].apply(list).to_dict()\n",
    "    )\n",
    "    # convert to strings\n",
    "    qrels_train = {str(k): [str(i) for i in v] for k, v in qrels_train.items()}\n",
    "    qrels_validation = {\n",
    "        str(k): [str(i) for i in v] for k, v in qrels_validation.items()\n",
    "    }\n",
    "    qrels_test = {str(k): [str(i) for i in v] for k, v in qrels_test.items()}\n",
    "\n",
    "    # Load the dataset\n",
    "    train_dataset = EmbeddingQAFinetuneDataset(\n",
    "        corpus=corpus, queries=queries_train, relevant_docs=qrels_train\n",
    "    )\n",
    "    validation_dataset = EmbeddingQAFinetuneDataset(\n",
    "        corpus=corpus, queries=queries_validation, relevant_docs=qrels_validation\n",
    "    )\n",
    "    test_dataset = EmbeddingQAFinetuneDataset(\n",
    "        corpus=corpus, queries=queries_test, relevant_docs=qrels_test\n",
    "    )\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and base embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = load_hf_dataset('scifact')\n",
    "base_embed_model = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "A common Information Retrieval metric to report during evaluation is NDCG@k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.base.embeddings.base import BaseEmbedding\n",
    "from llama_index.core.base.base_retriever import BaseRetriever\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "def build_retriever(\n",
    "    dataset: EmbeddingQAFinetuneDataset,\n",
    "    embed_model: BaseEmbedding | str,\n",
    "    corpus_embeddings: Optional[torch.Tensor] = None,\n",
    "    k: int=10\n",
    ") -> BaseRetriever:\n",
    "    corpus = dataset.corpus\n",
    "\n",
    "    nodes = []\n",
    "    for i, (id_, text) in enumerate(corpus.items()):\n",
    "        if corpus_embeddings is not None:\n",
    "            nodes.append(TextNode(id_=id_, text=text, embedding=corpus_embeddings[i].tolist()))\n",
    "        else:\n",
    "            nodes.append(TextNode(id_=id_, text=text))\n",
    "\n",
    "    index = VectorStoreIndex(\n",
    "        nodes=nodes, embeddings=corpus_embeddings, embed_model=embed_model, show_progress=True\n",
    "    )\n",
    "    return index.as_retriever(similarity_top_k=k)\n",
    "\n",
    "def ndcg_at_k(\n",
    "    dataset: EmbeddingQAFinetuneDataset,\n",
    "    retriever: BaseRetriever,\n",
    "    k: int=10\n",
    "):\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    ndcg_scores = []\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_ids = relevant_docs[query_id]\n",
    "\n",
    "        # Calculate NDCG\n",
    "        ideal_dcg = np.sum([1/np.log2(i+2) for i in range(min(k, len(expected_ids)))])\n",
    "        rel_scores = np.zeros(k)\n",
    "        for j in range(min(k, len(retrieved_ids))):\n",
    "            if retrieved_ids[j] in expected_ids:\n",
    "                rel_scores[j] = 1\n",
    "        dcg = np.sum([rel_scores[i]/np.log2(i+2) for i in range(len(rel_scores))])\n",
    "        ndcg = dcg/ideal_dcg if ideal_dcg > 0 else 0\n",
    "        \n",
    "        ndcg_scores.append(ndcg)\n",
    "\n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "    return mean_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the corpus embedding finetuning results\n",
    "Next we use, [NUDGE](https://www.arxiv.org/abs/2409.02343), the state of the art method for finetuning corpus embeddings to maximize the accuracy of k-NN retrieval. We then take our new corpus embeddings along with the original embedding model to build a retriever. NUDGE only finetunes the corpus embeddings and does not change any of the parameters in the base embedding model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.experimental.nudge.base:Use pytorch device: cuda\n",
      "Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from llama_index.experimental import Nudge\n",
    "\n",
    "k = 10\n",
    "\n",
    "nudge = Nudge(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    embed_model=base_embed_model,\n",
    "    epochs=10000,\n",
    "    train_batch_size=len(train_dataset.queries),\n",
    "    val_batch_size=len(val_dataset.queries)\n",
    ")\n",
    "nudge.finetune()\n",
    "nudge_corpus_embeddings = nudge.get_finetuned_corpus_embeddings()\n",
    "nudge_retriever = build_retriever(train_dataset, base_embed_model, nudge_corpus_embeddings, k=k)\n",
    "nudge_ndcg_test = ndcg_at_k(test_dataset, nudge_retriever, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the adapter finetuning results\n",
    "We use a smaller batchsize than NUDGE above due to the adapter finetune baseline having a significantly slower training process. We also note that even with a batchsize the size of the dataset and 10k epochs the adapter finetuned model performs similarly to the hyperparams currently used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.finetuning.embeddings.adapter:Use pytorch device: cuda\n",
      "Use pytorch device: cuda\n",
      "INFO:llama_index.embeddings.adapter.base:Use pytorch device: cuda\n",
      "Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from llama_index.finetuning import EmbeddingAdapterFinetuneEngine\n",
    "\n",
    "embedding_adapater_finetune_engine = EmbeddingAdapterFinetuneEngine(\n",
    "    train_dataset,\n",
    "    base_embed_model,\n",
    "    epochs=4,\n",
    "    batch_size=10,\n",
    ")\n",
    "embedding_adapater_finetune_engine.finetune()\n",
    "embedding_adapter_model = embedding_adapater_finetune_engine.get_finetuned_model()\n",
    "ft_retriever = build_retriever(train_dataset, embedding_adapter_model, k=k)\n",
    "ft_ndcg_test = ndcg_at_k(test_dataset, ft_retriever, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "base_retriever = build_retriever(train_dataset, base_embed_model, k=k)\n",
    "bge_ndcg_test = ndcg_at_k(test_dataset, base_retriever, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bge test - ndcg@10: 0.71\n",
      "adaptor finetune test - ndcg@10: 0.72\n",
      "NUDGE test - ndcg@10: 0.83\n"
     ]
    }
   ],
   "source": [
    "print(f\"bge test - ndcg@10: {bge_ndcg_test:.2f}\")\n",
    "print(f\"adaptor finetune test - ndcg@10: {ft_ndcg_test:.2f}\")\n",
    "print(f\"NUDGE test - ndcg@10: {nudge_ndcg_test:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
