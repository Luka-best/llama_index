{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mem0 for Function Calling Agents\n",
    "\n",
    "Use `Mem0` as memory for `FunctionCallingAgents`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import FunctionCallingAgent\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `from_client` (for Mem0 platform API): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.memory.mem0 import Mem0ComposableMemory\n",
    "\n",
    "context_dict = {\"user_id\": \"david_2\"}\n",
    "memory = Mem0ComposableMemory.from_client(\n",
    "    chat_history=ChatMemoryBuffer.from_defaults(),\n",
    "    context_dict=context_dict,\n",
    "    api_key=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize llm\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_fn(name: str):\n",
    "    \"\"\"Call the provided name.\n",
    "    Args:\n",
    "        name: str (Name of the person)\n",
    "    \"\"\"\n",
    "    print(f\"Calling... {name}\")\n",
    "\n",
    "\n",
    "def email_fn(name: str):\n",
    "    \"\"\"Email the provided name.\n",
    "    Args:\n",
    "        name: str (Name of the person)\n",
    "    \"\"\"\n",
    "    print(f\"Emailing... {name}\")\n",
    "\n",
    "\n",
    "call_tool = FunctionTool.from_defaults(fn=call_fn)\n",
    "email_tool = FunctionTool.from_defaults(fn=email_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(\n",
    "    [call_tool, email_tool],\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 720c2cbe-9e70-4f88-9d28-09fe4064b6fb. Step input: Hi, My name is Mayank.\n",
      "Added user message to memory: Hi, My name is Mayank.\n",
      "=== LLM Response ===\n",
      "Hello Mayank! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hi, My name is Mayank.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step c99b8ee5-af6b-4e88-b977-9bedbbd04d73. Step input: My preferred way of communication would be Email.\n",
      "Added user message to memory: My preferred way of communication would be Email.\n",
      "=== LLM Response ===\n",
      "Got it, Mayank! I'll make sure to use email as your preferred method of communication. If there's anything specific you need, just let me know!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"My preferred way of communication would be Email.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 4806bdb7-1123-4774-b7e1-a445d5fb9681. Step input: Send me an update of your product.\n",
      "Added user message to memory: Send me an update of your product.\n",
      "=== Calling Function ===\n",
      "Calling function: email_fn with args: {\"name\": \"Mayank\"}\n",
      "Emailing... Mayank\n",
      "=== Function Output ===\n",
      "None\n",
      "> Running step d060a412-006f-4d56-968a-c64e6b902590. Step input: None\n",
      "=== LLM Response ===\n",
      "I've sent you an update of our product via email. If you have any questions or need further information, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Send me an update of your product.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `from_config` (for Mem0 OSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"qdrant\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"test_9\",\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 6333,\n",
    "            \"embedding_model_dims\": 1536,  # Change this according to your local model's dimensions\n",
    "        },\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 1500,\n",
    "        },\n",
    "    },\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\"model\": \"text-embedding-3-small\"},\n",
    "    },\n",
    "    \"version\": \"v1.1\",\n",
    "}\n",
    "memory = Mem0ComposableMemory.from_config(\n",
    "    context_dict=context_dict,\n",
    "    confif_dict=config,\n",
    "    chat_history=ChatMemoryBuffer.from_defaults(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(\n",
    "    [call_tool, email_tool],\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 52ab5c4f-ba25-48e9-9a70-a4e0ae5db1b7. Step input: Hi, My name is Mayank.\n",
      "Added user message to memory: Hi, My name is Mayank.\n",
      "=== LLM Response ===\n",
      "Hello, Mayank! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hi, My name is Mayank.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step a661bd23-60a6-4085-bf5f-37783597f37f. Step input: My preferred way of communication would be Call.\n",
      "Added user message to memory: My preferred way of communication would be Call.\n",
      "=== LLM Response ===\n",
      "Got it, Mayank! If you need to communicate, I'll make sure to use a call. How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"My preferred way of communication would be Call.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 7fb66b1b-042f-4b3d-b04a-88ca93ec9281. Step input: Send me an update of your product.\n",
      "Added user message to memory: Send me an update of your product.\n",
      "=== Calling Function ===\n",
      "Calling function: call_fn with args: {\"name\": \"Mayank\"}\n",
      "Calling... Mayank\n",
      "=== Function Output ===\n",
      "None\n",
      "> Running step 132367ce-9afe-400d-bb29-deecc2bc25eb. Step input: None\n",
      "=== LLM Response ===\n",
      "I've initiated a call to provide you with the product update. Please check your phone.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Send me an update of your product.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
