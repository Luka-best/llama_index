{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mem0 for Function Calling Agents\n",
    "\n",
    "Use `Mem0` as memory for `FunctionCallingAgents`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import FunctionCallingAgent\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `from_client` (for Mem0 platform API): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.memory.mem0 import Mem0Composable\n",
    "context_dict = {\n",
    "    \"user_id\": \"mayank_11\"\n",
    "}\n",
    "memory=Mem0Composable.from_client(\n",
    "    chat_history=ChatMemoryBuffer.from_defaults(),\n",
    "    context_dict=context_dict,\n",
    "    api_key=\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize llm\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_fn(name: str):\n",
    "    \"\"\"Call the provided name.\n",
    "    Args:\n",
    "        name: str (Name of the person)\n",
    "    \"\"\"\n",
    "    print(f\"Calling... {name}\")\n",
    "\n",
    "def email_fn(name: str):\n",
    "    \"\"\"Email the provided name.\n",
    "    Args:\n",
    "        name: str (Name of the person)\n",
    "    \"\"\"\n",
    "    print(f\"Emailing... {name}\")\n",
    "\n",
    "\n",
    "call_tool = FunctionTool.from_defaults(fn=call_fn)\n",
    "email_tool = FunctionTool.from_defaults(fn=email_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(\n",
    "    [call_tool, email_tool],\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 708deb9e-029b-4720-a3e7-377d49c1d8b8. Step input: Hi, My name is Mayank.\n",
      "Added user message to memory: Hi, My name is Mayank.\n",
      "=== LLM Response ===\n",
      "Hello, Mayank! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hi, My name is Mayank.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 37d4c3db-1856-4d12-b365-20079e133b27. Step input: My preferred way of communication would be Email.\n",
      "Added user message to memory: My preferred way of communication would be Email.\n",
      "=== LLM Response ===\n",
      "Got it, Mayank! I'll use email as your preferred method of communication. If you need anything specific, just let me know!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"My preferred way of communication would be Email.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 1a9281ba-5041-4a76-8622-e98072cbf371. Step input: Send me an update of your product.\n",
      "Added user message to memory: Send me an update of your product.\n",
      "=== Calling Function ===\n",
      "Calling function: email_fn with args: {\"name\": \"Mayank\"}\n",
      "Emailing... Mayank\n",
      "=== Function Output ===\n",
      "None\n",
      "> Running step 3af3dcad-88cc-4f8e-9f87-838503261563. Step input: None\n",
      "=== LLM Response ===\n",
      "I've sent you an update of our product via email. If you have any questions or need further information, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Send me an update of your product.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `from_config` (for Mem0 OSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"qdrant\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"test_9\",\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 6333,\n",
    "            \"embedding_model_dims\": 1536,  # Change this according to your local model's dimensions\n",
    "        },\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 1500,\n",
    "        }\n",
    "    },\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"model\": \"text-embedding-3-small\"\n",
    "        }\n",
    "    },\n",
    "    \"version\": \"v1.1\"\n",
    "}\n",
    "memory = Mem0Composable .from_config(\n",
    "    context_dict=context_dict,\n",
    "    confif_dict=config,\n",
    "    primary_memory=ChatMemoryBuffer.from_defaults()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(\n",
    "    [call_tool, email_tool],\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 479c16d2-36f3-48e8-93f0-3f685e46243d. Step input: Hi, My name is Mayank.\n",
      "Added user message to memory: Hi, My name is Mayank.\n",
      "=== LLM Response ===\n",
      "Hello Mayank! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hi, My name is Mayank.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 9fe132bf-3c53-4f24-88e6-325702f121d0. Step input: My preferred way of communication would be Call.\n",
      "Added user message to memory: My preferred way of communication would be Call.\n",
      "=== LLM Response ===\n",
      "Thank you for updating your communication preference to calls. If you need anything, just let me know!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"My preferred way of communication would be Call.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step bf45f0b6-706a-4090-8045-be3dc6053d90. Step input: Send me an update of your product.\n",
      "Added user message to memory: Send me an update of your product.\n",
      "=== Calling Function ===\n",
      "Calling function: call_fn with args: {\"name\": \"Mayank\"}\n",
      "Calling... Mayank\n",
      "=== Function Output ===\n",
      "None\n",
      "> Running step b6ff6eb1-12f2-4c79-9792-6e5297839310. Step input: None\n",
      "=== LLM Response ===\n",
      "I've arranged to call you with an update on our product. If there's anything else you need, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Send me an update of your product.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
