{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mem0 for Chat Engines\n",
    "\n",
    "Use `Mem0` as memory to `SimpleChatEngine`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `from_client` (for Mem0 platform API): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing memory\n",
    "from llama_index.memory.mem0 import Mem0Memory\n",
    "\n",
    "context = {\"user_id\": \"hamlin_2\"}\n",
    "memory = Mem0Memory.from_client(context=context, api_key=\"<your-mem0-api-key>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize llm\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<your-openai-api-key>\"\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat engine\n",
    "from llama_index.core.chat_engine.simple import SimpleChatEngine\n",
    "\n",
    "agent = SimpleChatEngine.from_defaults(\n",
    "    llm=llm, memory=memory  # set you memory here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mayank! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hi, My name is mayank\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That sounds exciting! San Francisco has a lot to offer. Do you have any specific plans or places you want to visit while you're there? If you need any recommendations or tips, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"I am planning to visit SF tommorow.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When scheduling a meeting in San Francisco, it's important to consider the city's traffic patterns and your travel plans. Generally, late morning or early afternoon, such as 11:00 AM or 2:00 PM, can be good times to avoid rush hour traffic. However, if you have other activities planned, you might want to schedule around those. Let me know if you have any specific constraints or preferences!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Suggest a suitable time to schedule a meeting tommorow?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `from_config` (for Mem0 OSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"qdrant\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"test_7\",\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 6333,\n",
    "            \"embedding_model_dims\": 1536,  # Change this according to your local model's dimensions\n",
    "        },\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 1500,\n",
    "        },\n",
    "    },\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\"model\": \"text-embedding-3-small\"},\n",
    "    },\n",
    "    \"version\": \"v1.1\",\n",
    "}\n",
    "\n",
    "# Initialize memory\n",
    "memory = Mem0Memory.from_config(config=config, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SimpleChatEngine.from_defaults(\n",
    "    llm=llm, memory=memory  # set you memory here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mayank! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hi, My name is mayank\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That sounds exciting! San Francisco has a lot to offer. Do you have any specific plans or places you want to visit while you're there?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"I am planning to visit SF tommorow.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're planning to visit San Francisco tomorrow. Do you have any specific places or activities in mind for your trip? If you need recommendations, I'd be happy to help!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Where I will be visiting tommorow?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-C8qa2pNc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
