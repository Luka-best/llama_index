{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mem0 for Chat Engines\n",
    "\n",
    "Use `Mem0` as memory to `SimpleChatEngine`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `from_client` (for Mem0 platform API): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing memory\n",
    "from llama_index.memory.mem0 import Mem0\n",
    "context_dict = {\n",
    "    \"user_id\": \"mayank_1\"\n",
    "}\n",
    "memory = Mem0.from_client(\n",
    "    context_dict=context_dict,\n",
    "    api_key=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize llm\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat engine\n",
    "from llama_index.core.chat_engine.simple import SimpleChatEngine\n",
    "agent = SimpleChatEngine.from_defaults(\n",
    "    llm=llm,\n",
    "    memory=memory # set you memory here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Mayank! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hi, My name is mayank\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That sounds exciting, Mayank! San Francisco has so much to offer. Do you have any specific places or activities in mind that you want to explore while you're there?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"I am planning to visit SF tommorow.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since you are planning to visit San Francisco tomorrow, it might be best to schedule the meeting either early in the morning before your trip or later in the evening after your visit. This way, you can avoid any potential conflicts with your travel plans.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Suggest a suitable time to schedule a meeting tommorow?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `from_config` (for Mem0 OSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"qdrant\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"test_7\",\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 6333,\n",
    "            \"embedding_model_dims\": 1536,  # Change this according to your local model's dimensions\n",
    "        },\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 1500,\n",
    "        }\n",
    "    },\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"model\": \"text-embedding-3-small\"\n",
    "        }\n",
    "    },\n",
    "    \"version\": \"v1.1\"\n",
    "}\n",
    "\n",
    "# Initialize memory\n",
    "memory = Mem0.from_config(\n",
    "    confif_dict=config,\n",
    "    context_dict=context_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SimpleChatEngine.from_defaults(\n",
    "    llm=llm,\n",
    "    memory=memory # set you memory here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mayank! It's nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hi, My name is mayank\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That sounds exciting! Since you're planning to visit San Francisco on 2024-10-17, do you have any specific activities or places in mind that you'd like to explore? If you need any recommendations or tips for your trip, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"I am planning to visit SF tommorow.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since today is October 17, 2023, and you are planning to visit San Francisco on October 17, 2024, you are likely available tomorrow. However, I don't have specific details about your schedule or time zone. Generally, mid-morning or early afternoon are good times to schedule meetings, as people are often most alert and productive during these times. If you have any specific time constraints or preferences, please let me know!\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Suggest a suitable time to schedule a meeting tommorow?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `set_context` and `get_context`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.set_context({\n",
    "    \"user_id\": \"jhon_1\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'jhon_1'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-C8qa2pNc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
