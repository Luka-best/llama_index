{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRqdYoxukim-"
      },
      "source": [
        "## Build Agentic RAG using Vertex AI and Llamaindex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuBAt6dashTt"
      },
      "outputs": [],
      "source": [
        "# @title Copyright & License (click to expand)\n",
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-5v5HIpjZLb"
      },
      "source": [
        "### Pre-requirements\n",
        "- Set up a project\n",
        "- Create a bucket\n",
        "\n",
        "\n",
        "References:\n",
        "- https://colab.sandbox.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/VertexAIVectorSearchDemo.ipynb#scrollTo=_X0bKO2mnBHK\n",
        "\n",
        "- https://learn.deeplearning.ai/courses/building-agentic-rag-with-llamaindex/lesson/2/router-query-engine\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkClD3Aklocy"
      },
      "source": [
        "### Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0uHJ_pHj2iJ",
        "outputId": "b124aeee-fc31-455d-cc4f-d4f698043b30"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-vector-stores-vertexaivectorsearch llama-index-llms-vertex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install llama-index-vector-stores-vertexaivectorsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install --upgrade git+https://github.com/wadave/llama_index.git@main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68Y2mEPsJ9B-"
      },
      "outputs": [],
      "source": [
        "#Colab only\n",
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQe0yMStJur4"
      },
      "outputs": [],
      "source": [
        "#JupyterLab instance\n",
        "!gcloud auth login "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtPNg5W-J0NV"
      },
      "outputs": [],
      "source": [
        "#Colab only\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ELdj1Pd5jXWq"
      },
      "outputs": [],
      "source": [
        "# TODO : Set values as per your requirements\n",
        "\n",
        "# Project and Storage Constants\n",
        "PROJECT_ID = \"astute-psyche-419021\"\n",
        "REGION = \"us-central1\"\n",
        "GCS_BUCKET_NAME = \"astute-psyche-419021-bucket\"\n",
        "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET_NAME}\"\n",
        "\n",
        "# The number of dimensions for the textembedding-gecko@003 is 768\n",
        "# If other embedder is used, the dimensions would probably need to change.\n",
        "VS_DIMENSIONS = 768\n",
        "\n",
        "# Vertex AI Vector Search Index configuration\n",
        "# parameter description here\n",
        "# https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_create_tree_ah_index\n",
        "VS_INDEX_NAME = \"vertex_vector_search_index\"  # @param {type:\"string\"}\n",
        "VS_INDEX_ENDPOINT_NAME = \"vector_search_endpoint\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87zTYI33tIfN"
      },
      "source": [
        "Download Sample Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yds9ayaLslOR",
        "outputId": "7ed24976-4612-4151-c0a8-612cc4912e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded file from https://openreview.net/pdf?id=VtmBAGCN7o to metagpt.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=6PmJoRfdaK to longlora.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=LzPWWPAdY4 to loftq.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=VTF8yNQM66 to swebench.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=hSyW5go0v8 to selfrag.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=9WD9KwssyT to zipformer.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=yV6fD7LYkF to values.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=hnrB5YHoYu to finetune_fair_diffusion.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=WbWtOYIzIK to knowledge_card.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=c5pwL0Soay to metra.pdf\n",
            "Downloaded file from https://openreview.net/pdf?id=TpD2aG1h0D to vr_mcl.pdf\n"
          ]
        }
      ],
      "source": [
        "urls = [\n",
        "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
        "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
        "    \"https://openreview.net/pdf?id=LzPWWPAdY4\",\n",
        "    \"https://openreview.net/pdf?id=VTF8yNQM66\",\n",
        "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
        "    \"https://openreview.net/pdf?id=9WD9KwssyT\",\n",
        "    \"https://openreview.net/pdf?id=yV6fD7LYkF\",\n",
        "    \"https://openreview.net/pdf?id=hnrB5YHoYu\",\n",
        "    \"https://openreview.net/pdf?id=WbWtOYIzIK\",\n",
        "    \"https://openreview.net/pdf?id=c5pwL0Soay\",\n",
        "    \"https://openreview.net/pdf?id=TpD2aG1h0D\"\n",
        "]\n",
        "\n",
        "papers = [\n",
        "    \"metagpt.pdf\",\n",
        "    \"longlora.pdf\",\n",
        "    \"loftq.pdf\",\n",
        "    \"swebench.pdf\",\n",
        "    \"selfrag.pdf\",\n",
        "    \"zipformer.pdf\",\n",
        "    \"values.pdf\",\n",
        "    \"finetune_fair_diffusion.pdf\",\n",
        "    \"knowledge_card.pdf\",\n",
        "    \"metra.pdf\",\n",
        "    \"vr_mcl.pdf\"\n",
        "]\n",
        "import requests\n",
        "\n",
        "def download_file(url, file_path):\n",
        "    \"\"\"Downloads a file from a given URL and saves it to the specified file path.\n",
        "\n",
        "    Args:\n",
        "        url: The URL of the file to download.\n",
        "        file_path: The path to save the downloaded file.\n",
        "    \"\"\"\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for non-200 status codes\n",
        "\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:  # Filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "    print(f\"Downloaded file from {url} to {file_path}\")\n",
        "\n",
        "\n",
        "for url, paper in zip(urls, papers):\n",
        "    download_file(url, paper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c8HQFQPMslec"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geKoGEdAsrvk"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DsGk9Q9tshTu"
      },
      "outputs": [],
      "source": [
        "papers = [\n",
        "    \"metagpt.pdf\",\n",
        "    \"longlora.pdf\",\n",
        "    \"selfrag.pdf\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZM9cb3CgtrHD"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R5qWRt_v6AS"
      },
      "source": [
        "### Option 1: Create a new Vertex AI Vector Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm0ZCOcNwkLi"
      },
      "source": [
        "Create an empty index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXx-4_CPv6hE",
        "outputId": "10ddd8fc-02a4-4a2a-f12f-81cc8ec29842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector Search index vertex_vector_search_index exists with resource name projects/77923429797/locations/us-central1/indexes/8741403313842421760\n"
          ]
        }
      ],
      "source": [
        "# check if index exists\n",
        "index_names = [\n",
        "    index.resource_name\n",
        "    for index in aiplatform.MatchingEngineIndex.list(\n",
        "        filter=f\"display_name={VS_INDEX_NAME}\"\n",
        "    )\n",
        "]\n",
        "\n",
        "if len(index_names) == 0:\n",
        "    print(f\"Creating Vector Search index {VS_INDEX_NAME} ...\")\n",
        "    vs_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "        display_name=VS_INDEX_NAME,\n",
        "        dimensions=VS_DIMENSIONS,\n",
        "        distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "        approximate_neighbors_count=150,\n",
        "        shard_size=\"SHARD_SIZE_SMALL\",\n",
        "        index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} created with resource name {vs_index.resource_name}\"\n",
        "    )\n",
        "else:\n",
        "    vs_index = aiplatform.MatchingEngineIndex(index_name=index_names[0])\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} exists with resource name {vs_index.resource_name}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qakIcArTwlOk"
      },
      "source": [
        "Create an endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQplL82Iv6li",
        "outputId": "4630110d-c9d1-4bd2-d7c2-0b1ad0c7c2aa"
      },
      "outputs": [],
      "source": [
        "endpoint_names = [\n",
        "    endpoint.resource_name\n",
        "    for endpoint in aiplatform.MatchingEngineIndexEndpoint.list(\n",
        "        filter=f\"display_name={VS_INDEX_ENDPOINT_NAME}\"\n",
        "    )\n",
        "]\n",
        "\n",
        "if len(endpoint_names) == 0:\n",
        "    print(\n",
        "        f\"Creating Vector Search index endpoint {VS_INDEX_ENDPOINT_NAME} ...\"\n",
        "    )\n",
        "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "        display_name=VS_INDEX_ENDPOINT_NAME, public_endpoint_enabled=True\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index endpoint {vs_endpoint.display_name} created with resource name {vs_endpoint.resource_name}\"\n",
        "    )\n",
        "else:\n",
        "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
        "        index_endpoint_name=endpoint_names[0]\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index endpoint {vs_endpoint.display_name} exists with resource name {vs_endpoint.resource_name}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo7rI0UWwmMe"
      },
      "source": [
        "Deploy index to endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tnd_4YPv6pH",
        "outputId": "33c68c25-e253-483e-fbb7-c54950cdeed5"
      },
      "outputs": [],
      "source": [
        "# check if endpoint exists\n",
        "# it takes about 30 mins to finish\n",
        "index_endpoints = [\n",
        "    (deployed_index.index_endpoint, deployed_index.deployed_index_id)\n",
        "    for deployed_index in vs_index.deployed_indexes\n",
        "]\n",
        "\n",
        "if len(index_endpoints) == 0:\n",
        "    print(\n",
        "        f\"Deploying Vector Search index {vs_index.display_name} at endpoint {vs_endpoint.display_name} ...\"\n",
        "    )\n",
        "    vs_deployed_index = vs_endpoint.deploy_index(\n",
        "        index=vs_index,\n",
        "        deployed_index_id=VS_INDEX_NAME,\n",
        "        display_name=VS_INDEX_NAME,\n",
        "        machine_type=\"e2-standard-16\",\n",
        "        min_replica_count=1,\n",
        "        max_replica_count=1,\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} is deployed at endpoint {vs_deployed_index.display_name}\"\n",
        "    )\n",
        "else:\n",
        "    vs_deployed_index = aiplatform.MatchingEngineIndexEndpoint(\n",
        "        index_endpoint_name=index_endpoints[0][0]\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} is already deployed at endpoint {vs_deployed_index.display_name}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AMBIdCuwGE8"
      },
      "source": [
        "### Option 2: Use an existing Vertex AI Vector Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0B96WmdQv6tW"
      },
      "outputs": [],
      "source": [
        "# TODO : replace 1234567890123456789 with your actual index ID\n",
        "vs_index = aiplatform.MatchingEngineIndex(index_name='8741403313842421760')\n",
        "\n",
        "# TODO : replace 1234567890123456789 with your actual endpoint ID\n",
        "vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
        "    index_endpoint_name='5953112194546663424'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce5x4sXqv7BN"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "LK7HhR_juEW6"
      },
      "outputs": [],
      "source": [
        "# import modules needed\n",
        "from llama_index.core import (\n",
        "    StorageContext,\n",
        "    Settings,\n",
        "    VectorStoreIndex,\n",
        "    SummaryIndex,\n",
        "    SimpleDirectoryReader,\n",
        ")\n",
        "from llama_index.core.schema import TextNode\n",
        "from llama_index.core.vector_stores.types import (\n",
        "    MetadataFilters,\n",
        "    MetadataFilter,\n",
        "    FilterOperator,\n",
        ")\n",
        "from llama_index.llms.vertex import Vertex\n",
        "from llama_index.embeddings.vertex import VertexTextEmbedding\n",
        "from llama_index.vector_stores.vertexaivectorsearch import VertexAIVectorStore\n",
        "\n",
        "from typing import List\n",
        "from llama_index.core.vector_stores import FilterCondition\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "from llama_index.core.vector_stores import MetadataFilters\n",
        "from pathlib import Path\n",
        "\n",
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up Vector Search Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PuJhRR7PuEeT"
      },
      "outputs": [],
      "source": [
        "# setup vector store\n",
        "vector_store = VertexAIVectorStore(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    index_id=vs_index.name,\n",
        "    endpoint_id=vs_endpoint.name,\n",
        "    gcs_bucket_name=GCS_BUCKET_NAME,\n",
        ")\n",
        "\n",
        "# set storage context\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Hhf84mXAx-n3"
      },
      "outputs": [],
      "source": [
        "# configure embedding model\n",
        "embed_model = VertexTextEmbedding(\n",
        "    model_name=\"textembedding-gecko@003\",\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        ")\n",
        "\n",
        "vertex_gemini = Vertex(model=\"gemini-1.5-pro-preview-0514\", temperature=0, additional_kwargs={})\n",
        "\n",
        "# setup the index/query process, ie the embedding model (and completion if used)\n",
        "Settings.embed_model = embed_model\n",
        "Settings.llm = vertex_gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1: Router query engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1MDkcpmBmArQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xEllechyejh",
        "outputId": "a6de8295-046c-47f6-c3d4-7372f014713d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n"
          ]
        }
      ],
      "source": [
        "# define index from vector store\n",
        "vector_index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gBgP3UZ5uElY"
      },
      "outputs": [],
      "source": [
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FRT6zbh4uEpA"
      },
      "outputs": [],
      "source": [
        "summary_index = SummaryIndex(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHucYzj-_wb3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aF3__38XuEs4"
      },
      "outputs": [],
      "source": [
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "page_label: 1\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "METAGPT: M ETA PROGRAMMING FOR A\n",
            "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
            "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
            "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
            "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
            "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
            "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
            "5Nanjing University,6University of Pennsylvania,\n",
            "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
            "ABSTRACT\n",
            "Remarkable progress has been made on automated problem solving through so-\n",
            "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
            "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
            "complex tasks, however, are complicated through logic inconsistencies due to\n",
            "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
            "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
            "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
            "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
            "streamlined workflows, thus allowing agents with human-like domain expertise\n",
            "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
            "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
            "complex tasks into subtasks involving many agents working together. On col-\n",
            "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
            "solutions than previous chat-based multi-agent systems. Our project can be found\n",
            "at https://github.com/geekan/MetaGPT.\n",
            "1 I NTRODUCTION\n",
            "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
            "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
            "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
            "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
            "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
            "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
            "et al., 2023; Qian et al., 2023).\n",
            "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
            "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
            "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
            "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
            "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
            "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
            "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
            "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
            "(PRDs) using a standardized structure, to guide the developmental process.\n",
            "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
            "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
            "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
            "∗These authors contributed equally to this work.\n",
            "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
            "1\n",
            "\n",
            "page_label: 2\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
            "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
            "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
            "(e.g., Product Manager, Architect, Engineer, etc.).\n",
            "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
            "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
            "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
            "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
            "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
            "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
            "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
            "lunch?” – Bob (Architect).\n",
            "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
            "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
            "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
            "2006; Finn et al., 2017).\n",
            "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
            "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
            "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
            "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
            "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
            "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
            "ing how agent-based techniques can enhance meta-programming.\n",
            "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
            "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
            "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
            "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
            "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
            "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
            "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
            "We summarize our contributions as follows:\n",
            "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
            "2\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "•We introduce MetaGPT, a meta-programming framework for multi-agent collaboration based on\n",
            "LLMs. It is highly convenient and flexible, with well-defined functions like role definition and\n",
            "message sharing, making it a useful platform for developing LLM-based multi-agent systems.\n",
            "•Our innovative integration of human-like SOPs throughout MetaGPT’s design significantly en-\n",
            "hances its robustness, reducing unproductive collaboration among LLM-based agents. Furthermore,\n",
            "we introduce a novel executive feedback mechanism that debugs and executes code during runtime,\n",
            "significantly elevating code generation quality (e.g., 5.4% absolute improvement on MBPP).\n",
            "•We achieve state-of-the-art performance on HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021). Extensive results convincingly validate MetaGPT, suggesting that it is a promising\n",
            "meta-programming framework for developing LLM-based multi-agent systems.\n",
            "2 R ELATED WORK\n",
            "Automatic Programming The roots of automatic programming reach back deep into the previ-\n",
            "ous century. In 1969, Waldinger & Lee (1969) introduced “PROW,” a system designed to accept\n",
            "program specifications written in predicate calculus, generate algorithms, and create LISP imple-\n",
            "mentations (McCarthy, 1978). Balzer (1985) and Soloway (1986) made efforts to advance auto-\n",
            "matic programming and identified potential methods to achieve it. Recent approaches use natural\n",
            "language processing (NLP) techniques (Ni et al., 2023; Skreta et al., 2023; Feng et al., 2020; Li\n",
            "et al., 2022; Chen et al., 2018; 2021b; Zhang et al., 2023). Automatic programming has grown into\n",
            "an industry delivering paid functions such as Microsoft Copilot. Lately, LLMs-based agents (Yao\n",
            "et al., 2022; Shinn et al., 2023; Lin et al., 2023) have advanced automatic programming develop-\n",
            "ment. Among them, ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023) utilize a chain of\n",
            "thought prompts (Wei et al., 2022) to generate reasoning trajectories and action plans with LLMs.\n",
            "Both works demonstrate the effectiveness of the ReAct style loop of reasoning as a design paradigm\n",
            "for empowering automatic programming. Additionally, ToolFormer (Schick et al., 2023) can learn\n",
            "how to use external tools through simple APIs. The research most closely aligned with our work\n",
            "by Li et al. (2023) proposes a straightforward role-play framework for programming that involves\n",
            "communication between agents playing different roles. Qian et al. (2023) utilizes multiple agents for\n",
            "software development. Although existing papers (Li et al., 2023; Qian et al., 2023) have improved\n",
            "productivity, they have not fully tapped into effective workflows with structured output formats.\n",
            "This makes it harder to deal with complex software engineering issues.\n",
            "LLM-Based Multi-Agent Frameworks Recently, LLM-based autonomous agents have gained\n",
            "tremendous interest in both industry and academia (Wang et al., 2023b). Many works (Chen et al.,\n",
            "2024; Wang et al., 2023c; Du et al., 2023; Zhuge et al., 2023; Hao et al., 2023; Akata et al., 2023)\n",
            "have improved the problem-solving abilities of LLMs by integrating discussions among multiple\n",
            "agents. Stable-Alignment (Liu et al., 2023) creates instruction datasets by deriving consensus on\n",
            "value judgments through interactions across a sandbox with LLM agents. Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks.\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks. Besides, LLM-based agents face the challenges of “assistant repeated instruc-\n",
            "tion” or “infinite loop of message” (Talebirad & Nadiri, 2023; Li et al., 2023). These challenges\n",
            "become more urgent in task-oriented collaborations, which require consistent and mutually benefi-\n",
            "cial interactions (Elazar et al., 2021; Wang et al., 2022; Jiang et al., 2023). This motivates our focus\n",
            "on applying advanced concepts such as Standard Operating Procedures in software development to\n",
            "multi-agent frameworks.\n",
            "3\n",
            "\n",
            "page_label: 4\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 2: An example of the communication protocol (left) and iterative programming with exe-\n",
            "cutable feedback (right). Left: Agents use a shared message pool to publish structured messages.\n",
            "They can also subscribe to relevant messages based on their profiles. Right : After generating the\n",
            "initial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past\n",
            "messages stored in memory and compares them with the PRD, system design, and code files.\n",
            "3 M ETAGPT: A M ETA-PROGRAMMING FRAMEWORK\n",
            "MetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 pro-\n",
            "vides an explanation of role specialization, workflow and structured communication in this frame-\n",
            "work, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2\n",
            "presents a communication protocol that enhances role communication efficiency. We also imple-\n",
            "ment structured communication interfaces and an effective publish-subscribe mechanism. These\n",
            "methods enable agents to obtain directional information from other roles and public information\n",
            "from the environment. Finally, we introduce executable feedback—a self-correction mechanism for\n",
            "further enhancing code generation quality during run-time in Sec. 3.3.\n",
            "3.1 A GENTS IN STANDARD OPERATING PROCEDURES\n",
            "Specialization of Roles Unambiguous role specialization enables the breakdown of complex work\n",
            "into smaller and more specific tasks. Solving complex tasks or problems often requires the collab-\n",
            "oration of agents with diverse skills and expertise, each contributing specialized outputs tailored to\n",
            "specific issues.\n",
            "In a software company, a Product Manager typically conducts business-oriented analysis and derives\n",
            "insights, while a software engineer is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: what's the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design, the information is\n",
            "directed towards the Project Manager for task distribution. Engineers proceed to execute the des-\n",
            "ignated classes and functions as outlined (detailed in Figure 2). In the following stage, the QA\n",
            "Engineer formulates test cases to enforce stringent code quality. In the final step, MetaGPT pro-\n",
            "duces a meticulously crafted software solution. We provide a detailed schematic (Figure 3) and a\n",
            "concrete instance (Appendix B) of the SOP workflow in MetaGPT.\n",
            "3.2 C OMMUNICATION PROTOCOL\n",
            "Structured Communication Interfaces Most current LLM-based multi-agent frameworks (Li\n",
            "et al., 2023; Zhuge et al., 2023; Zhang et al., 2023; Park et al., 2023) utilize unconstrained natural\n",
            "language as a communication interface.\n",
            "However, despite the versatility of natural language, a question arises: does pure natural language\n",
            "communication suffice for solving complex tasks? For example, in the telephone game (or Chinese\n",
            "5\n",
            "\n",
            "page_label: 6\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "whispers)2, after several rounds of communication, the original information may be quite distorted.\n",
            "Inspired by human social structures, we propose using structured communication to formulate the\n",
            "communication of agents. We establish a schema and format for each role and request that individ-\n",
            "uals provide the necessary outputs based on their specific role and context.\n",
            "As shown in Figure 3, the Architect agent generates two outputs: the system interface design and a\n",
            "sequence flow diagram. These contain system module design and interaction sequences, which serve\n",
            "as important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT\n",
            "communicate through documents and diagrams (structured outputs) rather than dialogue. These\n",
            "documents contain all necessary information, preventing irrelevant or missing content.\n",
            "Publish-Subscribe Mechanism Sharing information is critical in collaboration. For instance,\n",
            "Architects and Engineers often need to reference PRDs. However, communicating this information\n",
            "each time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023;\n",
            "Zhang et al., 2023), can complicate the communication topology, resulting in inefficiencies.\n",
            "To address this challenge, a viable approach is to store information in a global message pool . As\n",
            "shown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange\n",
            "messages directly. These agents not only publish their structured messages in the pool but also access\n",
            "messages from other entities transparently. Any agent can directly retrieve required information\n",
            "from the shared pool, eliminating the need to inquire about other agents and await their responses.\n",
            "This enhances communication efficiency.\n",
            "Sharing all information with every agent can lead to information overload. During task execution,\n",
            "an agent typically prefers to receive only task-related information and avoid distractions through\n",
            "irrelevant details. Effective management and dissemination of this information play a crucial role.\n",
            "We offer a simple and effective solution- subscription mechanism (in Figure 2 (left)). Instead of\n",
            "relying on dialogue, agents utilize role-specific interests to extract relevant information. They can\n",
            "select information to follow based on their role profiles. In practical implementations, an agent\n",
            "activates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3,\n",
            "the Architect mainly focuses on PRDs provided by the Product Manager, while documents from\n",
            "roles such as the QA Engineer might be of lesser concern.\n",
            "3.3 I TERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK\n",
            "In daily programming tasks, the processes of debugging and optimization play important roles.\n",
            "However, existing methods often lack a self-correction mechanism, which leads to unsuccessful code\n",
            "generation. Previous work introduced non-executable code review and self-reflection (Zhao et al.,\n",
            "2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in\n",
            "ensuring code executability and runtime correctness.\n",
            "Our first MetaGPT implementations overlooked certain errors during the review process, due to\n",
            "LLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we\n",
            "introduce an executable feedback mechanism to improve the code iteratively. More specifically, as\n",
            "shown in Figure 2, the Engineer is asked to write code based on the original product requirements\n",
            "and design.\n",
            "This enables the Engineer to continuously improve code using its own historical execution and\n",
            "debugging memory. To obtain additional information, the Engineer writes and executes the corre-\n",
            "sponding unit test cases, and subsequently receives the test results. If satisfactory, additional devel-\n",
            "opment tasks are initiated. Otherwise the Engineer debugs the code before resuming programming.\n",
            "This iterative testing process continues until the test is passed or a maximum of 3 retries is reached.\n",
            "4 E XPERIMENTS\n",
            "4.1 E XPERIMENTAL SETTING\n",
            "Datasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021), and a self-generated, more challenging software development benchmark named Soft-\n",
            "2https://en.wikipedia.org/wiki/Chinese whispers\n",
            "6\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "wareDev: (1) HumanEval includes 164 handwritten programming tasks. These tasks encompass\n",
            "function specifications, descriptions, reference codes, and tests. (2) MBPP consists of 427 Python\n",
            "tasks. These tasks cover core concepts and standard library features and include descriptions, ref-\n",
            "erence codes, and automated tests. (3) Our SoftwareDev dataset is a collection of 70 representa-\n",
            "tive examples of software development tasks, each with its own task prompt (see Table 8). These\n",
            "tasks have diverse scopes (See Figure 5), such as mini-games, image processing algorithms, data\n",
            "visualization. They offer a robust testbed for authentic development tasks. Contrary to previous\n",
            "datasets (Chen et al., 2021a; Austin et al., 2021), SoftwareDev focuses on the engineering aspects.\n",
            "In the comparisons, we randomly select seven representative tasks for evaluation.\n",
            "Evaluation Metrics For HuamnEval and MBPP, we follow the unbiased version of Pass @ kas\n",
            "presented by (Chen et al., 2021a; Dong et al., 2023), to evaluate the functional accuracy of the top-k\n",
            "generated codes: Pass @ k=EProblems\u0014\n",
            "1−(n−c\n",
            "k)\n",
            "(n\n",
            "k)\u0015\n",
            ".\n",
            "For SoftwareDev, we prioritize practical use and evaluate performance through human evaluations\n",
            "(A, E) or statistical analysis (B, C, D): (A)Executability: this metric rates code from 1 (failure/non-\n",
            "functional) to 4 (flawless). ‘1’ is for non-functional, ‘2’ for runnable but imperfect, ‘3’ for nearly\n",
            "perfect, and ‘4’ for flawless code. (B)Cost: the cost evaluations here include the (1) running time,\n",
            "(2) token usage, and (3) expenses. (C)Code Statistics: this includes (1) code files, (2) lines of code\n",
            "per file, and (3) total code lines. (D)Productivity: basically, it is defined as the number of token\n",
            "usage divided by the number of lines of code, which refers to the consumption of tokens per code\n",
            "line. (E)Human Revision Cost: refers to times of manual code corrections, which tackle problems\n",
            "like package import errors, incorrect class names, or incomplete reference paths. Typically, each\n",
            "correction involves up to 3 lines of code.\n",
            "Baselines We compare our method with recent domain-specific LLMs in the code generation field,\n",
            "including AlphaCode (Li et al., 2022), Incoder (Fried et al., 2022), CodeGeeX (Zheng et al., 2023),\n",
            "CodeGen (Nijkamp et al., 2023), CodeX (Chen et al., 2021a), and CodeT (Chen et al., 2022) and\n",
            "general domain LLMs such as PaLM (Chowdhery et al., 2022), and GPT-4 (OpenAI, 2023). Several\n",
            "results of baselines (such as Incoder, CodeGeeX) are provided by Dong et al. (2023). In HumanEval\n",
            "and MBPP, we slightly modified the prompts to align with response format requirements. These\n",
            "modifications aim to address format-specific issues (i.e., Python problems). With the SoftwareDev\n",
            "benchmark, we provide a comprehensive comparison between MetaGPT, AutoGPT (Torantulino\n",
            "et al., 2023), LangChain (Chase, 2022) with Python Read-Eval-Print Loop (REPL) tool3, Agent-\n",
            "Verse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "4.2 M AINRESULT\n",
            "AlphaCode(1.1B)\n",
            "Incoder (6.7B)\n",
            "CodeGeeX (13B)17.1\n",
            "—15.2 17.6 18.926.9\n",
            "CodeGeeX-Mono(16.1B)32.938.6\n",
            "GPT-467.0\n",
            "—\n",
            "MetaGPT\n",
            "(w/o Feedback)81.7 82.3Pass@1 of MBPP  and HumanEval (%)\n",
            "PaLM Coder(540B)36.047.0\n",
            "Codex (175B)47.058.1\n",
            "Codex + CodeT65.8 67.7\n",
            "HumanEval\n",
            "MBPP\n",
            "MetaGPT85.9 87.7\n",
            "Figure 4: Pass rates on the MBPP and HumanEval with a single attempt.\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks.\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks. When MetaGPT collaborates with GPT-4, it significantly im-\n",
            "proves the Pass @ kin the HumanEval benchmark compared to GPT-4. It achieves 85.9% and 87.7%\n",
            "3https://en.wikipedia.org/wiki/Read–eval–print loop\n",
            "7\n",
            "\n",
            "page_label: 8\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 5: Demo softwares developed by MetaGPT.\n",
            "in these two public benchmarks. Moreover, as shown in Table 1, MetaGPT outperforms ChatDev on\n",
            "the challenging SoftwareDev dataset in nearly all metrics. For example, considering the executabil-\n",
            "ity, MetaGPT achieves a score of 3.75, which is very close to 4 (flawless). Besides, it takes less time\n",
            "(503 seconds), clearly less than ChatDev. Considering the code statistic and the cost of human revi-\n",
            "sion, it also significantly outperforms ChatDev. Although MetaGPT requires more tokens (24,613\n",
            "or 31,255 compared to 19,292), it needs only 126.5/124.3 tokens to generate one line of code. In\n",
            "contrast, ChatDev uses 248.9 tokens. These results highlight the benefits of SOPs in collabora-\n",
            "tions between multiple agents. Additionally, we demonstrate the autonomous software generation\n",
            "capabilities of MetaGPT through visualization samples (Figure 5). For additional experiments and\n",
            "analysis, please refer to Appendix C.\n",
            "Table 1: The statistical analysis on SoftwareDev.\n",
            "Statistical Index ChatDev MetaGPT w/o Feedback MetaGPT\n",
            "(A)Executability 2.25 3.67 3.75\n",
            "(B)Cost#1: Running Times (s) 762 503 541\n",
            "(B)Cost#2: Token Usage 19,292 24,613 31,255\n",
            "(C)Code Statistic#1: Code Files 1.9 4.6 5.1\n",
            "(C)Code Statistic#2: Lines of Code per File 40.8 42.3 49.3\n",
            "(C)Code Statistic#3: Total Code Lines 77.5 194.6 251.4\n",
            "(D)Productivity 248.9 126.5 124.3\n",
            "(E)Human Revision Cost 2.5 2.25 0.83\n",
            "4.3 C APABILITIES ANALYSIS\n",
            "Compared to open-source baseline methods such as AutoGPT and autonomous agents such as\n",
            "AgentVerse and ChatDev, MetaGPT offers functions for software engineering tasks. As presented\n",
            "in Table 2, our framework encompasses a wide range of abilities to handle complex and specialized\n",
            "development tasks efficiently. Incorporating SOPs (e.g., role-play expertise, structured communi-\n",
            "cation, streamlined workflow) can significantly improve code generation. Other baseline methods\n",
            "8\n",
            "\n",
            "page_label: 9\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 2: Comparison of capabilities for MetaGPT and other approaches. ‘!’ indicates the\n",
            "presence of a specific feature in the corresponding framework, ‘ %’ its absence.\n",
            "Framework Capabiliy AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "PRD generation % % % % !\n",
            "Tenical design genenration % % % % !\n",
            "API interface generation % % % % !\n",
            "Code generation ! ! ! ! !\n",
            "Precompilation execution % % % % !\n",
            "Role-based task management % % % ! !\n",
            "Code review % % ! ! !\n",
            "Table 3: Ablation study on roles. ‘#’ denotes ‘The number of’, ‘Product’ denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: what's the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "‘Product’ denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass @1 on Hu-\n",
            "manEval and MBPP, respectively. Besides, Table 1 shows that the feedback mechanism improves\n",
            "feasibility (3.67 to 3.75) and reduces the cost of human revisions (2.25 to 0.83). These results\n",
            "illustrate how our designed feedback mechanism can produce higher-quality code. Additional quan-\n",
            "titative results of MetaGPT and MetaGPT without executable feedback are shown in Table 4 and\n",
            "Table 9.\n",
            "5 C ONCLUSION\n",
            "This work introduces MetaGPT, a novel meta-programming framework that leverages SOPs to en-\n",
            "hance the problem-solving capabilities of multi-agent systems based on Large Language Models\n",
            "(LLMs). MetaGPT models a group of agents as a simulated software company, analogous to simu-\n",
            "lated towns (Park et al., 2023) and the Minecraft Sandbox in V oyager (Wang et al., 2023a). MetaGPT\n",
            "leverages role specialization, workflow management, and efficient sharing mechanisms such as mes-\n",
            "sage pools and subscriptions, rendering it a flexible and portable platform for autonomous agents\n",
            "and multi-agent frameworks. It uses an executable feedback mechanism to enhance code generation\n",
            "quality during runtime. In extensive experiments, MetaGPT achieves state-of-the-art performance\n",
            "on multiple benchmarks. The successful integration of human-like SOPs inspires future research\n",
            "on human-inspired techniques for artificial multi-agent systems. We also view our work as an early\n",
            "attempt to regulate LLM-based multi-agent frameworks. See also the outlook (Appendix A) .\n",
            "9\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Acknowledgement\n",
            "We thank Sarah Salhi, the Executive Secretary of KAUST AI Initiative, and Yuhui Wang, Postdoc-\n",
            "toral Fellow at the KAUST AI Initiative, for helping to polish some of the text. We would like to\n",
            "express our gratitude to Wenyi Wang, a PhD student at the KAUST AI Initiative, for providing com-\n",
            "prehensive feedback on the paper and for helping to draft the outlook (Appendix A) with Mingchen.\n",
            "We also thank Zongze Xu, the vice president of DeepWisdom, for providing illustrative materials\n",
            "for AgentStore.\n",
            "Author Contributions\n",
            "Sirui Hong conducted most of the experiments and designed the executable feedback module. She\n",
            "also led the initial version of the write-up, supported by Ceyao Zhang, and also by Jinlin Wang and\n",
            "Zili Wang. Mingchen Zhuge designed the self-improvement module, discussed additional experi-\n",
            "ments, and led the current write-up. Jonathan Chen helped with the MBPP experiments, outlined\n",
            "the methods section, and contributed to the current write-up. Xiawu Zheng provided valuable guid-\n",
            "ance, reviewed and edited the paper. Yuheng Cheng contributed to the evaluation metric design and\n",
            "HumanEval experiments. Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Lingfeng Xiao helped\n",
            "with the MBPP experiments and comparisons to open-source baseline methods. Chenyu Ran cre-\n",
            "ated most of the illustrative figures. Chenglin Wu is the CEO of DeepWisdom, initiated MetaGPT,\n",
            "made the most significant code contributions to it, and advised this project. J ¨urgen Schmidhuber,\n",
            "Director of the AI Initiative at KAUST and Scientific Director of IDSIA, advised this project and\n",
            "helped with the write-up.\n",
            "REFERENCES\n",
            "Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz.\n",
            "Playing repeated games with large language models. arXiv preprint , 2023.\n",
            "Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\n",
            "Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large\n",
            "language models, 2021.\n",
            "Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew\n",
            "Goff, Jonathan Gray, Hengyuan Hu, et al. Human-level play in the game of diplomacy by com-\n",
            "bining language models with strategic reasoning. Science , 2022.\n",
            "Robert Balzer. A 15 year perspective on automatic programming. TSE, 1985.\n",
            "R.M. Belbin. Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\n",
            "Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,\n",
            "Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\n",
            "Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,\n",
            "Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-\n",
            "tios Chantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex\n",
            "Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,\n",
            "Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec\n",
            "Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob Mc-\n",
            "Grew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large\n",
            "language models trained on code, 2021a.\n",
            "10\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan,\n",
            "Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facili-\n",
            "tating multi-agent collaboration and exploring emergent behaviors in agents, 2023.\n",
            "Xinyun Chen, Chang Liu, and Dawn Song. Execution-guided neural program synthesis. In ICLR ,\n",
            "2018.\n",
            "Xinyun Chen, Dawn Song, and Yuandong Tian. Latent execution for neural program synthesis\n",
            "beyond domain-specific languages. NeurIPS , 2021b.\n",
            "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\n",
            "Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\n",
            "Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\n",
            "Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\n",
            "Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\n",
            "skaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\n",
            "Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret\n",
            "Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,\n",
            "Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\n",
            "Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\n",
            "nan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas\n",
            "Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,\n",
            "2022.\n",
            "T. DeMarco and T.R. Lister. Peopleware: Productive Projects and Teams . Addison-Wesley, 2013.\n",
            "URLhttps://books.google.co.uk/books?id=DVlsAQAAQBAJ .\n",
            "Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. Self-collaboration code generation via chatgpt. arXiv\n",
            "preprint , 2023.\n",
            "Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving\n",
            "factuality and reasoning in language models through multiagent debate, 2023.\n",
            "Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\n",
            "Sch¨utze, and Yoav Goldberg. Measuring and improving consistency in pretrained language mod-\n",
            "els.TACL , 2021.\n",
            "Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing\n",
            "Qin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained model for programming and natural\n",
            "languages. arXiv preprint , 2020.\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, and Liqiang Nie. Chatllm network:\n",
            "More brains, more intelligence. arXiv preprint , 2023.\n",
            "S. Hochreiter, A. S. Younger, and P. R. Conwell. Learning to learn using gradient descent. In Lecture\n",
            "Notes on Comp. Sci. 2130, Proc. Intl. Conf. on Artificial Neural Networks (ICANN-2001) , pp. 87–\n",
            "94. Springer: Berlin, Heidelberg, 2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: what's the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "Heidelberg, 2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi Yang, and\n",
            "Soroush V osoughi. Training socially aligned language models in simulated human society. arXiv\n",
            "preprint , 2023.\n",
            "Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing\n",
            "Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with\n",
            "evol-instruct. arXiv preprint , 2023.\n",
            "Potsawee Manakul, Adian Liusie, and Mark JF Gales. Selfcheckgpt: Zero-resource black-box hal-\n",
            "lucination detection for generative large language models. arXiv preprint , 2023.\n",
            "Agile Manifesto. Manifesto for agile software development . Snowbird, UT, 2001.\n",
            "John McCarthy. History of lisp. In History of programming languages . 1978.\n",
            "Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-tau Yih, Sida Wang, and Xi Victoria\n",
            "Lin. Lever: Learning to verify language-to-code generation with execution. In ICML , 2023.\n",
            "Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese,\n",
            "and Caiming Xiong. Codegen: An open large language model for code with multi-turn program\n",
            "synthesis, 2023.\n",
            "OpenAI. Gpt-4 technical report, 2023.\n",
            "Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and\n",
            "Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint ,\n",
            "2023.\n",
            "Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and\n",
            "Maosong Sun. Communicative agents for software development, 2023.\n",
            "Baptiste Rozi `ere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi\n",
            "Adi, Jingyu Liu, Tal Remez, J ´er´emy Rapin, et al. Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements.\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements. Technical Report IDSIA-19-03, arXiv:cs.LO/0309048 v3, IDSIA,\n",
            "Manno-Lugano, Switzerland, December 2003.\n",
            "J. Schmidhuber. G ¨odel machines: Fully self-referential optimal universal self-improvers. In B. Go-\n",
            "ertzel and C. Pennachin (eds.), Artificial General Intelligence , pp. 199–226. Springer Verlag,\n",
            "2006. Variant available as arXiv:cs.LO/0309048.\n",
            "12\n",
            "\n",
            "page_label: 13\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "J. Schmidhuber. Ultimate cognition `a laG¨odel. Cognitive Computation , 1(2):177–193, 2009.\n",
            "J¨urgen Schmidhuber. Evolutionary principles in self-referential learning, or on learning how to\n",
            "learn: the meta-meta-... hook . PhD thesis, 1987.\n",
            "J¨urgen Schmidhuber. A ‘self-referential’weight matrix. In ICANN’93: Proceedings of the Interna-\n",
            "tional Conference on Artificial Neural Networks Amsterdam, The Netherlands 13–16 September\n",
            "1993 3 , 1993b.\n",
            "J¨urgen Schmidhuber. On learning to think: Algorithmic information theory for novel combinations\n",
            "of reinforcement learning controllers and recurrent neural world models. arXiv preprint , 2015.\n",
            "J¨urgen Schmidhuber, Jieyu Zhao, and Nicol N Schraudolph. Reinforcement learning with self-\n",
            "modifying policies. In Learning to learn . 1998.\n",
            "Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic\n",
            "memory and self-reflection. arXiv preprint , 2023.\n",
            "Marta Skreta, Naruki Yoshikawa, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen,\n",
            "Kourosh Darvish, Al ´an Aspuru-Guzik, Florian Shkurti, and Animesh Garg. Errors are useful\n",
            "prompts: Instruction guided task programming with verifier-assisted iterative prompting. arXiv\n",
            "preprint , 2023.\n",
            "Elliot Soloway. Learning to program =learning to construct mechanisms and explanations. Com-\n",
            "munications of the ACM , 1986.\n",
            "Yashar Talebirad and Amirhossein Nadiri. Multi-agent collaboration: Harnessing the power of\n",
            "intelligent llm agents, 2023.\n",
            "Torantulino et al. Auto-gpt. https://github.com/Significant-Gravitas/\n",
            "Auto-GPT , 2023.\n",
            "R. J. Waldinger and R. C. T. Lee. PROW: a step toward automatic program writing. In D. E. Walker\n",
            "and L. M. Norton (eds.), Proceedings of the 1st International Joint Conference on Artificial Intel-\n",
            "ligence (IJCAI) , 1969.\n",
            "Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan,\n",
            "and Anima Anandkumar. V oyager: An open-ended embodied agent with large language models.\n",
            "arXiv preprint , 2023a.\n",
            "Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\n",
            "Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\n",
            "arXiv preprint , 2023b.\n",
            "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\n",
            "ery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.\n",
            "arXiv preprint , 2022.\n",
            "Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. Unleashing\n",
            "cognitive synergy in large language models: A task-solving agent through multi-persona self-\n",
            "collaboration. arXiv preprint , 2023c.\n",
            "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\n",
            "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS ,\n",
            "2022.\n",
            "Michael Wooldridge and Nicholas R. Jennings. Pitfalls of agent-oriented development. In Pro-\n",
            "ceedings of the Second International Conference on Autonomous Agents , 1998. URL https:\n",
            "//doi.org/10.1145/280765.280867 .\n",
            "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\n",
            "React: Synergizing reasoning and acting in language models. arXiv preprint , 2022.\n",
            "Eric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. Self-taught optimizer (stop):\n",
            "Recursively self-improving code generation. arXiv preprint , 2023.\n",
            "13\n",
            "\n",
            "page_label: 14\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tian-\n",
            "min Shu, and Chuang Gan. Building cooperative embodied agents modularly with large language\n",
            "models. arXiv preprint , 2023.\n",
            "Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, and Stefan Wermter. Chat\n",
            "with the environment: Interactive multimodal perception using large language models. arXiv\n",
            "preprint , 2023.\n",
            "Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen,\n",
            "Andi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang. Codegeex: A pre-trained model for\n",
            "code generation with multilingual evaluations on humaneval-x, 2023.\n",
            "Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng,\n",
            "Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for building\n",
            "autonomous agents. arXiv preprint , 2023.\n",
            "Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, R ´obert Csord ´as, Anand\n",
            "Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki\n",
            "Irie, et al. Mindstorms in natural language-based societies of mind. arXiv preprint , 2023.\n",
            "14\n",
            "\n",
            "page_label: 15\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "A O UTLOOK\n",
            "A.1 S ELF-IMPROVEMENT MECHANISMS\n",
            "One limitation of the MetaGPT version in the main text of this paper is that each software project is\n",
            "executed independently. However, through active teamwork, a software development team should\n",
            "learn from the experience gained by developing each project, thus becoming more compatible and\n",
            "successful over time.\n",
            "This is somewhat related to the idea of recursive self-improvement, first informally proposed in\n",
            "1965 (Good, 1965), with first concrete implementations since 1987 (Schmidhuber, 1987; 1993b;\n",
            "Schmidhuber et al., 1998), culminating in the concept of mathematically optimal self-referential\n",
            "self-improvers (Schmidhuber, 2003; 2009). Generally speaking, a system should learn from experi-\n",
            "ence in the real world, and meta-learn better learning algorithms from experiences of learning, and\n",
            "meta-meta-learn better meta-learning algorithms from experiences of meta-learning, etc., without\n",
            "any limitations except those of computability and physics.\n",
            "More recent, somewhat related work leverages the reasoning ability of Large Language Models\n",
            "(LLMs) and recursively improves prompts of LLMs, to improve performance on certain downstream\n",
            "tasks (Fernando et al., 2023; Zelikman et al., 2023), analogous to the adaptive prompt engineer of\n",
            "2015 (Schmidhuber, 2015) where one neural network learns to generate sequence of queries or\n",
            "prompts for another pre-trained neural network whose answers may help the first network to learn\n",
            "new tasks more quickly.\n",
            "In our present work, we also explore a self-referential mechanism that recursively modifies the con-\n",
            "straint prompts of agents based on information they observe during software development. Our\n",
            "initial implementation works as follows. Prior to each project, every agent in the software company\n",
            "reviews previous feedback and makes necessary adjustments to their constraint prompts. This en-\n",
            "ables them to continuously learn from past project experiences and enhance the overall multi-agent\n",
            "system by improving each individual in the company. We first establish a handover feedback action\n",
            "for each agent. This action is responsible for critically summarizing the information received dur-\n",
            "ing the development of previous projects and integrating this information in an updated constraint\n",
            "prompt. The summarized information is stored in long-term memory such that it can be inherited\n",
            "by future constraint prompt updates. When initiating a new project, each agent starts with a react\n",
            "action. Each agent evaluates the received feedback and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: what's the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "agent evaluates the received feedback and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically, AgentStore allows users to subscribe to agents according to their demands\n",
            "4http://beta.deepwisdom.ai\n",
            "15\n",
            "\n",
            "page_label: 16\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "and pay according to their usage. Moreover, users can purchase additional capabilities to expand the\n",
            "plug-and-play functions of their existing agents. This allows users to gradually upgrade their agents.\n",
            "Within the MetaGPT framework, AgentStore can support the collaboration of various agents. Users\n",
            "can collect several agents together to carry out more complex tasks or projects, and all the agents\n",
            "share and comply with development and communication protocols defined in MetaGPT.\n",
            "Figure 6: AgentStore is a platform dedicated to serving users in the creation and development of\n",
            "agents within the MetaGPT framework. This platform provides users with an operational interface,\n",
            "allowing users to easily manage a variety of agents with different emotions, personalities, and capa-\n",
            "bilities for specific tasks.\n",
            "16\n",
            "\n",
            "page_label: 17\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "B A D EMO OF THE EXECUTION\n",
            "In this section, we outline the complete process of software development using MetaGPT. It begins\n",
            "with a user’s input command (as shown in Appendix B.1) and ends with software designed according\n",
            "to the user’s specifications.\n",
            "B.1 U SERINPUT\n",
            "Upon receiving an instruction from the user, MetaGPT collaborates with a professional development\n",
            "team to fulfill the task. Here is a demo of user input:\n",
            "User input\n",
            "1write a python3 GUI app such that you can draw an image with it\n",
            "B.2 M ETAGPT DEVELOPMENT PROCESS\n",
            "Now we provide a step-by-step explanation of the standardized output process for each agent.\n",
            "Product Manager The Product Manager generates a Product Requirement Document (PRD), as\n",
            "detailed in the specified documentation. This document encompasses goals, user stories, competitive\n",
            "analysis, requirement analysis and requirement pool. Additionally, a competitive quadrant chart is\n",
            "produced (see Figure 7). Subsequently, these documents and charts are handed over to the architect\n",
            "for system design.\n",
            "Product Requirement Document\n",
            "1## Original Requirements\n",
            "2The boss requires a Python3 GUI color meter that outputs the RGB values when it moves.\n",
            "3\n",
            "4## Product Goals\n",
            "5‘‘‘python\n",
            "6[\n",
            "7 \"Create a user-friendly GUI color meter\",\n",
            "8 \"Ensure the color meter accurately outputs RGB values\",\n",
            "9 \"Ensure the color meter updates RGB values in real-time as it moves\"\n",
            "10]\n",
            "11‘‘‘\n",
            "12\n",
            "13## User Stories\n",
            "14‘‘‘python\n",
            "15[\n",
            "16 \"As a user, I want to select any color on the screen, so that I can get its RGB values\",\n",
            "17 \"As a user, I want the RGB values to update in real-time as I move the color meter, so that I\n",
            ",→can get accurate color information\",\n",
            "18 \"As a user, I want a simple and intuitive interface, so that I can easily use the color meter\"\n",
            "19]\n",
            "20‘‘‘\n",
            "21\n",
            "22## Competitive Analysis\n",
            "23‘‘‘python\n",
            "24[\n",
            "25 \"Color Cop: A popular color picker for Windows. It’s simple and easy to use, but lacks real-\n",
            ",→time RGB value updates\",\n",
            "26 \"Just Color Picker: Offers real-time color picking and multiple color code formats. However,\n",
            ",→its interface is cluttered and not very user-friendly\",\n",
            "27 \"Instant Eyedropper: A simple color picker that lives in the system tray. It’s convenient but\n",
            ",→lacks advanced features\",\n",
            "28 \"ColorZilla: A color picker extension for browsers. It’s convenient for web design but not\n",
            ",→suitable for desktop applications\",\n",
            "29 \"ColorPic: Offers color palettes and mixer tools. It’s feature-rich but can be overwhelming\n",
            ",→for simple tasks\"\n",
            "30]\n",
            "31‘‘‘\n",
            "17\n",
            "\n",
            "page_label: 18\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1\n",
            "2## Requirement Analysis\n",
            "3The product should be a Python3 GUI application that serves as a color meter. It should allow\n",
            ",→users to select any color on the screen and display the corresponding RGB values. The RGB\n",
            ",→ values should update in real-time as the color meter moves. The interface should be\n",
            ",→simple and user-friendly.\n",
            "4\n",
            "5## Requirement Pool\n",
            "6‘‘‘python\n",
            "7[\n",
            "8 (\"Design a user-friendly GUI for the color meter\", \"P0\"),\n",
            "9 (\"Implement color selection functionality\", \"P0\"),\n",
            "10 (\"Display RGB values of the selected color\", \"P0\"),\n",
            "11 (\"Update RGB values in real-time as the color meter moves\", \"P0\"),\n",
            "12 (\"Test the application for accuracy and performance\", \"P1\")\n",
            "13]\n",
            "14‘‘‘\n",
            "15\n",
            "16## UI Design draft\n",
            "17The UI should be minimalistic and intuitive. It should primarily consist of a color meter, which\n",
            ",→could be a magnified area of the screen that the user can move around. The RGB values of\n",
            ",→the currently selected color should be prominently displayed, updating in real-time as\n",
            ",→the color meter moves. The layout should be clean and uncluttered, with a focus on\n",
            ",→functionality and ease of use.\n",
            "18\n",
            "19## Anything UNCLEAR\n",
            "20There are no unclear points.\n",
            "Figure 7: The quadrant chart for the “Drawing App” generated by the product manager agent.\n",
            "18\n",
            "\n",
            "page_label: 19\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Architect Based on the requirements in PRD, the Architect agent devises technical specifications\n",
            "including system architecture diagrams and interface definitions. Initially, the Architect defines the\n",
            "overarching technical trajectory. Subsequently, the project’s architecture, including files, classes\n",
            "(Figure 8) and the sequence flow chart (Figure 12), is designed. The Architect’s documentation is\n",
            "then given to the project manager for task allocation and execution.\n",
            "System design\n",
            "1## Implementation approach\n",
            "2We will use Python’s Tkinter library to create the GUI for the color meter. Tkinter is a standard\n",
            ",→Python interface to the Tk GUI toolkit and is included with most Python installations. It\n",
            ",→ is simple to use and powerful enough for our needs.\n",
            "3\n",
            "4The color selection functionality will be implemented using the PIL (Pillow) library, which allows\n",
            ",→ us to capture the screen’s pixel data. By moving the mouse, we can get the RGB values of\n",
            ",→ the pixel under the mouse cursor in real-time.\n",
            "5\n",
            "6The RGB values will be displayed on the GUI using Tkinter’s Label widget. We will use Python’s\n",
            ",→threading library to update the RGB values in real-time as the color meter moves.\n",
            "7\n",
            "8The application will be tested for accuracy and performance using Python’s unittest library.\n",
            "9\n",
            "10## Python package name\n",
            "11‘‘‘python\n",
            "12\"color_meter\"\n",
            "13‘‘‘\n",
            "14\n",
            "15## File list\n",
            "16‘‘‘python\n",
            "17[\n",
            "18 \"main.py\",\n",
            "19 \"color_picker.py\",\n",
            "20 \"gui.py\",\n",
            "21 \"tests.py\"\n",
            "22]\n",
            "23‘‘‘\n",
            "24\n",
            "25## Anything UNCLEAR\n",
            "26The requirement is clear to me.\n",
            "Figure 8: Data structures and interface definitions for the “Drawing App” generated by the architect\n",
            "agent.\n",
            "Project Manager The Project Manager breaks down the project into a task list. Furthermore, each\n",
            "code file is analyzed based on its intended functionality and then treated as a separate task assigned\n",
            "to Engineers.\n",
            "19\n",
            "\n",
            "page_label: 20\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 9: The program call flow for the “Drawing App” generated by the architect agent.\n",
            "Tasks\n",
            "1## Required Python third-party packages\n",
            "2\n",
            "3‘‘‘python\n",
            "4\"\"\"\n",
            "5tkinter==8.6\n",
            "6Pillow==8.3.1\n",
            "7\"\"\"\n",
            "8‘‘‘\n",
            "9\n",
            "10## Required Other language third-party packages\n",
            "11‘‘‘python\n",
            "12\"\"\"\n",
            "13No third-party packages required in other languages.\n",
            "14\"\"\"\n",
            "15‘‘‘\n",
            "16\n",
            "17## Full API spec\n",
            "18‘‘‘python\n",
            "19\"\"\"\n",
            "20No APIs are used in this project.\n",
            "21\"\"\"\n",
            "22‘‘‘\n",
            "23\n",
            "24## Logic Analysis\n",
            "25‘‘‘python\n",
            "26[\n",
            "27 (\"main.py\", \"Contains the main application loop and initializes all the other components.\"),\n",
            "28 (\"canvas.py\", \"Implements the drawing canvas, responds to mouse events, and uses the selected\n",
            ",→tool and color.\"),\n",
            "29 (\"tools.py\", \"Implements the tool selection interface.\"),\n",
            "30 (\"color_picker.py\", \"Implements the color selection interface.\"),\n",
            "31 (\"file_manager.py\", \"Implements the file saving and opening functionality.\")\n",
            "32]\n",
            "33‘‘‘\n",
            "20\n",
            "\n",
            "page_label: 21\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1## Task list\n",
            "2‘‘‘python\n",
            "3[\n",
            "4 \"main.py\",\n",
            "5 \"canvas.py\",\n",
            "6 \"tools.py\",\n",
            "7 \"color_picker.py\",\n",
            "8 \"file_manager.py\"\n",
            "9]\n",
            "10‘‘‘\n",
            "11\n",
            "12## Shared Knowledge\n",
            "13‘‘‘python\n",
            "14\"\"\"\n",
            "15The ’Tkinter’ library is used for creating the GUI of the application. It provides various widgets\n",
            ",→ like frames and canvases which are used in this project.\n",
            "16The ’Pillow’ library is used for handling image files. It is used in the ’file_manager.py’ for\n",
            ",→saving and opening image files.\n",
            "17The ’main.py’ file is the entry point of the application. It initializes all the other components\n",
            ",→and starts the application loop.\n",
            "18\"\"\"\n",
            "19‘‘‘\n",
            "20\n",
            "21## Anything UNCLEAR\n",
            "22The project requirements and implementation approach are clear. However, we need to ensure that\n",
            ",→all team members are familiar with the Tkinter and Pillow libraries. If not, they may\n",
            ",→need some time to learn these libraries before starting the development.\n",
            "21\n",
            "\n",
            "page_label: 22\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Engineer Given the provided file structure and function definitions, an Engineer agent requires\n",
            "only fundamental development skills to complete the development tasks. Due to the large number\n",
            "of files, we present only one auto-generated code file here.\n",
            "Generated code (color picker.py)\n",
            "1import tkinter as tk\n",
            "2from tkinter import colorchooser\n",
            "3class ColorPicker:\n",
            "4 def __init__(self, root: tk.Tk, color: str = ’black’):\n",
            "5 self.frame = tk.Frame(root)\n",
            "6 self.color = color\n",
            "7\n",
            "8 self.color_button = tk.Button(self.frame, text=’Color’, command=self.select_color)\n",
            "9 self.color_button.pack(fill=’x’)\n",
            "10\n",
            "11 def select_color(self):\n",
            "12 color = colorchooser.askcolor()[1]\n",
            "13 if color is not None:\n",
            "14 self.color = color\n",
            "15\n",
            "16 def pack(self, **kwargs):\n",
            "17 self.frame.pack( **kwargs)\n",
            "18\n",
            "19 def get_color(self):\n",
            "20 return self.color\n",
            "QA Engineer Upon receiving the code output from the Engineer, the QA Engineer generates unit\n",
            "test code and reviews it to identify and fix any bugs, ensuring high-quality software.\n",
            "Generated Unit tests (test.py)\n",
            "1import unittest\n",
            "2import tkinter as tk\n",
            "3# You might want to move the ColorPicker class to another file, let’s say color_picker.py\n",
            "4# from color_picker import ColorPicker\n",
            "5\n",
            "6class TestColorPicker(unittest.TestCase):\n",
            "7\n",
            "8 def setUp(self):\n",
            "9 self.root = tk.Tk()\n",
            "10 self.cp = ColorPicker(self.root)\n",
            "11\n",
            "12 def tearDown(self):\n",
            "13 # This is important to close the tk window after tests\n",
            "14 self.root.destroy()\n",
            "15\n",
            "16 def test_initial_color(self):\n",
            "17 # Test the default color during initialization\n",
            "18 self.assertEqual(self.cp.get_color(), ’black’)\n",
            "19\n",
            "20 def test_set_and_get_color(self):\n",
            "21 # Test setting a new color and retrieving it\n",
            "22 new_color = ’#ffffff’ # white color\n",
            "23 self.cp.color = new_color\n",
            "24 self.assertEqual(self.cp.get_color(), new_color)\n",
            "25\n",
            "26\n",
            "27if __name__ == ’__main__’:\n",
            "28 unittest.main()\n",
            "Output Ultimately, as shown in Figure 10, MetaGPT generates a functional application named\n",
            "“Drawing App”.\n",
            "22\n",
            "\n",
            "page_label: 23\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 10: The “Drawing App” generated by MetaGPT.\n",
            "C E XPERIMENTS\n",
            "C.1 D ETAILS OF THE SOFTWARE DEVDATASET\n",
            "The SoftwareDev dataset includes 70 diverse software development tasks. Table 8 displays the\n",
            "names and detailed prompts of 11 tasks within the dataset. Note that the first seven tasks listed are\n",
            "used in the main experiments of this paper.\n",
            "C.2 A DDITIONAL RESULTS\n",
            "Quantitative results of MetaGPT As shown in Table 4, MetaGPT achieves an average score\n",
            "of 3.9, surpassing ChatDev’s score of 2.1 Zhao et al. (2023), which is based on the Chat chain.\n",
            "Compare the scores of general intelligent algorithms, including AutoGPT Torantulino et al. (2023),\n",
            "which all score 1.0, failing to generate executable code. We observe that the generated code is often\n",
            "short, lacks comprehensive logic, and tends to fail to handle cross-file dependencies correctly.\n",
            "While models such as AutoGPT (Torantulino et al., 2023), Langchain (Chase, 2022), and Agent-\n",
            "Verse (Chen et al., 2023) display robust general problem-solving capabilities, they lack an essential\n",
            "element for developing complex systems: systematically deconstructing requirements. Conversely,\n",
            "MetaGPT simplifies the process of transforming abstract requirements into detailed class and func-\n",
            "tion designs through a specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: what's the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "designs through a specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1 1 2 4\n",
            "2048 game 1 1 1 1 4\n",
            "Snake game 1 1 1 3 4\n",
            "Brick breaker game 1 1 1 1 4\n",
            "Excel data process 1 1 1 4 4\n",
            "CRUD manage 1 1 1 2 4\n",
            "Average score 1.0 1.0 1.0 2.1 3.9\n",
            "Table 5: Performance of MetaGPT on SoftwareDev using different LLMs as agent backends.\n",
            "Model Open source Time(/s) # Lines Executability Revisions\n",
            "MetaGPT (w/ GPT-3.5) % 75.18 161.6 2.8 2.4\n",
            "MetaGPT (w/ GPT-4) % 552.94 178.2 3.8 1.2\n",
            "MetaGPT (w/ Deepseek Coder 33B) \" 1186.20 120.2 1.4 2.6\n",
            "Impact of Instruction Levels (High-level v.s.Detailed Instructions) Does the variation in the\n",
            "level of initial input from humans significantly influence performance outcomes? For examples:\n",
            "1.High-level prompt : Create a brick breaker game.\n",
            "2.Detailed prompt : Creating a brick breaker game. In a brick breaker game, the player\n",
            "typically controls a paddle at the bottom of the screen to bounce a ball towards a wall of\n",
            "bricks. The goal is to break all the bricks by hitting them with the ball.\n",
            "Additional experiments were conducted to investigate this aspect: we selected 5 tasks from Soft-\n",
            "wareDev, and constructed detailed prompts for them. Here are the experimental results:\n",
            "Table 6: Impact of Instruction Levels. The executability is scored on a grading system ranging\n",
            "from ‘1’ to ‘4’. A score of ‘1’ signifies complete failure, ‘2’ denotes runnable code, ‘3’ represents\n",
            "largely expected workflow, and ‘4’ indicates a perfect match to expectations.\n",
            "Model # Word Time(/s) Token usage # Lines Executability Productivity Reversions\n",
            "High-level 13.2 552.9 28384.2 178.2 3.8 163.8 1.2\n",
            "Detailed 42.2 567.8 29657.0 257.0 4.0 118.0 1.6\n",
            "We observe that: detailed prompts lead to better software projects with lower productivity ratios\n",
            "because of clearer requirements and functions, while simple inputs can still generate good enough\n",
            "software using MetaGPT with an executability rating of 3.8, which is comparable to the detailed\n",
            "prompt scenario. (Note that, Productivity = Token usage / Total Code Lines. The lower this ratio,\n",
            "the better.)\n",
            "The performance of GPT variants in HumanEval benchmark We use the GPT-4’s 67% Hu-\n",
            "manEval score (OpenAI, 2023) as our baseline, acknowledging its acceptance in the HumanEval\n",
            "benchmark. We further extend to experiments(five times) with GPT-4 (gpt-4-0613) and GPT-3.5-\n",
            "Turbo (gpt-3.5-turbo-0613) under various conditions to assess performance. (A)We directly called\n",
            "the OpenAI API with the prompt in HumanEval. (B)We called the OpenAI API and parsed the\n",
            "code with regex in the response. (C)We added an additional system prompt, then called the OpenAI\n",
            "API. The prompt is ”You are an AI that only responds with Python code, NOT ENGLISH. You will\n",
            "24\n",
            "\n",
            "page_label: 25\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "be given a function signature and its docstring by the user. Write your full implementation (restate\n",
            "the function signature).” As shown in Table 7, GPT-4 is more sensitive to prompt, code parser, and\n",
            "post-processing results on the HumanEval data set. It is difficult for GPT-3.5-Turbo to return the\n",
            "correct completion code without prompt words.\n",
            "Table 7: Performance of GPT models on HumanEval. Experiments were conducted five times\n",
            "using gpt-4-0613 and gpt-3.5-turbo-0613 with different settings.\n",
            "Settings Model 1 2 3 4 5 Avg. Std.\n",
            "A gpt-4-0613 0.732 0.707 0.732 0.713 0.738 0.724 0.013\n",
            "A gpt-3.5-turbo-0613 0.360 0.366 0.360 0.348 0.354 0.357 0.007\n",
            "B gpt-4-0613 0.787 0.811 0.817 0.829 0.817 0.812 0.016\n",
            "B gpt-3.5-turbo-0613 0.348 0.354 0.348 0.335 0.348 0.346 0.007\n",
            "C gpt-4-0613 0.805 0.805 0.817 0.793 0.780 0.800 0.014\n",
            "C gpt-3.5-turbo-0613 0.585 0.567 0.573 0.579 0.579 0.577 0.007\n",
            "Qualitative results Figure 11 and Figure 12 illustrate the outcomes of the Architect agent’s ef-\n",
            "forts to design a complex recommender system. These figures showcase the comprehensive system\n",
            "interface design and program call flow. The latter is essential for creating a sophisticated automated\n",
            "system. It is crucial to emphasize the importance of this division of labor in developing an automated\n",
            "software framework.\n",
            "D L IMITATION AND ETHICS CONCERNS\n",
            "D.1 L IMITATION\n",
            "System side At present, our system cannot fully cater to specific scenarios, such as UI and front-\n",
            "end, as we have yet to incorporate such agents and multimodal tools. Furthermore, despite gen-\n",
            "erating the most amount of code among comparable frameworks, it remains challenging to fulfill\n",
            "real-world applications’ diverse and complex requirements.\n",
            "Human user side A key challenge for users is to interrupt the running process of each agent, or\n",
            "set the starting running point (checkpoint) for each agent.\n",
            "D.2 E THICS CONCERNS\n",
            "Unemployment and Skill Obsolescence MetaGPT enables more people to program in natural\n",
            "languages, thereby making it easier for engineers to get started. Over the years, programming\n",
            "languages have evolved from punched cards to assembly, C, Java, Python, and now natural lan-\n",
            "guage. As a result, humans have become more proficient at programming, increasing the demand\n",
            "for programming-related positions. Furthermore, programming with natural language may offer a\n",
            "significantly easier learning curve, making programming more accessible to a broader audience.\n",
            "Transparency and Accountability MetaGPT is an open-source framework that facilitates inter-\n",
            "active communication between multiple agents through natural language. Humans can initiate, ob-\n",
            "serve, and stop running with the highest level of control. It provides real-time interpretation and op-\n",
            "eration of the natural language, displayed on the screen and logs, ensuring transparency. MetaGPT\n",
            "enhances “natural language programming” capabilities, and human engineers are the users and re-\n",
            "sponsible for the outcomes.\n",
            "Privacy and Data Security MetaGPT operates locally, ensuring user data privacy and security. It\n",
            "does not collect user data. For interactions with third-party LLMs, such as those by OpenAI, users\n",
            "are encouraged to refer to the respective privacy policies (e.g., OpenAI Privacy Policy). However,\n",
            "we provide the option of open-source LLMs as backends.\n",
            "25\n",
            "\n",
            "page_label: 26\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 11: The system interface design for “recommendation engine development” is generated by\n",
            "thearchitect agent ( zoom in for a better view ).\n",
            "E M ORE DISCUSSIONS\n",
            "E.1 D EEP-SEATED CHALLENGES\n",
            "MetaGPT also alleviates or solves these challenges with its unique designs:\n",
            "Use Context Efficiently Two sub-challenges are present. First, unfolding short natural language\n",
            "descriptions accurately to eliminate ambiguity. Second, maintaining information validity in lengthy\n",
            "contexts, enables LLMs to concentrate on relevant data without distraction.\n",
            "Reduce Hallucinations Using LLMs to generate entire software programs faces code halluci-\n",
            "nation problems—-including incomplete implementation of functions, missing dependencies, and\n",
            "potential undiscovered bugs, which may be more serious. LLMs often struggle with software gen-\n",
            "eration due to vague task definitions. Focusing on granular tasks like requirement analysis and\n",
            "package selection offers guided thinking, which LLMs lack in broad task solving.\n",
            "E.2 I NFORMATION OVERLOAD\n",
            "In MetaGPT, we use a global message pool and a subscription mechanism to address “information\n",
            "overload,” which refers to the problem of receiving excessive or irrelevant information. This issue\n",
            "is dependent on specific applications. MetaGPT employs a message pool to streamline communi-\n",
            "cation, ensuring efficiency. Additionally, a subscription mechanism filters out irrelevant contexts,\n",
            "enhancing the relevance and utility of the information. This design is particularly crucial in soft-\n",
            "26\n",
            "\n",
            "page_label: 27\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 12: The program call flow for “recommendation engine development” generated by the\n",
            "architect agent ( zoom in for a better view ).\n",
            "ware design scenarios and standard operating procedures (SOPs) where effective communication is\n",
            "essential.\n",
            "27\n",
            "\n",
            "page_label: 28\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 8: Examples of SoftwareDev dataset.\n",
            "Task ID Task Prompt\n",
            "0 Snake game Create a snake game.\n",
            "1 Brick breaker game Create a brick breaker game.\n",
            "2 2048 game Create a 2048 game for the web.\n",
            "3 Flappy bird game Write p5.js code for Flappy Bird where you control a yellow bird continu-\n",
            "ously flying between a series of green pipes. The bird flaps every time you\n",
            "left click the mouse. If it falls to the ground or hits a pipe, you lose. This\n",
            "game goes on indefinitely until you lose; you get points the further you go.\n",
            "4 Tank battle game Create a tank battle game.\n",
            "5 Excel data process Write an excel data processing program based on streamlit and pandas. The\n",
            "screen first shows an excel file upload button. After the excel file is uploaded,\n",
            "use pandas to display its data content. The program is required to be concise,\n",
            "easy to maintain, and not over-designed. It uses streamlit to process web\n",
            "screen displays, and pandas is sufficient to process excel reading and display.\n",
            "Please make sure others can execute directly without introducing additional\n",
            "packages.\n",
            "6 CRUD manage Write a management program based on the crud addition, deletion, modifi-\n",
            "cation and query processing of the customer business entity. The customer\n",
            "needs to save this information: name, birthday, age, sex, and phone. The data\n",
            "is stored in client.db, and there is a judgement whether the customer table ex-\n",
            "ists. If it doesn’t, it needs to be created first. Querying is done by name; same\n",
            "for deleting. The program is required to be concise, easy to maintain, and not\n",
            "over-designed. The screen is realized through streamlit and sqlite—no need\n",
            "to introduce other additional packages.\n",
            "7 Music transcriber Develop a program to transcribe sheet music into a digital format; provid-\n",
            "ing error-free transcribed symbolized sheet music intelligence from audio\n",
            "through signal processing involving pitch and time slicing then training a\n",
            "neural net to run Onset Detected CWT transforming scalograms to chroma-\n",
            "grams decoded with Recursive Neural Network focused networks.\n",
            "8 Custom press releases Create custom press releases; develop a Python script that extracts rele-\n",
            "vant information about company news from external sources, such as social\n",
            "media; extract update interval database for recent changes. The program\n",
            "should create press releases with customizable options and export writings\n",
            "to PDFs, NYTimes API JSONs, media format styled with interlink internal\n",
            "fixed character-length metadata.\n",
            "9 Gomoku game Implement a Gomoku game using Python, incorporating an AI opponent\n",
            "with varying difficulty levels.\n",
            "10 Weather dashboard Create a Python program to develop an interactive weather dashboard.\n",
            "28\n",
            "\n",
            "page_label: 29\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 9: Additional results of pure MetaGPT w/o feedback on SoftwareDev. Averages (Avg.) of 70 tasks are calculated and 10 randomly selected tasks are\n",
            "included. ‘#’ denotes ‘The number of’, while ‘ID’ is ‘Task ID’.\n",
            "ID Code statistics Doc statistics Cost statistics Cost of revision Code executability\n",
            "#code files #lines of code #lines per code file #doc files #lines of doc #lines per doc file #prompt tokens #completion tokens time costs money costs\n",
            "0 5.00 196.00 39.20 3.00 210.00 70.00 24087.00 6157.00 582.04 $ 1.09 1. TypeError 4\n",
            "1 6.00 191.00 31.83 3.00 230.00 76.67 32517.00 6238.00 566.30 $ 1.35 1. TypeError 4\n",
            "2 3.00 198.00 66.00 3.00 235.00 78.33 21934.00 6316.00 553.11 $ 1.04 1. lack\n",
            "@app.route(’/’)3\n",
            "3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: what's the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "lack\n",
            "@app.route(’/’)3\n",
            "3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method not\n",
            "implement2\n",
            "9 5.00 215.00 43.00 3.00 270.00 90.00 24799.00 5734.00 550.88 $ 1.27 1. dependency er-\n",
            "ror 2. URL 403 er-\n",
            "ror3\n",
            "10 3.00 93.00 31.00 3.00 254.00 84.67 24109.00 5363.00 438.50 $ 0.92 1. dependency er-\n",
            "ror 2. missing main\n",
            "func.4\n",
            "Avg. 4.71 191.57 42.98 3.00 240.00 80.00 26626.86 6218.00 516.71 $1.12 0.51 (only consider\n",
            "item scored 2, 3 or\n",
            "4)3.36\n",
            "29\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: what's the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "MetaGPT is a new meta-programming framework that helps multiple AI agents work together like a team of humans. It does this by using \"Standardized Operating Procedures\" or SOPs, which are like guidelines for how different roles should work together. \n",
            "\n",
            "MetaGPT is especially good at creating software because it assigns tasks like a real company would - a Product Manager creates requirements, an Architect designs the system, and Engineers write the code. This structured approach helps avoid errors and makes sure the final software is well-organized. \n",
            "\n",
            "Tests show that MetaGPT is very good at writing code and beats other similar systems, especially when the software is complex. This shows that using SOPs and a structured workflow is a promising way to build AI systems that can handle difficult tasks.\n",
            "\n",
            "This document introduces MetaGPT, a novel framework designed for autonomous software development. MetaGPT leverages the strengths of large language models (LLMs) and incorporates a structured approach inspired by the software development life cycle. \n",
            "\n",
            "Unlike other systems that rely solely on dialogue, MetaGPT employs a multi-agent system where each agent plays a specific role (e.g., Product Manager, Architect, Engineer) and communicates through structured documents and diagrams. This approach ensures clear and comprehensive information exchange, minimizing ambiguity and errors. \n",
            "\n",
            "Furthermore, MetaGPT emphasizes iterative code improvement through an executable feedback mechanism. This allows the system to learn from its mistakes, debug code, and ultimately generate higher-quality software solutions. \n",
            "\n",
            "Through extensive experiments and comparisons with existing methods, the document demonstrates MetaGPT's superior performance in code generation accuracy, efficiency, and its ability to handle complex, real-world software development tasks.\n",
            "\n",
            "This research introduces MetaGPT, a new meta-programming framework that uses Standard Operating Procedures (SOPs) to improve the problem-solving abilities of multi-agent systems based on Large Language Models (LLMs). MetaGPT is designed to be a flexible and portable platform for autonomous agents and multi-agent frameworks. It employs a unique executable feedback mechanism to improve the quality of code generated during runtime. Extensive experiments show that MetaGPT achieves state-of-the-art performance on multiple benchmarks. The successful integration of human-like SOPs inspires future research on human-inspired techniques for artificial multi-agent systems and represents an early attempt to regulate LLM-based multi-agent frameworks.\n",
            "\n",
            "This document discusses a system called MetaGPT that utilizes multiple AI agents to simulate a software development team. The authors argue that this approach is more effective than using a single large language model for complex software development tasks. The document details the structure of MetaGPT, including the roles of different agents, their communication protocols, and how they collaborate to complete a project. \n",
            "\n",
            "The authors also highlight the limitations of the current MetaGPT version and propose potential improvements, such as enabling the system to learn from past projects and adapt its communication protocols dynamically. They suggest incorporating concepts like recursive self-improvement and multi-agent economies to enhance the system's adaptability and efficiency. The document concludes by referencing other research in the field of multi-agent systems and large language models, emphasizing the potential of these technologies for advancing artificial intelligence.\n",
            "\n",
            "MetaGPT is a novel framework that uses large language models (LLMs) to simulate a software development team, aiming to automate the process. It leverages the strengths of different LLMs by assigning them specific roles within a structured organization, similar to a real-world software development team. This approach allows for a more efficient and organized development process, leading to higher-quality software. The framework has been tested on a dataset of software development tasks and has shown promising results, outperforming other LLM-based software development approaches.\n",
            "\n",
            "MetaGPT is a new framework that uses multiple AI agents to autonomously build software. It's more efficient and produces higher-quality code than other methods. MetaGPT divides tasks into smaller, more manageable steps, which makes it easier for AI to understand and complete complex projects. While it has limitations, such as not being able to create user interfaces, it shows promise in changing how we program.\n",
            "\n",
            "This document appears to be a spreadsheet containing data about software development tasks. It includes information such as the time taken to complete each task, the number of bugs encountered, and the cost. The data is summarized at the bottom of the spreadsheet, showing the average values for each metric.\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: what's the summary of the document?\n",
            "Answer: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Response(response='A new framework called MetaGPT leverages the power of large language models and a structured, team-based approach to develop software autonomously. This method, inspired by real-world software development processes, results in more efficient and high-quality code compared to other systems.  The framework shows great promise in revolutionizing software development, though it still has some limitations. \\n', source_nodes=[NodeWithScore(node=TextNode(id_='3bb2b85e-6a71-4c58-8951-f303afa89ff3', embedding=None, metadata={'page_label': '1', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b8e91252-3476-43a7-982d-fa7464ee78d4', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='87823526d8abf7ee709cd350a8164d9247e2bc6d822509afc75bc814e70b66b6')}, text='Preprint\\nMETAGPT: M ETA PROGRAMMING FOR A\\nMULTI -AGENT COLLABORATIVE FRAMEWORK\\nSirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\\nCeyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\\nLiyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\\n1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\\n3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\\n5Nanjing University,6University of Pennsylvania,\\n7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\\nABSTRACT\\nRemarkable progress has been made on automated problem solving through so-\\ncieties of agents based on large language models (LLMs). Existing LLM-based\\nmulti-agent systems can already solve simple dialogue tasks. Solutions to more\\ncomplex tasks, however, are complicated through logic inconsistencies due to\\ncascading hallucinations caused by naively chaining LLMs. Here we introduce\\nMetaGPT, an innovative meta-programming framework incorporating efficient\\nhuman workflows into LLM-based multi-agent collaborations. MetaGPT en-\\ncodes Standardized Operating Procedures (SOPs) into prompt sequences for more\\nstreamlined workflows, thus allowing agents with human-like domain expertise\\nto verify intermediate results and reduce errors. MetaGPT utilizes an assembly\\nline paradigm to assign diverse roles to various agents, efficiently breaking down\\ncomplex tasks into subtasks involving many agents working together. On col-\\nlaborative software engineering benchmarks, MetaGPT generates more coherent\\nsolutions than previous chat-based multi-agent systems. Our project can be found\\nat https://github.com/geekan/MetaGPT.\\n1 I NTRODUCTION\\nAutonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\\nhance and replicate human workflows. In real-world applications, however, existing systems (Park\\net al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\\nLiang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\\neffective, coherent, and accurate problem-solving processes, particularly when there is a need for\\nmeaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\\net al., 2023; Qian et al., 2023).\\nThrough extensive collaborative practice, humans have developed widely accepted Standardized\\nOperating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\\nLister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\\ndination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\\nstandards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\\ncution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\\nDeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\\nProduct Managers analyze competition and user needs to create Product Requirements Documents\\n(PRDs) using a standardized structure, to guide the developmental process.\\nInspired by such ideas, we design a promising GPT -based Meta -Programming framework called\\nMetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\\n2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\\n∗These authors contributed equally to this work.\\n†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\\n1', start_char_idx=0, end_char_idx=3612, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='dfb5434e-d16d-4588-a28e-d7a95afc3592', embedding=None, metadata={'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d318d46f-1c48-46ec-8758-fba898a8c1dd', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='c0e44f44597b9da8d3932702de8bd6d316242669aaea23a009edbedb7ab0b89a')}, text='Preprint\\nFigure 1: The software development SOPs between MetaGPT and real-world human teams.\\nIn software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\\nits ability to decompose complex tasks into specific actionable procedures assigned to various roles\\n(e.g., Product Manager, Architect, Engineer, etc.).\\ndocuments, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\\ntured outputs significantly increases the success rate of target code generation. Because it helps\\nmaintain consistency in communication, minimizing ambiguities and errors during collaboration.\\nMore graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\\nlined workflow, and all their handovers must comply with certain established standards. This reduces\\nthe risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\\nworks, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\\nlunch?” – Bob (Architect).\\nBenefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\\nwe adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\\nlearning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\\n2006; Finn et al., 2017).\\nThis notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\\n2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\\net al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\\nprogramming through a well-organized group of specialized agents. Each agent has a specific role\\nand expertise, following some established standards. This allows for automatic requirement analysis,\\nsystem design, code generation, modification, execution, and debugging during runtime, highlight-\\ning how agent-based techniques can enhance meta-programming.\\nTo validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\\nMBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\\nachieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\\npopular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\\n2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\\nMetaGPT also stands out in handling higher levels of software complexity and offering extensive\\nfunctionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\\npletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\\nWe summarize our contributions as follows:\\n1https://en.wikipedia.org/w/index.php?title=Metaprogramming\\n2', start_char_idx=0, end_char_idx=2866, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='464ebc4e-f66d-454c-a847-ae208cb8afcf', embedding=None, metadata={'page_label': '3', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6f1b23d7-cfbc-4c0a-ad70-0936eb2b5834', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '3', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='12706455113755fa232d126bfa65c09d466911b61f922537369b5567a0a0da49'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='083e8563-65db-4c33-bdf0-565ea7b137c4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='055dc5e4c33b187272421cfea1aa2f338b8fe0c864fabcd40ad7b4c4d73fc9fa')}, text='Preprint\\n•We introduce MetaGPT, a meta-programming framework for multi-agent collaboration based on\\nLLMs. It is highly convenient and flexible, with well-defined functions like role definition and\\nmessage sharing, making it a useful platform for developing LLM-based multi-agent systems.\\n•Our innovative integration of human-like SOPs throughout MetaGPT’s design significantly en-\\nhances its robustness, reducing unproductive collaboration among LLM-based agents. Furthermore,\\nwe introduce a novel executive feedback mechanism that debugs and executes code during runtime,\\nsignificantly elevating code generation quality (e.g., 5.4% absolute improvement on MBPP).\\n•We achieve state-of-the-art performance on HumanEval (Chen et al., 2021a) and MBPP (Austin\\net al., 2021). Extensive results convincingly validate MetaGPT, suggesting that it is a promising\\nmeta-programming framework for developing LLM-based multi-agent systems.\\n2 R ELATED WORK\\nAutomatic Programming The roots of automatic programming reach back deep into the previ-\\nous century. In 1969, Waldinger & Lee (1969) introduced “PROW,” a system designed to accept\\nprogram specifications written in predicate calculus, generate algorithms, and create LISP imple-\\nmentations (McCarthy, 1978). Balzer (1985) and Soloway (1986) made efforts to advance auto-\\nmatic programming and identified potential methods to achieve it. Recent approaches use natural\\nlanguage processing (NLP) techniques (Ni et al., 2023; Skreta et al., 2023; Feng et al., 2020; Li\\net al., 2022; Chen et al., 2018; 2021b; Zhang et al., 2023). Automatic programming has grown into\\nan industry delivering paid functions such as Microsoft Copilot. Lately, LLMs-based agents (Yao\\net al., 2022; Shinn et al., 2023; Lin et al., 2023) have advanced automatic programming develop-\\nment. Among them, ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023) utilize a chain of\\nthought prompts (Wei et al., 2022) to generate reasoning trajectories and action plans with LLMs.\\nBoth works demonstrate the effectiveness of the ReAct style loop of reasoning as a design paradigm\\nfor empowering automatic programming. Additionally, ToolFormer (Schick et al., 2023) can learn\\nhow to use external tools through simple APIs. The research most closely aligned with our work\\nby Li et al. (2023) proposes a straightforward role-play framework for programming that involves\\ncommunication between agents playing different roles. Qian et al. (2023) utilizes multiple agents for\\nsoftware development. Although existing papers (Li et al., 2023; Qian et al., 2023) have improved\\nproductivity, they have not fully tapped into effective workflows with structured output formats.\\nThis makes it harder to deal with complex software engineering issues.\\nLLM-Based Multi-Agent Frameworks Recently, LLM-based autonomous agents have gained\\ntremendous interest in both industry and academia (Wang et al., 2023b). Many works (Chen et al.,\\n2024; Wang et al., 2023c; Du et al., 2023; Zhuge et al., 2023; Hao et al., 2023; Akata et al., 2023)\\nhave improved the problem-solving abilities of LLMs by integrating discussions among multiple\\nagents. Stable-Alignment (Liu et al., 2023) creates instruction datasets by deriving consensus on\\nvalue judgments through interactions across a sandbox with LLM agents. Other works focus on\\nsociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\\nagents to study language interaction, social understanding, and collective memory. In the Natural\\nLanguage-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\\ninteract to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\\na model for cost reduction by combining large models as tool makers and small models as tool users.\\nSome works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\\n2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\\nworld human behavior simulation, while MetaGPT aims to introduce human practice into multi-\\nagents frameworks.', start_char_idx=0, end_char_idx=4102, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='083e8563-65db-4c33-bdf0-565ea7b137c4', embedding=None, metadata={'page_label': '3', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6f1b23d7-cfbc-4c0a-ad70-0936eb2b5834', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '3', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='12706455113755fa232d126bfa65c09d466911b61f922537369b5567a0a0da49'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='464ebc4e-f66d-454c-a847-ae208cb8afcf', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '3', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='acca9c8279a56b0cc3b5e5535b3b992493c6ec908aeec9ae3db8a8ed035b35d1')}, text='Other works focus on\\nsociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\\nagents to study language interaction, social understanding, and collective memory. In the Natural\\nLanguage-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\\ninteract to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\\na model for cost reduction by combining large models as tool makers and small models as tool users.\\nSome works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\\n2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\\nworld human behavior simulation, while MetaGPT aims to introduce human practice into multi-\\nagents frameworks. Besides, LLM-based agents face the challenges of “assistant repeated instruc-\\ntion” or “infinite loop of message” (Talebirad & Nadiri, 2023; Li et al., 2023). These challenges\\nbecome more urgent in task-oriented collaborations, which require consistent and mutually benefi-\\ncial interactions (Elazar et al., 2021; Wang et al., 2022; Jiang et al., 2023). This motivates our focus\\non applying advanced concepts such as Standard Operating Procedures in software development to\\nmulti-agent frameworks.\\n3', start_char_idx=3293, end_char_idx=4602, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='594b8a89-fabf-4cdf-9464-fa5657f40c89', embedding=None, metadata={'page_label': '4', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5ae8babe-4f61-4677-b4e6-f92b6986e0ba', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '4', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='d026c337a61d642d32afae3c594a77f6fdfec3a4e887222ac062c3478ee4da6c')}, text='Preprint\\nFigure 2: An example of the communication protocol (left) and iterative programming with exe-\\ncutable feedback (right). Left: Agents use a shared message pool to publish structured messages.\\nThey can also subscribe to relevant messages based on their profiles. Right : After generating the\\ninitial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past\\nmessages stored in memory and compares them with the PRD, system design, and code files.\\n3 M ETAGPT: A M ETA-PROGRAMMING FRAMEWORK\\nMetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 pro-\\nvides an explanation of role specialization, workflow and structured communication in this frame-\\nwork, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2\\npresents a communication protocol that enhances role communication efficiency. We also imple-\\nment structured communication interfaces and an effective publish-subscribe mechanism. These\\nmethods enable agents to obtain directional information from other roles and public information\\nfrom the environment. Finally, we introduce executable feedback—a self-correction mechanism for\\nfurther enhancing code generation quality during run-time in Sec. 3.3.\\n3.1 A GENTS IN STANDARD OPERATING PROCEDURES\\nSpecialization of Roles Unambiguous role specialization enables the breakdown of complex work\\ninto smaller and more specific tasks. Solving complex tasks or problems often requires the collab-\\noration of agents with diverse skills and expertise, each contributing specialized outputs tailored to\\nspecific issues.\\nIn a software company, a Product Manager typically conducts business-oriented analysis and derives\\ninsights, while a software engineer is responsible for programming. We define five roles in our\\nsoftware company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\\nshown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\\ngoal, and constraints for each role. We also initialize the specific context and skills for each role.\\nFor instance, a Product Manager can use web search tools, while an Engineer can execute code, as\\nshown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\\nEvery agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\\nservations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\\nassist in finishing the job.\\nWorkflow across Agents By defining the agents’ roles and operational skills, we can establish\\nbasic workflows. In our work, we follow SOP in software development, which enables all agents to\\nwork in a sequential manner.\\n4', start_char_idx=0, end_char_idx=2757, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='959e7eed-501b-4d4f-987b-8f144c3d8d79', embedding=None, metadata={'page_label': '5', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='1af39d61-bc53-41d2-aba5-07bbe1d3b9cc', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '5', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='0333a1ba4dd7d1ef2f05813fcde58b1eca78afd781fcd73022d1646351f83e30')}, text='Preprint\\nFigure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\\nnificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\\nSpecifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\\ntakes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\\nPool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\\nthe Architect, who translates the requirements into system design components, such as File Lists,\\nData Structures, and Interface Definitions. Once captured in the system design, the information is\\ndirected towards the Project Manager for task distribution. Engineers proceed to execute the des-\\nignated classes and functions as outlined (detailed in Figure 2). In the following stage, the QA\\nEngineer formulates test cases to enforce stringent code quality. In the final step, MetaGPT pro-\\nduces a meticulously crafted software solution. We provide a detailed schematic (Figure 3) and a\\nconcrete instance (Appendix B) of the SOP workflow in MetaGPT.\\n3.2 C OMMUNICATION PROTOCOL\\nStructured Communication Interfaces Most current LLM-based multi-agent frameworks (Li\\net al., 2023; Zhuge et al., 2023; Zhang et al., 2023; Park et al., 2023) utilize unconstrained natural\\nlanguage as a communication interface.\\nHowever, despite the versatility of natural language, a question arises: does pure natural language\\ncommunication suffice for solving complex tasks? For example, in the telephone game (or Chinese\\n5', start_char_idx=0, end_char_idx=1583, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='10824422-8512-4d1d-82ab-b8a5677d86c2', embedding=None, metadata={'page_label': '6', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cebe550a-46cb-4c7f-a516-c3d2bfafcf74', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '6', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='d54816fddee74ad5f1d33edd2ddce56e0513412fcb0cbc4434b8ba0a671cda46')}, text='Preprint\\nwhispers)2, after several rounds of communication, the original information may be quite distorted.\\nInspired by human social structures, we propose using structured communication to formulate the\\ncommunication of agents. We establish a schema and format for each role and request that individ-\\nuals provide the necessary outputs based on their specific role and context.\\nAs shown in Figure 3, the Architect agent generates two outputs: the system interface design and a\\nsequence flow diagram. These contain system module design and interaction sequences, which serve\\nas important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT\\ncommunicate through documents and diagrams (structured outputs) rather than dialogue. These\\ndocuments contain all necessary information, preventing irrelevant or missing content.\\nPublish-Subscribe Mechanism Sharing information is critical in collaboration. For instance,\\nArchitects and Engineers often need to reference PRDs. However, communicating this information\\neach time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023;\\nZhang et al., 2023), can complicate the communication topology, resulting in inefficiencies.\\nTo address this challenge, a viable approach is to store information in a global message pool . As\\nshown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange\\nmessages directly. These agents not only publish their structured messages in the pool but also access\\nmessages from other entities transparently. Any agent can directly retrieve required information\\nfrom the shared pool, eliminating the need to inquire about other agents and await their responses.\\nThis enhances communication efficiency.\\nSharing all information with every agent can lead to information overload. During task execution,\\nan agent typically prefers to receive only task-related information and avoid distractions through\\nirrelevant details. Effective management and dissemination of this information play a crucial role.\\nWe offer a simple and effective solution- subscription mechanism (in Figure 2 (left)). Instead of\\nrelying on dialogue, agents utilize role-specific interests to extract relevant information. They can\\nselect information to follow based on their role profiles. In practical implementations, an agent\\nactivates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3,\\nthe Architect mainly focuses on PRDs provided by the Product Manager, while documents from\\nroles such as the QA Engineer might be of lesser concern.\\n3.3 I TERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK\\nIn daily programming tasks, the processes of debugging and optimization play important roles.\\nHowever, existing methods often lack a self-correction mechanism, which leads to unsuccessful code\\ngeneration. Previous work introduced non-executable code review and self-reflection (Zhao et al.,\\n2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in\\nensuring code executability and runtime correctness.\\nOur first MetaGPT implementations overlooked certain errors during the review process, due to\\nLLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we\\nintroduce an executable feedback mechanism to improve the code iteratively. More specifically, as\\nshown in Figure 2, the Engineer is asked to write code based on the original product requirements\\nand design.\\nThis enables the Engineer to continuously improve code using its own historical execution and\\ndebugging memory. To obtain additional information, the Engineer writes and executes the corre-\\nsponding unit test cases, and subsequently receives the test results. If satisfactory, additional devel-\\nopment tasks are initiated. Otherwise the Engineer debugs the code before resuming programming.\\nThis iterative testing process continues until the test is passed or a maximum of 3 retries is reached.\\n4 E XPERIMENTS\\n4.1 E XPERIMENTAL SETTING\\nDatasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin\\net al., 2021), and a self-generated, more challenging software development benchmark named Soft-\\n2https://en.wikipedia.org/wiki/Chinese whispers\\n6', start_char_idx=0, end_char_idx=4280, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='22ef56fd-9cb7-41d9-bc27-53f1c002c9e2', embedding=None, metadata={'page_label': '7', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='19639536-c21e-4bf1-b461-53124e199d66', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '7', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='62c5b6b659b6a4a17048b741588728345d59c766190f8a31dda4eafb643a474b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4a764b46-8885-4dbe-8453-a72404266eb5', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='76006fa3a24f0109d89ab1945fd625fd4a5162026850e6268fb61645e8afa2f4')}, text='Preprint\\nwareDev: (1) HumanEval includes 164 handwritten programming tasks. These tasks encompass\\nfunction specifications, descriptions, reference codes, and tests. (2) MBPP consists of 427 Python\\ntasks. These tasks cover core concepts and standard library features and include descriptions, ref-\\nerence codes, and automated tests. (3) Our SoftwareDev dataset is a collection of 70 representa-\\ntive examples of software development tasks, each with its own task prompt (see Table 8). These\\ntasks have diverse scopes (See Figure 5), such as mini-games, image processing algorithms, data\\nvisualization. They offer a robust testbed for authentic development tasks. Contrary to previous\\ndatasets (Chen et al., 2021a; Austin et al., 2021), SoftwareDev focuses on the engineering aspects.\\nIn the comparisons, we randomly select seven representative tasks for evaluation.\\nEvaluation Metrics For HuamnEval and MBPP, we follow the unbiased version of Pass @ kas\\npresented by (Chen et al., 2021a; Dong et al., 2023), to evaluate the functional accuracy of the top-k\\ngenerated codes: Pass @ k=EProblems\\x14\\n1−(n−c\\nk)\\n(n\\nk)\\x15\\n.\\nFor SoftwareDev, we prioritize practical use and evaluate performance through human evaluations\\n(A, E) or statistical analysis (B, C, D): (A)Executability: this metric rates code from 1 (failure/non-\\nfunctional) to 4 (flawless). ‘1’ is for non-functional, ‘2’ for runnable but imperfect, ‘3’ for nearly\\nperfect, and ‘4’ for flawless code. (B)Cost: the cost evaluations here include the (1) running time,\\n(2) token usage, and (3) expenses. (C)Code Statistics: this includes (1) code files, (2) lines of code\\nper file, and (3) total code lines. (D)Productivity: basically, it is defined as the number of token\\nusage divided by the number of lines of code, which refers to the consumption of tokens per code\\nline. (E)Human Revision Cost: refers to times of manual code corrections, which tackle problems\\nlike package import errors, incorrect class names, or incomplete reference paths. Typically, each\\ncorrection involves up to 3 lines of code.\\nBaselines We compare our method with recent domain-specific LLMs in the code generation field,\\nincluding AlphaCode (Li et al., 2022), Incoder (Fried et al., 2022), CodeGeeX (Zheng et al., 2023),\\nCodeGen (Nijkamp et al., 2023), CodeX (Chen et al., 2021a), and CodeT (Chen et al., 2022) and\\ngeneral domain LLMs such as PaLM (Chowdhery et al., 2022), and GPT-4 (OpenAI, 2023). Several\\nresults of baselines (such as Incoder, CodeGeeX) are provided by Dong et al. (2023). In HumanEval\\nand MBPP, we slightly modified the prompts to align with response format requirements. These\\nmodifications aim to address format-specific issues (i.e., Python problems). With the SoftwareDev\\nbenchmark, we provide a comprehensive comparison between MetaGPT, AutoGPT (Torantulino\\net al., 2023), LangChain (Chase, 2022) with Python Read-Eval-Print Loop (REPL) tool3, Agent-\\nVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\\n4.2 M AINRESULT\\nAlphaCode(1.1B)\\nIncoder (6.7B)\\nCodeGeeX (13B)17.1\\n—15.2 17.6 18.926.9\\nCodeGeeX-Mono(16.1B)32.938.6\\nGPT-467.0\\n—\\nMetaGPT\\n(w/o Feedback)81.7 82.3Pass@1 of MBPP  and HumanEval (%)\\nPaLM Coder(540B)36.047.0\\nCodex (175B)47.058.1\\nCodex + CodeT65.8 67.7\\nHumanEval\\nMBPP\\nMetaGPT85.9 87.7\\nFigure 4: Pass rates on the MBPP and HumanEval with a single attempt.\\nPerformance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\\nHumanEval and MBPP benchmarks.', start_char_idx=0, end_char_idx=3450, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='4a764b46-8885-4dbe-8453-a72404266eb5', embedding=None, metadata={'page_label': '7', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='19639536-c21e-4bf1-b461-53124e199d66', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '7', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='62c5b6b659b6a4a17048b741588728345d59c766190f8a31dda4eafb643a474b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='22ef56fd-9cb7-41d9-bc27-53f1c002c9e2', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '7', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='f81b230c2e250a096b6d073038df7c6cfad6999a51af817e366bbc075959512d')}, text='Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\\nHumanEval and MBPP benchmarks. When MetaGPT collaborates with GPT-4, it significantly im-\\nproves the Pass @ kin the HumanEval benchmark compared to GPT-4. It achieves 85.9% and 87.7%\\n3https://en.wikipedia.org/wiki/Read–eval–print loop\\n7', start_char_idx=3328, end_char_idx=3656, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='4fa73455-8c77-4430-8050-4d371b68c9f3', embedding=None, metadata={'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7d3d1da2-2e83-4035-a888-8cceadba497e', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='b1750cb4e42bd66b5a7a5ece51f5bba0432a8d07fc34d5ae6735bb6b19364aca')}, text='Preprint\\nFigure 5: Demo softwares developed by MetaGPT.\\nin these two public benchmarks. Moreover, as shown in Table 1, MetaGPT outperforms ChatDev on\\nthe challenging SoftwareDev dataset in nearly all metrics. For example, considering the executabil-\\nity, MetaGPT achieves a score of 3.75, which is very close to 4 (flawless). Besides, it takes less time\\n(503 seconds), clearly less than ChatDev. Considering the code statistic and the cost of human revi-\\nsion, it also significantly outperforms ChatDev. Although MetaGPT requires more tokens (24,613\\nor 31,255 compared to 19,292), it needs only 126.5/124.3 tokens to generate one line of code. In\\ncontrast, ChatDev uses 248.9 tokens. These results highlight the benefits of SOPs in collabora-\\ntions between multiple agents. Additionally, we demonstrate the autonomous software generation\\ncapabilities of MetaGPT through visualization samples (Figure 5). For additional experiments and\\nanalysis, please refer to Appendix C.\\nTable 1: The statistical analysis on SoftwareDev.\\nStatistical Index ChatDev MetaGPT w/o Feedback MetaGPT\\n(A)Executability 2.25 3.67 3.75\\n(B)Cost#1: Running Times (s) 762 503 541\\n(B)Cost#2: Token Usage 19,292 24,613 31,255\\n(C)Code Statistic#1: Code Files 1.9 4.6 5.1\\n(C)Code Statistic#2: Lines of Code per File 40.8 42.3 49.3\\n(C)Code Statistic#3: Total Code Lines 77.5 194.6 251.4\\n(D)Productivity 248.9 126.5 124.3\\n(E)Human Revision Cost 2.5 2.25 0.83\\n4.3 C APABILITIES ANALYSIS\\nCompared to open-source baseline methods such as AutoGPT and autonomous agents such as\\nAgentVerse and ChatDev, MetaGPT offers functions for software engineering tasks. As presented\\nin Table 2, our framework encompasses a wide range of abilities to handle complex and specialized\\ndevelopment tasks efficiently. Incorporating SOPs (e.g., role-play expertise, structured communi-\\ncation, streamlined workflow) can significantly improve code generation. Other baseline methods\\n8', start_char_idx=0, end_char_idx=1925, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='23a0c522-c760-49f6-a4a3-0ab502780fde', embedding=None, metadata={'page_label': '9', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4f2bee25-f27c-415a-8a45-f894c39c45da', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '9', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='e0e11d63edd19ea27fee4f2daed3d21b70221c032c7b7e50ad7ec60afbe31195')}, text='Preprint\\nTable 2: Comparison of capabilities for MetaGPT and other approaches. ‘!’ indicates the\\npresence of a specific feature in the corresponding framework, ‘ %’ its absence.\\nFramework Capabiliy AutoGPT LangChain AgentVerse ChatDev MetaGPT\\nPRD generation % % % % !\\nTenical design genenration % % % % !\\nAPI interface generation % % % % !\\nCode generation ! ! ! ! !\\nPrecompilation execution % % % % !\\nRole-based task management % % % ! !\\nCode review % % ! ! !\\nTable 3: Ablation study on roles. ‘#’ denotes ‘The number of’, ‘Product’ denotes ‘Product man-\\nager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\\nsions’ refers to ‘Human Revision Cost’.\\nEngineer Product Architect Project #Agents #Lines Expense Revisions Executability\\n! % % % 1 83.0 $ 0.915 10 1.0\\n! ! % % 2 112.0 $ 1.059 6.5 2.0\\n! ! ! % 3 143.0 $ 1.204 4.0 2.5\\n! ! % ! 3 205.0 $ 1.251 3.5 2.0\\n! ! ! ! 4 191.0 $ 1.385 2.5 4.0\\ncan easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\\nthought (Wei et al., 2022) in LLMs.\\n4.4 A BLATION STUDY\\nThe Effectiveness of Roles To understand the impact of different roles on the final results, we\\nperform two tasks that involve generating effective code and calculating average statistics. When we\\nexclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\\ndifferent from just the Engineer consistently improves both revisions and executability. While more\\nroles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\\neffectiveness of the various roles.\\nThe Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\\nfeedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass @1 on Hu-\\nmanEval and MBPP, respectively. Besides, Table 1 shows that the feedback mechanism improves\\nfeasibility (3.67 to 3.75) and reduces the cost of human revisions (2.25 to 0.83). These results\\nillustrate how our designed feedback mechanism can produce higher-quality code. Additional quan-\\ntitative results of MetaGPT and MetaGPT without executable feedback are shown in Table 4 and\\nTable 9.\\n5 C ONCLUSION\\nThis work introduces MetaGPT, a novel meta-programming framework that leverages SOPs to en-\\nhance the problem-solving capabilities of multi-agent systems based on Large Language Models\\n(LLMs). MetaGPT models a group of agents as a simulated software company, analogous to simu-\\nlated towns (Park et al., 2023) and the Minecraft Sandbox in V oyager (Wang et al., 2023a). MetaGPT\\nleverages role specialization, workflow management, and efficient sharing mechanisms such as mes-\\nsage pools and subscriptions, rendering it a flexible and portable platform for autonomous agents\\nand multi-agent frameworks. It uses an executable feedback mechanism to enhance code generation\\nquality during runtime. In extensive experiments, MetaGPT achieves state-of-the-art performance\\non multiple benchmarks. The successful integration of human-like SOPs inspires future research\\non human-inspired techniques for artificial multi-agent systems. We also view our work as an early\\nattempt to regulate LLM-based multi-agent frameworks. See also the outlook (Appendix A) .\\n9', start_char_idx=0, end_char_idx=3265, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='f359960b-13a0-401a-8839-ee339bd36a04', embedding=None, metadata={'page_label': '10', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='db8e4852-2a09-4315-b05e-ed9f5da096b3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '10', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='04806469b6c3fe75908d900d0f56b0b1ea9070b1b0ac504436883b1eade419f3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4b0f8449-2a46-4c3f-8739-ecba14915c46', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c3285b8059c5f308c8ef62ab51fc003b1ac0d1dceead1bb36bc5cb56210f91da')}, text='Preprint\\nAcknowledgement\\nWe thank Sarah Salhi, the Executive Secretary of KAUST AI Initiative, and Yuhui Wang, Postdoc-\\ntoral Fellow at the KAUST AI Initiative, for helping to polish some of the text. We would like to\\nexpress our gratitude to Wenyi Wang, a PhD student at the KAUST AI Initiative, for providing com-\\nprehensive feedback on the paper and for helping to draft the outlook (Appendix A) with Mingchen.\\nWe also thank Zongze Xu, the vice president of DeepWisdom, for providing illustrative materials\\nfor AgentStore.\\nAuthor Contributions\\nSirui Hong conducted most of the experiments and designed the executable feedback module. She\\nalso led the initial version of the write-up, supported by Ceyao Zhang, and also by Jinlin Wang and\\nZili Wang. Mingchen Zhuge designed the self-improvement module, discussed additional experi-\\nments, and led the current write-up. Jonathan Chen helped with the MBPP experiments, outlined\\nthe methods section, and contributed to the current write-up. Xiawu Zheng provided valuable guid-\\nance, reviewed and edited the paper. Yuheng Cheng contributed to the evaluation metric design and\\nHumanEval experiments. Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Lingfeng Xiao helped\\nwith the MBPP experiments and comparisons to open-source baseline methods. Chenyu Ran cre-\\nated most of the illustrative figures. Chenglin Wu is the CEO of DeepWisdom, initiated MetaGPT,\\nmade the most significant code contributions to it, and advised this project. J ¨urgen Schmidhuber,\\nDirector of the AI Initiative at KAUST and Scientific Director of IDSIA, advised this project and\\nhelped with the write-up.\\nREFERENCES\\nElif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz.\\nPlaying repeated games with large language models. arXiv preprint , 2023.\\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\\nEllen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large\\nlanguage models, 2021.\\nAnton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew\\nGoff, Jonathan Gray, Hengyuan Hu, et al. Human-level play in the game of diplomacy by com-\\nbining language models with strategic reasoning. Science , 2022.\\nRobert Balzer. A 15 year perspective on automatic programming. TSE, 1985.\\nR.M. Belbin. Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\\nbooks?id=MHIQBAAAQBAJ .\\nTianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\\ntool makers. arXiv preprint , 2023.\\nHarrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\\nBei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\\nChen. Codet: Code generation with generated tests, 2022.\\nJiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\\nenvironment. arXiv preprint , 2024.', start_char_idx=0, end_char_idx=2924, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='4b0f8449-2a46-4c3f-8739-ecba14915c46', embedding=None, metadata={'page_label': '10', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='db8e4852-2a09-4315-b05e-ed9f5da096b3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '10', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='04806469b6c3fe75908d900d0f56b0b1ea9070b1b0ac504436883b1eade419f3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f359960b-13a0-401a-8839-ee339bd36a04', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '10', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='bf64a22c88ac738fe47c17e79ed151fe4484a4b3decf0fbe026a544dce622607')}, text='Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\\nbooks?id=MHIQBAAAQBAJ .\\nTianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\\ntool makers. arXiv preprint , 2023.\\nHarrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\\nBei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\\nChen. Codet: Code generation with generated tests, 2022.\\nJiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\\nenvironment. arXiv preprint , 2024.\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,\\nGretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\\nScott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,\\nClemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-\\ntios Chantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex\\nPaino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,\\nChristopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec\\nRadford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob Mc-\\nGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large\\nlanguage models trained on code, 2021a.\\n10', start_char_idx=2352, end_char_idx=3884, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='da340e3b-e00b-4c8e-a48d-167d0a2e53bd', embedding=None, metadata={'page_label': '11', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='dbf8e08b-fd8d-4689-936e-894690658f67', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '11', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='23b8a3d499892684c3e62f827673a62b1aaabba22f61a242763bce5ac1f3a1e4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='55263371-d149-4015-8edc-662f1f0a2d05', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d17fd1c20c9c28b8ca87f1cac0b081fef1134d3918569c5bc4391f4bf6a0bf11')}, text='Preprint\\nWeize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan,\\nYujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facili-\\ntating multi-agent collaboration and exploring emergent behaviors in agents, 2023.\\nXinyun Chen, Chang Liu, and Dawn Song. Execution-guided neural program synthesis. In ICLR ,\\n2018.\\nXinyun Chen, Dawn Song, and Yuandong Tian. Latent execution for neural program synthesis\\nbeyond domain-specific languages. NeurIPS , 2021b.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\\nShazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\\nBradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\\nskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\\nRobinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret\\nZoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,\\nAndrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\\nMoreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\\nnan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas\\nEck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,\\n2022.\\nT. DeMarco and T.R. Lister. Peopleware: Productive Projects and Teams . Addison-Wesley, 2013.\\nURLhttps://books.google.co.uk/books?id=DVlsAQAAQBAJ .\\nYihong Dong, Xue Jiang, Zhi Jin, and Ge Li. Self-collaboration code generation via chatgpt. arXiv\\npreprint , 2023.\\nYilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving\\nfactuality and reasoning in language models through multiagent debate, 2023.\\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\\nSch¨utze, and Yoav Goldberg. Measuring and improving consistency in pretrained language mod-\\nels.TACL , 2021.\\nZhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing\\nQin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained model for programming and natural\\nlanguages. arXiv preprint , 2020.\\nChrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\\nPromptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\\nChelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\\nof deep networks. In ICML , 2017.\\nDaniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\\nWen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\\nand synthesis. arXiv preprint , 2022.\\nIrving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.', start_char_idx=0, end_char_idx=3075, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='55263371-d149-4015-8edc-662f1f0a2d05', embedding=None, metadata={'page_label': '11', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='dbf8e08b-fd8d-4689-936e-894690658f67', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '11', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='23b8a3d499892684c3e62f827673a62b1aaabba22f61a242763bce5ac1f3a1e4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='da340e3b-e00b-4c8e-a48d-167d0a2e53bd', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '11', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='5c5dedb109c0337cc07b6d77aef10953a9f6242f05559c2f333b3b6b883f9afb')}, text='Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\\nPromptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\\nChelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\\nof deep networks. In ICML , 2017.\\nDaniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\\nWen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\\nand synthesis. arXiv preprint , 2022.\\nIrving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\\nRui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, and Liqiang Nie. Chatllm network:\\nMore brains, more intelligence. arXiv preprint , 2023.\\nS. Hochreiter, A. S. Younger, and P. R. Conwell. Learning to learn using gradient descent. In Lecture\\nNotes on Comp. Sci. 2130, Proc. Intl. Conf. on Artificial Neural Networks (ICANN-2001) , pp. 87–\\n94. Springer: Berlin, Heidelberg, 2001.\\nXue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\\nwith large language model. arXiv preprint , 2023.\\n11', start_char_idx=2433, end_char_idx=3605, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='25ee6698-c311-495b-9300-783c0f268dff', embedding=None, metadata={'page_label': '12', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4f4ed487-33d4-41d1-af7e-a79c8615617a', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '12', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='786e65ea5b44ebcb1a1abc21a9ccc7a394ee451988ed6c434411e0dcf4c199a5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d9636f41-9571-4323-9d1b-7acd0faec1ea', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='35dbd3c1cb3ac2071303e2261b93aede4aba6937fbaf3fdd59b451388a4e42ea')}, text='Preprint\\nGuohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\\nCamel: Communicative agents for” mind” exploration of large scale language model society.\\narXiv preprint , 2023.\\nYujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\\nEccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\\nwith alphacode. Science , 2022.\\nTian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\\nTu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\\nagent debate. arXiv preprint , 2023.\\nBill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\\nChandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\\nslow thinking for complex interactive tasks. arXiv preprint , 2023.\\nRuibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi Yang, and\\nSoroush V osoughi. Training socially aligned language models in simulated human society. arXiv\\npreprint , 2023.\\nZiyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing\\nMa, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with\\nevol-instruct. arXiv preprint , 2023.\\nPotsawee Manakul, Adian Liusie, and Mark JF Gales. Selfcheckgpt: Zero-resource black-box hal-\\nlucination detection for generative large language models. arXiv preprint , 2023.\\nAgile Manifesto. Manifesto for agile software development . Snowbird, UT, 2001.\\nJohn McCarthy. History of lisp. In History of programming languages . 1978.\\nAnsong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-tau Yih, Sida Wang, and Xi Victoria\\nLin. Lever: Learning to verify language-to-code generation with execution. In ICML , 2023.\\nErik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese,\\nand Caiming Xiong. Codegen: An open large language model for code with multi-turn program\\nsynthesis, 2023.\\nOpenAI. Gpt-4 technical report, 2023.\\nJoon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and\\nMichael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint ,\\n2023.\\nChen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and\\nMaosong Sun. Communicative agents for software development, 2023.\\nBaptiste Rozi `ere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi\\nAdi, Jingyu Liu, Tal Remez, J ´er´emy Rapin, et al. Code llama: Open foundation models for code.\\narXiv preprint , 2023.\\nTimo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\\nNicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\\nuse tools. arXiv preprint , 2023.\\nJ. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\\non Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\\nJ. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\\noptimal self-improvements.', start_char_idx=0, end_char_idx=3154, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='d9636f41-9571-4323-9d1b-7acd0faec1ea', embedding=None, metadata={'page_label': '12', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4f4ed487-33d4-41d1-af7e-a79c8615617a', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '12', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='786e65ea5b44ebcb1a1abc21a9ccc7a394ee451988ed6c434411e0dcf4c199a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='25ee6698-c311-495b-9300-783c0f268dff', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '12', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='6f969617f69632ab079a18e793e7fe4067d80708d1438c30a982387e6bcb2f4f')}, text='Code llama: Open foundation models for code.\\narXiv preprint , 2023.\\nTimo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\\nNicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\\nuse tools. arXiv preprint , 2023.\\nJ. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\\non Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\\nJ. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\\noptimal self-improvements. Technical Report IDSIA-19-03, arXiv:cs.LO/0309048 v3, IDSIA,\\nManno-Lugano, Switzerland, December 2003.\\nJ. Schmidhuber. G ¨odel machines: Fully self-referential optimal universal self-improvers. In B. Go-\\nertzel and C. Pennachin (eds.), Artificial General Intelligence , pp. 199–226. Springer Verlag,\\n2006. Variant available as arXiv:cs.LO/0309048.\\n12', start_char_idx=2577, end_char_idx=3505, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='5c1629c3-f213-4a65-bb0d-50ccf73a4f71', embedding=None, metadata={'page_label': '13', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7340feef-cc39-45c5-abe3-d8bd981be443', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '13', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='59c6cd4d1c7933e1d5b50c8def37fcb00c478e951c25c3af1bdf00fed261c311')}, text='Preprint\\nJ. Schmidhuber. Ultimate cognition `a laG¨odel. Cognitive Computation , 1(2):177–193, 2009.\\nJ¨urgen Schmidhuber. Evolutionary principles in self-referential learning, or on learning how to\\nlearn: the meta-meta-... hook . PhD thesis, 1987.\\nJ¨urgen Schmidhuber. A ‘self-referential’weight matrix. In ICANN’93: Proceedings of the Interna-\\ntional Conference on Artificial Neural Networks Amsterdam, The Netherlands 13–16 September\\n1993 3 , 1993b.\\nJ¨urgen Schmidhuber. On learning to think: Algorithmic information theory for novel combinations\\nof reinforcement learning controllers and recurrent neural world models. arXiv preprint , 2015.\\nJ¨urgen Schmidhuber, Jieyu Zhao, and Nicol N Schraudolph. Reinforcement learning with self-\\nmodifying policies. In Learning to learn . 1998.\\nNoah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic\\nmemory and self-reflection. arXiv preprint , 2023.\\nMarta Skreta, Naruki Yoshikawa, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen,\\nKourosh Darvish, Al ´an Aspuru-Guzik, Florian Shkurti, and Animesh Garg. Errors are useful\\nprompts: Instruction guided task programming with verifier-assisted iterative prompting. arXiv\\npreprint , 2023.\\nElliot Soloway. Learning to program =learning to construct mechanisms and explanations. Com-\\nmunications of the ACM , 1986.\\nYashar Talebirad and Amirhossein Nadiri. Multi-agent collaboration: Harnessing the power of\\nintelligent llm agents, 2023.\\nTorantulino et al. Auto-gpt. https://github.com/Significant-Gravitas/\\nAuto-GPT , 2023.\\nR. J. Waldinger and R. C. T. Lee. PROW: a step toward automatic program writing. In D. E. Walker\\nand L. M. Norton (eds.), Proceedings of the 1st International Joint Conference on Artificial Intel-\\nligence (IJCAI) , 1969.\\nGuanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan,\\nand Anima Anandkumar. V oyager: An open-ended embodied agent with large language models.\\narXiv preprint , 2023a.\\nLei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\\nTang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\\narXiv preprint , 2023b.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\\nery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.\\narXiv preprint , 2022.\\nZhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. Unleashing\\ncognitive synergy in large language models: A task-solving agent through multi-persona self-\\ncollaboration. arXiv preprint , 2023c.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\\nZhou, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS ,\\n2022.\\nMichael Wooldridge and Nicholas R. Jennings. Pitfalls of agent-oriented development. In Pro-\\nceedings of the Second International Conference on Autonomous Agents , 1998. URL https:\\n//doi.org/10.1145/280765.280867 .\\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\\nReact: Synergizing reasoning and acting in language models. arXiv preprint , 2022.\\nEric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. Self-taught optimizer (stop):\\nRecursively self-improving code generation. arXiv preprint , 2023.\\n13', start_char_idx=0, end_char_idx=3357, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='e4fcfbdd-2913-438f-9c5c-0cc207ca75b2', embedding=None, metadata={'page_label': '14', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='755bd128-920d-43db-86df-fc1a2af35ba8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '14', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='becfc1bfbfd5ac64cd772f0b6f5d3ede21d32554389c0ac7ce93955b21f27f4a')}, text='Preprint\\nHongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tian-\\nmin Shu, and Chuang Gan. Building cooperative embodied agents modularly with large language\\nmodels. arXiv preprint , 2023.\\nXufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, and Stefan Wermter. Chat\\nwith the environment: Interactive multimodal perception using large language models. arXiv\\npreprint , 2023.\\nQinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen,\\nAndi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang. Codegeex: A pre-trained model for\\ncode generation with multilingual evaluations on humaneval-x, 2023.\\nShuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng,\\nYonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for building\\nautonomous agents. arXiv preprint , 2023.\\nMingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, R ´obert Csord ´as, Anand\\nGopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki\\nIrie, et al. Mindstorms in natural language-based societies of mind. arXiv preprint , 2023.\\n14', start_char_idx=0, end_char_idx=1160, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='355163c7-534f-46e5-9300-b9da7095869c', embedding=None, metadata={'page_label': '15', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ebbd22ab-f064-4149-af8a-c7194418a3fa', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '15', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='00c3ec12b0ed093c121d2c30344f36e0af620d7159c711e09fd933ce472b1a4e')}, text='Preprint\\nA O UTLOOK\\nA.1 S ELF-IMPROVEMENT MECHANISMS\\nOne limitation of the MetaGPT version in the main text of this paper is that each software project is\\nexecuted independently. However, through active teamwork, a software development team should\\nlearn from the experience gained by developing each project, thus becoming more compatible and\\nsuccessful over time.\\nThis is somewhat related to the idea of recursive self-improvement, first informally proposed in\\n1965 (Good, 1965), with first concrete implementations since 1987 (Schmidhuber, 1987; 1993b;\\nSchmidhuber et al., 1998), culminating in the concept of mathematically optimal self-referential\\nself-improvers (Schmidhuber, 2003; 2009). Generally speaking, a system should learn from experi-\\nence in the real world, and meta-learn better learning algorithms from experiences of learning, and\\nmeta-meta-learn better meta-learning algorithms from experiences of meta-learning, etc., without\\nany limitations except those of computability and physics.\\nMore recent, somewhat related work leverages the reasoning ability of Large Language Models\\n(LLMs) and recursively improves prompts of LLMs, to improve performance on certain downstream\\ntasks (Fernando et al., 2023; Zelikman et al., 2023), analogous to the adaptive prompt engineer of\\n2015 (Schmidhuber, 2015) where one neural network learns to generate sequence of queries or\\nprompts for another pre-trained neural network whose answers may help the first network to learn\\nnew tasks more quickly.\\nIn our present work, we also explore a self-referential mechanism that recursively modifies the con-\\nstraint prompts of agents based on information they observe during software development. Our\\ninitial implementation works as follows. Prior to each project, every agent in the software company\\nreviews previous feedback and makes necessary adjustments to their constraint prompts. This en-\\nables them to continuously learn from past project experiences and enhance the overall multi-agent\\nsystem by improving each individual in the company. We first establish a handover feedback action\\nfor each agent. This action is responsible for critically summarizing the information received dur-\\ning the development of previous projects and integrating this information in an updated constraint\\nprompt. The summarized information is stored in long-term memory such that it can be inherited\\nby future constraint prompt updates. When initiating a new project, each agent starts with a react\\naction. Each agent evaluates the received feedback and summarizes how they can improve in a\\nconstraint prompt.\\nOne current limitation is that these summary-based optimizations only modify constraints in the\\nspecialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\\nprotocols (Sec. 3.2). Future advancements are yet to be explored.\\nA.2 M ULTI -AGENT ECONOMIES\\nIn real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\\nware company, the collaboration SOP may change dynamically.\\nOne implementation of such self-organization is discussed in the paper on a “Natural Language-\\nBased Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\\nof Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\\nagents. Instead of using standard RL techniques to optimize the total reward of the system through\\nmodifications of neural network parameters, EOMs use the principles of supply and demand in free\\nmarkets to assign credit (money) to those agents that contribute to economic success (reward).\\nThe recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\\nsignment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\\ncosts. A convenient API is provided so that human users or agents in the platform can easily pur-\\nchase services from other agents to accomplish their services. Figure 6 displays the User Interface\\n(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\\ndevelopers can participate in building new agents and enable collaborative development within the\\ncommunity. Specifically, AgentStore allows users to subscribe to agents according to their demands\\n4http://beta.deepwisdom.ai\\n15', start_char_idx=0, end_char_idx=4326, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='669282ce-eb1d-4f34-a2b0-097e80474b1e', embedding=None, metadata={'page_label': '16', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b2479a42-ff30-4527-b013-5b9c2c030952', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '16', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='e2d00920bfb24336522f4acd6533aa24f3d9c4eae7a2691158a723243f636210')}, text='Preprint\\nand pay according to their usage. Moreover, users can purchase additional capabilities to expand the\\nplug-and-play functions of their existing agents. This allows users to gradually upgrade their agents.\\nWithin the MetaGPT framework, AgentStore can support the collaboration of various agents. Users\\ncan collect several agents together to carry out more complex tasks or projects, and all the agents\\nshare and comply with development and communication protocols defined in MetaGPT.\\nFigure 6: AgentStore is a platform dedicated to serving users in the creation and development of\\nagents within the MetaGPT framework. This platform provides users with an operational interface,\\nallowing users to easily manage a variety of agents with different emotions, personalities, and capa-\\nbilities for specific tasks.\\n16', start_char_idx=0, end_char_idx=818, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='c144ba95-85cc-46fb-beb4-f87507ccf0f4', embedding=None, metadata={'page_label': '17', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='dfccb03f-d42f-441c-bb37-6575f7afd234', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='a95f8f4d9b9b33cc8fe47e9564cdfc378ae160060ed5cd6d44838e3294b30ec7')}, text='Preprint\\nB A D EMO OF THE EXECUTION\\nIn this section, we outline the complete process of software development using MetaGPT. It begins\\nwith a user’s input command (as shown in Appendix B.1) and ends with software designed according\\nto the user’s specifications.\\nB.1 U SERINPUT\\nUpon receiving an instruction from the user, MetaGPT collaborates with a professional development\\nteam to fulfill the task. Here is a demo of user input:\\nUser input\\n1write a python3 GUI app such that you can draw an image with it\\nB.2 M ETAGPT DEVELOPMENT PROCESS\\nNow we provide a step-by-step explanation of the standardized output process for each agent.\\nProduct Manager The Product Manager generates a Product Requirement Document (PRD), as\\ndetailed in the specified documentation. This document encompasses goals, user stories, competitive\\nanalysis, requirement analysis and requirement pool. Additionally, a competitive quadrant chart is\\nproduced (see Figure 7). Subsequently, these documents and charts are handed over to the architect\\nfor system design.\\nProduct Requirement Document\\n1## Original Requirements\\n2The boss requires a Python3 GUI color meter that outputs the RGB values when it moves.\\n3\\n4## Product Goals\\n5‘‘‘python\\n6[\\n7 \"Create a user-friendly GUI color meter\",\\n8 \"Ensure the color meter accurately outputs RGB values\",\\n9 \"Ensure the color meter updates RGB values in real-time as it moves\"\\n10]\\n11‘‘‘\\n12\\n13## User Stories\\n14‘‘‘python\\n15[\\n16 \"As a user, I want to select any color on the screen, so that I can get its RGB values\",\\n17 \"As a user, I want the RGB values to update in real-time as I move the color meter, so that I\\n,→can get accurate color information\",\\n18 \"As a user, I want a simple and intuitive interface, so that I can easily use the color meter\"\\n19]\\n20‘‘‘\\n21\\n22## Competitive Analysis\\n23‘‘‘python\\n24[\\n25 \"Color Cop: A popular color picker for Windows. It’s simple and easy to use, but lacks real-\\n,→time RGB value updates\",\\n26 \"Just Color Picker: Offers real-time color picking and multiple color code formats. However,\\n,→its interface is cluttered and not very user-friendly\",\\n27 \"Instant Eyedropper: A simple color picker that lives in the system tray. It’s convenient but\\n,→lacks advanced features\",\\n28 \"ColorZilla: A color picker extension for browsers. It’s convenient for web design but not\\n,→suitable for desktop applications\",\\n29 \"ColorPic: Offers color palettes and mixer tools. It’s feature-rich but can be overwhelming\\n,→for simple tasks\"\\n30]\\n31‘‘‘\\n17', start_char_idx=0, end_char_idx=2475, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='fbb92e14-c40b-442c-846a-7446c6be8ef1', embedding=None, metadata={'page_label': '18', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f35181f6-7f86-46d8-9d7a-2962031dd372', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '18', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='1f79bc3576b6ccf486cf43b05e7960de7910d1eafc49edab05dd3059e23a531c')}, text='Preprint\\nProduct Requirement Document\\n1\\n2## Requirement Analysis\\n3The product should be a Python3 GUI application that serves as a color meter. It should allow\\n,→users to select any color on the screen and display the corresponding RGB values. The RGB\\n,→ values should update in real-time as the color meter moves. The interface should be\\n,→simple and user-friendly.\\n4\\n5## Requirement Pool\\n6‘‘‘python\\n7[\\n8 (\"Design a user-friendly GUI for the color meter\", \"P0\"),\\n9 (\"Implement color selection functionality\", \"P0\"),\\n10 (\"Display RGB values of the selected color\", \"P0\"),\\n11 (\"Update RGB values in real-time as the color meter moves\", \"P0\"),\\n12 (\"Test the application for accuracy and performance\", \"P1\")\\n13]\\n14‘‘‘\\n15\\n16## UI Design draft\\n17The UI should be minimalistic and intuitive. It should primarily consist of a color meter, which\\n,→could be a magnified area of the screen that the user can move around. The RGB values of\\n,→the currently selected color should be prominently displayed, updating in real-time as\\n,→the color meter moves. The layout should be clean and uncluttered, with a focus on\\n,→functionality and ease of use.\\n18\\n19## Anything UNCLEAR\\n20There are no unclear points.\\nFigure 7: The quadrant chart for the “Drawing App” generated by the product manager agent.\\n18', start_char_idx=0, end_char_idx=1285, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='70397ad9-b8dd-49ef-b8eb-8f40d901a214', embedding=None, metadata={'page_label': '19', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='44e18695-20cb-4717-88ba-6e7360bbae3a', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '19', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='6fb5c6395b9491ac0fc0e0e19979c96490fcc4d79e74647123592e3ca1a1e6ce')}, text='Preprint\\nArchitect Based on the requirements in PRD, the Architect agent devises technical specifications\\nincluding system architecture diagrams and interface definitions. Initially, the Architect defines the\\noverarching technical trajectory. Subsequently, the project’s architecture, including files, classes\\n(Figure 8) and the sequence flow chart (Figure 12), is designed. The Architect’s documentation is\\nthen given to the project manager for task allocation and execution.\\nSystem design\\n1## Implementation approach\\n2We will use Python’s Tkinter library to create the GUI for the color meter. Tkinter is a standard\\n,→Python interface to the Tk GUI toolkit and is included with most Python installations. It\\n,→ is simple to use and powerful enough for our needs.\\n3\\n4The color selection functionality will be implemented using the PIL (Pillow) library, which allows\\n,→ us to capture the screen’s pixel data. By moving the mouse, we can get the RGB values of\\n,→ the pixel under the mouse cursor in real-time.\\n5\\n6The RGB values will be displayed on the GUI using Tkinter’s Label widget. We will use Python’s\\n,→threading library to update the RGB values in real-time as the color meter moves.\\n7\\n8The application will be tested for accuracy and performance using Python’s unittest library.\\n9\\n10## Python package name\\n11‘‘‘python\\n12\"color_meter\"\\n13‘‘‘\\n14\\n15## File list\\n16‘‘‘python\\n17[\\n18 \"main.py\",\\n19 \"color_picker.py\",\\n20 \"gui.py\",\\n21 \"tests.py\"\\n22]\\n23‘‘‘\\n24\\n25## Anything UNCLEAR\\n26The requirement is clear to me.\\nFigure 8: Data structures and interface definitions for the “Drawing App” generated by the architect\\nagent.\\nProject Manager The Project Manager breaks down the project into a task list. Furthermore, each\\ncode file is analyzed based on its intended functionality and then treated as a separate task assigned\\nto Engineers.\\n19', start_char_idx=0, end_char_idx=1837, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='9e0273e3-5dde-47cb-99a7-ea5268ea5235', embedding=None, metadata={'page_label': '20', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d3b2720a-ebd3-4eee-b5e1-ab7f8b8f88da', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '20', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='51508be7b5b7ad905ea89fcda5dc373b354802220dff47c45e77cdf1da9a13f5')}, text='Preprint\\nFigure 9: The program call flow for the “Drawing App” generated by the architect agent.\\nTasks\\n1## Required Python third-party packages\\n2\\n3‘‘‘python\\n4\"\"\"\\n5tkinter==8.6\\n6Pillow==8.3.1\\n7\"\"\"\\n8‘‘‘\\n9\\n10## Required Other language third-party packages\\n11‘‘‘python\\n12\"\"\"\\n13No third-party packages required in other languages.\\n14\"\"\"\\n15‘‘‘\\n16\\n17## Full API spec\\n18‘‘‘python\\n19\"\"\"\\n20No APIs are used in this project.\\n21\"\"\"\\n22‘‘‘\\n23\\n24## Logic Analysis\\n25‘‘‘python\\n26[\\n27 (\"main.py\", \"Contains the main application loop and initializes all the other components.\"),\\n28 (\"canvas.py\", \"Implements the drawing canvas, responds to mouse events, and uses the selected\\n,→tool and color.\"),\\n29 (\"tools.py\", \"Implements the tool selection interface.\"),\\n30 (\"color_picker.py\", \"Implements the color selection interface.\"),\\n31 (\"file_manager.py\", \"Implements the file saving and opening functionality.\")\\n32]\\n33‘‘‘\\n20', start_char_idx=0, end_char_idx=901, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='d6b5b797-54e7-41ba-b44a-90d17e9105eb', embedding=None, metadata={'page_label': '21', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='12cf4840-9e14-42e4-95c1-75d3cad9a1a0', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '21', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='a469d69b6d3b8b2e317ddb3bc9600e0b93d3639d62771e1e5234ecc91b483c83')}, text='Preprint\\nProduct Requirement Document\\n1## Task list\\n2‘‘‘python\\n3[\\n4 \"main.py\",\\n5 \"canvas.py\",\\n6 \"tools.py\",\\n7 \"color_picker.py\",\\n8 \"file_manager.py\"\\n9]\\n10‘‘‘\\n11\\n12## Shared Knowledge\\n13‘‘‘python\\n14\"\"\"\\n15The ’Tkinter’ library is used for creating the GUI of the application. It provides various widgets\\n,→ like frames and canvases which are used in this project.\\n16The ’Pillow’ library is used for handling image files. It is used in the ’file_manager.py’ for\\n,→saving and opening image files.\\n17The ’main.py’ file is the entry point of the application. It initializes all the other components\\n,→and starts the application loop.\\n18\"\"\"\\n19‘‘‘\\n20\\n21## Anything UNCLEAR\\n22The project requirements and implementation approach are clear. However, we need to ensure that\\n,→all team members are familiar with the Tkinter and Pillow libraries. If not, they may\\n,→need some time to learn these libraries before starting the development.\\n21', start_char_idx=0, end_char_idx=928, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='b64050d3-6409-4f36-a1da-ffa0283cc8d7', embedding=None, metadata={'page_label': '22', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='03c0ecd0-3be7-442a-9747-08e873f44b0c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '22', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='5638e43e36c8b0af11d1f0fee02bac13b4ee212e7c7d2f66b3e4d1c8bfe7a866')}, text='Preprint\\nEngineer Given the provided file structure and function definitions, an Engineer agent requires\\nonly fundamental development skills to complete the development tasks. Due to the large number\\nof files, we present only one auto-generated code file here.\\nGenerated code (color picker.py)\\n1import tkinter as tk\\n2from tkinter import colorchooser\\n3class ColorPicker:\\n4 def __init__(self, root: tk.Tk, color: str = ’black’):\\n5 self.frame = tk.Frame(root)\\n6 self.color = color\\n7\\n8 self.color_button = tk.Button(self.frame, text=’Color’, command=self.select_color)\\n9 self.color_button.pack(fill=’x’)\\n10\\n11 def select_color(self):\\n12 color = colorchooser.askcolor()[1]\\n13 if color is not None:\\n14 self.color = color\\n15\\n16 def pack(self, **kwargs):\\n17 self.frame.pack( **kwargs)\\n18\\n19 def get_color(self):\\n20 return self.color\\nQA Engineer Upon receiving the code output from the Engineer, the QA Engineer generates unit\\ntest code and reviews it to identify and fix any bugs, ensuring high-quality software.\\nGenerated Unit tests (test.py)\\n1import unittest\\n2import tkinter as tk\\n3# You might want to move the ColorPicker class to another file, let’s say color_picker.py\\n4# from color_picker import ColorPicker\\n5\\n6class TestColorPicker(unittest.TestCase):\\n7\\n8 def setUp(self):\\n9 self.root = tk.Tk()\\n10 self.cp = ColorPicker(self.root)\\n11\\n12 def tearDown(self):\\n13 # This is important to close the tk window after tests\\n14 self.root.destroy()\\n15\\n16 def test_initial_color(self):\\n17 # Test the default color during initialization\\n18 self.assertEqual(self.cp.get_color(), ’black’)\\n19\\n20 def test_set_and_get_color(self):\\n21 # Test setting a new color and retrieving it\\n22 new_color = ’#ffffff’ # white color\\n23 self.cp.color = new_color\\n24 self.assertEqual(self.cp.get_color(), new_color)\\n25\\n26\\n27if __name__ == ’__main__’:\\n28 unittest.main()\\nOutput Ultimately, as shown in Figure 10, MetaGPT generates a functional application named\\n“Drawing App”.\\n22', start_char_idx=0, end_char_idx=1943, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='7ff3ef45-b356-4881-bc7f-0be610459e6b', embedding=None, metadata={'page_label': '23', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3d1e14d8-ffd7-43f0-bdd6-da25fac2cb6b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '23', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='e7f022bfa75847771dd87ecd2652372c6d171d89741bb67af4ecde90f5087565')}, text='Preprint\\nFigure 10: The “Drawing App” generated by MetaGPT.\\nC E XPERIMENTS\\nC.1 D ETAILS OF THE SOFTWARE DEVDATASET\\nThe SoftwareDev dataset includes 70 diverse software development tasks. Table 8 displays the\\nnames and detailed prompts of 11 tasks within the dataset. Note that the first seven tasks listed are\\nused in the main experiments of this paper.\\nC.2 A DDITIONAL RESULTS\\nQuantitative results of MetaGPT As shown in Table 4, MetaGPT achieves an average score\\nof 3.9, surpassing ChatDev’s score of 2.1 Zhao et al. (2023), which is based on the Chat chain.\\nCompare the scores of general intelligent algorithms, including AutoGPT Torantulino et al. (2023),\\nwhich all score 1.0, failing to generate executable code. We observe that the generated code is often\\nshort, lacks comprehensive logic, and tends to fail to handle cross-file dependencies correctly.\\nWhile models such as AutoGPT (Torantulino et al., 2023), Langchain (Chase, 2022), and Agent-\\nVerse (Chen et al., 2023) display robust general problem-solving capabilities, they lack an essential\\nelement for developing complex systems: systematically deconstructing requirements. Conversely,\\nMetaGPT simplifies the process of transforming abstract requirements into detailed class and func-\\ntion designs through a specialized division of labor and SOPs workflow. When compared to Chat-\\nDev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\\nloss of communication information but also improve the execution of code.\\nQuantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\\nMetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\\nperformance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\\nbasic version without the executable feedback mechanism.\\nQuantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\\non different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\\nGPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\\nalthough MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\\nperformance.\\n5https://deepseekcoder.github.io\\n23', start_char_idx=0, end_char_idx=2274, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='ecd56118-b847-4d8a-8b62-e5ac339a33ae', embedding=None, metadata={'page_label': '24', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f5edc68-080d-49be-bc23-2a23face1e05', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '24', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='3b788afaeb02d56ed5b492ae8f2978893fffe80ae83bc914afba04dea087d14e')}, text='Preprint\\nTable 4: Executability comparison. The executability scores are on a grading system ranging from\\n’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\\nlargely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\\nTask AutoGPT LangChain AgentVerse ChatDev MetaGPT\\nFlappy bird 1 1 1 2 3\\nTank battle game 1 1 1 2 4\\n2048 game 1 1 1 1 4\\nSnake game 1 1 1 3 4\\nBrick breaker game 1 1 1 1 4\\nExcel data process 1 1 1 4 4\\nCRUD manage 1 1 1 2 4\\nAverage score 1.0 1.0 1.0 2.1 3.9\\nTable 5: Performance of MetaGPT on SoftwareDev using different LLMs as agent backends.\\nModel Open source Time(/s) # Lines Executability Revisions\\nMetaGPT (w/ GPT-3.5) % 75.18 161.6 2.8 2.4\\nMetaGPT (w/ GPT-4) % 552.94 178.2 3.8 1.2\\nMetaGPT (w/ Deepseek Coder 33B) \" 1186.20 120.2 1.4 2.6\\nImpact of Instruction Levels (High-level v.s.Detailed Instructions) Does the variation in the\\nlevel of initial input from humans significantly influence performance outcomes? For examples:\\n1.High-level prompt : Create a brick breaker game.\\n2.Detailed prompt : Creating a brick breaker game. In a brick breaker game, the player\\ntypically controls a paddle at the bottom of the screen to bounce a ball towards a wall of\\nbricks. The goal is to break all the bricks by hitting them with the ball.\\nAdditional experiments were conducted to investigate this aspect: we selected 5 tasks from Soft-\\nwareDev, and constructed detailed prompts for them. Here are the experimental results:\\nTable 6: Impact of Instruction Levels. The executability is scored on a grading system ranging\\nfrom ‘1’ to ‘4’. A score of ‘1’ signifies complete failure, ‘2’ denotes runnable code, ‘3’ represents\\nlargely expected workflow, and ‘4’ indicates a perfect match to expectations.\\nModel # Word Time(/s) Token usage # Lines Executability Productivity Reversions\\nHigh-level 13.2 552.9 28384.2 178.2 3.8 163.8 1.2\\nDetailed 42.2 567.8 29657.0 257.0 4.0 118.0 1.6\\nWe observe that: detailed prompts lead to better software projects with lower productivity ratios\\nbecause of clearer requirements and functions, while simple inputs can still generate good enough\\nsoftware using MetaGPT with an executability rating of 3.8, which is comparable to the detailed\\nprompt scenario. (Note that, Productivity = Token usage / Total Code Lines. The lower this ratio,\\nthe better.)\\nThe performance of GPT variants in HumanEval benchmark We use the GPT-4’s 67% Hu-\\nmanEval score (OpenAI, 2023) as our baseline, acknowledging its acceptance in the HumanEval\\nbenchmark. We further extend to experiments(five times) with GPT-4 (gpt-4-0613) and GPT-3.5-\\nTurbo (gpt-3.5-turbo-0613) under various conditions to assess performance. (A)We directly called\\nthe OpenAI API with the prompt in HumanEval. (B)We called the OpenAI API and parsed the\\ncode with regex in the response. (C)We added an additional system prompt, then called the OpenAI\\nAPI. The prompt is ”You are an AI that only responds with Python code, NOT ENGLISH. You will\\n24', start_char_idx=0, end_char_idx=3014, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='638a2a11-d274-4f85-a94c-74f772a89ba6', embedding=None, metadata={'page_label': '25', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='40da9251-7301-4aae-923a-15985c777c86', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '25', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='e558e9b9f22315b391570c1570c88470d2b1e96e0ba5b0f09aa745bf62ad11b5')}, text='Preprint\\nbe given a function signature and its docstring by the user. Write your full implementation (restate\\nthe function signature).” As shown in Table 7, GPT-4 is more sensitive to prompt, code parser, and\\npost-processing results on the HumanEval data set. It is difficult for GPT-3.5-Turbo to return the\\ncorrect completion code without prompt words.\\nTable 7: Performance of GPT models on HumanEval. Experiments were conducted five times\\nusing gpt-4-0613 and gpt-3.5-turbo-0613 with different settings.\\nSettings Model 1 2 3 4 5 Avg. Std.\\nA gpt-4-0613 0.732 0.707 0.732 0.713 0.738 0.724 0.013\\nA gpt-3.5-turbo-0613 0.360 0.366 0.360 0.348 0.354 0.357 0.007\\nB gpt-4-0613 0.787 0.811 0.817 0.829 0.817 0.812 0.016\\nB gpt-3.5-turbo-0613 0.348 0.354 0.348 0.335 0.348 0.346 0.007\\nC gpt-4-0613 0.805 0.805 0.817 0.793 0.780 0.800 0.014\\nC gpt-3.5-turbo-0613 0.585 0.567 0.573 0.579 0.579 0.577 0.007\\nQualitative results Figure 11 and Figure 12 illustrate the outcomes of the Architect agent’s ef-\\nforts to design a complex recommender system. These figures showcase the comprehensive system\\ninterface design and program call flow. The latter is essential for creating a sophisticated automated\\nsystem. It is crucial to emphasize the importance of this division of labor in developing an automated\\nsoftware framework.\\nD L IMITATION AND ETHICS CONCERNS\\nD.1 L IMITATION\\nSystem side At present, our system cannot fully cater to specific scenarios, such as UI and front-\\nend, as we have yet to incorporate such agents and multimodal tools. Furthermore, despite gen-\\nerating the most amount of code among comparable frameworks, it remains challenging to fulfill\\nreal-world applications’ diverse and complex requirements.\\nHuman user side A key challenge for users is to interrupt the running process of each agent, or\\nset the starting running point (checkpoint) for each agent.\\nD.2 E THICS CONCERNS\\nUnemployment and Skill Obsolescence MetaGPT enables more people to program in natural\\nlanguages, thereby making it easier for engineers to get started. Over the years, programming\\nlanguages have evolved from punched cards to assembly, C, Java, Python, and now natural lan-\\nguage. As a result, humans have become more proficient at programming, increasing the demand\\nfor programming-related positions. Furthermore, programming with natural language may offer a\\nsignificantly easier learning curve, making programming more accessible to a broader audience.\\nTransparency and Accountability MetaGPT is an open-source framework that facilitates inter-\\nactive communication between multiple agents through natural language. Humans can initiate, ob-\\nserve, and stop running with the highest level of control. It provides real-time interpretation and op-\\neration of the natural language, displayed on the screen and logs, ensuring transparency. MetaGPT\\nenhances “natural language programming” capabilities, and human engineers are the users and re-\\nsponsible for the outcomes.\\nPrivacy and Data Security MetaGPT operates locally, ensuring user data privacy and security. It\\ndoes not collect user data. For interactions with third-party LLMs, such as those by OpenAI, users\\nare encouraged to refer to the respective privacy policies (e.g., OpenAI Privacy Policy). However,\\nwe provide the option of open-source LLMs as backends.\\n25', start_char_idx=0, end_char_idx=3307, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='04308344-4141-4a2c-8660-8aed689f2545', embedding=None, metadata={'page_label': '26', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='451613a3-1946-47f1-8e43-584d8128c979', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '26', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='3a3bdeccd782cd0bf6a81f84f8d1bb51cb100216b38b708992b31a703d7d19cf')}, text='Preprint\\nFigure 11: The system interface design for “recommendation engine development” is generated by\\nthearchitect agent ( zoom in for a better view ).\\nE M ORE DISCUSSIONS\\nE.1 D EEP-SEATED CHALLENGES\\nMetaGPT also alleviates or solves these challenges with its unique designs:\\nUse Context Efficiently Two sub-challenges are present. First, unfolding short natural language\\ndescriptions accurately to eliminate ambiguity. Second, maintaining information validity in lengthy\\ncontexts, enables LLMs to concentrate on relevant data without distraction.\\nReduce Hallucinations Using LLMs to generate entire software programs faces code halluci-\\nnation problems—-including incomplete implementation of functions, missing dependencies, and\\npotential undiscovered bugs, which may be more serious. LLMs often struggle with software gen-\\neration due to vague task definitions. Focusing on granular tasks like requirement analysis and\\npackage selection offers guided thinking, which LLMs lack in broad task solving.\\nE.2 I NFORMATION OVERLOAD\\nIn MetaGPT, we use a global message pool and a subscription mechanism to address “information\\noverload,” which refers to the problem of receiving excessive or irrelevant information. This issue\\nis dependent on specific applications. MetaGPT employs a message pool to streamline communi-\\ncation, ensuring efficiency. Additionally, a subscription mechanism filters out irrelevant contexts,\\nenhancing the relevance and utility of the information. This design is particularly crucial in soft-\\n26', start_char_idx=0, end_char_idx=1522, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='c38b0863-f411-44ff-9144-f8e85a6f4577', embedding=None, metadata={'page_label': '27', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4e18e4cd-1cf8-44c4-8779-52bd3d170016', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '27', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='c25ba2a809a8299d0bf3b4ce6347803e59318017b07ddef3c6f5231fba164b00')}, text='Preprint\\nFigure 12: The program call flow for “recommendation engine development” generated by the\\narchitect agent ( zoom in for a better view ).\\nware design scenarios and standard operating procedures (SOPs) where effective communication is\\nessential.\\n27', start_char_idx=0, end_char_idx=255, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='5bada30e-158d-4cbd-93ad-d8053381f734', embedding=None, metadata={'page_label': '28', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3bafb3ff-fcaa-4e3c-b398-e048ecbfe5e0', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '28', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='2fe42d419b0b3cb171364c582f3bdd4b5902bdda4655c447cb544e55622dda44')}, text='Preprint\\nTable 8: Examples of SoftwareDev dataset.\\nTask ID Task Prompt\\n0 Snake game Create a snake game.\\n1 Brick breaker game Create a brick breaker game.\\n2 2048 game Create a 2048 game for the web.\\n3 Flappy bird game Write p5.js code for Flappy Bird where you control a yellow bird continu-\\nously flying between a series of green pipes. The bird flaps every time you\\nleft click the mouse. If it falls to the ground or hits a pipe, you lose. This\\ngame goes on indefinitely until you lose; you get points the further you go.\\n4 Tank battle game Create a tank battle game.\\n5 Excel data process Write an excel data processing program based on streamlit and pandas. The\\nscreen first shows an excel file upload button. After the excel file is uploaded,\\nuse pandas to display its data content. The program is required to be concise,\\neasy to maintain, and not over-designed. It uses streamlit to process web\\nscreen displays, and pandas is sufficient to process excel reading and display.\\nPlease make sure others can execute directly without introducing additional\\npackages.\\n6 CRUD manage Write a management program based on the crud addition, deletion, modifi-\\ncation and query processing of the customer business entity. The customer\\nneeds to save this information: name, birthday, age, sex, and phone. The data\\nis stored in client.db, and there is a judgement whether the customer table ex-\\nists. If it doesn’t, it needs to be created first. Querying is done by name; same\\nfor deleting. The program is required to be concise, easy to maintain, and not\\nover-designed. The screen is realized through streamlit and sqlite—no need\\nto introduce other additional packages.\\n7 Music transcriber Develop a program to transcribe sheet music into a digital format; provid-\\ning error-free transcribed symbolized sheet music intelligence from audio\\nthrough signal processing involving pitch and time slicing then training a\\nneural net to run Onset Detected CWT transforming scalograms to chroma-\\ngrams decoded with Recursive Neural Network focused networks.\\n8 Custom press releases Create custom press releases; develop a Python script that extracts rele-\\nvant information about company news from external sources, such as social\\nmedia; extract update interval database for recent changes. The program\\nshould create press releases with customizable options and export writings\\nto PDFs, NYTimes API JSONs, media format styled with interlink internal\\nfixed character-length metadata.\\n9 Gomoku game Implement a Gomoku game using Python, incorporating an AI opponent\\nwith varying difficulty levels.\\n10 Weather dashboard Create a Python program to develop an interactive weather dashboard.\\n28', start_char_idx=0, end_char_idx=2668, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='a24d49e1-eea9-4573-a542-c1ce6ca502cc', embedding=None, metadata={'page_label': '29', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4b7f35ae-9fb6-43db-adc6-d6258862da98', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '29', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, hash='27e7e57e83ba13e63b34a7e99bfa173aca5e94d0f0a7d4ee1035c4872461f042')}, text='Preprint\\nTable 9: Additional results of pure MetaGPT w/o feedback on SoftwareDev. Averages (Avg.) of 70 tasks are calculated and 10 randomly selected tasks are\\nincluded. ‘#’ denotes ‘The number of’, while ‘ID’ is ‘Task ID’.\\nID Code statistics Doc statistics Cost statistics Cost of revision Code executability\\n#code files #lines of code #lines per code file #doc files #lines of doc #lines per doc file #prompt tokens #completion tokens time costs money costs\\n0 5.00 196.00 39.20 3.00 210.00 70.00 24087.00 6157.00 582.04 $ 1.09 1. TypeError 4\\n1 6.00 191.00 31.83 3.00 230.00 76.67 32517.00 6238.00 566.30 $ 1.35 1. TypeError 4\\n2 3.00 198.00 66.00 3.00 235.00 78.33 21934.00 6316.00 553.11 $ 1.04 1. lack\\n@app.route(’/’)3\\n3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\\ning 2. Compile bug\\nfixes2\\n4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\\nmissing 2. Com-\\npile bug fixes 3.\\npygame.surface not\\ninitialize3\\n5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\\nror 2. ModuleNot-\\nFoundError4\\n6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\\n7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\\n8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\\nsion error 2. model\\ntraining method not\\nimplement2\\n9 5.00 215.00 43.00 3.00 270.00 90.00 24799.00 5734.00 550.88 $ 1.27 1. dependency er-\\nror 2. URL 403 er-\\nror3\\n10 3.00 93.00 31.00 3.00 254.00 84.67 24109.00 5363.00 438.50 $ 0.92 1. dependency er-\\nror 2. missing main\\nfunc.4\\nAvg. 4.71 191.57 42.98 3.00 240.00 80.00 26626.86 6218.00 516.71 $1.12 0.51 (only consider\\nitem scored 2, 3 or\\n4)3.36\\n29', start_char_idx=0, end_char_idx=1726, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None)], metadata={'3bb2b85e-6a71-4c58-8951-f303afa89ff3': {'page_label': '1', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'dfb5434e-d16d-4588-a28e-d7a95afc3592': {'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '464ebc4e-f66d-454c-a847-ae208cb8afcf': {'page_label': '3', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '083e8563-65db-4c33-bdf0-565ea7b137c4': {'page_label': '3', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '594b8a89-fabf-4cdf-9464-fa5657f40c89': {'page_label': '4', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '959e7eed-501b-4d4f-987b-8f144c3d8d79': {'page_label': '5', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '10824422-8512-4d1d-82ab-b8a5677d86c2': {'page_label': '6', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '22ef56fd-9cb7-41d9-bc27-53f1c002c9e2': {'page_label': '7', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '4a764b46-8885-4dbe-8453-a72404266eb5': {'page_label': '7', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '4fa73455-8c77-4430-8050-4d371b68c9f3': {'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '23a0c522-c760-49f6-a4a3-0ab502780fde': {'page_label': '9', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'f359960b-13a0-401a-8839-ee339bd36a04': {'page_label': '10', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '4b0f8449-2a46-4c3f-8739-ecba14915c46': {'page_label': '10', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'da340e3b-e00b-4c8e-a48d-167d0a2e53bd': {'page_label': '11', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '55263371-d149-4015-8edc-662f1f0a2d05': {'page_label': '11', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '25ee6698-c311-495b-9300-783c0f268dff': {'page_label': '12', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'd9636f41-9571-4323-9d1b-7acd0faec1ea': {'page_label': '12', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '5c1629c3-f213-4a65-bb0d-50ccf73a4f71': {'page_label': '13', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'e4fcfbdd-2913-438f-9c5c-0cc207ca75b2': {'page_label': '14', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '355163c7-534f-46e5-9300-b9da7095869c': {'page_label': '15', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '669282ce-eb1d-4f34-a2b0-097e80474b1e': {'page_label': '16', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'c144ba95-85cc-46fb-beb4-f87507ccf0f4': {'page_label': '17', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'fbb92e14-c40b-442c-846a-7446c6be8ef1': {'page_label': '18', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '70397ad9-b8dd-49ef-b8eb-8f40d901a214': {'page_label': '19', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '9e0273e3-5dde-47cb-99a7-ea5268ea5235': {'page_label': '20', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'd6b5b797-54e7-41ba-b44a-90d17e9105eb': {'page_label': '21', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'b64050d3-6409-4f36-a1da-ffa0283cc8d7': {'page_label': '22', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '7ff3ef45-b356-4881-bc7f-0be610459e6b': {'page_label': '23', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'ecd56118-b847-4d8a-8b62-e5ac339a33ae': {'page_label': '24', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '638a2a11-d274-4f85-a94c-74f772a89ba6': {'page_label': '25', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '04308344-4141-4a2c-8660-8aed689f2545': {'page_label': '26', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'c38b0863-f411-44ff-9144-f8e85a6f4577': {'page_label': '27', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, '5bada30e-158d-4cbd-93ad-d8053381f734': {'page_label': '28', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}, 'a24d49e1-eea9-4573-a542-c1ce6ca502cc': {'page_label': '29', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary_query_engine.query(\"what's the summary of the document?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D2bbgKGkyeCo"
      },
      "outputs": [],
      "source": [
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful for summarization questions related to MetaGPT\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=(\n",
        "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ewJ5jn4yykzi"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMj8DxCIyn0H",
        "outputId": "5143b1df-5650-4c22-8cd4-2e2e4f455151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_message user: Some choices are given below. It is provided in a numbered list (1 to 2), where each item in the list corresponds to a summary.\n",
            "---------------------\n",
            "(1) Useful for summarization questions related to MetaGPT\n",
            "\n",
            "(2) Useful for retrieving specific context from the MetaGPT paper.\n",
            "---------------------\n",
            "Using only the choices above and not prior knowledge, return the choice that is most relevant to the question: 'What is the summary of the document?'\n",
            "\n",
            "\n",
            "The output should be ONLY JSON formatted as a JSON instance.\n",
            "\n",
            "Here is an example:\n",
            "[\n",
            "    {{\n",
            "        choice: 1,\n",
            "        reason: \"<insert reason for choice>\"\n",
            "    }},\n",
            "    ...\n",
            "]\n",
            "\n",
            "\u001b[1;3;38;5;200mSelecting query engine 0: The question 'What is the summary of the document?' is asking for a concise overview of the document's content. Option (1), which mentions usefulness for summarization questions, directly addresses this need..\n",
            "\u001b[0mmerged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "page_label: 1\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "METAGPT: M ETA PROGRAMMING FOR A\n",
            "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
            "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
            "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
            "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
            "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
            "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
            "5Nanjing University,6University of Pennsylvania,\n",
            "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
            "ABSTRACT\n",
            "Remarkable progress has been made on automated problem solving through so-\n",
            "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
            "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
            "complex tasks, however, are complicated through logic inconsistencies due to\n",
            "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
            "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
            "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
            "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
            "streamlined workflows, thus allowing agents with human-like domain expertise\n",
            "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
            "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
            "complex tasks into subtasks involving many agents working together. On col-\n",
            "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
            "solutions than previous chat-based multi-agent systems. Our project can be found\n",
            "at https://github.com/geekan/MetaGPT.\n",
            "1 I NTRODUCTION\n",
            "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
            "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
            "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
            "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
            "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
            "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
            "et al., 2023; Qian et al., 2023).\n",
            "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
            "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
            "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
            "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
            "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
            "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
            "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
            "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
            "(PRDs) using a standardized structure, to guide the developmental process.\n",
            "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
            "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
            "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
            "∗These authors contributed equally to this work.\n",
            "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
            "1\n",
            "\n",
            "page_label: 2\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
            "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
            "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
            "(e.g., Product Manager, Architect, Engineer, etc.).\n",
            "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
            "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
            "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
            "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
            "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
            "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
            "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
            "lunch?” – Bob (Architect).\n",
            "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
            "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
            "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
            "2006; Finn et al., 2017).\n",
            "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
            "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
            "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
            "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
            "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
            "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
            "ing how agent-based techniques can enhance meta-programming.\n",
            "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
            "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
            "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
            "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
            "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
            "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
            "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
            "We summarize our contributions as follows:\n",
            "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
            "2\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "•We introduce MetaGPT, a meta-programming framework for multi-agent collaboration based on\n",
            "LLMs. It is highly convenient and flexible, with well-defined functions like role definition and\n",
            "message sharing, making it a useful platform for developing LLM-based multi-agent systems.\n",
            "•Our innovative integration of human-like SOPs throughout MetaGPT’s design significantly en-\n",
            "hances its robustness, reducing unproductive collaboration among LLM-based agents. Furthermore,\n",
            "we introduce a novel executive feedback mechanism that debugs and executes code during runtime,\n",
            "significantly elevating code generation quality (e.g., 5.4% absolute improvement on MBPP).\n",
            "•We achieve state-of-the-art performance on HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021). Extensive results convincingly validate MetaGPT, suggesting that it is a promising\n",
            "meta-programming framework for developing LLM-based multi-agent systems.\n",
            "2 R ELATED WORK\n",
            "Automatic Programming The roots of automatic programming reach back deep into the previ-\n",
            "ous century. In 1969, Waldinger & Lee (1969) introduced “PROW,” a system designed to accept\n",
            "program specifications written in predicate calculus, generate algorithms, and create LISP imple-\n",
            "mentations (McCarthy, 1978). Balzer (1985) and Soloway (1986) made efforts to advance auto-\n",
            "matic programming and identified potential methods to achieve it. Recent approaches use natural\n",
            "language processing (NLP) techniques (Ni et al., 2023; Skreta et al., 2023; Feng et al., 2020; Li\n",
            "et al., 2022; Chen et al., 2018; 2021b; Zhang et al., 2023). Automatic programming has grown into\n",
            "an industry delivering paid functions such as Microsoft Copilot. Lately, LLMs-based agents (Yao\n",
            "et al., 2022; Shinn et al., 2023; Lin et al., 2023) have advanced automatic programming develop-\n",
            "ment. Among them, ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023) utilize a chain of\n",
            "thought prompts (Wei et al., 2022) to generate reasoning trajectories and action plans with LLMs.\n",
            "Both works demonstrate the effectiveness of the ReAct style loop of reasoning as a design paradigm\n",
            "for empowering automatic programming. Additionally, ToolFormer (Schick et al., 2023) can learn\n",
            "how to use external tools through simple APIs. The research most closely aligned with our work\n",
            "by Li et al. (2023) proposes a straightforward role-play framework for programming that involves\n",
            "communication between agents playing different roles. Qian et al. (2023) utilizes multiple agents for\n",
            "software development. Although existing papers (Li et al., 2023; Qian et al., 2023) have improved\n",
            "productivity, they have not fully tapped into effective workflows with structured output formats.\n",
            "This makes it harder to deal with complex software engineering issues.\n",
            "LLM-Based Multi-Agent Frameworks Recently, LLM-based autonomous agents have gained\n",
            "tremendous interest in both industry and academia (Wang et al., 2023b). Many works (Chen et al.,\n",
            "2024; Wang et al., 2023c; Du et al., 2023; Zhuge et al., 2023; Hao et al., 2023; Akata et al., 2023)\n",
            "have improved the problem-solving abilities of LLMs by integrating discussions among multiple\n",
            "agents. Stable-Alignment (Liu et al., 2023) creates instruction datasets by deriving consensus on\n",
            "value judgments through interactions across a sandbox with LLM agents. Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks.\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks. Besides, LLM-based agents face the challenges of “assistant repeated instruc-\n",
            "tion” or “infinite loop of message” (Talebirad & Nadiri, 2023; Li et al., 2023). These challenges\n",
            "become more urgent in task-oriented collaborations, which require consistent and mutually benefi-\n",
            "cial interactions (Elazar et al., 2021; Wang et al., 2022; Jiang et al., 2023). This motivates our focus\n",
            "on applying advanced concepts such as Standard Operating Procedures in software development to\n",
            "multi-agent frameworks.\n",
            "3\n",
            "\n",
            "page_label: 4\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 2: An example of the communication protocol (left) and iterative programming with exe-\n",
            "cutable feedback (right). Left: Agents use a shared message pool to publish structured messages.\n",
            "They can also subscribe to relevant messages based on their profiles. Right : After generating the\n",
            "initial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past\n",
            "messages stored in memory and compares them with the PRD, system design, and code files.\n",
            "3 M ETAGPT: A M ETA-PROGRAMMING FRAMEWORK\n",
            "MetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 pro-\n",
            "vides an explanation of role specialization, workflow and structured communication in this frame-\n",
            "work, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2\n",
            "presents a communication protocol that enhances role communication efficiency. We also imple-\n",
            "ment structured communication interfaces and an effective publish-subscribe mechanism. These\n",
            "methods enable agents to obtain directional information from other roles and public information\n",
            "from the environment. Finally, we introduce executable feedback—a self-correction mechanism for\n",
            "further enhancing code generation quality during run-time in Sec. 3.3.\n",
            "3.1 A GENTS IN STANDARD OPERATING PROCEDURES\n",
            "Specialization of Roles Unambiguous role specialization enables the breakdown of complex work\n",
            "into smaller and more specific tasks. Solving complex tasks or problems often requires the collab-\n",
            "oration of agents with diverse skills and expertise, each contributing specialized outputs tailored to\n",
            "specific issues.\n",
            "In a software company, a Product Manager typically conducts business-oriented analysis and derives\n",
            "insights, while a software engineer is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design, the information is\n",
            "directed towards the Project Manager for task distribution. Engineers proceed to execute the des-\n",
            "ignated classes and functions as outlined (detailed in Figure 2). In the following stage, the QA\n",
            "Engineer formulates test cases to enforce stringent code quality. In the final step, MetaGPT pro-\n",
            "duces a meticulously crafted software solution. We provide a detailed schematic (Figure 3) and a\n",
            "concrete instance (Appendix B) of the SOP workflow in MetaGPT.\n",
            "3.2 C OMMUNICATION PROTOCOL\n",
            "Structured Communication Interfaces Most current LLM-based multi-agent frameworks (Li\n",
            "et al., 2023; Zhuge et al., 2023; Zhang et al., 2023; Park et al., 2023) utilize unconstrained natural\n",
            "language as a communication interface.\n",
            "However, despite the versatility of natural language, a question arises: does pure natural language\n",
            "communication suffice for solving complex tasks? For example, in the telephone game (or Chinese\n",
            "5\n",
            "\n",
            "page_label: 6\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "whispers)2, after several rounds of communication, the original information may be quite distorted.\n",
            "Inspired by human social structures, we propose using structured communication to formulate the\n",
            "communication of agents. We establish a schema and format for each role and request that individ-\n",
            "uals provide the necessary outputs based on their specific role and context.\n",
            "As shown in Figure 3, the Architect agent generates two outputs: the system interface design and a\n",
            "sequence flow diagram. These contain system module design and interaction sequences, which serve\n",
            "as important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT\n",
            "communicate through documents and diagrams (structured outputs) rather than dialogue. These\n",
            "documents contain all necessary information, preventing irrelevant or missing content.\n",
            "Publish-Subscribe Mechanism Sharing information is critical in collaboration. For instance,\n",
            "Architects and Engineers often need to reference PRDs. However, communicating this information\n",
            "each time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023;\n",
            "Zhang et al., 2023), can complicate the communication topology, resulting in inefficiencies.\n",
            "To address this challenge, a viable approach is to store information in a global message pool . As\n",
            "shown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange\n",
            "messages directly. These agents not only publish their structured messages in the pool but also access\n",
            "messages from other entities transparently. Any agent can directly retrieve required information\n",
            "from the shared pool, eliminating the need to inquire about other agents and await their responses.\n",
            "This enhances communication efficiency.\n",
            "Sharing all information with every agent can lead to information overload. During task execution,\n",
            "an agent typically prefers to receive only task-related information and avoid distractions through\n",
            "irrelevant details. Effective management and dissemination of this information play a crucial role.\n",
            "We offer a simple and effective solution- subscription mechanism (in Figure 2 (left)). Instead of\n",
            "relying on dialogue, agents utilize role-specific interests to extract relevant information. They can\n",
            "select information to follow based on their role profiles. In practical implementations, an agent\n",
            "activates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3,\n",
            "the Architect mainly focuses on PRDs provided by the Product Manager, while documents from\n",
            "roles such as the QA Engineer might be of lesser concern.\n",
            "3.3 I TERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK\n",
            "In daily programming tasks, the processes of debugging and optimization play important roles.\n",
            "However, existing methods often lack a self-correction mechanism, which leads to unsuccessful code\n",
            "generation. Previous work introduced non-executable code review and self-reflection (Zhao et al.,\n",
            "2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in\n",
            "ensuring code executability and runtime correctness.\n",
            "Our first MetaGPT implementations overlooked certain errors during the review process, due to\n",
            "LLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we\n",
            "introduce an executable feedback mechanism to improve the code iteratively. More specifically, as\n",
            "shown in Figure 2, the Engineer is asked to write code based on the original product requirements\n",
            "and design.\n",
            "This enables the Engineer to continuously improve code using its own historical execution and\n",
            "debugging memory. To obtain additional information, the Engineer writes and executes the corre-\n",
            "sponding unit test cases, and subsequently receives the test results. If satisfactory, additional devel-\n",
            "opment tasks are initiated. Otherwise the Engineer debugs the code before resuming programming.\n",
            "This iterative testing process continues until the test is passed or a maximum of 3 retries is reached.\n",
            "4 E XPERIMENTS\n",
            "4.1 E XPERIMENTAL SETTING\n",
            "Datasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021), and a self-generated, more challenging software development benchmark named Soft-\n",
            "2https://en.wikipedia.org/wiki/Chinese whispers\n",
            "6\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "wareDev: (1) HumanEval includes 164 handwritten programming tasks. These tasks encompass\n",
            "function specifications, descriptions, reference codes, and tests. (2) MBPP consists of 427 Python\n",
            "tasks. These tasks cover core concepts and standard library features and include descriptions, ref-\n",
            "erence codes, and automated tests. (3) Our SoftwareDev dataset is a collection of 70 representa-\n",
            "tive examples of software development tasks, each with its own task prompt (see Table 8). These\n",
            "tasks have diverse scopes (See Figure 5), such as mini-games, image processing algorithms, data\n",
            "visualization. They offer a robust testbed for authentic development tasks. Contrary to previous\n",
            "datasets (Chen et al., 2021a; Austin et al., 2021), SoftwareDev focuses on the engineering aspects.\n",
            "In the comparisons, we randomly select seven representative tasks for evaluation.\n",
            "Evaluation Metrics For HuamnEval and MBPP, we follow the unbiased version of Pass @ kas\n",
            "presented by (Chen et al., 2021a; Dong et al., 2023), to evaluate the functional accuracy of the top-k\n",
            "generated codes: Pass @ k=EProblems\u0014\n",
            "1−(n−c\n",
            "k)\n",
            "(n\n",
            "k)\u0015\n",
            ".\n",
            "For SoftwareDev, we prioritize practical use and evaluate performance through human evaluations\n",
            "(A, E) or statistical analysis (B, C, D): (A)Executability: this metric rates code from 1 (failure/non-\n",
            "functional) to 4 (flawless). ‘1’ is for non-functional, ‘2’ for runnable but imperfect, ‘3’ for nearly\n",
            "perfect, and ‘4’ for flawless code. (B)Cost: the cost evaluations here include the (1) running time,\n",
            "(2) token usage, and (3) expenses. (C)Code Statistics: this includes (1) code files, (2) lines of code\n",
            "per file, and (3) total code lines. (D)Productivity: basically, it is defined as the number of token\n",
            "usage divided by the number of lines of code, which refers to the consumption of tokens per code\n",
            "line. (E)Human Revision Cost: refers to times of manual code corrections, which tackle problems\n",
            "like package import errors, incorrect class names, or incomplete reference paths. Typically, each\n",
            "correction involves up to 3 lines of code.\n",
            "Baselines We compare our method with recent domain-specific LLMs in the code generation field,\n",
            "including AlphaCode (Li et al., 2022), Incoder (Fried et al., 2022), CodeGeeX (Zheng et al., 2023),\n",
            "CodeGen (Nijkamp et al., 2023), CodeX (Chen et al., 2021a), and CodeT (Chen et al., 2022) and\n",
            "general domain LLMs such as PaLM (Chowdhery et al., 2022), and GPT-4 (OpenAI, 2023). Several\n",
            "results of baselines (such as Incoder, CodeGeeX) are provided by Dong et al. (2023). In HumanEval\n",
            "and MBPP, we slightly modified the prompts to align with response format requirements. These\n",
            "modifications aim to address format-specific issues (i.e., Python problems). With the SoftwareDev\n",
            "benchmark, we provide a comprehensive comparison between MetaGPT, AutoGPT (Torantulino\n",
            "et al., 2023), LangChain (Chase, 2022) with Python Read-Eval-Print Loop (REPL) tool3, Agent-\n",
            "Verse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "4.2 M AINRESULT\n",
            "AlphaCode(1.1B)\n",
            "Incoder (6.7B)\n",
            "CodeGeeX (13B)17.1\n",
            "—15.2 17.6 18.926.9\n",
            "CodeGeeX-Mono(16.1B)32.938.6\n",
            "GPT-467.0\n",
            "—\n",
            "MetaGPT\n",
            "(w/o Feedback)81.7 82.3Pass@1 of MBPP  and HumanEval (%)\n",
            "PaLM Coder(540B)36.047.0\n",
            "Codex (175B)47.058.1\n",
            "Codex + CodeT65.8 67.7\n",
            "HumanEval\n",
            "MBPP\n",
            "MetaGPT85.9 87.7\n",
            "Figure 4: Pass rates on the MBPP and HumanEval with a single attempt.\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks.\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks. When MetaGPT collaborates with GPT-4, it significantly im-\n",
            "proves the Pass @ kin the HumanEval benchmark compared to GPT-4. It achieves 85.9% and 87.7%\n",
            "3https://en.wikipedia.org/wiki/Read–eval–print loop\n",
            "7\n",
            "\n",
            "page_label: 8\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 5: Demo softwares developed by MetaGPT.\n",
            "in these two public benchmarks. Moreover, as shown in Table 1, MetaGPT outperforms ChatDev on\n",
            "the challenging SoftwareDev dataset in nearly all metrics. For example, considering the executabil-\n",
            "ity, MetaGPT achieves a score of 3.75, which is very close to 4 (flawless). Besides, it takes less time\n",
            "(503 seconds), clearly less than ChatDev. Considering the code statistic and the cost of human revi-\n",
            "sion, it also significantly outperforms ChatDev. Although MetaGPT requires more tokens (24,613\n",
            "or 31,255 compared to 19,292), it needs only 126.5/124.3 tokens to generate one line of code. In\n",
            "contrast, ChatDev uses 248.9 tokens. These results highlight the benefits of SOPs in collabora-\n",
            "tions between multiple agents. Additionally, we demonstrate the autonomous software generation\n",
            "capabilities of MetaGPT through visualization samples (Figure 5). For additional experiments and\n",
            "analysis, please refer to Appendix C.\n",
            "Table 1: The statistical analysis on SoftwareDev.\n",
            "Statistical Index ChatDev MetaGPT w/o Feedback MetaGPT\n",
            "(A)Executability 2.25 3.67 3.75\n",
            "(B)Cost#1: Running Times (s) 762 503 541\n",
            "(B)Cost#2: Token Usage 19,292 24,613 31,255\n",
            "(C)Code Statistic#1: Code Files 1.9 4.6 5.1\n",
            "(C)Code Statistic#2: Lines of Code per File 40.8 42.3 49.3\n",
            "(C)Code Statistic#3: Total Code Lines 77.5 194.6 251.4\n",
            "(D)Productivity 248.9 126.5 124.3\n",
            "(E)Human Revision Cost 2.5 2.25 0.83\n",
            "4.3 C APABILITIES ANALYSIS\n",
            "Compared to open-source baseline methods such as AutoGPT and autonomous agents such as\n",
            "AgentVerse and ChatDev, MetaGPT offers functions for software engineering tasks. As presented\n",
            "in Table 2, our framework encompasses a wide range of abilities to handle complex and specialized\n",
            "development tasks efficiently. Incorporating SOPs (e.g., role-play expertise, structured communi-\n",
            "cation, streamlined workflow) can significantly improve code generation. Other baseline methods\n",
            "8\n",
            "\n",
            "page_label: 9\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 2: Comparison of capabilities for MetaGPT and other approaches. ‘!’ indicates the\n",
            "presence of a specific feature in the corresponding framework, ‘ %’ its absence.\n",
            "Framework Capabiliy AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "PRD generation % % % % !\n",
            "Tenical design genenration % % % % !\n",
            "API interface generation % % % % !\n",
            "Code generation ! ! ! ! !\n",
            "Precompilation execution % % % % !\n",
            "Role-based task management % % % ! !\n",
            "Code review % % ! ! !\n",
            "Table 3: Ablation study on roles. ‘#’ denotes ‘The number of’, ‘Product’ denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "‘Product’ denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass @1 on Hu-\n",
            "manEval and MBPP, respectively. Besides, Table 1 shows that the feedback mechanism improves\n",
            "feasibility (3.67 to 3.75) and reduces the cost of human revisions (2.25 to 0.83). These results\n",
            "illustrate how our designed feedback mechanism can produce higher-quality code. Additional quan-\n",
            "titative results of MetaGPT and MetaGPT without executable feedback are shown in Table 4 and\n",
            "Table 9.\n",
            "5 C ONCLUSION\n",
            "This work introduces MetaGPT, a novel meta-programming framework that leverages SOPs to en-\n",
            "hance the problem-solving capabilities of multi-agent systems based on Large Language Models\n",
            "(LLMs). MetaGPT models a group of agents as a simulated software company, analogous to simu-\n",
            "lated towns (Park et al., 2023) and the Minecraft Sandbox in V oyager (Wang et al., 2023a). MetaGPT\n",
            "leverages role specialization, workflow management, and efficient sharing mechanisms such as mes-\n",
            "sage pools and subscriptions, rendering it a flexible and portable platform for autonomous agents\n",
            "and multi-agent frameworks. It uses an executable feedback mechanism to enhance code generation\n",
            "quality during runtime. In extensive experiments, MetaGPT achieves state-of-the-art performance\n",
            "on multiple benchmarks. The successful integration of human-like SOPs inspires future research\n",
            "on human-inspired techniques for artificial multi-agent systems. We also view our work as an early\n",
            "attempt to regulate LLM-based multi-agent frameworks. See also the outlook (Appendix A) .\n",
            "9\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Acknowledgement\n",
            "We thank Sarah Salhi, the Executive Secretary of KAUST AI Initiative, and Yuhui Wang, Postdoc-\n",
            "toral Fellow at the KAUST AI Initiative, for helping to polish some of the text. We would like to\n",
            "express our gratitude to Wenyi Wang, a PhD student at the KAUST AI Initiative, for providing com-\n",
            "prehensive feedback on the paper and for helping to draft the outlook (Appendix A) with Mingchen.\n",
            "We also thank Zongze Xu, the vice president of DeepWisdom, for providing illustrative materials\n",
            "for AgentStore.\n",
            "Author Contributions\n",
            "Sirui Hong conducted most of the experiments and designed the executable feedback module. She\n",
            "also led the initial version of the write-up, supported by Ceyao Zhang, and also by Jinlin Wang and\n",
            "Zili Wang. Mingchen Zhuge designed the self-improvement module, discussed additional experi-\n",
            "ments, and led the current write-up. Jonathan Chen helped with the MBPP experiments, outlined\n",
            "the methods section, and contributed to the current write-up. Xiawu Zheng provided valuable guid-\n",
            "ance, reviewed and edited the paper. Yuheng Cheng contributed to the evaluation metric design and\n",
            "HumanEval experiments. Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Lingfeng Xiao helped\n",
            "with the MBPP experiments and comparisons to open-source baseline methods. Chenyu Ran cre-\n",
            "ated most of the illustrative figures. Chenglin Wu is the CEO of DeepWisdom, initiated MetaGPT,\n",
            "made the most significant code contributions to it, and advised this project. J ¨urgen Schmidhuber,\n",
            "Director of the AI Initiative at KAUST and Scientific Director of IDSIA, advised this project and\n",
            "helped with the write-up.\n",
            "REFERENCES\n",
            "Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz.\n",
            "Playing repeated games with large language models. arXiv preprint , 2023.\n",
            "Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\n",
            "Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large\n",
            "language models, 2021.\n",
            "Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew\n",
            "Goff, Jonathan Gray, Hengyuan Hu, et al. Human-level play in the game of diplomacy by com-\n",
            "bining language models with strategic reasoning. Science , 2022.\n",
            "Robert Balzer. A 15 year perspective on automatic programming. TSE, 1985.\n",
            "R.M. Belbin. Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\n",
            "Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,\n",
            "Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\n",
            "Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,\n",
            "Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-\n",
            "tios Chantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex\n",
            "Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,\n",
            "Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec\n",
            "Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob Mc-\n",
            "Grew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large\n",
            "language models trained on code, 2021a.\n",
            "10\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan,\n",
            "Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facili-\n",
            "tating multi-agent collaboration and exploring emergent behaviors in agents, 2023.\n",
            "Xinyun Chen, Chang Liu, and Dawn Song. Execution-guided neural program synthesis. In ICLR ,\n",
            "2018.\n",
            "Xinyun Chen, Dawn Song, and Yuandong Tian. Latent execution for neural program synthesis\n",
            "beyond domain-specific languages. NeurIPS , 2021b.\n",
            "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\n",
            "Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\n",
            "Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\n",
            "Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\n",
            "Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\n",
            "skaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\n",
            "Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret\n",
            "Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,\n",
            "Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\n",
            "Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\n",
            "nan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas\n",
            "Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,\n",
            "2022.\n",
            "T. DeMarco and T.R. Lister. Peopleware: Productive Projects and Teams . Addison-Wesley, 2013.\n",
            "URLhttps://books.google.co.uk/books?id=DVlsAQAAQBAJ .\n",
            "Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. Self-collaboration code generation via chatgpt. arXiv\n",
            "preprint , 2023.\n",
            "Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving\n",
            "factuality and reasoning in language models through multiagent debate, 2023.\n",
            "Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\n",
            "Sch¨utze, and Yoav Goldberg. Measuring and improving consistency in pretrained language mod-\n",
            "els.TACL , 2021.\n",
            "Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing\n",
            "Qin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained model for programming and natural\n",
            "languages. arXiv preprint , 2020.\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, and Liqiang Nie. Chatllm network:\n",
            "More brains, more intelligence. arXiv preprint , 2023.\n",
            "S. Hochreiter, A. S. Younger, and P. R. Conwell. Learning to learn using gradient descent. In Lecture\n",
            "Notes on Comp. Sci. 2130, Proc. Intl. Conf. on Artificial Neural Networks (ICANN-2001) , pp. 87–\n",
            "94. Springer: Berlin, Heidelberg, 2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "Heidelberg, 2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi Yang, and\n",
            "Soroush V osoughi. Training socially aligned language models in simulated human society. arXiv\n",
            "preprint , 2023.\n",
            "Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing\n",
            "Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with\n",
            "evol-instruct. arXiv preprint , 2023.\n",
            "Potsawee Manakul, Adian Liusie, and Mark JF Gales. Selfcheckgpt: Zero-resource black-box hal-\n",
            "lucination detection for generative large language models. arXiv preprint , 2023.\n",
            "Agile Manifesto. Manifesto for agile software development . Snowbird, UT, 2001.\n",
            "John McCarthy. History of lisp. In History of programming languages . 1978.\n",
            "Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-tau Yih, Sida Wang, and Xi Victoria\n",
            "Lin. Lever: Learning to verify language-to-code generation with execution. In ICML , 2023.\n",
            "Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese,\n",
            "and Caiming Xiong. Codegen: An open large language model for code with multi-turn program\n",
            "synthesis, 2023.\n",
            "OpenAI. Gpt-4 technical report, 2023.\n",
            "Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and\n",
            "Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint ,\n",
            "2023.\n",
            "Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and\n",
            "Maosong Sun. Communicative agents for software development, 2023.\n",
            "Baptiste Rozi `ere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi\n",
            "Adi, Jingyu Liu, Tal Remez, J ´er´emy Rapin, et al. Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements.\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements. Technical Report IDSIA-19-03, arXiv:cs.LO/0309048 v3, IDSIA,\n",
            "Manno-Lugano, Switzerland, December 2003.\n",
            "J. Schmidhuber. G ¨odel machines: Fully self-referential optimal universal self-improvers. In B. Go-\n",
            "ertzel and C. Pennachin (eds.), Artificial General Intelligence , pp. 199–226. Springer Verlag,\n",
            "2006. Variant available as arXiv:cs.LO/0309048.\n",
            "12\n",
            "\n",
            "page_label: 13\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "J. Schmidhuber. Ultimate cognition `a laG¨odel. Cognitive Computation , 1(2):177–193, 2009.\n",
            "J¨urgen Schmidhuber. Evolutionary principles in self-referential learning, or on learning how to\n",
            "learn: the meta-meta-... hook . PhD thesis, 1987.\n",
            "J¨urgen Schmidhuber. A ‘self-referential’weight matrix. In ICANN’93: Proceedings of the Interna-\n",
            "tional Conference on Artificial Neural Networks Amsterdam, The Netherlands 13–16 September\n",
            "1993 3 , 1993b.\n",
            "J¨urgen Schmidhuber. On learning to think: Algorithmic information theory for novel combinations\n",
            "of reinforcement learning controllers and recurrent neural world models. arXiv preprint , 2015.\n",
            "J¨urgen Schmidhuber, Jieyu Zhao, and Nicol N Schraudolph. Reinforcement learning with self-\n",
            "modifying policies. In Learning to learn . 1998.\n",
            "Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic\n",
            "memory and self-reflection. arXiv preprint , 2023.\n",
            "Marta Skreta, Naruki Yoshikawa, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen,\n",
            "Kourosh Darvish, Al ´an Aspuru-Guzik, Florian Shkurti, and Animesh Garg. Errors are useful\n",
            "prompts: Instruction guided task programming with verifier-assisted iterative prompting. arXiv\n",
            "preprint , 2023.\n",
            "Elliot Soloway. Learning to program =learning to construct mechanisms and explanations. Com-\n",
            "munications of the ACM , 1986.\n",
            "Yashar Talebirad and Amirhossein Nadiri. Multi-agent collaboration: Harnessing the power of\n",
            "intelligent llm agents, 2023.\n",
            "Torantulino et al. Auto-gpt. https://github.com/Significant-Gravitas/\n",
            "Auto-GPT , 2023.\n",
            "R. J. Waldinger and R. C. T. Lee. PROW: a step toward automatic program writing. In D. E. Walker\n",
            "and L. M. Norton (eds.), Proceedings of the 1st International Joint Conference on Artificial Intel-\n",
            "ligence (IJCAI) , 1969.\n",
            "Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan,\n",
            "and Anima Anandkumar. V oyager: An open-ended embodied agent with large language models.\n",
            "arXiv preprint , 2023a.\n",
            "Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\n",
            "Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\n",
            "arXiv preprint , 2023b.\n",
            "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\n",
            "ery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.\n",
            "arXiv preprint , 2022.\n",
            "Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. Unleashing\n",
            "cognitive synergy in large language models: A task-solving agent through multi-persona self-\n",
            "collaboration. arXiv preprint , 2023c.\n",
            "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\n",
            "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS ,\n",
            "2022.\n",
            "Michael Wooldridge and Nicholas R. Jennings. Pitfalls of agent-oriented development. In Pro-\n",
            "ceedings of the Second International Conference on Autonomous Agents , 1998. URL https:\n",
            "//doi.org/10.1145/280765.280867 .\n",
            "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\n",
            "React: Synergizing reasoning and acting in language models. arXiv preprint , 2022.\n",
            "Eric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. Self-taught optimizer (stop):\n",
            "Recursively self-improving code generation. arXiv preprint , 2023.\n",
            "13\n",
            "\n",
            "page_label: 14\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tian-\n",
            "min Shu, and Chuang Gan. Building cooperative embodied agents modularly with large language\n",
            "models. arXiv preprint , 2023.\n",
            "Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, and Stefan Wermter. Chat\n",
            "with the environment: Interactive multimodal perception using large language models. arXiv\n",
            "preprint , 2023.\n",
            "Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen,\n",
            "Andi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang. Codegeex: A pre-trained model for\n",
            "code generation with multilingual evaluations on humaneval-x, 2023.\n",
            "Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng,\n",
            "Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for building\n",
            "autonomous agents. arXiv preprint , 2023.\n",
            "Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, R ´obert Csord ´as, Anand\n",
            "Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki\n",
            "Irie, et al. Mindstorms in natural language-based societies of mind. arXiv preprint , 2023.\n",
            "14\n",
            "\n",
            "page_label: 15\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "A O UTLOOK\n",
            "A.1 S ELF-IMPROVEMENT MECHANISMS\n",
            "One limitation of the MetaGPT version in the main text of this paper is that each software project is\n",
            "executed independently. However, through active teamwork, a software development team should\n",
            "learn from the experience gained by developing each project, thus becoming more compatible and\n",
            "successful over time.\n",
            "This is somewhat related to the idea of recursive self-improvement, first informally proposed in\n",
            "1965 (Good, 1965), with first concrete implementations since 1987 (Schmidhuber, 1987; 1993b;\n",
            "Schmidhuber et al., 1998), culminating in the concept of mathematically optimal self-referential\n",
            "self-improvers (Schmidhuber, 2003; 2009). Generally speaking, a system should learn from experi-\n",
            "ence in the real world, and meta-learn better learning algorithms from experiences of learning, and\n",
            "meta-meta-learn better meta-learning algorithms from experiences of meta-learning, etc., without\n",
            "any limitations except those of computability and physics.\n",
            "More recent, somewhat related work leverages the reasoning ability of Large Language Models\n",
            "(LLMs) and recursively improves prompts of LLMs, to improve performance on certain downstream\n",
            "tasks (Fernando et al., 2023; Zelikman et al., 2023), analogous to the adaptive prompt engineer of\n",
            "2015 (Schmidhuber, 2015) where one neural network learns to generate sequence of queries or\n",
            "prompts for another pre-trained neural network whose answers may help the first network to learn\n",
            "new tasks more quickly.\n",
            "In our present work, we also explore a self-referential mechanism that recursively modifies the con-\n",
            "straint prompts of agents based on information they observe during software development. Our\n",
            "initial implementation works as follows. Prior to each project, every agent in the software company\n",
            "reviews previous feedback and makes necessary adjustments to their constraint prompts. This en-\n",
            "ables them to continuously learn from past project experiences and enhance the overall multi-agent\n",
            "system by improving each individual in the company. We first establish a handover feedback action\n",
            "for each agent. This action is responsible for critically summarizing the information received dur-\n",
            "ing the development of previous projects and integrating this information in an updated constraint\n",
            "prompt. The summarized information is stored in long-term memory such that it can be inherited\n",
            "by future constraint prompt updates. When initiating a new project, each agent starts with a react\n",
            "action. Each agent evaluates the received feedback and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "agent evaluates the received feedback and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically, AgentStore allows users to subscribe to agents according to their demands\n",
            "4http://beta.deepwisdom.ai\n",
            "15\n",
            "\n",
            "page_label: 16\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "and pay according to their usage. Moreover, users can purchase additional capabilities to expand the\n",
            "plug-and-play functions of their existing agents. This allows users to gradually upgrade their agents.\n",
            "Within the MetaGPT framework, AgentStore can support the collaboration of various agents. Users\n",
            "can collect several agents together to carry out more complex tasks or projects, and all the agents\n",
            "share and comply with development and communication protocols defined in MetaGPT.\n",
            "Figure 6: AgentStore is a platform dedicated to serving users in the creation and development of\n",
            "agents within the MetaGPT framework. This platform provides users with an operational interface,\n",
            "allowing users to easily manage a variety of agents with different emotions, personalities, and capa-\n",
            "bilities for specific tasks.\n",
            "16\n",
            "\n",
            "page_label: 17\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "B A D EMO OF THE EXECUTION\n",
            "In this section, we outline the complete process of software development using MetaGPT. It begins\n",
            "with a user’s input command (as shown in Appendix B.1) and ends with software designed according\n",
            "to the user’s specifications.\n",
            "B.1 U SERINPUT\n",
            "Upon receiving an instruction from the user, MetaGPT collaborates with a professional development\n",
            "team to fulfill the task. Here is a demo of user input:\n",
            "User input\n",
            "1write a python3 GUI app such that you can draw an image with it\n",
            "B.2 M ETAGPT DEVELOPMENT PROCESS\n",
            "Now we provide a step-by-step explanation of the standardized output process for each agent.\n",
            "Product Manager The Product Manager generates a Product Requirement Document (PRD), as\n",
            "detailed in the specified documentation. This document encompasses goals, user stories, competitive\n",
            "analysis, requirement analysis and requirement pool. Additionally, a competitive quadrant chart is\n",
            "produced (see Figure 7). Subsequently, these documents and charts are handed over to the architect\n",
            "for system design.\n",
            "Product Requirement Document\n",
            "1## Original Requirements\n",
            "2The boss requires a Python3 GUI color meter that outputs the RGB values when it moves.\n",
            "3\n",
            "4## Product Goals\n",
            "5‘‘‘python\n",
            "6[\n",
            "7 \"Create a user-friendly GUI color meter\",\n",
            "8 \"Ensure the color meter accurately outputs RGB values\",\n",
            "9 \"Ensure the color meter updates RGB values in real-time as it moves\"\n",
            "10]\n",
            "11‘‘‘\n",
            "12\n",
            "13## User Stories\n",
            "14‘‘‘python\n",
            "15[\n",
            "16 \"As a user, I want to select any color on the screen, so that I can get its RGB values\",\n",
            "17 \"As a user, I want the RGB values to update in real-time as I move the color meter, so that I\n",
            ",→can get accurate color information\",\n",
            "18 \"As a user, I want a simple and intuitive interface, so that I can easily use the color meter\"\n",
            "19]\n",
            "20‘‘‘\n",
            "21\n",
            "22## Competitive Analysis\n",
            "23‘‘‘python\n",
            "24[\n",
            "25 \"Color Cop: A popular color picker for Windows. It’s simple and easy to use, but lacks real-\n",
            ",→time RGB value updates\",\n",
            "26 \"Just Color Picker: Offers real-time color picking and multiple color code formats. However,\n",
            ",→its interface is cluttered and not very user-friendly\",\n",
            "27 \"Instant Eyedropper: A simple color picker that lives in the system tray. It’s convenient but\n",
            ",→lacks advanced features\",\n",
            "28 \"ColorZilla: A color picker extension for browsers. It’s convenient for web design but not\n",
            ",→suitable for desktop applications\",\n",
            "29 \"ColorPic: Offers color palettes and mixer tools. It’s feature-rich but can be overwhelming\n",
            ",→for simple tasks\"\n",
            "30]\n",
            "31‘‘‘\n",
            "17\n",
            "\n",
            "page_label: 18\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1\n",
            "2## Requirement Analysis\n",
            "3The product should be a Python3 GUI application that serves as a color meter. It should allow\n",
            ",→users to select any color on the screen and display the corresponding RGB values. The RGB\n",
            ",→ values should update in real-time as the color meter moves. The interface should be\n",
            ",→simple and user-friendly.\n",
            "4\n",
            "5## Requirement Pool\n",
            "6‘‘‘python\n",
            "7[\n",
            "8 (\"Design a user-friendly GUI for the color meter\", \"P0\"),\n",
            "9 (\"Implement color selection functionality\", \"P0\"),\n",
            "10 (\"Display RGB values of the selected color\", \"P0\"),\n",
            "11 (\"Update RGB values in real-time as the color meter moves\", \"P0\"),\n",
            "12 (\"Test the application for accuracy and performance\", \"P1\")\n",
            "13]\n",
            "14‘‘‘\n",
            "15\n",
            "16## UI Design draft\n",
            "17The UI should be minimalistic and intuitive. It should primarily consist of a color meter, which\n",
            ",→could be a magnified area of the screen that the user can move around. The RGB values of\n",
            ",→the currently selected color should be prominently displayed, updating in real-time as\n",
            ",→the color meter moves. The layout should be clean and uncluttered, with a focus on\n",
            ",→functionality and ease of use.\n",
            "18\n",
            "19## Anything UNCLEAR\n",
            "20There are no unclear points.\n",
            "Figure 7: The quadrant chart for the “Drawing App” generated by the product manager agent.\n",
            "18\n",
            "\n",
            "page_label: 19\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Architect Based on the requirements in PRD, the Architect agent devises technical specifications\n",
            "including system architecture diagrams and interface definitions. Initially, the Architect defines the\n",
            "overarching technical trajectory. Subsequently, the project’s architecture, including files, classes\n",
            "(Figure 8) and the sequence flow chart (Figure 12), is designed. The Architect’s documentation is\n",
            "then given to the project manager for task allocation and execution.\n",
            "System design\n",
            "1## Implementation approach\n",
            "2We will use Python’s Tkinter library to create the GUI for the color meter. Tkinter is a standard\n",
            ",→Python interface to the Tk GUI toolkit and is included with most Python installations. It\n",
            ",→ is simple to use and powerful enough for our needs.\n",
            "3\n",
            "4The color selection functionality will be implemented using the PIL (Pillow) library, which allows\n",
            ",→ us to capture the screen’s pixel data. By moving the mouse, we can get the RGB values of\n",
            ",→ the pixel under the mouse cursor in real-time.\n",
            "5\n",
            "6The RGB values will be displayed on the GUI using Tkinter’s Label widget. We will use Python’s\n",
            ",→threading library to update the RGB values in real-time as the color meter moves.\n",
            "7\n",
            "8The application will be tested for accuracy and performance using Python’s unittest library.\n",
            "9\n",
            "10## Python package name\n",
            "11‘‘‘python\n",
            "12\"color_meter\"\n",
            "13‘‘‘\n",
            "14\n",
            "15## File list\n",
            "16‘‘‘python\n",
            "17[\n",
            "18 \"main.py\",\n",
            "19 \"color_picker.py\",\n",
            "20 \"gui.py\",\n",
            "21 \"tests.py\"\n",
            "22]\n",
            "23‘‘‘\n",
            "24\n",
            "25## Anything UNCLEAR\n",
            "26The requirement is clear to me.\n",
            "Figure 8: Data structures and interface definitions for the “Drawing App” generated by the architect\n",
            "agent.\n",
            "Project Manager The Project Manager breaks down the project into a task list. Furthermore, each\n",
            "code file is analyzed based on its intended functionality and then treated as a separate task assigned\n",
            "to Engineers.\n",
            "19\n",
            "\n",
            "page_label: 20\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 9: The program call flow for the “Drawing App” generated by the architect agent.\n",
            "Tasks\n",
            "1## Required Python third-party packages\n",
            "2\n",
            "3‘‘‘python\n",
            "4\"\"\"\n",
            "5tkinter==8.6\n",
            "6Pillow==8.3.1\n",
            "7\"\"\"\n",
            "8‘‘‘\n",
            "9\n",
            "10## Required Other language third-party packages\n",
            "11‘‘‘python\n",
            "12\"\"\"\n",
            "13No third-party packages required in other languages.\n",
            "14\"\"\"\n",
            "15‘‘‘\n",
            "16\n",
            "17## Full API spec\n",
            "18‘‘‘python\n",
            "19\"\"\"\n",
            "20No APIs are used in this project.\n",
            "21\"\"\"\n",
            "22‘‘‘\n",
            "23\n",
            "24## Logic Analysis\n",
            "25‘‘‘python\n",
            "26[\n",
            "27 (\"main.py\", \"Contains the main application loop and initializes all the other components.\"),\n",
            "28 (\"canvas.py\", \"Implements the drawing canvas, responds to mouse events, and uses the selected\n",
            ",→tool and color.\"),\n",
            "29 (\"tools.py\", \"Implements the tool selection interface.\"),\n",
            "30 (\"color_picker.py\", \"Implements the color selection interface.\"),\n",
            "31 (\"file_manager.py\", \"Implements the file saving and opening functionality.\")\n",
            "32]\n",
            "33‘‘‘\n",
            "20\n",
            "\n",
            "page_label: 21\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1## Task list\n",
            "2‘‘‘python\n",
            "3[\n",
            "4 \"main.py\",\n",
            "5 \"canvas.py\",\n",
            "6 \"tools.py\",\n",
            "7 \"color_picker.py\",\n",
            "8 \"file_manager.py\"\n",
            "9]\n",
            "10‘‘‘\n",
            "11\n",
            "12## Shared Knowledge\n",
            "13‘‘‘python\n",
            "14\"\"\"\n",
            "15The ’Tkinter’ library is used for creating the GUI of the application. It provides various widgets\n",
            ",→ like frames and canvases which are used in this project.\n",
            "16The ’Pillow’ library is used for handling image files. It is used in the ’file_manager.py’ for\n",
            ",→saving and opening image files.\n",
            "17The ’main.py’ file is the entry point of the application. It initializes all the other components\n",
            ",→and starts the application loop.\n",
            "18\"\"\"\n",
            "19‘‘‘\n",
            "20\n",
            "21## Anything UNCLEAR\n",
            "22The project requirements and implementation approach are clear. However, we need to ensure that\n",
            ",→all team members are familiar with the Tkinter and Pillow libraries. If not, they may\n",
            ",→need some time to learn these libraries before starting the development.\n",
            "21\n",
            "\n",
            "page_label: 22\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Engineer Given the provided file structure and function definitions, an Engineer agent requires\n",
            "only fundamental development skills to complete the development tasks. Due to the large number\n",
            "of files, we present only one auto-generated code file here.\n",
            "Generated code (color picker.py)\n",
            "1import tkinter as tk\n",
            "2from tkinter import colorchooser\n",
            "3class ColorPicker:\n",
            "4 def __init__(self, root: tk.Tk, color: str = ’black’):\n",
            "5 self.frame = tk.Frame(root)\n",
            "6 self.color = color\n",
            "7\n",
            "8 self.color_button = tk.Button(self.frame, text=’Color’, command=self.select_color)\n",
            "9 self.color_button.pack(fill=’x’)\n",
            "10\n",
            "11 def select_color(self):\n",
            "12 color = colorchooser.askcolor()[1]\n",
            "13 if color is not None:\n",
            "14 self.color = color\n",
            "15\n",
            "16 def pack(self, **kwargs):\n",
            "17 self.frame.pack( **kwargs)\n",
            "18\n",
            "19 def get_color(self):\n",
            "20 return self.color\n",
            "QA Engineer Upon receiving the code output from the Engineer, the QA Engineer generates unit\n",
            "test code and reviews it to identify and fix any bugs, ensuring high-quality software.\n",
            "Generated Unit tests (test.py)\n",
            "1import unittest\n",
            "2import tkinter as tk\n",
            "3# You might want to move the ColorPicker class to another file, let’s say color_picker.py\n",
            "4# from color_picker import ColorPicker\n",
            "5\n",
            "6class TestColorPicker(unittest.TestCase):\n",
            "7\n",
            "8 def setUp(self):\n",
            "9 self.root = tk.Tk()\n",
            "10 self.cp = ColorPicker(self.root)\n",
            "11\n",
            "12 def tearDown(self):\n",
            "13 # This is important to close the tk window after tests\n",
            "14 self.root.destroy()\n",
            "15\n",
            "16 def test_initial_color(self):\n",
            "17 # Test the default color during initialization\n",
            "18 self.assertEqual(self.cp.get_color(), ’black’)\n",
            "19\n",
            "20 def test_set_and_get_color(self):\n",
            "21 # Test setting a new color and retrieving it\n",
            "22 new_color = ’#ffffff’ # white color\n",
            "23 self.cp.color = new_color\n",
            "24 self.assertEqual(self.cp.get_color(), new_color)\n",
            "25\n",
            "26\n",
            "27if __name__ == ’__main__’:\n",
            "28 unittest.main()\n",
            "Output Ultimately, as shown in Figure 10, MetaGPT generates a functional application named\n",
            "“Drawing App”.\n",
            "22\n",
            "\n",
            "page_label: 23\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 10: The “Drawing App” generated by MetaGPT.\n",
            "C E XPERIMENTS\n",
            "C.1 D ETAILS OF THE SOFTWARE DEVDATASET\n",
            "The SoftwareDev dataset includes 70 diverse software development tasks. Table 8 displays the\n",
            "names and detailed prompts of 11 tasks within the dataset. Note that the first seven tasks listed are\n",
            "used in the main experiments of this paper.\n",
            "C.2 A DDITIONAL RESULTS\n",
            "Quantitative results of MetaGPT As shown in Table 4, MetaGPT achieves an average score\n",
            "of 3.9, surpassing ChatDev’s score of 2.1 Zhao et al. (2023), which is based on the Chat chain.\n",
            "Compare the scores of general intelligent algorithms, including AutoGPT Torantulino et al. (2023),\n",
            "which all score 1.0, failing to generate executable code. We observe that the generated code is often\n",
            "short, lacks comprehensive logic, and tends to fail to handle cross-file dependencies correctly.\n",
            "While models such as AutoGPT (Torantulino et al., 2023), Langchain (Chase, 2022), and Agent-\n",
            "Verse (Chen et al., 2023) display robust general problem-solving capabilities, they lack an essential\n",
            "element for developing complex systems: systematically deconstructing requirements. Conversely,\n",
            "MetaGPT simplifies the process of transforming abstract requirements into detailed class and func-\n",
            "tion designs through a specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "designs through a specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1 1 2 4\n",
            "2048 game 1 1 1 1 4\n",
            "Snake game 1 1 1 3 4\n",
            "Brick breaker game 1 1 1 1 4\n",
            "Excel data process 1 1 1 4 4\n",
            "CRUD manage 1 1 1 2 4\n",
            "Average score 1.0 1.0 1.0 2.1 3.9\n",
            "Table 5: Performance of MetaGPT on SoftwareDev using different LLMs as agent backends.\n",
            "Model Open source Time(/s) # Lines Executability Revisions\n",
            "MetaGPT (w/ GPT-3.5) % 75.18 161.6 2.8 2.4\n",
            "MetaGPT (w/ GPT-4) % 552.94 178.2 3.8 1.2\n",
            "MetaGPT (w/ Deepseek Coder 33B) \" 1186.20 120.2 1.4 2.6\n",
            "Impact of Instruction Levels (High-level v.s.Detailed Instructions) Does the variation in the\n",
            "level of initial input from humans significantly influence performance outcomes? For examples:\n",
            "1.High-level prompt : Create a brick breaker game.\n",
            "2.Detailed prompt : Creating a brick breaker game. In a brick breaker game, the player\n",
            "typically controls a paddle at the bottom of the screen to bounce a ball towards a wall of\n",
            "bricks. The goal is to break all the bricks by hitting them with the ball.\n",
            "Additional experiments were conducted to investigate this aspect: we selected 5 tasks from Soft-\n",
            "wareDev, and constructed detailed prompts for them. Here are the experimental results:\n",
            "Table 6: Impact of Instruction Levels. The executability is scored on a grading system ranging\n",
            "from ‘1’ to ‘4’. A score of ‘1’ signifies complete failure, ‘2’ denotes runnable code, ‘3’ represents\n",
            "largely expected workflow, and ‘4’ indicates a perfect match to expectations.\n",
            "Model # Word Time(/s) Token usage # Lines Executability Productivity Reversions\n",
            "High-level 13.2 552.9 28384.2 178.2 3.8 163.8 1.2\n",
            "Detailed 42.2 567.8 29657.0 257.0 4.0 118.0 1.6\n",
            "We observe that: detailed prompts lead to better software projects with lower productivity ratios\n",
            "because of clearer requirements and functions, while simple inputs can still generate good enough\n",
            "software using MetaGPT with an executability rating of 3.8, which is comparable to the detailed\n",
            "prompt scenario. (Note that, Productivity = Token usage / Total Code Lines. The lower this ratio,\n",
            "the better.)\n",
            "The performance of GPT variants in HumanEval benchmark We use the GPT-4’s 67% Hu-\n",
            "manEval score (OpenAI, 2023) as our baseline, acknowledging its acceptance in the HumanEval\n",
            "benchmark. We further extend to experiments(five times) with GPT-4 (gpt-4-0613) and GPT-3.5-\n",
            "Turbo (gpt-3.5-turbo-0613) under various conditions to assess performance. (A)We directly called\n",
            "the OpenAI API with the prompt in HumanEval. (B)We called the OpenAI API and parsed the\n",
            "code with regex in the response. (C)We added an additional system prompt, then called the OpenAI\n",
            "API. The prompt is ”You are an AI that only responds with Python code, NOT ENGLISH. You will\n",
            "24\n",
            "\n",
            "page_label: 25\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "be given a function signature and its docstring by the user. Write your full implementation (restate\n",
            "the function signature).” As shown in Table 7, GPT-4 is more sensitive to prompt, code parser, and\n",
            "post-processing results on the HumanEval data set. It is difficult for GPT-3.5-Turbo to return the\n",
            "correct completion code without prompt words.\n",
            "Table 7: Performance of GPT models on HumanEval. Experiments were conducted five times\n",
            "using gpt-4-0613 and gpt-3.5-turbo-0613 with different settings.\n",
            "Settings Model 1 2 3 4 5 Avg. Std.\n",
            "A gpt-4-0613 0.732 0.707 0.732 0.713 0.738 0.724 0.013\n",
            "A gpt-3.5-turbo-0613 0.360 0.366 0.360 0.348 0.354 0.357 0.007\n",
            "B gpt-4-0613 0.787 0.811 0.817 0.829 0.817 0.812 0.016\n",
            "B gpt-3.5-turbo-0613 0.348 0.354 0.348 0.335 0.348 0.346 0.007\n",
            "C gpt-4-0613 0.805 0.805 0.817 0.793 0.780 0.800 0.014\n",
            "C gpt-3.5-turbo-0613 0.585 0.567 0.573 0.579 0.579 0.577 0.007\n",
            "Qualitative results Figure 11 and Figure 12 illustrate the outcomes of the Architect agent’s ef-\n",
            "forts to design a complex recommender system. These figures showcase the comprehensive system\n",
            "interface design and program call flow. The latter is essential for creating a sophisticated automated\n",
            "system. It is crucial to emphasize the importance of this division of labor in developing an automated\n",
            "software framework.\n",
            "D L IMITATION AND ETHICS CONCERNS\n",
            "D.1 L IMITATION\n",
            "System side At present, our system cannot fully cater to specific scenarios, such as UI and front-\n",
            "end, as we have yet to incorporate such agents and multimodal tools. Furthermore, despite gen-\n",
            "erating the most amount of code among comparable frameworks, it remains challenging to fulfill\n",
            "real-world applications’ diverse and complex requirements.\n",
            "Human user side A key challenge for users is to interrupt the running process of each agent, or\n",
            "set the starting running point (checkpoint) for each agent.\n",
            "D.2 E THICS CONCERNS\n",
            "Unemployment and Skill Obsolescence MetaGPT enables more people to program in natural\n",
            "languages, thereby making it easier for engineers to get started. Over the years, programming\n",
            "languages have evolved from punched cards to assembly, C, Java, Python, and now natural lan-\n",
            "guage. As a result, humans have become more proficient at programming, increasing the demand\n",
            "for programming-related positions. Furthermore, programming with natural language may offer a\n",
            "significantly easier learning curve, making programming more accessible to a broader audience.\n",
            "Transparency and Accountability MetaGPT is an open-source framework that facilitates inter-\n",
            "active communication between multiple agents through natural language. Humans can initiate, ob-\n",
            "serve, and stop running with the highest level of control. It provides real-time interpretation and op-\n",
            "eration of the natural language, displayed on the screen and logs, ensuring transparency. MetaGPT\n",
            "enhances “natural language programming” capabilities, and human engineers are the users and re-\n",
            "sponsible for the outcomes.\n",
            "Privacy and Data Security MetaGPT operates locally, ensuring user data privacy and security. It\n",
            "does not collect user data. For interactions with third-party LLMs, such as those by OpenAI, users\n",
            "are encouraged to refer to the respective privacy policies (e.g., OpenAI Privacy Policy). However,\n",
            "we provide the option of open-source LLMs as backends.\n",
            "25\n",
            "\n",
            "page_label: 26\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 11: The system interface design for “recommendation engine development” is generated by\n",
            "thearchitect agent ( zoom in for a better view ).\n",
            "E M ORE DISCUSSIONS\n",
            "E.1 D EEP-SEATED CHALLENGES\n",
            "MetaGPT also alleviates or solves these challenges with its unique designs:\n",
            "Use Context Efficiently Two sub-challenges are present. First, unfolding short natural language\n",
            "descriptions accurately to eliminate ambiguity. Second, maintaining information validity in lengthy\n",
            "contexts, enables LLMs to concentrate on relevant data without distraction.\n",
            "Reduce Hallucinations Using LLMs to generate entire software programs faces code halluci-\n",
            "nation problems—-including incomplete implementation of functions, missing dependencies, and\n",
            "potential undiscovered bugs, which may be more serious. LLMs often struggle with software gen-\n",
            "eration due to vague task definitions. Focusing on granular tasks like requirement analysis and\n",
            "package selection offers guided thinking, which LLMs lack in broad task solving.\n",
            "E.2 I NFORMATION OVERLOAD\n",
            "In MetaGPT, we use a global message pool and a subscription mechanism to address “information\n",
            "overload,” which refers to the problem of receiving excessive or irrelevant information. This issue\n",
            "is dependent on specific applications. MetaGPT employs a message pool to streamline communi-\n",
            "cation, ensuring efficiency. Additionally, a subscription mechanism filters out irrelevant contexts,\n",
            "enhancing the relevance and utility of the information. This design is particularly crucial in soft-\n",
            "26\n",
            "\n",
            "page_label: 27\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 12: The program call flow for “recommendation engine development” generated by the\n",
            "architect agent ( zoom in for a better view ).\n",
            "ware design scenarios and standard operating procedures (SOPs) where effective communication is\n",
            "essential.\n",
            "27\n",
            "\n",
            "page_label: 28\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 8: Examples of SoftwareDev dataset.\n",
            "Task ID Task Prompt\n",
            "0 Snake game Create a snake game.\n",
            "1 Brick breaker game Create a brick breaker game.\n",
            "2 2048 game Create a 2048 game for the web.\n",
            "3 Flappy bird game Write p5.js code for Flappy Bird where you control a yellow bird continu-\n",
            "ously flying between a series of green pipes. The bird flaps every time you\n",
            "left click the mouse. If it falls to the ground or hits a pipe, you lose. This\n",
            "game goes on indefinitely until you lose; you get points the further you go.\n",
            "4 Tank battle game Create a tank battle game.\n",
            "5 Excel data process Write an excel data processing program based on streamlit and pandas. The\n",
            "screen first shows an excel file upload button. After the excel file is uploaded,\n",
            "use pandas to display its data content. The program is required to be concise,\n",
            "easy to maintain, and not over-designed. It uses streamlit to process web\n",
            "screen displays, and pandas is sufficient to process excel reading and display.\n",
            "Please make sure others can execute directly without introducing additional\n",
            "packages.\n",
            "6 CRUD manage Write a management program based on the crud addition, deletion, modifi-\n",
            "cation and query processing of the customer business entity. The customer\n",
            "needs to save this information: name, birthday, age, sex, and phone. The data\n",
            "is stored in client.db, and there is a judgement whether the customer table ex-\n",
            "ists. If it doesn’t, it needs to be created first. Querying is done by name; same\n",
            "for deleting. The program is required to be concise, easy to maintain, and not\n",
            "over-designed. The screen is realized through streamlit and sqlite—no need\n",
            "to introduce other additional packages.\n",
            "7 Music transcriber Develop a program to transcribe sheet music into a digital format; provid-\n",
            "ing error-free transcribed symbolized sheet music intelligence from audio\n",
            "through signal processing involving pitch and time slicing then training a\n",
            "neural net to run Onset Detected CWT transforming scalograms to chroma-\n",
            "grams decoded with Recursive Neural Network focused networks.\n",
            "8 Custom press releases Create custom press releases; develop a Python script that extracts rele-\n",
            "vant information about company news from external sources, such as social\n",
            "media; extract update interval database for recent changes. The program\n",
            "should create press releases with customizable options and export writings\n",
            "to PDFs, NYTimes API JSONs, media format styled with interlink internal\n",
            "fixed character-length metadata.\n",
            "9 Gomoku game Implement a Gomoku game using Python, incorporating an AI opponent\n",
            "with varying difficulty levels.\n",
            "10 Weather dashboard Create a Python program to develop an interactive weather dashboard.\n",
            "28\n",
            "\n",
            "page_label: 29\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 9: Additional results of pure MetaGPT w/o feedback on SoftwareDev. Averages (Avg.) of 70 tasks are calculated and 10 randomly selected tasks are\n",
            "included. ‘#’ denotes ‘The number of’, while ‘ID’ is ‘Task ID’.\n",
            "ID Code statistics Doc statistics Cost statistics Cost of revision Code executability\n",
            "#code files #lines of code #lines per code file #doc files #lines of doc #lines per doc file #prompt tokens #completion tokens time costs money costs\n",
            "0 5.00 196.00 39.20 3.00 210.00 70.00 24087.00 6157.00 582.04 $ 1.09 1. TypeError 4\n",
            "1 6.00 191.00 31.83 3.00 230.00 76.67 32517.00 6238.00 566.30 $ 1.35 1. TypeError 4\n",
            "2 3.00 198.00 66.00 3.00 235.00 78.33 21934.00 6316.00 553.11 $ 1.04 1. lack\n",
            "@app.route(’/’)3\n",
            "3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "lack\n",
            "@app.route(’/’)3\n",
            "3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method not\n",
            "implement2\n",
            "9 5.00 215.00 43.00 3.00 270.00 90.00 24799.00 5734.00 550.88 $ 1.27 1. dependency er-\n",
            "ror 2. URL 403 er-\n",
            "ror3\n",
            "10 3.00 93.00 31.00 3.00 254.00 84.67 24109.00 5363.00 438.50 $ 0.92 1. dependency er-\n",
            "ror 2. missing main\n",
            "func.4\n",
            "Avg. 4.71 191.57 42.98 3.00 240.00 80.00 26626.86 6218.00 516.71 $1.12 0.51 (only consider\n",
            "item scored 2, 3 or\n",
            "4)3.36\n",
            "29\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "MetaGPT is a new meta-programming framework that helps multiple AI agents work together like a team of humans. It does this by using \"Standardized Operating Procedures\" or SOPs, which are like guidelines for how different roles should work together. \n",
            "\n",
            "MetaGPT is especially good at creating software because it assigns roles like \"Product Manager\" and \"Software Engineer\" to different AI agents. These agents communicate with each other, just like in a real company, to make sure the software is well-designed and works properly.  MetaGPT has been tested on challenging coding tasks and has achieved impressive results, even surpassing other similar systems.\n",
            "\n",
            "This document introduces MetaGPT, an innovative framework designed for autonomous software development. MetaGPT leverages the strengths of large language models (LLMs) and incorporates a structured \"Software  Development  Operations\" (SOP) approach. This approach involves assigning distinct roles to different agents, such as Product Manager, Architect, and Engineer, enabling them to collaborate effectively and produce high-quality code. \n",
            "\n",
            "The document highlights MetaGPT's superior performance over existing code generation methods, especially in tackling complex software development tasks. This superior performance is attributed to its unique features, including a structured communication protocol, a publish-subscribe mechanism for efficient information sharing, and an iterative programming approach that incorporates executable feedback for continuous improvement.\n",
            "\n",
            "This document presents MetaGPT, a new meta-programming framework that uses \"Standard Operating Procedures\" (SOPs) to improve the problem-solving abilities of multi-agent systems powered by Large Language Models (LLMs). \n",
            "\n",
            "MetaGPT simulates a software company with different roles like engineers and product managers, each represented by an LLM agent. These agents work together, similar to a real company, to complete tasks. \n",
            "\n",
            "The document highlights that adding more specialized roles, beyond just engineers, leads to better results, even though it might slightly increase costs. This emphasizes the importance of role specialization in this framework. \n",
            "\n",
            "Furthermore, the document explains how MetaGPT utilizes an \"executable feedback mechanism\" to enhance the quality of code generated during its operation. This mechanism contributes to producing more reliable and efficient code. \n",
            "\n",
            "Through various experiments, MetaGPT demonstrates state-of-the-art performance on different benchmarks. The success of integrating human-like SOPs in MetaGPT opens up new research avenues in developing artificial multi-agent systems.\n",
            "\n",
            "This document describes a system called MetaGPT that uses multiple AI agents to simulate the process of software development.  The authors argue that this approach is more effective than using a single agent, as it allows for specialization and collaboration between agents. The document also discusses the limitations of the current MetaGPT system and outlines potential areas for future improvement. One area of focus is the development of self-improvement mechanisms that would allow the system to learn from its experiences and become more effective over time. Another area of interest is the creation of multi-agent economies, where agents can interact and collaborate in a more flexible and dynamic way.\n",
            "\n",
            "MetaGPT is a novel framework that uses large language models (LLMs) to build different \"agents\" that simulate a software development team. Each agent, such as a product manager, architect, and engineer, has a specific role and communicates with other agents to complete a software development task. This approach enables the development of complex software applications by breaking down the process into smaller, more manageable tasks. Experiments demonstrate that MetaGPT outperforms other methods, including those based on chat or general-purpose agents, in terms of generating executable and functional code.\n",
            "\n",
            "MetaGPT is a framework that uses multiple agents to complete tasks such as software development.  Different language models can be used with MetaGPT, but GPT-4 produces the best results.  MetaGPT outperforms other models in terms of code executability. Clearer instructions given to MetaGPT result in better software projects. While MetaGPT is a promising framework, it faces challenges such as the inability to fully cater to specific scenarios like UI and front-end development. There are also ethical concerns, such as the potential for unemployment and skill obsolescence.\n",
            "\n",
            "This document summarizes the average time taken to complete a task, along with the associated costs and errors encountered.\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "A new framework called MetaGPT uses multiple AI agents, each assigned specific roles like those in a software development team, to collaboratively solve problems, particularly in software development. This approach, inspired by human organizational structures and workflows, has shown promising results, surpassing existing methods in code generation and problem-solving.  The framework's effectiveness is attributed to its unique features, including specialized roles, efficient communication protocols, and an iterative feedback mechanism. While promising, the framework faces challenges such as limitations in handling specific development scenarios and potential ethical implications. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"What is the summary of the document?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IhIxCf1ys3h",
        "outputId": "97546c2a-b94b-4ade-c0d9-9256b0f64fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34\n"
          ]
        }
      ],
      "source": [
        "print(len(response.source_nodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yclq6ET3y8Vj",
        "outputId": "a3b57de0-f61c-4e4a-d7c9-747c6617eb6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_message user: Some choices are given below. It is provided in a numbered list (1 to 2), where each item in the list corresponds to a summary.\n",
            "---------------------\n",
            "(1) Useful for summarization questions related to MetaGPT\n",
            "\n",
            "(2) Useful for retrieving specific context from the MetaGPT paper.\n",
            "---------------------\n",
            "Using only the choices above and not prior knowledge, return the choice that is most relevant to the question: 'How do agents share information with other agents?'\n",
            "\n",
            "\n",
            "The output should be ONLY JSON formatted as a JSON instance.\n",
            "\n",
            "Here is an example:\n",
            "[\n",
            "    {{\n",
            "        choice: 1,\n",
            "        reason: \"<insert reason for choice>\"\n",
            "    }},\n",
            "    ...\n",
            "]\n",
            "\n",
            "\u001b[1;3;38;5;200mSelecting query engine 1: We need to retrieve specific context from the MetaGPT paper to answer how agents share information. This is not a summarization question..\n",
            "\u001b[0mmerged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information is below.\n",
            "---------------------\n",
            "page_label: 6\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "whispers)2, after several rounds of communication, the original information may be quite distorted.\n",
            "Inspired by human social structures, we propose using structured communication to formulate the\n",
            "communication of agents. We establish a schema and format for each role and request that individ-\n",
            "uals provide the necessary outputs based on their specific role and context.\n",
            "As shown in Figure 3, the Architect agent generates two outputs: the system interface design and a\n",
            "sequence flow diagram. These contain system module design and interaction sequences, which serve\n",
            "as important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT\n",
            "communicate through documents and diagrams (structured outputs) rather than dialogue. These\n",
            "documents contain all necessary information, preventing irrelevant or missing content.\n",
            "Publish-Subscribe Mechanism Sharing information is critical in collaboration. For instance,\n",
            "Architects and Engineers often need to reference PRDs. However, communicating this information\n",
            "each time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023;\n",
            "Zhang et al., 2023), can complicate the communication topology, resulting in inefficiencies.\n",
            "To address this challenge, a viable approach is to store information in a global message pool . As\n",
            "shown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange\n",
            "messages directly. These agents not only publish their structured messages in the pool but also access\n",
            "messages from other entities transparently. Any agent can directly retrieve required information\n",
            "from the shared pool, eliminating the need to inquire about other agents and await their responses.\n",
            "This enhances communication efficiency.\n",
            "Sharing all information with every agent can lead to information overload. During task execution,\n",
            "an agent typically prefers to receive only task-related information and avoid distractions through\n",
            "irrelevant details. Effective management and dissemination of this information play a crucial role.\n",
            "We offer a simple and effective solution- subscription mechanism (in Figure 2 (left)). Instead of\n",
            "relying on dialogue, agents utilize role-specific interests to extract relevant information. They can\n",
            "select information to follow based on their role profiles. In practical implementations, an agent\n",
            "activates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3,\n",
            "the Architect mainly focuses on PRDs provided by the Product Manager, while documents from\n",
            "roles such as the QA Engineer might be of lesser concern.\n",
            "3.3 I TERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK\n",
            "In daily programming tasks, the processes of debugging and optimization play important roles.\n",
            "However, existing methods often lack a self-correction mechanism, which leads to unsuccessful code\n",
            "generation. Previous work introduced non-executable code review and self-reflection (Zhao et al.,\n",
            "2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in\n",
            "ensuring code executability and runtime correctness.\n",
            "Our first MetaGPT implementations overlooked certain errors during the review process, due to\n",
            "LLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we\n",
            "introduce an executable feedback mechanism to improve the code iteratively. More specifically, as\n",
            "shown in Figure 2, the Engineer is asked to write code based on the original product requirements\n",
            "and design.\n",
            "This enables the Engineer to continuously improve code using its own historical execution and\n",
            "debugging memory. To obtain additional information, the Engineer writes and executes the corre-\n",
            "sponding unit test cases, and subsequently receives the test results. If satisfactory, additional devel-\n",
            "opment tasks are initiated. Otherwise the Engineer debugs the code before resuming programming.\n",
            "This iterative testing process continues until the test is passed or a maximum of 3 retries is reached.\n",
            "4 E XPERIMENTS\n",
            "4.1 E XPERIMENTAL SETTING\n",
            "Datasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021), and a self-generated, more challenging software development benchmark named Soft-\n",
            "2https://en.wikipedia.org/wiki/Chinese whispers\n",
            "6\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: How do agents share information with other agents?\n",
            "Answer: \n",
            "Agents can share information through a global message pool.  This allows agents to both publish their own messages and read messages from other agents. To avoid information overload, agents can subscribe to specific information based on their roles. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"How do agents share information with other agents?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSJjmym8_18X"
      },
      "source": [
        "### Task 2: Tool calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeFeWlPVAIhI"
      },
      "source": [
        "Auto-retrieval tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UkmH0eGxAfjN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information is below.\n",
            "---------------------\n",
            "page_label: 2\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
            "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
            "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
            "(e.g., Product Manager, Architect, Engineer, etc.).\n",
            "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
            "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
            "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
            "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
            "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
            "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
            "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
            "lunch?” – Bob (Architect).\n",
            "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
            "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
            "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
            "2006; Finn et al., 2017).\n",
            "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
            "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
            "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
            "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
            "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
            "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
            "ing how agent-based techniques can enhance meta-programming.\n",
            "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
            "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
            "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
            "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
            "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
            "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
            "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
            "We summarize our contributions as follows:\n",
            "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
            "2\n",
            "\n",
            "page_label: 2\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
            "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
            "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
            "(e.g., Product Manager, Architect, Engineer, etc.).\n",
            "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
            "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
            "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
            "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
            "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
            "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
            "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
            "lunch?” – Bob (Architect).\n",
            "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
            "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
            "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
            "2006; Finn et al., 2017).\n",
            "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
            "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
            "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
            "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
            "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
            "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
            "ing how agent-based techniques can enhance meta-programming.\n",
            "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
            "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
            "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
            "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
            "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
            "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
            "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
            "We summarize our contributions as follows:\n",
            "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
            "2\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: What are some high-level results of MetaGPT?\n",
            "Answer: \n"
          ]
        }
      ],
      "source": [
        "query_engine = vector_index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    filters=MetadataFilters.from_dicts(\n",
        "        [\n",
        "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"What are some high-level results of MetaGPT?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful for summarization questions related to MetaGPT\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifpf_hXIAjUo",
        "outputId": "c29cdcc1-2312-48ab-f37a-f9e8708fb3b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This system achieves state-of-the-art results in code generation, with 85.9% and 87.7% in Pass@1. Additionally, it has a 100% task completion rate. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0gvnfkiAjfK",
        "outputId": "af804ea0-34cc-44a9-9b66-e47cc5e6aa78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}\n",
            "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-05', 'last_modified_date': '2024-06-05'}\n"
          ]
        }
      ],
      "source": [
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbUk9hrSAqPn"
      },
      "source": [
        "Define auto-retrieval tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Rt59-OULAjjU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def vector_query(\n",
        "    query: str,\n",
        "    page_numbers: List[str]\n",
        ") -> str:\n",
        "    \"\"\"Perform a vector search over an index.\n",
        "\n",
        "    query (str): the string query to be embedded.\n",
        "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
        "        over all pages. Otherwise, filter by the set of specified pages.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    metadata_dicts = [\n",
        "        {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
        "    ]\n",
        "\n",
        "    query_engine = vector_index.as_query_engine(\n",
        "        similarity_top_k=2,\n",
        "        filters=MetadataFilters.from_dicts(\n",
        "            metadata_dicts,\n",
        "            condition=FilterCondition.OR\n",
        "        )\n",
        "    )\n",
        "    response = query_engine.query(query)\n",
        "    return response\n",
        "\n",
        "\n",
        "vector_query_tool = FunctionTool.from_defaults(\n",
        "    \n",
        "    fn=vector_query,\n",
        "    #name='vector_query'\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summary_query(\n",
        "    query: str,\n",
        ") -> str:\n",
        "    \"\"\"Perform a summary of document\n",
        "    query (str): the string query to be embedded.\n",
        "    \"\"\"\n",
        "    summary_engine = summary_index.as_query_engine(\n",
        "        response_mode=\"tree_summarize\",\n",
        "        use_async=True,\n",
        "    )\n",
        "\n",
        "    response = summary_engine.query(query)\n",
        "    return response\n",
        "\n",
        "\n",
        "summary_tool = FunctionTool.from_defaults(\n",
        "    \n",
        "    fn=summary_query,\n",
        "    #name='summary_query'\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nJWfsCKBLI_",
        "outputId": "5430b0e4-b3a9-4e53-b128-f71d95fa5221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_message user: What are the high-level results of MetaGPT as described on page 2?\n",
            "Function Calling, No Text Content\n",
            "=== Calling Function ===\n",
            "Calling function: vector_query with args: {\"query\": \"What are the high-level results of MetaGPT as described on page 2?\", \"page_numbers\": [\"2\"]}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information is below.\n",
            "---------------------\n",
            "page_label: 2\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
            "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
            "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
            "(e.g., Product Manager, Architect, Engineer, etc.).\n",
            "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
            "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
            "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
            "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
            "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
            "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
            "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
            "lunch?” – Bob (Architect).\n",
            "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
            "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
            "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
            "2006; Finn et al., 2017).\n",
            "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
            "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
            "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
            "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
            "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
            "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
            "ing how agent-based techniques can enhance meta-programming.\n",
            "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
            "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
            "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
            "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
            "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
            "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
            "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
            "We summarize our contributions as follows:\n",
            "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
            "2\n",
            "\n",
            "page_label: 2\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
            "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
            "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
            "(e.g., Product Manager, Architect, Engineer, etc.).\n",
            "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
            "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
            "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
            "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
            "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
            "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
            "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
            "lunch?” – Bob (Architect).\n",
            "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
            "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
            "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
            "2006; Finn et al., 2017).\n",
            "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
            "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
            "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
            "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
            "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
            "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
            "ing how agent-based techniques can enhance meta-programming.\n",
            "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
            "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
            "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
            "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
            "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
            "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
            "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
            "We summarize our contributions as follows:\n",
            "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
            "2\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: What are the high-level results of MetaGPT as described on page 2?\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "This system achieves state-of-the-art results of 85.9% and 87.7% on code generation benchmarks. Additionally, it achieves a 100% task completion rate. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.vertex import Vertex\n",
        "vertex_gemini = Vertex(model=\"gemini-1.5-flash\")\n",
        "response = vertex_gemini.predict_and_call(\n",
        "    [vector_query_tool],\n",
        "    \"What are the high-level results of MetaGPT as described on page 2?\",\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_message user: What is the summary of the document?\n",
            "Function Calling, No Text Content\n",
            "=== Calling Function ===\n",
            "Calling function: summary_query with args: {\"query\": \"What is the summary of the document?\"}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "page_label: 1\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "METAGPT: M ETA PROGRAMMING FOR A\n",
            "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
            "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
            "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
            "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
            "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
            "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
            "5Nanjing University,6University of Pennsylvania,\n",
            "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
            "ABSTRACT\n",
            "Remarkable progress has been made on automated problem solving through so-\n",
            "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
            "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
            "complex tasks, however, are complicated through logic inconsistencies due to\n",
            "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
            "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
            "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
            "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
            "streamlined workflows, thus allowing agents with human-like domain expertise\n",
            "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
            "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
            "complex tasks into subtasks involving many agents working together. On col-\n",
            "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
            "solutions than previous chat-based multi-agent systems. Our project can be found\n",
            "at https://github.com/geekan/MetaGPT.\n",
            "1 I NTRODUCTION\n",
            "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
            "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
            "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
            "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
            "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
            "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
            "et al., 2023; Qian et al., 2023).\n",
            "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
            "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
            "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
            "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
            "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
            "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
            "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
            "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
            "(PRDs) using a standardized structure, to guide the developmental process.\n",
            "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
            "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
            "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
            "∗These authors contributed equally to this work.\n",
            "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
            "1\n",
            "\n",
            "page_label: 2\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
            "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
            "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
            "(e.g., Product Manager, Architect, Engineer, etc.).\n",
            "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
            "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
            "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
            "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
            "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
            "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
            "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
            "lunch?” – Bob (Architect).\n",
            "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
            "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
            "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
            "2006; Finn et al., 2017).\n",
            "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
            "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
            "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
            "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
            "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
            "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
            "ing how agent-based techniques can enhance meta-programming.\n",
            "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
            "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
            "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
            "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
            "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
            "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
            "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
            "We summarize our contributions as follows:\n",
            "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
            "2\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "•We introduce MetaGPT, a meta-programming framework for multi-agent collaboration based on\n",
            "LLMs. It is highly convenient and flexible, with well-defined functions like role definition and\n",
            "message sharing, making it a useful platform for developing LLM-based multi-agent systems.\n",
            "•Our innovative integration of human-like SOPs throughout MetaGPT’s design significantly en-\n",
            "hances its robustness, reducing unproductive collaboration among LLM-based agents. Furthermore,\n",
            "we introduce a novel executive feedback mechanism that debugs and executes code during runtime,\n",
            "significantly elevating code generation quality (e.g., 5.4% absolute improvement on MBPP).\n",
            "•We achieve state-of-the-art performance on HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021). Extensive results convincingly validate MetaGPT, suggesting that it is a promising\n",
            "meta-programming framework for developing LLM-based multi-agent systems.\n",
            "2 R ELATED WORK\n",
            "Automatic Programming The roots of automatic programming reach back deep into the previ-\n",
            "ous century. In 1969, Waldinger & Lee (1969) introduced “PROW,” a system designed to accept\n",
            "program specifications written in predicate calculus, generate algorithms, and create LISP imple-\n",
            "mentations (McCarthy, 1978). Balzer (1985) and Soloway (1986) made efforts to advance auto-\n",
            "matic programming and identified potential methods to achieve it. Recent approaches use natural\n",
            "language processing (NLP) techniques (Ni et al., 2023; Skreta et al., 2023; Feng et al., 2020; Li\n",
            "et al., 2022; Chen et al., 2018; 2021b; Zhang et al., 2023). Automatic programming has grown into\n",
            "an industry delivering paid functions such as Microsoft Copilot. Lately, LLMs-based agents (Yao\n",
            "et al., 2022; Shinn et al., 2023; Lin et al., 2023) have advanced automatic programming develop-\n",
            "ment. Among them, ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023) utilize a chain of\n",
            "thought prompts (Wei et al., 2022) to generate reasoning trajectories and action plans with LLMs.\n",
            "Both works demonstrate the effectiveness of the ReAct style loop of reasoning as a design paradigm\n",
            "for empowering automatic programming. Additionally, ToolFormer (Schick et al., 2023) can learn\n",
            "how to use external tools through simple APIs. The research most closely aligned with our work\n",
            "by Li et al. (2023) proposes a straightforward role-play framework for programming that involves\n",
            "communication between agents playing different roles. Qian et al. (2023) utilizes multiple agents for\n",
            "software development. Although existing papers (Li et al., 2023; Qian et al., 2023) have improved\n",
            "productivity, they have not fully tapped into effective workflows with structured output formats.\n",
            "This makes it harder to deal with complex software engineering issues.\n",
            "LLM-Based Multi-Agent Frameworks Recently, LLM-based autonomous agents have gained\n",
            "tremendous interest in both industry and academia (Wang et al., 2023b). Many works (Chen et al.,\n",
            "2024; Wang et al., 2023c; Du et al., 2023; Zhuge et al., 2023; Hao et al., 2023; Akata et al., 2023)\n",
            "have improved the problem-solving abilities of LLMs by integrating discussions among multiple\n",
            "agents. Stable-Alignment (Liu et al., 2023) creates instruction datasets by deriving consensus on\n",
            "value judgments through interactions across a sandbox with LLM agents. Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks.\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks. Besides, LLM-based agents face the challenges of “assistant repeated instruc-\n",
            "tion” or “infinite loop of message” (Talebirad & Nadiri, 2023; Li et al., 2023). These challenges\n",
            "become more urgent in task-oriented collaborations, which require consistent and mutually benefi-\n",
            "cial interactions (Elazar et al., 2021; Wang et al., 2022; Jiang et al., 2023). This motivates our focus\n",
            "on applying advanced concepts such as Standard Operating Procedures in software development to\n",
            "multi-agent frameworks.\n",
            "3\n",
            "\n",
            "page_label: 4\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 2: An example of the communication protocol (left) and iterative programming with exe-\n",
            "cutable feedback (right). Left: Agents use a shared message pool to publish structured messages.\n",
            "They can also subscribe to relevant messages based on their profiles. Right : After generating the\n",
            "initial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past\n",
            "messages stored in memory and compares them with the PRD, system design, and code files.\n",
            "3 M ETAGPT: A M ETA-PROGRAMMING FRAMEWORK\n",
            "MetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 pro-\n",
            "vides an explanation of role specialization, workflow and structured communication in this frame-\n",
            "work, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2\n",
            "presents a communication protocol that enhances role communication efficiency. We also imple-\n",
            "ment structured communication interfaces and an effective publish-subscribe mechanism. These\n",
            "methods enable agents to obtain directional information from other roles and public information\n",
            "from the environment. Finally, we introduce executable feedback—a self-correction mechanism for\n",
            "further enhancing code generation quality during run-time in Sec. 3.3.\n",
            "3.1 A GENTS IN STANDARD OPERATING PROCEDURES\n",
            "Specialization of Roles Unambiguous role specialization enables the breakdown of complex work\n",
            "into smaller and more specific tasks. Solving complex tasks or problems often requires the collab-\n",
            "oration of agents with diverse skills and expertise, each contributing specialized outputs tailored to\n",
            "specific issues.\n",
            "In a software company, a Product Manager typically conducts business-oriented analysis and derives\n",
            "insights, while a software engineer is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design, the information is\n",
            "directed towards the Project Manager for task distribution. Engineers proceed to execute the des-\n",
            "ignated classes and functions as outlined (detailed in Figure 2). In the following stage, the QA\n",
            "Engineer formulates test cases to enforce stringent code quality. In the final step, MetaGPT pro-\n",
            "duces a meticulously crafted software solution. We provide a detailed schematic (Figure 3) and a\n",
            "concrete instance (Appendix B) of the SOP workflow in MetaGPT.\n",
            "3.2 C OMMUNICATION PROTOCOL\n",
            "Structured Communication Interfaces Most current LLM-based multi-agent frameworks (Li\n",
            "et al., 2023; Zhuge et al., 2023; Zhang et al., 2023; Park et al., 2023) utilize unconstrained natural\n",
            "language as a communication interface.\n",
            "However, despite the versatility of natural language, a question arises: does pure natural language\n",
            "communication suffice for solving complex tasks? For example, in the telephone game (or Chinese\n",
            "5\n",
            "\n",
            "page_label: 6\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "whispers)2, after several rounds of communication, the original information may be quite distorted.\n",
            "Inspired by human social structures, we propose using structured communication to formulate the\n",
            "communication of agents. We establish a schema and format for each role and request that individ-\n",
            "uals provide the necessary outputs based on their specific role and context.\n",
            "As shown in Figure 3, the Architect agent generates two outputs: the system interface design and a\n",
            "sequence flow diagram. These contain system module design and interaction sequences, which serve\n",
            "as important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT\n",
            "communicate through documents and diagrams (structured outputs) rather than dialogue. These\n",
            "documents contain all necessary information, preventing irrelevant or missing content.\n",
            "Publish-Subscribe Mechanism Sharing information is critical in collaboration. For instance,\n",
            "Architects and Engineers often need to reference PRDs. However, communicating this information\n",
            "each time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023;\n",
            "Zhang et al., 2023), can complicate the communication topology, resulting in inefficiencies.\n",
            "To address this challenge, a viable approach is to store information in a global message pool . As\n",
            "shown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange\n",
            "messages directly. These agents not only publish their structured messages in the pool but also access\n",
            "messages from other entities transparently. Any agent can directly retrieve required information\n",
            "from the shared pool, eliminating the need to inquire about other agents and await their responses.\n",
            "This enhances communication efficiency.\n",
            "Sharing all information with every agent can lead to information overload. During task execution,\n",
            "an agent typically prefers to receive only task-related information and avoid distractions through\n",
            "irrelevant details. Effective management and dissemination of this information play a crucial role.\n",
            "We offer a simple and effective solution- subscription mechanism (in Figure 2 (left)). Instead of\n",
            "relying on dialogue, agents utilize role-specific interests to extract relevant information. They can\n",
            "select information to follow based on their role profiles. In practical implementations, an agent\n",
            "activates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3,\n",
            "the Architect mainly focuses on PRDs provided by the Product Manager, while documents from\n",
            "roles such as the QA Engineer might be of lesser concern.\n",
            "3.3 I TERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK\n",
            "In daily programming tasks, the processes of debugging and optimization play important roles.\n",
            "However, existing methods often lack a self-correction mechanism, which leads to unsuccessful code\n",
            "generation. Previous work introduced non-executable code review and self-reflection (Zhao et al.,\n",
            "2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in\n",
            "ensuring code executability and runtime correctness.\n",
            "Our first MetaGPT implementations overlooked certain errors during the review process, due to\n",
            "LLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we\n",
            "introduce an executable feedback mechanism to improve the code iteratively. More specifically, as\n",
            "shown in Figure 2, the Engineer is asked to write code based on the original product requirements\n",
            "and design.\n",
            "This enables the Engineer to continuously improve code using its own historical execution and\n",
            "debugging memory. To obtain additional information, the Engineer writes and executes the corre-\n",
            "sponding unit test cases, and subsequently receives the test results. If satisfactory, additional devel-\n",
            "opment tasks are initiated. Otherwise the Engineer debugs the code before resuming programming.\n",
            "This iterative testing process continues until the test is passed or a maximum of 3 retries is reached.\n",
            "4 E XPERIMENTS\n",
            "4.1 E XPERIMENTAL SETTING\n",
            "Datasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021), and a self-generated, more challenging software development benchmark named Soft-\n",
            "2https://en.wikipedia.org/wiki/Chinese whispers\n",
            "6\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "wareDev: (1) HumanEval includes 164 handwritten programming tasks. These tasks encompass\n",
            "function specifications, descriptions, reference codes, and tests. (2) MBPP consists of 427 Python\n",
            "tasks. These tasks cover core concepts and standard library features and include descriptions, ref-\n",
            "erence codes, and automated tests. (3) Our SoftwareDev dataset is a collection of 70 representa-\n",
            "tive examples of software development tasks, each with its own task prompt (see Table 8). These\n",
            "tasks have diverse scopes (See Figure 5), such as mini-games, image processing algorithms, data\n",
            "visualization. They offer a robust testbed for authentic development tasks. Contrary to previous\n",
            "datasets (Chen et al., 2021a; Austin et al., 2021), SoftwareDev focuses on the engineering aspects.\n",
            "In the comparisons, we randomly select seven representative tasks for evaluation.\n",
            "Evaluation Metrics For HuamnEval and MBPP, we follow the unbiased version of Pass @ kas\n",
            "presented by (Chen et al., 2021a; Dong et al., 2023), to evaluate the functional accuracy of the top-k\n",
            "generated codes: Pass @ k=EProblems\u0014\n",
            "1−(n−c\n",
            "k)\n",
            "(n\n",
            "k)\u0015\n",
            ".\n",
            "For SoftwareDev, we prioritize practical use and evaluate performance through human evaluations\n",
            "(A, E) or statistical analysis (B, C, D): (A)Executability: this metric rates code from 1 (failure/non-\n",
            "functional) to 4 (flawless). ‘1’ is for non-functional, ‘2’ for runnable but imperfect, ‘3’ for nearly\n",
            "perfect, and ‘4’ for flawless code. (B)Cost: the cost evaluations here include the (1) running time,\n",
            "(2) token usage, and (3) expenses. (C)Code Statistics: this includes (1) code files, (2) lines of code\n",
            "per file, and (3) total code lines. (D)Productivity: basically, it is defined as the number of token\n",
            "usage divided by the number of lines of code, which refers to the consumption of tokens per code\n",
            "line. (E)Human Revision Cost: refers to times of manual code corrections, which tackle problems\n",
            "like package import errors, incorrect class names, or incomplete reference paths. Typically, each\n",
            "correction involves up to 3 lines of code.\n",
            "Baselines We compare our method with recent domain-specific LLMs in the code generation field,\n",
            "including AlphaCode (Li et al., 2022), Incoder (Fried et al., 2022), CodeGeeX (Zheng et al., 2023),\n",
            "CodeGen (Nijkamp et al., 2023), CodeX (Chen et al., 2021a), and CodeT (Chen et al., 2022) and\n",
            "general domain LLMs such as PaLM (Chowdhery et al., 2022), and GPT-4 (OpenAI, 2023). Several\n",
            "results of baselines (such as Incoder, CodeGeeX) are provided by Dong et al. (2023). In HumanEval\n",
            "and MBPP, we slightly modified the prompts to align with response format requirements. These\n",
            "modifications aim to address format-specific issues (i.e., Python problems). With the SoftwareDev\n",
            "benchmark, we provide a comprehensive comparison between MetaGPT, AutoGPT (Torantulino\n",
            "et al., 2023), LangChain (Chase, 2022) with Python Read-Eval-Print Loop (REPL) tool3, Agent-\n",
            "Verse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "4.2 M AINRESULT\n",
            "AlphaCode(1.1B)\n",
            "Incoder (6.7B)\n",
            "CodeGeeX (13B)17.1\n",
            "—15.2 17.6 18.926.9\n",
            "CodeGeeX-Mono(16.1B)32.938.6\n",
            "GPT-467.0\n",
            "—\n",
            "MetaGPT\n",
            "(w/o Feedback)81.7 82.3Pass@1 of MBPP  and HumanEval (%)\n",
            "PaLM Coder(540B)36.047.0\n",
            "Codex (175B)47.058.1\n",
            "Codex + CodeT65.8 67.7\n",
            "HumanEval\n",
            "MBPP\n",
            "MetaGPT85.9 87.7\n",
            "Figure 4: Pass rates on the MBPP and HumanEval with a single attempt.\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks.\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks. When MetaGPT collaborates with GPT-4, it significantly im-\n",
            "proves the Pass @ kin the HumanEval benchmark compared to GPT-4. It achieves 85.9% and 87.7%\n",
            "3https://en.wikipedia.org/wiki/Read–eval–print loop\n",
            "7\n",
            "\n",
            "page_label: 8\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 5: Demo softwares developed by MetaGPT.\n",
            "in these two public benchmarks. Moreover, as shown in Table 1, MetaGPT outperforms ChatDev on\n",
            "the challenging SoftwareDev dataset in nearly all metrics. For example, considering the executabil-\n",
            "ity, MetaGPT achieves a score of 3.75, which is very close to 4 (flawless). Besides, it takes less time\n",
            "(503 seconds), clearly less than ChatDev. Considering the code statistic and the cost of human revi-\n",
            "sion, it also significantly outperforms ChatDev. Although MetaGPT requires more tokens (24,613\n",
            "or 31,255 compared to 19,292), it needs only 126.5/124.3 tokens to generate one line of code. In\n",
            "contrast, ChatDev uses 248.9 tokens. These results highlight the benefits of SOPs in collabora-\n",
            "tions between multiple agents. Additionally, we demonstrate the autonomous software generation\n",
            "capabilities of MetaGPT through visualization samples (Figure 5). For additional experiments and\n",
            "analysis, please refer to Appendix C.\n",
            "Table 1: The statistical analysis on SoftwareDev.\n",
            "Statistical Index ChatDev MetaGPT w/o Feedback MetaGPT\n",
            "(A)Executability 2.25 3.67 3.75\n",
            "(B)Cost#1: Running Times (s) 762 503 541\n",
            "(B)Cost#2: Token Usage 19,292 24,613 31,255\n",
            "(C)Code Statistic#1: Code Files 1.9 4.6 5.1\n",
            "(C)Code Statistic#2: Lines of Code per File 40.8 42.3 49.3\n",
            "(C)Code Statistic#3: Total Code Lines 77.5 194.6 251.4\n",
            "(D)Productivity 248.9 126.5 124.3\n",
            "(E)Human Revision Cost 2.5 2.25 0.83\n",
            "4.3 C APABILITIES ANALYSIS\n",
            "Compared to open-source baseline methods such as AutoGPT and autonomous agents such as\n",
            "AgentVerse and ChatDev, MetaGPT offers functions for software engineering tasks. As presented\n",
            "in Table 2, our framework encompasses a wide range of abilities to handle complex and specialized\n",
            "development tasks efficiently. Incorporating SOPs (e.g., role-play expertise, structured communi-\n",
            "cation, streamlined workflow) can significantly improve code generation. Other baseline methods\n",
            "8\n",
            "\n",
            "page_label: 9\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 2: Comparison of capabilities for MetaGPT and other approaches. ‘!’ indicates the\n",
            "presence of a specific feature in the corresponding framework, ‘ %’ its absence.\n",
            "Framework Capabiliy AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "PRD generation % % % % !\n",
            "Tenical design genenration % % % % !\n",
            "API interface generation % % % % !\n",
            "Code generation ! ! ! ! !\n",
            "Precompilation execution % % % % !\n",
            "Role-based task management % % % ! !\n",
            "Code review % % ! ! !\n",
            "Table 3: Ablation study on roles. ‘#’ denotes ‘The number of’, ‘Product’ denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "‘Product’ denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass @1 on Hu-\n",
            "manEval and MBPP, respectively. Besides, Table 1 shows that the feedback mechanism improves\n",
            "feasibility (3.67 to 3.75) and reduces the cost of human revisions (2.25 to 0.83). These results\n",
            "illustrate how our designed feedback mechanism can produce higher-quality code. Additional quan-\n",
            "titative results of MetaGPT and MetaGPT without executable feedback are shown in Table 4 and\n",
            "Table 9.\n",
            "5 C ONCLUSION\n",
            "This work introduces MetaGPT, a novel meta-programming framework that leverages SOPs to en-\n",
            "hance the problem-solving capabilities of multi-agent systems based on Large Language Models\n",
            "(LLMs). MetaGPT models a group of agents as a simulated software company, analogous to simu-\n",
            "lated towns (Park et al., 2023) and the Minecraft Sandbox in V oyager (Wang et al., 2023a). MetaGPT\n",
            "leverages role specialization, workflow management, and efficient sharing mechanisms such as mes-\n",
            "sage pools and subscriptions, rendering it a flexible and portable platform for autonomous agents\n",
            "and multi-agent frameworks. It uses an executable feedback mechanism to enhance code generation\n",
            "quality during runtime. In extensive experiments, MetaGPT achieves state-of-the-art performance\n",
            "on multiple benchmarks. The successful integration of human-like SOPs inspires future research\n",
            "on human-inspired techniques for artificial multi-agent systems. We also view our work as an early\n",
            "attempt to regulate LLM-based multi-agent frameworks. See also the outlook (Appendix A) .\n",
            "9\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Acknowledgement\n",
            "We thank Sarah Salhi, the Executive Secretary of KAUST AI Initiative, and Yuhui Wang, Postdoc-\n",
            "toral Fellow at the KAUST AI Initiative, for helping to polish some of the text. We would like to\n",
            "express our gratitude to Wenyi Wang, a PhD student at the KAUST AI Initiative, for providing com-\n",
            "prehensive feedback on the paper and for helping to draft the outlook (Appendix A) with Mingchen.\n",
            "We also thank Zongze Xu, the vice president of DeepWisdom, for providing illustrative materials\n",
            "for AgentStore.\n",
            "Author Contributions\n",
            "Sirui Hong conducted most of the experiments and designed the executable feedback module. She\n",
            "also led the initial version of the write-up, supported by Ceyao Zhang, and also by Jinlin Wang and\n",
            "Zili Wang. Mingchen Zhuge designed the self-improvement module, discussed additional experi-\n",
            "ments, and led the current write-up. Jonathan Chen helped with the MBPP experiments, outlined\n",
            "the methods section, and contributed to the current write-up. Xiawu Zheng provided valuable guid-\n",
            "ance, reviewed and edited the paper. Yuheng Cheng contributed to the evaluation metric design and\n",
            "HumanEval experiments. Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Lingfeng Xiao helped\n",
            "with the MBPP experiments and comparisons to open-source baseline methods. Chenyu Ran cre-\n",
            "ated most of the illustrative figures. Chenglin Wu is the CEO of DeepWisdom, initiated MetaGPT,\n",
            "made the most significant code contributions to it, and advised this project. J ¨urgen Schmidhuber,\n",
            "Director of the AI Initiative at KAUST and Scientific Director of IDSIA, advised this project and\n",
            "helped with the write-up.\n",
            "REFERENCES\n",
            "Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz.\n",
            "Playing repeated games with large language models. arXiv preprint , 2023.\n",
            "Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\n",
            "Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large\n",
            "language models, 2021.\n",
            "Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew\n",
            "Goff, Jonathan Gray, Hengyuan Hu, et al. Human-level play in the game of diplomacy by com-\n",
            "bining language models with strategic reasoning. Science , 2022.\n",
            "Robert Balzer. A 15 year perspective on automatic programming. TSE, 1985.\n",
            "R.M. Belbin. Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\n",
            "Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,\n",
            "Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\n",
            "Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,\n",
            "Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-\n",
            "tios Chantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex\n",
            "Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,\n",
            "Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec\n",
            "Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob Mc-\n",
            "Grew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large\n",
            "language models trained on code, 2021a.\n",
            "10\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan,\n",
            "Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facili-\n",
            "tating multi-agent collaboration and exploring emergent behaviors in agents, 2023.\n",
            "Xinyun Chen, Chang Liu, and Dawn Song. Execution-guided neural program synthesis. In ICLR ,\n",
            "2018.\n",
            "Xinyun Chen, Dawn Song, and Yuandong Tian. Latent execution for neural program synthesis\n",
            "beyond domain-specific languages. NeurIPS , 2021b.\n",
            "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\n",
            "Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\n",
            "Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\n",
            "Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\n",
            "Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\n",
            "skaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\n",
            "Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret\n",
            "Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,\n",
            "Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\n",
            "Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\n",
            "nan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas\n",
            "Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,\n",
            "2022.\n",
            "T. DeMarco and T.R. Lister. Peopleware: Productive Projects and Teams . Addison-Wesley, 2013.\n",
            "URLhttps://books.google.co.uk/books?id=DVlsAQAAQBAJ .\n",
            "Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. Self-collaboration code generation via chatgpt. arXiv\n",
            "preprint , 2023.\n",
            "Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving\n",
            "factuality and reasoning in language models through multiagent debate, 2023.\n",
            "Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\n",
            "Sch¨utze, and Yoav Goldberg. Measuring and improving consistency in pretrained language mod-\n",
            "els.TACL , 2021.\n",
            "Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing\n",
            "Qin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained model for programming and natural\n",
            "languages. arXiv preprint , 2020.\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, and Liqiang Nie. Chatllm network:\n",
            "More brains, more intelligence. arXiv preprint , 2023.\n",
            "S. Hochreiter, A. S. Younger, and P. R. Conwell. Learning to learn using gradient descent. In Lecture\n",
            "Notes on Comp. Sci. 2130, Proc. Intl. Conf. on Artificial Neural Networks (ICANN-2001) , pp. 87–\n",
            "94. Springer: Berlin, Heidelberg, 2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "Heidelberg, 2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi Yang, and\n",
            "Soroush V osoughi. Training socially aligned language models in simulated human society. arXiv\n",
            "preprint , 2023.\n",
            "Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing\n",
            "Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with\n",
            "evol-instruct. arXiv preprint , 2023.\n",
            "Potsawee Manakul, Adian Liusie, and Mark JF Gales. Selfcheckgpt: Zero-resource black-box hal-\n",
            "lucination detection for generative large language models. arXiv preprint , 2023.\n",
            "Agile Manifesto. Manifesto for agile software development . Snowbird, UT, 2001.\n",
            "John McCarthy. History of lisp. In History of programming languages . 1978.\n",
            "Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-tau Yih, Sida Wang, and Xi Victoria\n",
            "Lin. Lever: Learning to verify language-to-code generation with execution. In ICML , 2023.\n",
            "Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese,\n",
            "and Caiming Xiong. Codegen: An open large language model for code with multi-turn program\n",
            "synthesis, 2023.\n",
            "OpenAI. Gpt-4 technical report, 2023.\n",
            "Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and\n",
            "Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint ,\n",
            "2023.\n",
            "Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and\n",
            "Maosong Sun. Communicative agents for software development, 2023.\n",
            "Baptiste Rozi `ere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi\n",
            "Adi, Jingyu Liu, Tal Remez, J ´er´emy Rapin, et al. Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements.\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements. Technical Report IDSIA-19-03, arXiv:cs.LO/0309048 v3, IDSIA,\n",
            "Manno-Lugano, Switzerland, December 2003.\n",
            "J. Schmidhuber. G ¨odel machines: Fully self-referential optimal universal self-improvers. In B. Go-\n",
            "ertzel and C. Pennachin (eds.), Artificial General Intelligence , pp. 199–226. Springer Verlag,\n",
            "2006. Variant available as arXiv:cs.LO/0309048.\n",
            "12\n",
            "\n",
            "page_label: 13\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "J. Schmidhuber. Ultimate cognition `a laG¨odel. Cognitive Computation , 1(2):177–193, 2009.\n",
            "J¨urgen Schmidhuber. Evolutionary principles in self-referential learning, or on learning how to\n",
            "learn: the meta-meta-... hook . PhD thesis, 1987.\n",
            "J¨urgen Schmidhuber. A ‘self-referential’weight matrix. In ICANN’93: Proceedings of the Interna-\n",
            "tional Conference on Artificial Neural Networks Amsterdam, The Netherlands 13–16 September\n",
            "1993 3 , 1993b.\n",
            "J¨urgen Schmidhuber. On learning to think: Algorithmic information theory for novel combinations\n",
            "of reinforcement learning controllers and recurrent neural world models. arXiv preprint , 2015.\n",
            "J¨urgen Schmidhuber, Jieyu Zhao, and Nicol N Schraudolph. Reinforcement learning with self-\n",
            "modifying policies. In Learning to learn . 1998.\n",
            "Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic\n",
            "memory and self-reflection. arXiv preprint , 2023.\n",
            "Marta Skreta, Naruki Yoshikawa, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen,\n",
            "Kourosh Darvish, Al ´an Aspuru-Guzik, Florian Shkurti, and Animesh Garg. Errors are useful\n",
            "prompts: Instruction guided task programming with verifier-assisted iterative prompting. arXiv\n",
            "preprint , 2023.\n",
            "Elliot Soloway. Learning to program =learning to construct mechanisms and explanations. Com-\n",
            "munications of the ACM , 1986.\n",
            "Yashar Talebirad and Amirhossein Nadiri. Multi-agent collaboration: Harnessing the power of\n",
            "intelligent llm agents, 2023.\n",
            "Torantulino et al. Auto-gpt. https://github.com/Significant-Gravitas/\n",
            "Auto-GPT , 2023.\n",
            "R. J. Waldinger and R. C. T. Lee. PROW: a step toward automatic program writing. In D. E. Walker\n",
            "and L. M. Norton (eds.), Proceedings of the 1st International Joint Conference on Artificial Intel-\n",
            "ligence (IJCAI) , 1969.\n",
            "Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan,\n",
            "and Anima Anandkumar. V oyager: An open-ended embodied agent with large language models.\n",
            "arXiv preprint , 2023a.\n",
            "Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\n",
            "Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\n",
            "arXiv preprint , 2023b.\n",
            "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\n",
            "ery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.\n",
            "arXiv preprint , 2022.\n",
            "Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. Unleashing\n",
            "cognitive synergy in large language models: A task-solving agent through multi-persona self-\n",
            "collaboration. arXiv preprint , 2023c.\n",
            "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\n",
            "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS ,\n",
            "2022.\n",
            "Michael Wooldridge and Nicholas R. Jennings. Pitfalls of agent-oriented development. In Pro-\n",
            "ceedings of the Second International Conference on Autonomous Agents , 1998. URL https:\n",
            "//doi.org/10.1145/280765.280867 .\n",
            "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\n",
            "React: Synergizing reasoning and acting in language models. arXiv preprint , 2022.\n",
            "Eric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. Self-taught optimizer (stop):\n",
            "Recursively self-improving code generation. arXiv preprint , 2023.\n",
            "13\n",
            "\n",
            "page_label: 14\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tian-\n",
            "min Shu, and Chuang Gan. Building cooperative embodied agents modularly with large language\n",
            "models. arXiv preprint , 2023.\n",
            "Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, and Stefan Wermter. Chat\n",
            "with the environment: Interactive multimodal perception using large language models. arXiv\n",
            "preprint , 2023.\n",
            "Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen,\n",
            "Andi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang. Codegeex: A pre-trained model for\n",
            "code generation with multilingual evaluations on humaneval-x, 2023.\n",
            "Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng,\n",
            "Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for building\n",
            "autonomous agents. arXiv preprint , 2023.\n",
            "Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, R ´obert Csord ´as, Anand\n",
            "Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki\n",
            "Irie, et al. Mindstorms in natural language-based societies of mind. arXiv preprint , 2023.\n",
            "14\n",
            "\n",
            "page_label: 15\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "A O UTLOOK\n",
            "A.1 S ELF-IMPROVEMENT MECHANISMS\n",
            "One limitation of the MetaGPT version in the main text of this paper is that each software project is\n",
            "executed independently. However, through active teamwork, a software development team should\n",
            "learn from the experience gained by developing each project, thus becoming more compatible and\n",
            "successful over time.\n",
            "This is somewhat related to the idea of recursive self-improvement, first informally proposed in\n",
            "1965 (Good, 1965), with first concrete implementations since 1987 (Schmidhuber, 1987; 1993b;\n",
            "Schmidhuber et al., 1998), culminating in the concept of mathematically optimal self-referential\n",
            "self-improvers (Schmidhuber, 2003; 2009). Generally speaking, a system should learn from experi-\n",
            "ence in the real world, and meta-learn better learning algorithms from experiences of learning, and\n",
            "meta-meta-learn better meta-learning algorithms from experiences of meta-learning, etc., without\n",
            "any limitations except those of computability and physics.\n",
            "More recent, somewhat related work leverages the reasoning ability of Large Language Models\n",
            "(LLMs) and recursively improves prompts of LLMs, to improve performance on certain downstream\n",
            "tasks (Fernando et al., 2023; Zelikman et al., 2023), analogous to the adaptive prompt engineer of\n",
            "2015 (Schmidhuber, 2015) where one neural network learns to generate sequence of queries or\n",
            "prompts for another pre-trained neural network whose answers may help the first network to learn\n",
            "new tasks more quickly.\n",
            "In our present work, we also explore a self-referential mechanism that recursively modifies the con-\n",
            "straint prompts of agents based on information they observe during software development. Our\n",
            "initial implementation works as follows. Prior to each project, every agent in the software company\n",
            "reviews previous feedback and makes necessary adjustments to their constraint prompts. This en-\n",
            "ables them to continuously learn from past project experiences and enhance the overall multi-agent\n",
            "system by improving each individual in the company. We first establish a handover feedback action\n",
            "for each agent. This action is responsible for critically summarizing the information received dur-\n",
            "ing the development of previous projects and integrating this information in an updated constraint\n",
            "prompt. The summarized information is stored in long-term memory such that it can be inherited\n",
            "by future constraint prompt updates. When initiating a new project, each agent starts with a react\n",
            "action. Each agent evaluates the received feedback and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "agent evaluates the received feedback and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically, AgentStore allows users to subscribe to agents according to their demands\n",
            "4http://beta.deepwisdom.ai\n",
            "15\n",
            "\n",
            "page_label: 16\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "and pay according to their usage. Moreover, users can purchase additional capabilities to expand the\n",
            "plug-and-play functions of their existing agents. This allows users to gradually upgrade their agents.\n",
            "Within the MetaGPT framework, AgentStore can support the collaboration of various agents. Users\n",
            "can collect several agents together to carry out more complex tasks or projects, and all the agents\n",
            "share and comply with development and communication protocols defined in MetaGPT.\n",
            "Figure 6: AgentStore is a platform dedicated to serving users in the creation and development of\n",
            "agents within the MetaGPT framework. This platform provides users with an operational interface,\n",
            "allowing users to easily manage a variety of agents with different emotions, personalities, and capa-\n",
            "bilities for specific tasks.\n",
            "16\n",
            "\n",
            "page_label: 17\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "B A D EMO OF THE EXECUTION\n",
            "In this section, we outline the complete process of software development using MetaGPT. It begins\n",
            "with a user’s input command (as shown in Appendix B.1) and ends with software designed according\n",
            "to the user’s specifications.\n",
            "B.1 U SERINPUT\n",
            "Upon receiving an instruction from the user, MetaGPT collaborates with a professional development\n",
            "team to fulfill the task. Here is a demo of user input:\n",
            "User input\n",
            "1write a python3 GUI app such that you can draw an image with it\n",
            "B.2 M ETAGPT DEVELOPMENT PROCESS\n",
            "Now we provide a step-by-step explanation of the standardized output process for each agent.\n",
            "Product Manager The Product Manager generates a Product Requirement Document (PRD), as\n",
            "detailed in the specified documentation. This document encompasses goals, user stories, competitive\n",
            "analysis, requirement analysis and requirement pool. Additionally, a competitive quadrant chart is\n",
            "produced (see Figure 7). Subsequently, these documents and charts are handed over to the architect\n",
            "for system design.\n",
            "Product Requirement Document\n",
            "1## Original Requirements\n",
            "2The boss requires a Python3 GUI color meter that outputs the RGB values when it moves.\n",
            "3\n",
            "4## Product Goals\n",
            "5‘‘‘python\n",
            "6[\n",
            "7 \"Create a user-friendly GUI color meter\",\n",
            "8 \"Ensure the color meter accurately outputs RGB values\",\n",
            "9 \"Ensure the color meter updates RGB values in real-time as it moves\"\n",
            "10]\n",
            "11‘‘‘\n",
            "12\n",
            "13## User Stories\n",
            "14‘‘‘python\n",
            "15[\n",
            "16 \"As a user, I want to select any color on the screen, so that I can get its RGB values\",\n",
            "17 \"As a user, I want the RGB values to update in real-time as I move the color meter, so that I\n",
            ",→can get accurate color information\",\n",
            "18 \"As a user, I want a simple and intuitive interface, so that I can easily use the color meter\"\n",
            "19]\n",
            "20‘‘‘\n",
            "21\n",
            "22## Competitive Analysis\n",
            "23‘‘‘python\n",
            "24[\n",
            "25 \"Color Cop: A popular color picker for Windows. It’s simple and easy to use, but lacks real-\n",
            ",→time RGB value updates\",\n",
            "26 \"Just Color Picker: Offers real-time color picking and multiple color code formats. However,\n",
            ",→its interface is cluttered and not very user-friendly\",\n",
            "27 \"Instant Eyedropper: A simple color picker that lives in the system tray. It’s convenient but\n",
            ",→lacks advanced features\",\n",
            "28 \"ColorZilla: A color picker extension for browsers. It’s convenient for web design but not\n",
            ",→suitable for desktop applications\",\n",
            "29 \"ColorPic: Offers color palettes and mixer tools. It’s feature-rich but can be overwhelming\n",
            ",→for simple tasks\"\n",
            "30]\n",
            "31‘‘‘\n",
            "17\n",
            "\n",
            "page_label: 18\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1\n",
            "2## Requirement Analysis\n",
            "3The product should be a Python3 GUI application that serves as a color meter. It should allow\n",
            ",→users to select any color on the screen and display the corresponding RGB values. The RGB\n",
            ",→ values should update in real-time as the color meter moves. The interface should be\n",
            ",→simple and user-friendly.\n",
            "4\n",
            "5## Requirement Pool\n",
            "6‘‘‘python\n",
            "7[\n",
            "8 (\"Design a user-friendly GUI for the color meter\", \"P0\"),\n",
            "9 (\"Implement color selection functionality\", \"P0\"),\n",
            "10 (\"Display RGB values of the selected color\", \"P0\"),\n",
            "11 (\"Update RGB values in real-time as the color meter moves\", \"P0\"),\n",
            "12 (\"Test the application for accuracy and performance\", \"P1\")\n",
            "13]\n",
            "14‘‘‘\n",
            "15\n",
            "16## UI Design draft\n",
            "17The UI should be minimalistic and intuitive. It should primarily consist of a color meter, which\n",
            ",→could be a magnified area of the screen that the user can move around. The RGB values of\n",
            ",→the currently selected color should be prominently displayed, updating in real-time as\n",
            ",→the color meter moves. The layout should be clean and uncluttered, with a focus on\n",
            ",→functionality and ease of use.\n",
            "18\n",
            "19## Anything UNCLEAR\n",
            "20There are no unclear points.\n",
            "Figure 7: The quadrant chart for the “Drawing App” generated by the product manager agent.\n",
            "18\n",
            "\n",
            "page_label: 19\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Architect Based on the requirements in PRD, the Architect agent devises technical specifications\n",
            "including system architecture diagrams and interface definitions. Initially, the Architect defines the\n",
            "overarching technical trajectory. Subsequently, the project’s architecture, including files, classes\n",
            "(Figure 8) and the sequence flow chart (Figure 12), is designed. The Architect’s documentation is\n",
            "then given to the project manager for task allocation and execution.\n",
            "System design\n",
            "1## Implementation approach\n",
            "2We will use Python’s Tkinter library to create the GUI for the color meter. Tkinter is a standard\n",
            ",→Python interface to the Tk GUI toolkit and is included with most Python installations. It\n",
            ",→ is simple to use and powerful enough for our needs.\n",
            "3\n",
            "4The color selection functionality will be implemented using the PIL (Pillow) library, which allows\n",
            ",→ us to capture the screen’s pixel data. By moving the mouse, we can get the RGB values of\n",
            ",→ the pixel under the mouse cursor in real-time.\n",
            "5\n",
            "6The RGB values will be displayed on the GUI using Tkinter’s Label widget. We will use Python’s\n",
            ",→threading library to update the RGB values in real-time as the color meter moves.\n",
            "7\n",
            "8The application will be tested for accuracy and performance using Python’s unittest library.\n",
            "9\n",
            "10## Python package name\n",
            "11‘‘‘python\n",
            "12\"color_meter\"\n",
            "13‘‘‘\n",
            "14\n",
            "15## File list\n",
            "16‘‘‘python\n",
            "17[\n",
            "18 \"main.py\",\n",
            "19 \"color_picker.py\",\n",
            "20 \"gui.py\",\n",
            "21 \"tests.py\"\n",
            "22]\n",
            "23‘‘‘\n",
            "24\n",
            "25## Anything UNCLEAR\n",
            "26The requirement is clear to me.\n",
            "Figure 8: Data structures and interface definitions for the “Drawing App” generated by the architect\n",
            "agent.\n",
            "Project Manager The Project Manager breaks down the project into a task list. Furthermore, each\n",
            "code file is analyzed based on its intended functionality and then treated as a separate task assigned\n",
            "to Engineers.\n",
            "19\n",
            "\n",
            "page_label: 20\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 9: The program call flow for the “Drawing App” generated by the architect agent.\n",
            "Tasks\n",
            "1## Required Python third-party packages\n",
            "2\n",
            "3‘‘‘python\n",
            "4\"\"\"\n",
            "5tkinter==8.6\n",
            "6Pillow==8.3.1\n",
            "7\"\"\"\n",
            "8‘‘‘\n",
            "9\n",
            "10## Required Other language third-party packages\n",
            "11‘‘‘python\n",
            "12\"\"\"\n",
            "13No third-party packages required in other languages.\n",
            "14\"\"\"\n",
            "15‘‘‘\n",
            "16\n",
            "17## Full API spec\n",
            "18‘‘‘python\n",
            "19\"\"\"\n",
            "20No APIs are used in this project.\n",
            "21\"\"\"\n",
            "22‘‘‘\n",
            "23\n",
            "24## Logic Analysis\n",
            "25‘‘‘python\n",
            "26[\n",
            "27 (\"main.py\", \"Contains the main application loop and initializes all the other components.\"),\n",
            "28 (\"canvas.py\", \"Implements the drawing canvas, responds to mouse events, and uses the selected\n",
            ",→tool and color.\"),\n",
            "29 (\"tools.py\", \"Implements the tool selection interface.\"),\n",
            "30 (\"color_picker.py\", \"Implements the color selection interface.\"),\n",
            "31 (\"file_manager.py\", \"Implements the file saving and opening functionality.\")\n",
            "32]\n",
            "33‘‘‘\n",
            "20\n",
            "\n",
            "page_label: 21\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1## Task list\n",
            "2‘‘‘python\n",
            "3[\n",
            "4 \"main.py\",\n",
            "5 \"canvas.py\",\n",
            "6 \"tools.py\",\n",
            "7 \"color_picker.py\",\n",
            "8 \"file_manager.py\"\n",
            "9]\n",
            "10‘‘‘\n",
            "11\n",
            "12## Shared Knowledge\n",
            "13‘‘‘python\n",
            "14\"\"\"\n",
            "15The ’Tkinter’ library is used for creating the GUI of the application. It provides various widgets\n",
            ",→ like frames and canvases which are used in this project.\n",
            "16The ’Pillow’ library is used for handling image files. It is used in the ’file_manager.py’ for\n",
            ",→saving and opening image files.\n",
            "17The ’main.py’ file is the entry point of the application. It initializes all the other components\n",
            ",→and starts the application loop.\n",
            "18\"\"\"\n",
            "19‘‘‘\n",
            "20\n",
            "21## Anything UNCLEAR\n",
            "22The project requirements and implementation approach are clear. However, we need to ensure that\n",
            ",→all team members are familiar with the Tkinter and Pillow libraries. If not, they may\n",
            ",→need some time to learn these libraries before starting the development.\n",
            "21\n",
            "\n",
            "page_label: 22\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Engineer Given the provided file structure and function definitions, an Engineer agent requires\n",
            "only fundamental development skills to complete the development tasks. Due to the large number\n",
            "of files, we present only one auto-generated code file here.\n",
            "Generated code (color picker.py)\n",
            "1import tkinter as tk\n",
            "2from tkinter import colorchooser\n",
            "3class ColorPicker:\n",
            "4 def __init__(self, root: tk.Tk, color: str = ’black’):\n",
            "5 self.frame = tk.Frame(root)\n",
            "6 self.color = color\n",
            "7\n",
            "8 self.color_button = tk.Button(self.frame, text=’Color’, command=self.select_color)\n",
            "9 self.color_button.pack(fill=’x’)\n",
            "10\n",
            "11 def select_color(self):\n",
            "12 color = colorchooser.askcolor()[1]\n",
            "13 if color is not None:\n",
            "14 self.color = color\n",
            "15\n",
            "16 def pack(self, **kwargs):\n",
            "17 self.frame.pack( **kwargs)\n",
            "18\n",
            "19 def get_color(self):\n",
            "20 return self.color\n",
            "QA Engineer Upon receiving the code output from the Engineer, the QA Engineer generates unit\n",
            "test code and reviews it to identify and fix any bugs, ensuring high-quality software.\n",
            "Generated Unit tests (test.py)\n",
            "1import unittest\n",
            "2import tkinter as tk\n",
            "3# You might want to move the ColorPicker class to another file, let’s say color_picker.py\n",
            "4# from color_picker import ColorPicker\n",
            "5\n",
            "6class TestColorPicker(unittest.TestCase):\n",
            "7\n",
            "8 def setUp(self):\n",
            "9 self.root = tk.Tk()\n",
            "10 self.cp = ColorPicker(self.root)\n",
            "11\n",
            "12 def tearDown(self):\n",
            "13 # This is important to close the tk window after tests\n",
            "14 self.root.destroy()\n",
            "15\n",
            "16 def test_initial_color(self):\n",
            "17 # Test the default color during initialization\n",
            "18 self.assertEqual(self.cp.get_color(), ’black’)\n",
            "19\n",
            "20 def test_set_and_get_color(self):\n",
            "21 # Test setting a new color and retrieving it\n",
            "22 new_color = ’#ffffff’ # white color\n",
            "23 self.cp.color = new_color\n",
            "24 self.assertEqual(self.cp.get_color(), new_color)\n",
            "25\n",
            "26\n",
            "27if __name__ == ’__main__’:\n",
            "28 unittest.main()\n",
            "Output Ultimately, as shown in Figure 10, MetaGPT generates a functional application named\n",
            "“Drawing App”.\n",
            "22\n",
            "\n",
            "page_label: 23\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 10: The “Drawing App” generated by MetaGPT.\n",
            "C E XPERIMENTS\n",
            "C.1 D ETAILS OF THE SOFTWARE DEVDATASET\n",
            "The SoftwareDev dataset includes 70 diverse software development tasks. Table 8 displays the\n",
            "names and detailed prompts of 11 tasks within the dataset. Note that the first seven tasks listed are\n",
            "used in the main experiments of this paper.\n",
            "C.2 A DDITIONAL RESULTS\n",
            "Quantitative results of MetaGPT As shown in Table 4, MetaGPT achieves an average score\n",
            "of 3.9, surpassing ChatDev’s score of 2.1 Zhao et al. (2023), which is based on the Chat chain.\n",
            "Compare the scores of general intelligent algorithms, including AutoGPT Torantulino et al. (2023),\n",
            "which all score 1.0, failing to generate executable code. We observe that the generated code is often\n",
            "short, lacks comprehensive logic, and tends to fail to handle cross-file dependencies correctly.\n",
            "While models such as AutoGPT (Torantulino et al., 2023), Langchain (Chase, 2022), and Agent-\n",
            "Verse (Chen et al., 2023) display robust general problem-solving capabilities, they lack an essential\n",
            "element for developing complex systems: systematically deconstructing requirements. Conversely,\n",
            "MetaGPT simplifies the process of transforming abstract requirements into detailed class and func-\n",
            "tion designs through a specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "designs through a specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1 1 2 4\n",
            "2048 game 1 1 1 1 4\n",
            "Snake game 1 1 1 3 4\n",
            "Brick breaker game 1 1 1 1 4\n",
            "Excel data process 1 1 1 4 4\n",
            "CRUD manage 1 1 1 2 4\n",
            "Average score 1.0 1.0 1.0 2.1 3.9\n",
            "Table 5: Performance of MetaGPT on SoftwareDev using different LLMs as agent backends.\n",
            "Model Open source Time(/s) # Lines Executability Revisions\n",
            "MetaGPT (w/ GPT-3.5) % 75.18 161.6 2.8 2.4\n",
            "MetaGPT (w/ GPT-4) % 552.94 178.2 3.8 1.2\n",
            "MetaGPT (w/ Deepseek Coder 33B) \" 1186.20 120.2 1.4 2.6\n",
            "Impact of Instruction Levels (High-level v.s.Detailed Instructions) Does the variation in the\n",
            "level of initial input from humans significantly influence performance outcomes? For examples:\n",
            "1.High-level prompt : Create a brick breaker game.\n",
            "2.Detailed prompt : Creating a brick breaker game. In a brick breaker game, the player\n",
            "typically controls a paddle at the bottom of the screen to bounce a ball towards a wall of\n",
            "bricks. The goal is to break all the bricks by hitting them with the ball.\n",
            "Additional experiments were conducted to investigate this aspect: we selected 5 tasks from Soft-\n",
            "wareDev, and constructed detailed prompts for them. Here are the experimental results:\n",
            "Table 6: Impact of Instruction Levels. The executability is scored on a grading system ranging\n",
            "from ‘1’ to ‘4’. A score of ‘1’ signifies complete failure, ‘2’ denotes runnable code, ‘3’ represents\n",
            "largely expected workflow, and ‘4’ indicates a perfect match to expectations.\n",
            "Model # Word Time(/s) Token usage # Lines Executability Productivity Reversions\n",
            "High-level 13.2 552.9 28384.2 178.2 3.8 163.8 1.2\n",
            "Detailed 42.2 567.8 29657.0 257.0 4.0 118.0 1.6\n",
            "We observe that: detailed prompts lead to better software projects with lower productivity ratios\n",
            "because of clearer requirements and functions, while simple inputs can still generate good enough\n",
            "software using MetaGPT with an executability rating of 3.8, which is comparable to the detailed\n",
            "prompt scenario. (Note that, Productivity = Token usage / Total Code Lines. The lower this ratio,\n",
            "the better.)\n",
            "The performance of GPT variants in HumanEval benchmark We use the GPT-4’s 67% Hu-\n",
            "manEval score (OpenAI, 2023) as our baseline, acknowledging its acceptance in the HumanEval\n",
            "benchmark. We further extend to experiments(five times) with GPT-4 (gpt-4-0613) and GPT-3.5-\n",
            "Turbo (gpt-3.5-turbo-0613) under various conditions to assess performance. (A)We directly called\n",
            "the OpenAI API with the prompt in HumanEval. (B)We called the OpenAI API and parsed the\n",
            "code with regex in the response. (C)We added an additional system prompt, then called the OpenAI\n",
            "API. The prompt is ”You are an AI that only responds with Python code, NOT ENGLISH. You will\n",
            "24\n",
            "\n",
            "page_label: 25\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "be given a function signature and its docstring by the user. Write your full implementation (restate\n",
            "the function signature).” As shown in Table 7, GPT-4 is more sensitive to prompt, code parser, and\n",
            "post-processing results on the HumanEval data set. It is difficult for GPT-3.5-Turbo to return the\n",
            "correct completion code without prompt words.\n",
            "Table 7: Performance of GPT models on HumanEval. Experiments were conducted five times\n",
            "using gpt-4-0613 and gpt-3.5-turbo-0613 with different settings.\n",
            "Settings Model 1 2 3 4 5 Avg. Std.\n",
            "A gpt-4-0613 0.732 0.707 0.732 0.713 0.738 0.724 0.013\n",
            "A gpt-3.5-turbo-0613 0.360 0.366 0.360 0.348 0.354 0.357 0.007\n",
            "B gpt-4-0613 0.787 0.811 0.817 0.829 0.817 0.812 0.016\n",
            "B gpt-3.5-turbo-0613 0.348 0.354 0.348 0.335 0.348 0.346 0.007\n",
            "C gpt-4-0613 0.805 0.805 0.817 0.793 0.780 0.800 0.014\n",
            "C gpt-3.5-turbo-0613 0.585 0.567 0.573 0.579 0.579 0.577 0.007\n",
            "Qualitative results Figure 11 and Figure 12 illustrate the outcomes of the Architect agent’s ef-\n",
            "forts to design a complex recommender system. These figures showcase the comprehensive system\n",
            "interface design and program call flow. The latter is essential for creating a sophisticated automated\n",
            "system. It is crucial to emphasize the importance of this division of labor in developing an automated\n",
            "software framework.\n",
            "D L IMITATION AND ETHICS CONCERNS\n",
            "D.1 L IMITATION\n",
            "System side At present, our system cannot fully cater to specific scenarios, such as UI and front-\n",
            "end, as we have yet to incorporate such agents and multimodal tools. Furthermore, despite gen-\n",
            "erating the most amount of code among comparable frameworks, it remains challenging to fulfill\n",
            "real-world applications’ diverse and complex requirements.\n",
            "Human user side A key challenge for users is to interrupt the running process of each agent, or\n",
            "set the starting running point (checkpoint) for each agent.\n",
            "D.2 E THICS CONCERNS\n",
            "Unemployment and Skill Obsolescence MetaGPT enables more people to program in natural\n",
            "languages, thereby making it easier for engineers to get started. Over the years, programming\n",
            "languages have evolved from punched cards to assembly, C, Java, Python, and now natural lan-\n",
            "guage. As a result, humans have become more proficient at programming, increasing the demand\n",
            "for programming-related positions. Furthermore, programming with natural language may offer a\n",
            "significantly easier learning curve, making programming more accessible to a broader audience.\n",
            "Transparency and Accountability MetaGPT is an open-source framework that facilitates inter-\n",
            "active communication between multiple agents through natural language. Humans can initiate, ob-\n",
            "serve, and stop running with the highest level of control. It provides real-time interpretation and op-\n",
            "eration of the natural language, displayed on the screen and logs, ensuring transparency. MetaGPT\n",
            "enhances “natural language programming” capabilities, and human engineers are the users and re-\n",
            "sponsible for the outcomes.\n",
            "Privacy and Data Security MetaGPT operates locally, ensuring user data privacy and security. It\n",
            "does not collect user data. For interactions with third-party LLMs, such as those by OpenAI, users\n",
            "are encouraged to refer to the respective privacy policies (e.g., OpenAI Privacy Policy). However,\n",
            "we provide the option of open-source LLMs as backends.\n",
            "25\n",
            "\n",
            "page_label: 26\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 11: The system interface design for “recommendation engine development” is generated by\n",
            "thearchitect agent ( zoom in for a better view ).\n",
            "E M ORE DISCUSSIONS\n",
            "E.1 D EEP-SEATED CHALLENGES\n",
            "MetaGPT also alleviates or solves these challenges with its unique designs:\n",
            "Use Context Efficiently Two sub-challenges are present. First, unfolding short natural language\n",
            "descriptions accurately to eliminate ambiguity. Second, maintaining information validity in lengthy\n",
            "contexts, enables LLMs to concentrate on relevant data without distraction.\n",
            "Reduce Hallucinations Using LLMs to generate entire software programs faces code halluci-\n",
            "nation problems—-including incomplete implementation of functions, missing dependencies, and\n",
            "potential undiscovered bugs, which may be more serious. LLMs often struggle with software gen-\n",
            "eration due to vague task definitions. Focusing on granular tasks like requirement analysis and\n",
            "package selection offers guided thinking, which LLMs lack in broad task solving.\n",
            "E.2 I NFORMATION OVERLOAD\n",
            "In MetaGPT, we use a global message pool and a subscription mechanism to address “information\n",
            "overload,” which refers to the problem of receiving excessive or irrelevant information. This issue\n",
            "is dependent on specific applications. MetaGPT employs a message pool to streamline communi-\n",
            "cation, ensuring efficiency. Additionally, a subscription mechanism filters out irrelevant contexts,\n",
            "enhancing the relevance and utility of the information. This design is particularly crucial in soft-\n",
            "26\n",
            "\n",
            "page_label: 27\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 12: The program call flow for “recommendation engine development” generated by the\n",
            "architect agent ( zoom in for a better view ).\n",
            "ware design scenarios and standard operating procedures (SOPs) where effective communication is\n",
            "essential.\n",
            "27\n",
            "\n",
            "page_label: 28\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 8: Examples of SoftwareDev dataset.\n",
            "Task ID Task Prompt\n",
            "0 Snake game Create a snake game.\n",
            "1 Brick breaker game Create a brick breaker game.\n",
            "2 2048 game Create a 2048 game for the web.\n",
            "3 Flappy bird game Write p5.js code for Flappy Bird where you control a yellow bird continu-\n",
            "ously flying between a series of green pipes. The bird flaps every time you\n",
            "left click the mouse. If it falls to the ground or hits a pipe, you lose. This\n",
            "game goes on indefinitely until you lose; you get points the further you go.\n",
            "4 Tank battle game Create a tank battle game.\n",
            "5 Excel data process Write an excel data processing program based on streamlit and pandas. The\n",
            "screen first shows an excel file upload button. After the excel file is uploaded,\n",
            "use pandas to display its data content. The program is required to be concise,\n",
            "easy to maintain, and not over-designed. It uses streamlit to process web\n",
            "screen displays, and pandas is sufficient to process excel reading and display.\n",
            "Please make sure others can execute directly without introducing additional\n",
            "packages.\n",
            "6 CRUD manage Write a management program based on the crud addition, deletion, modifi-\n",
            "cation and query processing of the customer business entity. The customer\n",
            "needs to save this information: name, birthday, age, sex, and phone. The data\n",
            "is stored in client.db, and there is a judgement whether the customer table ex-\n",
            "ists. If it doesn’t, it needs to be created first. Querying is done by name; same\n",
            "for deleting. The program is required to be concise, easy to maintain, and not\n",
            "over-designed. The screen is realized through streamlit and sqlite—no need\n",
            "to introduce other additional packages.\n",
            "7 Music transcriber Develop a program to transcribe sheet music into a digital format; provid-\n",
            "ing error-free transcribed symbolized sheet music intelligence from audio\n",
            "through signal processing involving pitch and time slicing then training a\n",
            "neural net to run Onset Detected CWT transforming scalograms to chroma-\n",
            "grams decoded with Recursive Neural Network focused networks.\n",
            "8 Custom press releases Create custom press releases; develop a Python script that extracts rele-\n",
            "vant information about company news from external sources, such as social\n",
            "media; extract update interval database for recent changes. The program\n",
            "should create press releases with customizable options and export writings\n",
            "to PDFs, NYTimes API JSONs, media format styled with interlink internal\n",
            "fixed character-length metadata.\n",
            "9 Gomoku game Implement a Gomoku game using Python, incorporating an AI opponent\n",
            "with varying difficulty levels.\n",
            "10 Weather dashboard Create a Python program to develop an interactive weather dashboard.\n",
            "28\n",
            "\n",
            "page_label: 29\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 9: Additional results of pure MetaGPT w/o feedback on SoftwareDev. Averages (Avg.) of 70 tasks are calculated and 10 randomly selected tasks are\n",
            "included. ‘#’ denotes ‘The number of’, while ‘ID’ is ‘Task ID’.\n",
            "ID Code statistics Doc statistics Cost statistics Cost of revision Code executability\n",
            "#code files #lines of code #lines per code file #doc files #lines of doc #lines per doc file #prompt tokens #completion tokens time costs money costs\n",
            "0 5.00 196.00 39.20 3.00 210.00 70.00 24087.00 6157.00 582.04 $ 1.09 1. TypeError 4\n",
            "1 6.00 191.00 31.83 3.00 230.00 76.67 32517.00 6238.00 566.30 $ 1.35 1. TypeError 4\n",
            "2 3.00 198.00 66.00 3.00 235.00 78.33 21934.00 6316.00 553.11 $ 1.04 1. lack\n",
            "@app.route(’/’)3\n",
            "3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "lack\n",
            "@app.route(’/’)3\n",
            "3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method not\n",
            "implement2\n",
            "9 5.00 215.00 43.00 3.00 270.00 90.00 24799.00 5734.00 550.88 $ 1.27 1. dependency er-\n",
            "ror 2. URL 403 er-\n",
            "ror3\n",
            "10 3.00 93.00 31.00 3.00 254.00 84.67 24109.00 5363.00 438.50 $ 0.92 1. dependency er-\n",
            "ror 2. missing main\n",
            "func.4\n",
            "Avg. 4.71 191.57 42.98 3.00 240.00 80.00 26626.86 6218.00 516.71 $1.12 0.51 (only consider\n",
            "item scored 2, 3 or\n",
            "4)3.36\n",
            "29\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "MetaGPT is a new meta-programming framework that helps multiple AI agents work together like a team of humans. It does this by using \"Standardized Operating Procedures\" or SOPs, which are like guidelines for how different roles should interact and what kind of work they should produce. \n",
            "\n",
            "This approach helps to avoid common problems in AI teamwork, such as illogical outputs or agents getting stuck in unproductive conversations. MetaGPT has been tested on tasks like writing code, where it outperforms other systems, especially when dealing with complex software projects.\n",
            "\n",
            "This document introduces MetaGPT, an innovative framework designed for autonomous software development. MetaGPT leverages the strengths of large language models (LLMs) and incorporates a structured approach inspired by the software development life cycle. \n",
            "\n",
            "The key innovation of MetaGPT lies in its multi-agent framework. Each agent in MetaGPT embodies a specific role within the software development process, such as product manager, architect, engineer, and QA engineer. These agents collaborate seamlessly, communicating through structured documents and diagrams to ensure clarity and completeness. \n",
            "\n",
            "Furthermore, MetaGPT emphasizes an iterative programming approach with executable feedback. This means that the code generated undergoes continuous testing and refinement, enhancing its quality and functionality.  \n",
            "\n",
            "Through extensive experiments on public programming benchmarks and a specifically curated software development dataset, MetaGPT demonstrates superior performance compared to existing LLMs and other autonomous agents. Its effectiveness is attributed to the structured communication, role specialization, and iterative feedback mechanism.\n",
            "\n",
            "This research introduces MetaGPT, a new meta-programming framework that uses Standard Operating Procedures (SOPs) to improve the problem-solving abilities of multi-agent systems powered by Large Language Models (LLMs). MetaGPT simulates a software company with different roles, workflows, and sharing mechanisms. It uses an executable feedback system to improve the quality of code produced. Experiments show that MetaGPT performs very well on various benchmarks, demonstrating the potential of using human-like SOPs in artificial multi-agent systems.\n",
            "\n",
            "This document describes a \"Natural Language-Based Society of Mind\" (NLSOM) that uses an \"Economy of Minds\" (EOM) framework.  The EOM is a Reinforcement Learning framework for a society of LLMs and other agents that uses the principles of supply and demand to assign credit to agents that contribute to economic success.  The agent-based platform DeepWisdom (AgentStore4) is compatible with the credit assignment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding costs, and users or other agents can purchase services through an API. Developers can build new agents and collaborate within the community.\n",
            "\n",
            "MetaGPT is a novel framework that leverages the capabilities of large language models (LLMs) to build different types of software applications by emulating the workflow of a software development team.  MetaGPT uses a team of specialized agents, each playing a specific role in the software development process, such as product manager, architect, project manager, engineer, and QA engineer. These agents communicate and collaborate with each other through a structured messaging and feedback mechanism, ensuring efficient and effective software development. MetaGPT outperforms existing code generation methods, including those based on general intelligent agents and chat-based code generation, in terms of code executability and adherence to user requirements.\n",
            "\n",
            "MetaGPT is a framework that uses multiple AI agents to complete tasks such as software development.  It employs a structured approach to reduce communication errors and improve code execution.  MetaGPT has been shown to outperform other language models, such as GPT-3.5 and Deepseek Coder 33B, in terms of code executability and efficiency.  While MetaGPT offers advantages in software development, it still faces challenges such as handling UI/frontend tasks and addressing real-world application requirements.  Additionally, ethical considerations arise concerning potential job displacement and the need for transparency and accountability in AI-generated code.\n",
            "\n",
            "This document summarizes the effort and cost of fixing bugs for ten work items. On average, each work item required 4.71 hours to fix and cost $1.12. The most common issues encountered were missing PNG files, compile bugs, dependency errors, and module not found errors.\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is the summary of the document?\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "A new framework uses a team of specialized AI agents that mimic the roles of a software development team to build different types of software applications. This framework improves the efficiency and effectiveness of software development through structured communication and feedback mechanisms among the agents.  This approach has been shown to be more effective than other code generation methods. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = vertex_gemini.predict_and_call(\n",
        "    [summary_tool],\n",
        "    \"What is the summary of the document?\",\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6T_TQ-fByVF",
        "outputId": "540410cc-66a6-4c80-8971-05c7c9514b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_message user: What are the MetaGPT comparisons with ChatDev described on page 8?\n",
            "Function Calling, No Text Content\n",
            "=== Calling Function ===\n",
            "Calling function: vector_query with args: {\"query\": \"MetaGPT comparisons with ChatDev described on page 8\", \"page_numbers\": [\"8\"]}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information is below.\n",
            "---------------------\n",
            "page_label: 8\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 5: Demo softwares developed by MetaGPT.\n",
            "in these two public benchmarks. Moreover, as shown in Table 1, MetaGPT outperforms ChatDev on\n",
            "the challenging SoftwareDev dataset in nearly all metrics. For example, considering the executabil-\n",
            "ity, MetaGPT achieves a score of 3.75, which is very close to 4 (flawless). Besides, it takes less time\n",
            "(503 seconds), clearly less than ChatDev. Considering the code statistic and the cost of human revi-\n",
            "sion, it also significantly outperforms ChatDev. Although MetaGPT requires more tokens (24,613\n",
            "or 31,255 compared to 19,292), it needs only 126.5/124.3 tokens to generate one line of code. In\n",
            "contrast, ChatDev uses 248.9 tokens. These results highlight the benefits of SOPs in collabora-\n",
            "tions between multiple agents. Additionally, we demonstrate the autonomous software generation\n",
            "capabilities of MetaGPT through visualization samples (Figure 5). For additional experiments and\n",
            "analysis, please refer to Appendix C.\n",
            "Table 1: The statistical analysis on SoftwareDev.\n",
            "Statistical Index ChatDev MetaGPT w/o Feedback MetaGPT\n",
            "(A)Executability 2.25 3.67 3.75\n",
            "(B)Cost#1: Running Times (s) 762 503 541\n",
            "(B)Cost#2: Token Usage 19,292 24,613 31,255\n",
            "(C)Code Statistic#1: Code Files 1.9 4.6 5.1\n",
            "(C)Code Statistic#2: Lines of Code per File 40.8 42.3 49.3\n",
            "(C)Code Statistic#3: Total Code Lines 77.5 194.6 251.4\n",
            "(D)Productivity 248.9 126.5 124.3\n",
            "(E)Human Revision Cost 2.5 2.25 0.83\n",
            "4.3 C APABILITIES ANALYSIS\n",
            "Compared to open-source baseline methods such as AutoGPT and autonomous agents such as\n",
            "AgentVerse and ChatDev, MetaGPT offers functions for software engineering tasks. As presented\n",
            "in Table 2, our framework encompasses a wide range of abilities to handle complex and specialized\n",
            "development tasks efficiently. Incorporating SOPs (e.g., role-play expertise, structured communi-\n",
            "cation, streamlined workflow) can significantly improve code generation. Other baseline methods\n",
            "8\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: MetaGPT comparisons with ChatDev described on page 8\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "One system achieves nearly perfect scores in terms of executability and takes less time to complete tasks.  This system also generates more lines of code, despite using a similar number of tokens per line.  In conclusion, incorporating standard operating procedures for role-play expertise, structured communication, and streamlined workflow can significantly improve code generation. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = vertex_gemini.predict_and_call(\n",
        "    [vector_query_tool, summary_tool],\n",
        "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\",\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyo1l6vnB7U1",
        "outputId": "5ea0f8df-4605-4b96-f174-0956b84c5d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-06', 'last_modified_date': '2024-06-06'}\n"
          ]
        }
      ],
      "source": [
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "314M6wLmB8vt",
        "outputId": "b204a56f-9aed-426f-d796-7fff5ef9bd9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_message user: What is a summary of the paper?\n",
            "Function Calling, No Text Content\n",
            "=== Calling Function ===\n",
            "Calling function: summary_query with args: {\"query\": \"What is a summary of the paper?\"}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "page_label: 1\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "METAGPT: M ETA PROGRAMMING FOR A\n",
            "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
            "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
            "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
            "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
            "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
            "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
            "5Nanjing University,6University of Pennsylvania,\n",
            "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
            "ABSTRACT\n",
            "Remarkable progress has been made on automated problem solving through so-\n",
            "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
            "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
            "complex tasks, however, are complicated through logic inconsistencies due to\n",
            "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
            "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
            "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
            "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
            "streamlined workflows, thus allowing agents with human-like domain expertise\n",
            "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
            "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
            "complex tasks into subtasks involving many agents working together. On col-\n",
            "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
            "solutions than previous chat-based multi-agent systems. Our project can be found\n",
            "at https://github.com/geekan/MetaGPT.\n",
            "1 I NTRODUCTION\n",
            "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
            "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
            "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
            "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
            "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
            "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
            "et al., 2023; Qian et al., 2023).\n",
            "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
            "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
            "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
            "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
            "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
            "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
            "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
            "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
            "(PRDs) using a standardized structure, to guide the developmental process.\n",
            "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
            "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
            "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
            "∗These authors contributed equally to this work.\n",
            "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
            "1\n",
            "\n",
            "page_label: 2\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
            "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
            "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
            "(e.g., Product Manager, Architect, Engineer, etc.).\n",
            "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
            "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
            "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
            "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
            "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
            "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
            "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
            "lunch?” – Bob (Architect).\n",
            "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
            "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
            "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
            "2006; Finn et al., 2017).\n",
            "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
            "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
            "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
            "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
            "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
            "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
            "ing how agent-based techniques can enhance meta-programming.\n",
            "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
            "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
            "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
            "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
            "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
            "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
            "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
            "We summarize our contributions as follows:\n",
            "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
            "2\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "•We introduce MetaGPT, a meta-programming framework for multi-agent collaboration based on\n",
            "LLMs. It is highly convenient and flexible, with well-defined functions like role definition and\n",
            "message sharing, making it a useful platform for developing LLM-based multi-agent systems.\n",
            "•Our innovative integration of human-like SOPs throughout MetaGPT’s design significantly en-\n",
            "hances its robustness, reducing unproductive collaboration among LLM-based agents. Furthermore,\n",
            "we introduce a novel executive feedback mechanism that debugs and executes code during runtime,\n",
            "significantly elevating code generation quality (e.g., 5.4% absolute improvement on MBPP).\n",
            "•We achieve state-of-the-art performance on HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021). Extensive results convincingly validate MetaGPT, suggesting that it is a promising\n",
            "meta-programming framework for developing LLM-based multi-agent systems.\n",
            "2 R ELATED WORK\n",
            "Automatic Programming The roots of automatic programming reach back deep into the previ-\n",
            "ous century. In 1969, Waldinger & Lee (1969) introduced “PROW,” a system designed to accept\n",
            "program specifications written in predicate calculus, generate algorithms, and create LISP imple-\n",
            "mentations (McCarthy, 1978). Balzer (1985) and Soloway (1986) made efforts to advance auto-\n",
            "matic programming and identified potential methods to achieve it. Recent approaches use natural\n",
            "language processing (NLP) techniques (Ni et al., 2023; Skreta et al., 2023; Feng et al., 2020; Li\n",
            "et al., 2022; Chen et al., 2018; 2021b; Zhang et al., 2023). Automatic programming has grown into\n",
            "an industry delivering paid functions such as Microsoft Copilot. Lately, LLMs-based agents (Yao\n",
            "et al., 2022; Shinn et al., 2023; Lin et al., 2023) have advanced automatic programming develop-\n",
            "ment. Among them, ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023) utilize a chain of\n",
            "thought prompts (Wei et al., 2022) to generate reasoning trajectories and action plans with LLMs.\n",
            "Both works demonstrate the effectiveness of the ReAct style loop of reasoning as a design paradigm\n",
            "for empowering automatic programming. Additionally, ToolFormer (Schick et al., 2023) can learn\n",
            "how to use external tools through simple APIs. The research most closely aligned with our work\n",
            "by Li et al. (2023) proposes a straightforward role-play framework for programming that involves\n",
            "communication between agents playing different roles. Qian et al. (2023) utilizes multiple agents for\n",
            "software development. Although existing papers (Li et al., 2023; Qian et al., 2023) have improved\n",
            "productivity, they have not fully tapped into effective workflows with structured output formats.\n",
            "This makes it harder to deal with complex software engineering issues.\n",
            "LLM-Based Multi-Agent Frameworks Recently, LLM-based autonomous agents have gained\n",
            "tremendous interest in both industry and academia (Wang et al., 2023b). Many works (Chen et al.,\n",
            "2024; Wang et al., 2023c; Du et al., 2023; Zhuge et al., 2023; Hao et al., 2023; Akata et al., 2023)\n",
            "have improved the problem-solving abilities of LLMs by integrating discussions among multiple\n",
            "agents. Stable-Alignment (Liu et al., 2023) creates instruction datasets by deriving consensus on\n",
            "value judgments through interactions across a sandbox with LLM agents. Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks.\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks. Besides, LLM-based agents face the challenges of “assistant repeated instruc-\n",
            "tion” or “infinite loop of message” (Talebirad & Nadiri, 2023; Li et al., 2023). These challenges\n",
            "become more urgent in task-oriented collaborations, which require consistent and mutually benefi-\n",
            "cial interactions (Elazar et al., 2021; Wang et al., 2022; Jiang et al., 2023). This motivates our focus\n",
            "on applying advanced concepts such as Standard Operating Procedures in software development to\n",
            "multi-agent frameworks.\n",
            "3\n",
            "\n",
            "page_label: 4\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 2: An example of the communication protocol (left) and iterative programming with exe-\n",
            "cutable feedback (right). Left: Agents use a shared message pool to publish structured messages.\n",
            "They can also subscribe to relevant messages based on their profiles. Right : After generating the\n",
            "initial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past\n",
            "messages stored in memory and compares them with the PRD, system design, and code files.\n",
            "3 M ETAGPT: A M ETA-PROGRAMMING FRAMEWORK\n",
            "MetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 pro-\n",
            "vides an explanation of role specialization, workflow and structured communication in this frame-\n",
            "work, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2\n",
            "presents a communication protocol that enhances role communication efficiency. We also imple-\n",
            "ment structured communication interfaces and an effective publish-subscribe mechanism. These\n",
            "methods enable agents to obtain directional information from other roles and public information\n",
            "from the environment. Finally, we introduce executable feedback—a self-correction mechanism for\n",
            "further enhancing code generation quality during run-time in Sec. 3.3.\n",
            "3.1 A GENTS IN STANDARD OPERATING PROCEDURES\n",
            "Specialization of Roles Unambiguous role specialization enables the breakdown of complex work\n",
            "into smaller and more specific tasks. Solving complex tasks or problems often requires the collab-\n",
            "oration of agents with diverse skills and expertise, each contributing specialized outputs tailored to\n",
            "specific issues.\n",
            "In a software company, a Product Manager typically conducts business-oriented analysis and derives\n",
            "insights, while a software engineer is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is a summary of the paper?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design, the information is\n",
            "directed towards the Project Manager for task distribution. Engineers proceed to execute the des-\n",
            "ignated classes and functions as outlined (detailed in Figure 2). In the following stage, the QA\n",
            "Engineer formulates test cases to enforce stringent code quality. In the final step, MetaGPT pro-\n",
            "duces a meticulously crafted software solution. We provide a detailed schematic (Figure 3) and a\n",
            "concrete instance (Appendix B) of the SOP workflow in MetaGPT.\n",
            "3.2 C OMMUNICATION PROTOCOL\n",
            "Structured Communication Interfaces Most current LLM-based multi-agent frameworks (Li\n",
            "et al., 2023; Zhuge et al., 2023; Zhang et al., 2023; Park et al., 2023) utilize unconstrained natural\n",
            "language as a communication interface.\n",
            "However, despite the versatility of natural language, a question arises: does pure natural language\n",
            "communication suffice for solving complex tasks? For example, in the telephone game (or Chinese\n",
            "5\n",
            "\n",
            "page_label: 6\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "whispers)2, after several rounds of communication, the original information may be quite distorted.\n",
            "Inspired by human social structures, we propose using structured communication to formulate the\n",
            "communication of agents. We establish a schema and format for each role and request that individ-\n",
            "uals provide the necessary outputs based on their specific role and context.\n",
            "As shown in Figure 3, the Architect agent generates two outputs: the system interface design and a\n",
            "sequence flow diagram. These contain system module design and interaction sequences, which serve\n",
            "as important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT\n",
            "communicate through documents and diagrams (structured outputs) rather than dialogue. These\n",
            "documents contain all necessary information, preventing irrelevant or missing content.\n",
            "Publish-Subscribe Mechanism Sharing information is critical in collaboration. For instance,\n",
            "Architects and Engineers often need to reference PRDs. However, communicating this information\n",
            "each time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023;\n",
            "Zhang et al., 2023), can complicate the communication topology, resulting in inefficiencies.\n",
            "To address this challenge, a viable approach is to store information in a global message pool . As\n",
            "shown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange\n",
            "messages directly. These agents not only publish their structured messages in the pool but also access\n",
            "messages from other entities transparently. Any agent can directly retrieve required information\n",
            "from the shared pool, eliminating the need to inquire about other agents and await their responses.\n",
            "This enhances communication efficiency.\n",
            "Sharing all information with every agent can lead to information overload. During task execution,\n",
            "an agent typically prefers to receive only task-related information and avoid distractions through\n",
            "irrelevant details. Effective management and dissemination of this information play a crucial role.\n",
            "We offer a simple and effective solution- subscription mechanism (in Figure 2 (left)). Instead of\n",
            "relying on dialogue, agents utilize role-specific interests to extract relevant information. They can\n",
            "select information to follow based on their role profiles. In practical implementations, an agent\n",
            "activates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3,\n",
            "the Architect mainly focuses on PRDs provided by the Product Manager, while documents from\n",
            "roles such as the QA Engineer might be of lesser concern.\n",
            "3.3 I TERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK\n",
            "In daily programming tasks, the processes of debugging and optimization play important roles.\n",
            "However, existing methods often lack a self-correction mechanism, which leads to unsuccessful code\n",
            "generation. Previous work introduced non-executable code review and self-reflection (Zhao et al.,\n",
            "2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in\n",
            "ensuring code executability and runtime correctness.\n",
            "Our first MetaGPT implementations overlooked certain errors during the review process, due to\n",
            "LLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we\n",
            "introduce an executable feedback mechanism to improve the code iteratively. More specifically, as\n",
            "shown in Figure 2, the Engineer is asked to write code based on the original product requirements\n",
            "and design.\n",
            "This enables the Engineer to continuously improve code using its own historical execution and\n",
            "debugging memory. To obtain additional information, the Engineer writes and executes the corre-\n",
            "sponding unit test cases, and subsequently receives the test results. If satisfactory, additional devel-\n",
            "opment tasks are initiated. Otherwise the Engineer debugs the code before resuming programming.\n",
            "This iterative testing process continues until the test is passed or a maximum of 3 retries is reached.\n",
            "4 E XPERIMENTS\n",
            "4.1 E XPERIMENTAL SETTING\n",
            "Datasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021), and a self-generated, more challenging software development benchmark named Soft-\n",
            "2https://en.wikipedia.org/wiki/Chinese whispers\n",
            "6\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "wareDev: (1) HumanEval includes 164 handwritten programming tasks. These tasks encompass\n",
            "function specifications, descriptions, reference codes, and tests. (2) MBPP consists of 427 Python\n",
            "tasks. These tasks cover core concepts and standard library features and include descriptions, ref-\n",
            "erence codes, and automated tests. (3) Our SoftwareDev dataset is a collection of 70 representa-\n",
            "tive examples of software development tasks, each with its own task prompt (see Table 8). These\n",
            "tasks have diverse scopes (See Figure 5), such as mini-games, image processing algorithms, data\n",
            "visualization. They offer a robust testbed for authentic development tasks. Contrary to previous\n",
            "datasets (Chen et al., 2021a; Austin et al., 2021), SoftwareDev focuses on the engineering aspects.\n",
            "In the comparisons, we randomly select seven representative tasks for evaluation.\n",
            "Evaluation Metrics For HuamnEval and MBPP, we follow the unbiased version of Pass @ kas\n",
            "presented by (Chen et al., 2021a; Dong et al., 2023), to evaluate the functional accuracy of the top-k\n",
            "generated codes: Pass @ k=EProblems\u0014\n",
            "1−(n−c\n",
            "k)\n",
            "(n\n",
            "k)\u0015\n",
            ".\n",
            "For SoftwareDev, we prioritize practical use and evaluate performance through human evaluations\n",
            "(A, E) or statistical analysis (B, C, D): (A)Executability: this metric rates code from 1 (failure/non-\n",
            "functional) to 4 (flawless). ‘1’ is for non-functional, ‘2’ for runnable but imperfect, ‘3’ for nearly\n",
            "perfect, and ‘4’ for flawless code. (B)Cost: the cost evaluations here include the (1) running time,\n",
            "(2) token usage, and (3) expenses. (C)Code Statistics: this includes (1) code files, (2) lines of code\n",
            "per file, and (3) total code lines. (D)Productivity: basically, it is defined as the number of token\n",
            "usage divided by the number of lines of code, which refers to the consumption of tokens per code\n",
            "line. (E)Human Revision Cost: refers to times of manual code corrections, which tackle problems\n",
            "like package import errors, incorrect class names, or incomplete reference paths. Typically, each\n",
            "correction involves up to 3 lines of code.\n",
            "Baselines We compare our method with recent domain-specific LLMs in the code generation field,\n",
            "including AlphaCode (Li et al., 2022), Incoder (Fried et al., 2022), CodeGeeX (Zheng et al., 2023),\n",
            "CodeGen (Nijkamp et al., 2023), CodeX (Chen et al., 2021a), and CodeT (Chen et al., 2022) and\n",
            "general domain LLMs such as PaLM (Chowdhery et al., 2022), and GPT-4 (OpenAI, 2023). Several\n",
            "results of baselines (such as Incoder, CodeGeeX) are provided by Dong et al. (2023). In HumanEval\n",
            "and MBPP, we slightly modified the prompts to align with response format requirements. These\n",
            "modifications aim to address format-specific issues (i.e., Python problems). With the SoftwareDev\n",
            "benchmark, we provide a comprehensive comparison between MetaGPT, AutoGPT (Torantulino\n",
            "et al., 2023), LangChain (Chase, 2022) with Python Read-Eval-Print Loop (REPL) tool3, Agent-\n",
            "Verse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "4.2 M AINRESULT\n",
            "AlphaCode(1.1B)\n",
            "Incoder (6.7B)\n",
            "CodeGeeX (13B)17.1\n",
            "—15.2 17.6 18.926.9\n",
            "CodeGeeX-Mono(16.1B)32.938.6\n",
            "GPT-467.0\n",
            "—\n",
            "MetaGPT\n",
            "(w/o Feedback)81.7 82.3Pass@1 of MBPP  and HumanEval (%)\n",
            "PaLM Coder(540B)36.047.0\n",
            "Codex (175B)47.058.1\n",
            "Codex + CodeT65.8 67.7\n",
            "HumanEval\n",
            "MBPP\n",
            "MetaGPT85.9 87.7\n",
            "Figure 4: Pass rates on the MBPP and HumanEval with a single attempt.\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks.\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks. When MetaGPT collaborates with GPT-4, it significantly im-\n",
            "proves the Pass @ kin the HumanEval benchmark compared to GPT-4. It achieves 85.9% and 87.7%\n",
            "3https://en.wikipedia.org/wiki/Read–eval–print loop\n",
            "7\n",
            "\n",
            "page_label: 8\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 5: Demo softwares developed by MetaGPT.\n",
            "in these two public benchmarks. Moreover, as shown in Table 1, MetaGPT outperforms ChatDev on\n",
            "the challenging SoftwareDev dataset in nearly all metrics. For example, considering the executabil-\n",
            "ity, MetaGPT achieves a score of 3.75, which is very close to 4 (flawless). Besides, it takes less time\n",
            "(503 seconds), clearly less than ChatDev. Considering the code statistic and the cost of human revi-\n",
            "sion, it also significantly outperforms ChatDev. Although MetaGPT requires more tokens (24,613\n",
            "or 31,255 compared to 19,292), it needs only 126.5/124.3 tokens to generate one line of code. In\n",
            "contrast, ChatDev uses 248.9 tokens. These results highlight the benefits of SOPs in collabora-\n",
            "tions between multiple agents. Additionally, we demonstrate the autonomous software generation\n",
            "capabilities of MetaGPT through visualization samples (Figure 5). For additional experiments and\n",
            "analysis, please refer to Appendix C.\n",
            "Table 1: The statistical analysis on SoftwareDev.\n",
            "Statistical Index ChatDev MetaGPT w/o Feedback MetaGPT\n",
            "(A)Executability 2.25 3.67 3.75\n",
            "(B)Cost#1: Running Times (s) 762 503 541\n",
            "(B)Cost#2: Token Usage 19,292 24,613 31,255\n",
            "(C)Code Statistic#1: Code Files 1.9 4.6 5.1\n",
            "(C)Code Statistic#2: Lines of Code per File 40.8 42.3 49.3\n",
            "(C)Code Statistic#3: Total Code Lines 77.5 194.6 251.4\n",
            "(D)Productivity 248.9 126.5 124.3\n",
            "(E)Human Revision Cost 2.5 2.25 0.83\n",
            "4.3 C APABILITIES ANALYSIS\n",
            "Compared to open-source baseline methods such as AutoGPT and autonomous agents such as\n",
            "AgentVerse and ChatDev, MetaGPT offers functions for software engineering tasks. As presented\n",
            "in Table 2, our framework encompasses a wide range of abilities to handle complex and specialized\n",
            "development tasks efficiently. Incorporating SOPs (e.g., role-play expertise, structured communi-\n",
            "cation, streamlined workflow) can significantly improve code generation. Other baseline methods\n",
            "8\n",
            "\n",
            "page_label: 9\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 2: Comparison of capabilities for MetaGPT and other approaches. ‘!’ indicates the\n",
            "presence of a specific feature in the corresponding framework, ‘ %’ its absence.\n",
            "Framework Capabiliy AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "PRD generation % % % % !\n",
            "Tenical design genenration % % % % !\n",
            "API interface generation % % % % !\n",
            "Code generation ! ! ! ! !\n",
            "Precompilation execution % % % % !\n",
            "Role-based task management % % % ! !\n",
            "Code review % % ! ! !\n",
            "Table 3: Ablation study on roles. ‘#’ denotes ‘The number of’, ‘Product’ denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is a summary of the paper?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "‘Product’ denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass @1 on Hu-\n",
            "manEval and MBPP, respectively. Besides, Table 1 shows that the feedback mechanism improves\n",
            "feasibility (3.67 to 3.75) and reduces the cost of human revisions (2.25 to 0.83). These results\n",
            "illustrate how our designed feedback mechanism can produce higher-quality code. Additional quan-\n",
            "titative results of MetaGPT and MetaGPT without executable feedback are shown in Table 4 and\n",
            "Table 9.\n",
            "5 C ONCLUSION\n",
            "This work introduces MetaGPT, a novel meta-programming framework that leverages SOPs to en-\n",
            "hance the problem-solving capabilities of multi-agent systems based on Large Language Models\n",
            "(LLMs). MetaGPT models a group of agents as a simulated software company, analogous to simu-\n",
            "lated towns (Park et al., 2023) and the Minecraft Sandbox in V oyager (Wang et al., 2023a). MetaGPT\n",
            "leverages role specialization, workflow management, and efficient sharing mechanisms such as mes-\n",
            "sage pools and subscriptions, rendering it a flexible and portable platform for autonomous agents\n",
            "and multi-agent frameworks. It uses an executable feedback mechanism to enhance code generation\n",
            "quality during runtime. In extensive experiments, MetaGPT achieves state-of-the-art performance\n",
            "on multiple benchmarks. The successful integration of human-like SOPs inspires future research\n",
            "on human-inspired techniques for artificial multi-agent systems. We also view our work as an early\n",
            "attempt to regulate LLM-based multi-agent frameworks. See also the outlook (Appendix A) .\n",
            "9\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Acknowledgement\n",
            "We thank Sarah Salhi, the Executive Secretary of KAUST AI Initiative, and Yuhui Wang, Postdoc-\n",
            "toral Fellow at the KAUST AI Initiative, for helping to polish some of the text. We would like to\n",
            "express our gratitude to Wenyi Wang, a PhD student at the KAUST AI Initiative, for providing com-\n",
            "prehensive feedback on the paper and for helping to draft the outlook (Appendix A) with Mingchen.\n",
            "We also thank Zongze Xu, the vice president of DeepWisdom, for providing illustrative materials\n",
            "for AgentStore.\n",
            "Author Contributions\n",
            "Sirui Hong conducted most of the experiments and designed the executable feedback module. She\n",
            "also led the initial version of the write-up, supported by Ceyao Zhang, and also by Jinlin Wang and\n",
            "Zili Wang. Mingchen Zhuge designed the self-improvement module, discussed additional experi-\n",
            "ments, and led the current write-up. Jonathan Chen helped with the MBPP experiments, outlined\n",
            "the methods section, and contributed to the current write-up. Xiawu Zheng provided valuable guid-\n",
            "ance, reviewed and edited the paper. Yuheng Cheng contributed to the evaluation metric design and\n",
            "HumanEval experiments. Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Lingfeng Xiao helped\n",
            "with the MBPP experiments and comparisons to open-source baseline methods. Chenyu Ran cre-\n",
            "ated most of the illustrative figures. Chenglin Wu is the CEO of DeepWisdom, initiated MetaGPT,\n",
            "made the most significant code contributions to it, and advised this project. J ¨urgen Schmidhuber,\n",
            "Director of the AI Initiative at KAUST and Scientific Director of IDSIA, advised this project and\n",
            "helped with the write-up.\n",
            "REFERENCES\n",
            "Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz.\n",
            "Playing repeated games with large language models. arXiv preprint , 2023.\n",
            "Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\n",
            "Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large\n",
            "language models, 2021.\n",
            "Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew\n",
            "Goff, Jonathan Gray, Hengyuan Hu, et al. Human-level play in the game of diplomacy by com-\n",
            "bining language models with strategic reasoning. Science , 2022.\n",
            "Robert Balzer. A 15 year perspective on automatic programming. TSE, 1985.\n",
            "R.M. Belbin. Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\n",
            "Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,\n",
            "Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\n",
            "Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,\n",
            "Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-\n",
            "tios Chantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex\n",
            "Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,\n",
            "Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec\n",
            "Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob Mc-\n",
            "Grew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large\n",
            "language models trained on code, 2021a.\n",
            "10\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan,\n",
            "Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facili-\n",
            "tating multi-agent collaboration and exploring emergent behaviors in agents, 2023.\n",
            "Xinyun Chen, Chang Liu, and Dawn Song. Execution-guided neural program synthesis. In ICLR ,\n",
            "2018.\n",
            "Xinyun Chen, Dawn Song, and Yuandong Tian. Latent execution for neural program synthesis\n",
            "beyond domain-specific languages. NeurIPS , 2021b.\n",
            "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\n",
            "Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\n",
            "Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\n",
            "Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\n",
            "Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\n",
            "skaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\n",
            "Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret\n",
            "Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,\n",
            "Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\n",
            "Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\n",
            "nan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas\n",
            "Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,\n",
            "2022.\n",
            "T. DeMarco and T.R. Lister. Peopleware: Productive Projects and Teams . Addison-Wesley, 2013.\n",
            "URLhttps://books.google.co.uk/books?id=DVlsAQAAQBAJ .\n",
            "Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. Self-collaboration code generation via chatgpt. arXiv\n",
            "preprint , 2023.\n",
            "Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving\n",
            "factuality and reasoning in language models through multiagent debate, 2023.\n",
            "Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\n",
            "Sch¨utze, and Yoav Goldberg. Measuring and improving consistency in pretrained language mod-\n",
            "els.TACL , 2021.\n",
            "Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing\n",
            "Qin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained model for programming and natural\n",
            "languages. arXiv preprint , 2020.\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, and Liqiang Nie. Chatllm network:\n",
            "More brains, more intelligence. arXiv preprint , 2023.\n",
            "S. Hochreiter, A. S. Younger, and P. R. Conwell. Learning to learn using gradient descent. In Lecture\n",
            "Notes on Comp. Sci. 2130, Proc. Intl. Conf. on Artificial Neural Networks (ICANN-2001) , pp. 87–\n",
            "94. Springer: Berlin, Heidelberg, 2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is a summary of the paper?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "Heidelberg, 2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi Yang, and\n",
            "Soroush V osoughi. Training socially aligned language models in simulated human society. arXiv\n",
            "preprint , 2023.\n",
            "Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing\n",
            "Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with\n",
            "evol-instruct. arXiv preprint , 2023.\n",
            "Potsawee Manakul, Adian Liusie, and Mark JF Gales. Selfcheckgpt: Zero-resource black-box hal-\n",
            "lucination detection for generative large language models. arXiv preprint , 2023.\n",
            "Agile Manifesto. Manifesto for agile software development . Snowbird, UT, 2001.\n",
            "John McCarthy. History of lisp. In History of programming languages . 1978.\n",
            "Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-tau Yih, Sida Wang, and Xi Victoria\n",
            "Lin. Lever: Learning to verify language-to-code generation with execution. In ICML , 2023.\n",
            "Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese,\n",
            "and Caiming Xiong. Codegen: An open large language model for code with multi-turn program\n",
            "synthesis, 2023.\n",
            "OpenAI. Gpt-4 technical report, 2023.\n",
            "Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and\n",
            "Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint ,\n",
            "2023.\n",
            "Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and\n",
            "Maosong Sun. Communicative agents for software development, 2023.\n",
            "Baptiste Rozi `ere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi\n",
            "Adi, Jingyu Liu, Tal Remez, J ´er´emy Rapin, et al. Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements.\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements. Technical Report IDSIA-19-03, arXiv:cs.LO/0309048 v3, IDSIA,\n",
            "Manno-Lugano, Switzerland, December 2003.\n",
            "J. Schmidhuber. G ¨odel machines: Fully self-referential optimal universal self-improvers. In B. Go-\n",
            "ertzel and C. Pennachin (eds.), Artificial General Intelligence , pp. 199–226. Springer Verlag,\n",
            "2006. Variant available as arXiv:cs.LO/0309048.\n",
            "12\n",
            "\n",
            "page_label: 13\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "J. Schmidhuber. Ultimate cognition `a laG¨odel. Cognitive Computation , 1(2):177–193, 2009.\n",
            "J¨urgen Schmidhuber. Evolutionary principles in self-referential learning, or on learning how to\n",
            "learn: the meta-meta-... hook . PhD thesis, 1987.\n",
            "J¨urgen Schmidhuber. A ‘self-referential’weight matrix. In ICANN’93: Proceedings of the Interna-\n",
            "tional Conference on Artificial Neural Networks Amsterdam, The Netherlands 13–16 September\n",
            "1993 3 , 1993b.\n",
            "J¨urgen Schmidhuber. On learning to think: Algorithmic information theory for novel combinations\n",
            "of reinforcement learning controllers and recurrent neural world models. arXiv preprint , 2015.\n",
            "J¨urgen Schmidhuber, Jieyu Zhao, and Nicol N Schraudolph. Reinforcement learning with self-\n",
            "modifying policies. In Learning to learn . 1998.\n",
            "Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic\n",
            "memory and self-reflection. arXiv preprint , 2023.\n",
            "Marta Skreta, Naruki Yoshikawa, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen,\n",
            "Kourosh Darvish, Al ´an Aspuru-Guzik, Florian Shkurti, and Animesh Garg. Errors are useful\n",
            "prompts: Instruction guided task programming with verifier-assisted iterative prompting. arXiv\n",
            "preprint , 2023.\n",
            "Elliot Soloway. Learning to program =learning to construct mechanisms and explanations. Com-\n",
            "munications of the ACM , 1986.\n",
            "Yashar Talebirad and Amirhossein Nadiri. Multi-agent collaboration: Harnessing the power of\n",
            "intelligent llm agents, 2023.\n",
            "Torantulino et al. Auto-gpt. https://github.com/Significant-Gravitas/\n",
            "Auto-GPT , 2023.\n",
            "R. J. Waldinger and R. C. T. Lee. PROW: a step toward automatic program writing. In D. E. Walker\n",
            "and L. M. Norton (eds.), Proceedings of the 1st International Joint Conference on Artificial Intel-\n",
            "ligence (IJCAI) , 1969.\n",
            "Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan,\n",
            "and Anima Anandkumar. V oyager: An open-ended embodied agent with large language models.\n",
            "arXiv preprint , 2023a.\n",
            "Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\n",
            "Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\n",
            "arXiv preprint , 2023b.\n",
            "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\n",
            "ery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.\n",
            "arXiv preprint , 2022.\n",
            "Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. Unleashing\n",
            "cognitive synergy in large language models: A task-solving agent through multi-persona self-\n",
            "collaboration. arXiv preprint , 2023c.\n",
            "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\n",
            "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS ,\n",
            "2022.\n",
            "Michael Wooldridge and Nicholas R. Jennings. Pitfalls of agent-oriented development. In Pro-\n",
            "ceedings of the Second International Conference on Autonomous Agents , 1998. URL https:\n",
            "//doi.org/10.1145/280765.280867 .\n",
            "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\n",
            "React: Synergizing reasoning and acting in language models. arXiv preprint , 2022.\n",
            "Eric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. Self-taught optimizer (stop):\n",
            "Recursively self-improving code generation. arXiv preprint , 2023.\n",
            "13\n",
            "\n",
            "page_label: 14\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tian-\n",
            "min Shu, and Chuang Gan. Building cooperative embodied agents modularly with large language\n",
            "models. arXiv preprint , 2023.\n",
            "Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, and Stefan Wermter. Chat\n",
            "with the environment: Interactive multimodal perception using large language models. arXiv\n",
            "preprint , 2023.\n",
            "Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen,\n",
            "Andi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang. Codegeex: A pre-trained model for\n",
            "code generation with multilingual evaluations on humaneval-x, 2023.\n",
            "Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng,\n",
            "Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for building\n",
            "autonomous agents. arXiv preprint , 2023.\n",
            "Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, R ´obert Csord ´as, Anand\n",
            "Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki\n",
            "Irie, et al. Mindstorms in natural language-based societies of mind. arXiv preprint , 2023.\n",
            "14\n",
            "\n",
            "page_label: 15\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "A O UTLOOK\n",
            "A.1 S ELF-IMPROVEMENT MECHANISMS\n",
            "One limitation of the MetaGPT version in the main text of this paper is that each software project is\n",
            "executed independently. However, through active teamwork, a software development team should\n",
            "learn from the experience gained by developing each project, thus becoming more compatible and\n",
            "successful over time.\n",
            "This is somewhat related to the idea of recursive self-improvement, first informally proposed in\n",
            "1965 (Good, 1965), with first concrete implementations since 1987 (Schmidhuber, 1987; 1993b;\n",
            "Schmidhuber et al., 1998), culminating in the concept of mathematically optimal self-referential\n",
            "self-improvers (Schmidhuber, 2003; 2009). Generally speaking, a system should learn from experi-\n",
            "ence in the real world, and meta-learn better learning algorithms from experiences of learning, and\n",
            "meta-meta-learn better meta-learning algorithms from experiences of meta-learning, etc., without\n",
            "any limitations except those of computability and physics.\n",
            "More recent, somewhat related work leverages the reasoning ability of Large Language Models\n",
            "(LLMs) and recursively improves prompts of LLMs, to improve performance on certain downstream\n",
            "tasks (Fernando et al., 2023; Zelikman et al., 2023), analogous to the adaptive prompt engineer of\n",
            "2015 (Schmidhuber, 2015) where one neural network learns to generate sequence of queries or\n",
            "prompts for another pre-trained neural network whose answers may help the first network to learn\n",
            "new tasks more quickly.\n",
            "In our present work, we also explore a self-referential mechanism that recursively modifies the con-\n",
            "straint prompts of agents based on information they observe during software development. Our\n",
            "initial implementation works as follows. Prior to each project, every agent in the software company\n",
            "reviews previous feedback and makes necessary adjustments to their constraint prompts. This en-\n",
            "ables them to continuously learn from past project experiences and enhance the overall multi-agent\n",
            "system by improving each individual in the company. We first establish a handover feedback action\n",
            "for each agent. This action is responsible for critically summarizing the information received dur-\n",
            "ing the development of previous projects and integrating this information in an updated constraint\n",
            "prompt. The summarized information is stored in long-term memory such that it can be inherited\n",
            "by future constraint prompt updates. When initiating a new project, each agent starts with a react\n",
            "action. Each agent evaluates the received feedback and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is a summary of the paper?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "agent evaluates the received feedback and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically, AgentStore allows users to subscribe to agents according to their demands\n",
            "4http://beta.deepwisdom.ai\n",
            "15\n",
            "\n",
            "page_label: 16\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "and pay according to their usage. Moreover, users can purchase additional capabilities to expand the\n",
            "plug-and-play functions of their existing agents. This allows users to gradually upgrade their agents.\n",
            "Within the MetaGPT framework, AgentStore can support the collaboration of various agents. Users\n",
            "can collect several agents together to carry out more complex tasks or projects, and all the agents\n",
            "share and comply with development and communication protocols defined in MetaGPT.\n",
            "Figure 6: AgentStore is a platform dedicated to serving users in the creation and development of\n",
            "agents within the MetaGPT framework. This platform provides users with an operational interface,\n",
            "allowing users to easily manage a variety of agents with different emotions, personalities, and capa-\n",
            "bilities for specific tasks.\n",
            "16\n",
            "\n",
            "page_label: 17\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "B A D EMO OF THE EXECUTION\n",
            "In this section, we outline the complete process of software development using MetaGPT. It begins\n",
            "with a user’s input command (as shown in Appendix B.1) and ends with software designed according\n",
            "to the user’s specifications.\n",
            "B.1 U SERINPUT\n",
            "Upon receiving an instruction from the user, MetaGPT collaborates with a professional development\n",
            "team to fulfill the task. Here is a demo of user input:\n",
            "User input\n",
            "1write a python3 GUI app such that you can draw an image with it\n",
            "B.2 M ETAGPT DEVELOPMENT PROCESS\n",
            "Now we provide a step-by-step explanation of the standardized output process for each agent.\n",
            "Product Manager The Product Manager generates a Product Requirement Document (PRD), as\n",
            "detailed in the specified documentation. This document encompasses goals, user stories, competitive\n",
            "analysis, requirement analysis and requirement pool. Additionally, a competitive quadrant chart is\n",
            "produced (see Figure 7). Subsequently, these documents and charts are handed over to the architect\n",
            "for system design.\n",
            "Product Requirement Document\n",
            "1## Original Requirements\n",
            "2The boss requires a Python3 GUI color meter that outputs the RGB values when it moves.\n",
            "3\n",
            "4## Product Goals\n",
            "5‘‘‘python\n",
            "6[\n",
            "7 \"Create a user-friendly GUI color meter\",\n",
            "8 \"Ensure the color meter accurately outputs RGB values\",\n",
            "9 \"Ensure the color meter updates RGB values in real-time as it moves\"\n",
            "10]\n",
            "11‘‘‘\n",
            "12\n",
            "13## User Stories\n",
            "14‘‘‘python\n",
            "15[\n",
            "16 \"As a user, I want to select any color on the screen, so that I can get its RGB values\",\n",
            "17 \"As a user, I want the RGB values to update in real-time as I move the color meter, so that I\n",
            ",→can get accurate color information\",\n",
            "18 \"As a user, I want a simple and intuitive interface, so that I can easily use the color meter\"\n",
            "19]\n",
            "20‘‘‘\n",
            "21\n",
            "22## Competitive Analysis\n",
            "23‘‘‘python\n",
            "24[\n",
            "25 \"Color Cop: A popular color picker for Windows. It’s simple and easy to use, but lacks real-\n",
            ",→time RGB value updates\",\n",
            "26 \"Just Color Picker: Offers real-time color picking and multiple color code formats. However,\n",
            ",→its interface is cluttered and not very user-friendly\",\n",
            "27 \"Instant Eyedropper: A simple color picker that lives in the system tray. It’s convenient but\n",
            ",→lacks advanced features\",\n",
            "28 \"ColorZilla: A color picker extension for browsers. It’s convenient for web design but not\n",
            ",→suitable for desktop applications\",\n",
            "29 \"ColorPic: Offers color palettes and mixer tools. It’s feature-rich but can be overwhelming\n",
            ",→for simple tasks\"\n",
            "30]\n",
            "31‘‘‘\n",
            "17\n",
            "\n",
            "page_label: 18\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1\n",
            "2## Requirement Analysis\n",
            "3The product should be a Python3 GUI application that serves as a color meter. It should allow\n",
            ",→users to select any color on the screen and display the corresponding RGB values. The RGB\n",
            ",→ values should update in real-time as the color meter moves. The interface should be\n",
            ",→simple and user-friendly.\n",
            "4\n",
            "5## Requirement Pool\n",
            "6‘‘‘python\n",
            "7[\n",
            "8 (\"Design a user-friendly GUI for the color meter\", \"P0\"),\n",
            "9 (\"Implement color selection functionality\", \"P0\"),\n",
            "10 (\"Display RGB values of the selected color\", \"P0\"),\n",
            "11 (\"Update RGB values in real-time as the color meter moves\", \"P0\"),\n",
            "12 (\"Test the application for accuracy and performance\", \"P1\")\n",
            "13]\n",
            "14‘‘‘\n",
            "15\n",
            "16## UI Design draft\n",
            "17The UI should be minimalistic and intuitive. It should primarily consist of a color meter, which\n",
            ",→could be a magnified area of the screen that the user can move around. The RGB values of\n",
            ",→the currently selected color should be prominently displayed, updating in real-time as\n",
            ",→the color meter moves. The layout should be clean and uncluttered, with a focus on\n",
            ",→functionality and ease of use.\n",
            "18\n",
            "19## Anything UNCLEAR\n",
            "20There are no unclear points.\n",
            "Figure 7: The quadrant chart for the “Drawing App” generated by the product manager agent.\n",
            "18\n",
            "\n",
            "page_label: 19\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Architect Based on the requirements in PRD, the Architect agent devises technical specifications\n",
            "including system architecture diagrams and interface definitions. Initially, the Architect defines the\n",
            "overarching technical trajectory. Subsequently, the project’s architecture, including files, classes\n",
            "(Figure 8) and the sequence flow chart (Figure 12), is designed. The Architect’s documentation is\n",
            "then given to the project manager for task allocation and execution.\n",
            "System design\n",
            "1## Implementation approach\n",
            "2We will use Python’s Tkinter library to create the GUI for the color meter. Tkinter is a standard\n",
            ",→Python interface to the Tk GUI toolkit and is included with most Python installations. It\n",
            ",→ is simple to use and powerful enough for our needs.\n",
            "3\n",
            "4The color selection functionality will be implemented using the PIL (Pillow) library, which allows\n",
            ",→ us to capture the screen’s pixel data. By moving the mouse, we can get the RGB values of\n",
            ",→ the pixel under the mouse cursor in real-time.\n",
            "5\n",
            "6The RGB values will be displayed on the GUI using Tkinter’s Label widget. We will use Python’s\n",
            ",→threading library to update the RGB values in real-time as the color meter moves.\n",
            "7\n",
            "8The application will be tested for accuracy and performance using Python’s unittest library.\n",
            "9\n",
            "10## Python package name\n",
            "11‘‘‘python\n",
            "12\"color_meter\"\n",
            "13‘‘‘\n",
            "14\n",
            "15## File list\n",
            "16‘‘‘python\n",
            "17[\n",
            "18 \"main.py\",\n",
            "19 \"color_picker.py\",\n",
            "20 \"gui.py\",\n",
            "21 \"tests.py\"\n",
            "22]\n",
            "23‘‘‘\n",
            "24\n",
            "25## Anything UNCLEAR\n",
            "26The requirement is clear to me.\n",
            "Figure 8: Data structures and interface definitions for the “Drawing App” generated by the architect\n",
            "agent.\n",
            "Project Manager The Project Manager breaks down the project into a task list. Furthermore, each\n",
            "code file is analyzed based on its intended functionality and then treated as a separate task assigned\n",
            "to Engineers.\n",
            "19\n",
            "\n",
            "page_label: 20\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 9: The program call flow for the “Drawing App” generated by the architect agent.\n",
            "Tasks\n",
            "1## Required Python third-party packages\n",
            "2\n",
            "3‘‘‘python\n",
            "4\"\"\"\n",
            "5tkinter==8.6\n",
            "6Pillow==8.3.1\n",
            "7\"\"\"\n",
            "8‘‘‘\n",
            "9\n",
            "10## Required Other language third-party packages\n",
            "11‘‘‘python\n",
            "12\"\"\"\n",
            "13No third-party packages required in other languages.\n",
            "14\"\"\"\n",
            "15‘‘‘\n",
            "16\n",
            "17## Full API spec\n",
            "18‘‘‘python\n",
            "19\"\"\"\n",
            "20No APIs are used in this project.\n",
            "21\"\"\"\n",
            "22‘‘‘\n",
            "23\n",
            "24## Logic Analysis\n",
            "25‘‘‘python\n",
            "26[\n",
            "27 (\"main.py\", \"Contains the main application loop and initializes all the other components.\"),\n",
            "28 (\"canvas.py\", \"Implements the drawing canvas, responds to mouse events, and uses the selected\n",
            ",→tool and color.\"),\n",
            "29 (\"tools.py\", \"Implements the tool selection interface.\"),\n",
            "30 (\"color_picker.py\", \"Implements the color selection interface.\"),\n",
            "31 (\"file_manager.py\", \"Implements the file saving and opening functionality.\")\n",
            "32]\n",
            "33‘‘‘\n",
            "20\n",
            "\n",
            "page_label: 21\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1## Task list\n",
            "2‘‘‘python\n",
            "3[\n",
            "4 \"main.py\",\n",
            "5 \"canvas.py\",\n",
            "6 \"tools.py\",\n",
            "7 \"color_picker.py\",\n",
            "8 \"file_manager.py\"\n",
            "9]\n",
            "10‘‘‘\n",
            "11\n",
            "12## Shared Knowledge\n",
            "13‘‘‘python\n",
            "14\"\"\"\n",
            "15The ’Tkinter’ library is used for creating the GUI of the application. It provides various widgets\n",
            ",→ like frames and canvases which are used in this project.\n",
            "16The ’Pillow’ library is used for handling image files. It is used in the ’file_manager.py’ for\n",
            ",→saving and opening image files.\n",
            "17The ’main.py’ file is the entry point of the application. It initializes all the other components\n",
            ",→and starts the application loop.\n",
            "18\"\"\"\n",
            "19‘‘‘\n",
            "20\n",
            "21## Anything UNCLEAR\n",
            "22The project requirements and implementation approach are clear. However, we need to ensure that\n",
            ",→all team members are familiar with the Tkinter and Pillow libraries. If not, they may\n",
            ",→need some time to learn these libraries before starting the development.\n",
            "21\n",
            "\n",
            "page_label: 22\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Engineer Given the provided file structure and function definitions, an Engineer agent requires\n",
            "only fundamental development skills to complete the development tasks. Due to the large number\n",
            "of files, we present only one auto-generated code file here.\n",
            "Generated code (color picker.py)\n",
            "1import tkinter as tk\n",
            "2from tkinter import colorchooser\n",
            "3class ColorPicker:\n",
            "4 def __init__(self, root: tk.Tk, color: str = ’black’):\n",
            "5 self.frame = tk.Frame(root)\n",
            "6 self.color = color\n",
            "7\n",
            "8 self.color_button = tk.Button(self.frame, text=’Color’, command=self.select_color)\n",
            "9 self.color_button.pack(fill=’x’)\n",
            "10\n",
            "11 def select_color(self):\n",
            "12 color = colorchooser.askcolor()[1]\n",
            "13 if color is not None:\n",
            "14 self.color = color\n",
            "15\n",
            "16 def pack(self, **kwargs):\n",
            "17 self.frame.pack( **kwargs)\n",
            "18\n",
            "19 def get_color(self):\n",
            "20 return self.color\n",
            "QA Engineer Upon receiving the code output from the Engineer, the QA Engineer generates unit\n",
            "test code and reviews it to identify and fix any bugs, ensuring high-quality software.\n",
            "Generated Unit tests (test.py)\n",
            "1import unittest\n",
            "2import tkinter as tk\n",
            "3# You might want to move the ColorPicker class to another file, let’s say color_picker.py\n",
            "4# from color_picker import ColorPicker\n",
            "5\n",
            "6class TestColorPicker(unittest.TestCase):\n",
            "7\n",
            "8 def setUp(self):\n",
            "9 self.root = tk.Tk()\n",
            "10 self.cp = ColorPicker(self.root)\n",
            "11\n",
            "12 def tearDown(self):\n",
            "13 # This is important to close the tk window after tests\n",
            "14 self.root.destroy()\n",
            "15\n",
            "16 def test_initial_color(self):\n",
            "17 # Test the default color during initialization\n",
            "18 self.assertEqual(self.cp.get_color(), ’black’)\n",
            "19\n",
            "20 def test_set_and_get_color(self):\n",
            "21 # Test setting a new color and retrieving it\n",
            "22 new_color = ’#ffffff’ # white color\n",
            "23 self.cp.color = new_color\n",
            "24 self.assertEqual(self.cp.get_color(), new_color)\n",
            "25\n",
            "26\n",
            "27if __name__ == ’__main__’:\n",
            "28 unittest.main()\n",
            "Output Ultimately, as shown in Figure 10, MetaGPT generates a functional application named\n",
            "“Drawing App”.\n",
            "22\n",
            "\n",
            "page_label: 23\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 10: The “Drawing App” generated by MetaGPT.\n",
            "C E XPERIMENTS\n",
            "C.1 D ETAILS OF THE SOFTWARE DEVDATASET\n",
            "The SoftwareDev dataset includes 70 diverse software development tasks. Table 8 displays the\n",
            "names and detailed prompts of 11 tasks within the dataset. Note that the first seven tasks listed are\n",
            "used in the main experiments of this paper.\n",
            "C.2 A DDITIONAL RESULTS\n",
            "Quantitative results of MetaGPT As shown in Table 4, MetaGPT achieves an average score\n",
            "of 3.9, surpassing ChatDev’s score of 2.1 Zhao et al. (2023), which is based on the Chat chain.\n",
            "Compare the scores of general intelligent algorithms, including AutoGPT Torantulino et al. (2023),\n",
            "which all score 1.0, failing to generate executable code. We observe that the generated code is often\n",
            "short, lacks comprehensive logic, and tends to fail to handle cross-file dependencies correctly.\n",
            "While models such as AutoGPT (Torantulino et al., 2023), Langchain (Chase, 2022), and Agent-\n",
            "Verse (Chen et al., 2023) display robust general problem-solving capabilities, they lack an essential\n",
            "element for developing complex systems: systematically deconstructing requirements. Conversely,\n",
            "MetaGPT simplifies the process of transforming abstract requirements into detailed class and func-\n",
            "tion designs through a specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is a summary of the paper?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "designs through a specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1 1 2 4\n",
            "2048 game 1 1 1 1 4\n",
            "Snake game 1 1 1 3 4\n",
            "Brick breaker game 1 1 1 1 4\n",
            "Excel data process 1 1 1 4 4\n",
            "CRUD manage 1 1 1 2 4\n",
            "Average score 1.0 1.0 1.0 2.1 3.9\n",
            "Table 5: Performance of MetaGPT on SoftwareDev using different LLMs as agent backends.\n",
            "Model Open source Time(/s) # Lines Executability Revisions\n",
            "MetaGPT (w/ GPT-3.5) % 75.18 161.6 2.8 2.4\n",
            "MetaGPT (w/ GPT-4) % 552.94 178.2 3.8 1.2\n",
            "MetaGPT (w/ Deepseek Coder 33B) \" 1186.20 120.2 1.4 2.6\n",
            "Impact of Instruction Levels (High-level v.s.Detailed Instructions) Does the variation in the\n",
            "level of initial input from humans significantly influence performance outcomes? For examples:\n",
            "1.High-level prompt : Create a brick breaker game.\n",
            "2.Detailed prompt : Creating a brick breaker game. In a brick breaker game, the player\n",
            "typically controls a paddle at the bottom of the screen to bounce a ball towards a wall of\n",
            "bricks. The goal is to break all the bricks by hitting them with the ball.\n",
            "Additional experiments were conducted to investigate this aspect: we selected 5 tasks from Soft-\n",
            "wareDev, and constructed detailed prompts for them. Here are the experimental results:\n",
            "Table 6: Impact of Instruction Levels. The executability is scored on a grading system ranging\n",
            "from ‘1’ to ‘4’. A score of ‘1’ signifies complete failure, ‘2’ denotes runnable code, ‘3’ represents\n",
            "largely expected workflow, and ‘4’ indicates a perfect match to expectations.\n",
            "Model # Word Time(/s) Token usage # Lines Executability Productivity Reversions\n",
            "High-level 13.2 552.9 28384.2 178.2 3.8 163.8 1.2\n",
            "Detailed 42.2 567.8 29657.0 257.0 4.0 118.0 1.6\n",
            "We observe that: detailed prompts lead to better software projects with lower productivity ratios\n",
            "because of clearer requirements and functions, while simple inputs can still generate good enough\n",
            "software using MetaGPT with an executability rating of 3.8, which is comparable to the detailed\n",
            "prompt scenario. (Note that, Productivity = Token usage / Total Code Lines. The lower this ratio,\n",
            "the better.)\n",
            "The performance of GPT variants in HumanEval benchmark We use the GPT-4’s 67% Hu-\n",
            "manEval score (OpenAI, 2023) as our baseline, acknowledging its acceptance in the HumanEval\n",
            "benchmark. We further extend to experiments(five times) with GPT-4 (gpt-4-0613) and GPT-3.5-\n",
            "Turbo (gpt-3.5-turbo-0613) under various conditions to assess performance. (A)We directly called\n",
            "the OpenAI API with the prompt in HumanEval. (B)We called the OpenAI API and parsed the\n",
            "code with regex in the response. (C)We added an additional system prompt, then called the OpenAI\n",
            "API. The prompt is ”You are an AI that only responds with Python code, NOT ENGLISH. You will\n",
            "24\n",
            "\n",
            "page_label: 25\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "be given a function signature and its docstring by the user. Write your full implementation (restate\n",
            "the function signature).” As shown in Table 7, GPT-4 is more sensitive to prompt, code parser, and\n",
            "post-processing results on the HumanEval data set. It is difficult for GPT-3.5-Turbo to return the\n",
            "correct completion code without prompt words.\n",
            "Table 7: Performance of GPT models on HumanEval. Experiments were conducted five times\n",
            "using gpt-4-0613 and gpt-3.5-turbo-0613 with different settings.\n",
            "Settings Model 1 2 3 4 5 Avg. Std.\n",
            "A gpt-4-0613 0.732 0.707 0.732 0.713 0.738 0.724 0.013\n",
            "A gpt-3.5-turbo-0613 0.360 0.366 0.360 0.348 0.354 0.357 0.007\n",
            "B gpt-4-0613 0.787 0.811 0.817 0.829 0.817 0.812 0.016\n",
            "B gpt-3.5-turbo-0613 0.348 0.354 0.348 0.335 0.348 0.346 0.007\n",
            "C gpt-4-0613 0.805 0.805 0.817 0.793 0.780 0.800 0.014\n",
            "C gpt-3.5-turbo-0613 0.585 0.567 0.573 0.579 0.579 0.577 0.007\n",
            "Qualitative results Figure 11 and Figure 12 illustrate the outcomes of the Architect agent’s ef-\n",
            "forts to design a complex recommender system. These figures showcase the comprehensive system\n",
            "interface design and program call flow. The latter is essential for creating a sophisticated automated\n",
            "system. It is crucial to emphasize the importance of this division of labor in developing an automated\n",
            "software framework.\n",
            "D L IMITATION AND ETHICS CONCERNS\n",
            "D.1 L IMITATION\n",
            "System side At present, our system cannot fully cater to specific scenarios, such as UI and front-\n",
            "end, as we have yet to incorporate such agents and multimodal tools. Furthermore, despite gen-\n",
            "erating the most amount of code among comparable frameworks, it remains challenging to fulfill\n",
            "real-world applications’ diverse and complex requirements.\n",
            "Human user side A key challenge for users is to interrupt the running process of each agent, or\n",
            "set the starting running point (checkpoint) for each agent.\n",
            "D.2 E THICS CONCERNS\n",
            "Unemployment and Skill Obsolescence MetaGPT enables more people to program in natural\n",
            "languages, thereby making it easier for engineers to get started. Over the years, programming\n",
            "languages have evolved from punched cards to assembly, C, Java, Python, and now natural lan-\n",
            "guage. As a result, humans have become more proficient at programming, increasing the demand\n",
            "for programming-related positions. Furthermore, programming with natural language may offer a\n",
            "significantly easier learning curve, making programming more accessible to a broader audience.\n",
            "Transparency and Accountability MetaGPT is an open-source framework that facilitates inter-\n",
            "active communication between multiple agents through natural language. Humans can initiate, ob-\n",
            "serve, and stop running with the highest level of control. It provides real-time interpretation and op-\n",
            "eration of the natural language, displayed on the screen and logs, ensuring transparency. MetaGPT\n",
            "enhances “natural language programming” capabilities, and human engineers are the users and re-\n",
            "sponsible for the outcomes.\n",
            "Privacy and Data Security MetaGPT operates locally, ensuring user data privacy and security. It\n",
            "does not collect user data. For interactions with third-party LLMs, such as those by OpenAI, users\n",
            "are encouraged to refer to the respective privacy policies (e.g., OpenAI Privacy Policy). However,\n",
            "we provide the option of open-source LLMs as backends.\n",
            "25\n",
            "\n",
            "page_label: 26\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 11: The system interface design for “recommendation engine development” is generated by\n",
            "thearchitect agent ( zoom in for a better view ).\n",
            "E M ORE DISCUSSIONS\n",
            "E.1 D EEP-SEATED CHALLENGES\n",
            "MetaGPT also alleviates or solves these challenges with its unique designs:\n",
            "Use Context Efficiently Two sub-challenges are present. First, unfolding short natural language\n",
            "descriptions accurately to eliminate ambiguity. Second, maintaining information validity in lengthy\n",
            "contexts, enables LLMs to concentrate on relevant data without distraction.\n",
            "Reduce Hallucinations Using LLMs to generate entire software programs faces code halluci-\n",
            "nation problems—-including incomplete implementation of functions, missing dependencies, and\n",
            "potential undiscovered bugs, which may be more serious. LLMs often struggle with software gen-\n",
            "eration due to vague task definitions. Focusing on granular tasks like requirement analysis and\n",
            "package selection offers guided thinking, which LLMs lack in broad task solving.\n",
            "E.2 I NFORMATION OVERLOAD\n",
            "In MetaGPT, we use a global message pool and a subscription mechanism to address “information\n",
            "overload,” which refers to the problem of receiving excessive or irrelevant information. This issue\n",
            "is dependent on specific applications. MetaGPT employs a message pool to streamline communi-\n",
            "cation, ensuring efficiency. Additionally, a subscription mechanism filters out irrelevant contexts,\n",
            "enhancing the relevance and utility of the information. This design is particularly crucial in soft-\n",
            "26\n",
            "\n",
            "page_label: 27\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 12: The program call flow for “recommendation engine development” generated by the\n",
            "architect agent ( zoom in for a better view ).\n",
            "ware design scenarios and standard operating procedures (SOPs) where effective communication is\n",
            "essential.\n",
            "27\n",
            "\n",
            "page_label: 28\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 8: Examples of SoftwareDev dataset.\n",
            "Task ID Task Prompt\n",
            "0 Snake game Create a snake game.\n",
            "1 Brick breaker game Create a brick breaker game.\n",
            "2 2048 game Create a 2048 game for the web.\n",
            "3 Flappy bird game Write p5.js code for Flappy Bird where you control a yellow bird continu-\n",
            "ously flying between a series of green pipes. The bird flaps every time you\n",
            "left click the mouse. If it falls to the ground or hits a pipe, you lose. This\n",
            "game goes on indefinitely until you lose; you get points the further you go.\n",
            "4 Tank battle game Create a tank battle game.\n",
            "5 Excel data process Write an excel data processing program based on streamlit and pandas. The\n",
            "screen first shows an excel file upload button. After the excel file is uploaded,\n",
            "use pandas to display its data content. The program is required to be concise,\n",
            "easy to maintain, and not over-designed. It uses streamlit to process web\n",
            "screen displays, and pandas is sufficient to process excel reading and display.\n",
            "Please make sure others can execute directly without introducing additional\n",
            "packages.\n",
            "6 CRUD manage Write a management program based on the crud addition, deletion, modifi-\n",
            "cation and query processing of the customer business entity. The customer\n",
            "needs to save this information: name, birthday, age, sex, and phone. The data\n",
            "is stored in client.db, and there is a judgement whether the customer table ex-\n",
            "ists. If it doesn’t, it needs to be created first. Querying is done by name; same\n",
            "for deleting. The program is required to be concise, easy to maintain, and not\n",
            "over-designed. The screen is realized through streamlit and sqlite—no need\n",
            "to introduce other additional packages.\n",
            "7 Music transcriber Develop a program to transcribe sheet music into a digital format; provid-\n",
            "ing error-free transcribed symbolized sheet music intelligence from audio\n",
            "through signal processing involving pitch and time slicing then training a\n",
            "neural net to run Onset Detected CWT transforming scalograms to chroma-\n",
            "grams decoded with Recursive Neural Network focused networks.\n",
            "8 Custom press releases Create custom press releases; develop a Python script that extracts rele-\n",
            "vant information about company news from external sources, such as social\n",
            "media; extract update interval database for recent changes. The program\n",
            "should create press releases with customizable options and export writings\n",
            "to PDFs, NYTimes API JSONs, media format styled with interlink internal\n",
            "fixed character-length metadata.\n",
            "9 Gomoku game Implement a Gomoku game using Python, incorporating an AI opponent\n",
            "with varying difficulty levels.\n",
            "10 Weather dashboard Create a Python program to develop an interactive weather dashboard.\n",
            "28\n",
            "\n",
            "page_label: 29\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 9: Additional results of pure MetaGPT w/o feedback on SoftwareDev. Averages (Avg.) of 70 tasks are calculated and 10 randomly selected tasks are\n",
            "included. ‘#’ denotes ‘The number of’, while ‘ID’ is ‘Task ID’.\n",
            "ID Code statistics Doc statistics Cost statistics Cost of revision Code executability\n",
            "#code files #lines of code #lines per code file #doc files #lines of doc #lines per doc file #prompt tokens #completion tokens time costs money costs\n",
            "0 5.00 196.00 39.20 3.00 210.00 70.00 24087.00 6157.00 582.04 $ 1.09 1. TypeError 4\n",
            "1 6.00 191.00 31.83 3.00 230.00 76.67 32517.00 6238.00 566.30 $ 1.35 1. TypeError 4\n",
            "2 3.00 198.00 66.00 3.00 235.00 78.33 21934.00 6316.00 553.11 $ 1.04 1. lack\n",
            "@app.route(’/’)3\n",
            "3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is a summary of the paper?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "lack\n",
            "@app.route(’/’)3\n",
            "3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method not\n",
            "implement2\n",
            "9 5.00 215.00 43.00 3.00 270.00 90.00 24799.00 5734.00 550.88 $ 1.27 1. dependency er-\n",
            "ror 2. URL 403 er-\n",
            "ror3\n",
            "10 3.00 93.00 31.00 3.00 254.00 84.67 24109.00 5363.00 438.50 $ 0.92 1. dependency er-\n",
            "ror 2. missing main\n",
            "func.4\n",
            "Avg. 4.71 191.57 42.98 3.00 240.00 80.00 26626.86 6218.00 516.71 $1.12 0.51 (only consider\n",
            "item scored 2, 3 or\n",
            "4)3.36\n",
            "29\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is a summary of the paper?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "The paper introduces MetaGPT, a new framework designed for multi-agent collaboration using large language models (LLMs). MetaGPT is built upon the concept of \"meta-programming,\" which in this context refers to using LLMs to automate the programming process. \n",
            "\n",
            "What sets MetaGPT apart is its incorporation of Standardized Operating Procedures (SOPs) similar to those used in human workflows. This means agents within MetaGPT have specialized roles (like Product Manager, Architect, Engineer) and follow a structured workflow, mimicking real-world software development practices. This approach reduces errors and inconsistencies that can arise from the unstructured communication often seen in LLM-based multi-agent systems.\n",
            "\n",
            "The paper highlights MetaGPT's ability to generate structured outputs (like design documents and code) and its unique \"executable feedback\" mechanism, which allows for code debugging and improvement during runtime.  Evaluations on code generation benchmarks demonstrate MetaGPT's superior performance compared to other systems, achieving state-of-the-art results and a 100% task completion rate.\n",
            "\n",
            "This paper introduces MetaGPT, an innovative framework that leverages the strengths of large language models (LLMs) for sophisticated software development. MetaGPT distinguishes itself through its unique incorporation of a structured \"Standard Operating Procedure\" (SOP), mimicking real-world software engineering practices. This SOP empowers MetaGPT to manage complex projects by assigning specialized roles to different agents, such as Product Manager, Architect, Engineer, and QA Engineer. These agents collaborate seamlessly, communicating through structured documents and diagrams, leading to more efficient and accurate code generation.  Rigorous experiments, including comparisons with established methods on standard benchmarks (HumanEval, MBPP) and a newly introduced SoftwareDev dataset, demonstrate MetaGPT's superior performance in code generation, particularly in terms of functionality and executability. The paper further emphasizes the importance of each role and the iterative feedback mechanism in MetaGPT through detailed ablation studies, highlighting its potential to redefine the landscape of AI-driven software development.\n",
            "\n",
            "This paper introduces MetaGPT, a new meta-programming framework that uses Standard Operating Procedures (SOPs) to improve the problem-solving abilities of multi-agent systems powered by Large Language Models (LLMs). MetaGPT simulates a software company with different roles like engineers, product managers, architects, and project managers. It uses role specialization, workflow management, and efficient communication to create a flexible platform for autonomous agents. The framework also includes an executable feedback mechanism to improve the quality of code generated during runtime. Extensive experiments show that MetaGPT achieves state-of-the-art performance on multiple benchmarks. The successful integration of human-like SOPs inspires future research on human-inspired techniques for artificial multi-agent systems and represents an early attempt to regulate LLM-based multi-agent frameworks.\n",
            "\n",
            "The paper discusses MetaGPT, a framework that utilizes the strengths of large language models to build a multi-agent simulation of a software company. This system allows for the autonomous operation of the company, encompassing the entire software development lifecycle from design to project delivery.  The authors highlight that MetaGPT goes beyond simple code generation and incorporates economic principles to foster collaboration and self-improvement within the simulated company. The ultimate goal is to create a more realistic and effective model for software development using AI agents.\n",
            "\n",
            "This paper introduces MetaGPT, an innovative framework designed for multi-agent collaborative software development.  MetaGPT leverages the strengths of large language models (LLMs) to create a structured and efficient development process.  The framework employs a team of specialized agents, each responsible for a specific stage of the software development lifecycle, such as product management, system design, coding, and quality assurance.  This division of labor, combined with standardized communication protocols and feedback mechanisms, enables MetaGPT to effectively handle complex software projects.  Experimental results demonstrate MetaGPT's superiority over existing methods in terms of code executability and adherence to user requirements.  The paper also highlights the impact of different LLMs on MetaGPT's performance and explores future research directions, including the optimization of communication protocols and the integration of external tools.\n",
            "\n",
            "MetaGPT is a framework that uses multiple AI agents to autonomously build software. It assigns roles to agents like product managers, architects, project managers, and engineers to simulate a software development team. This approach leads to more comprehensive and executable code compared to other methods. MetaGPT has been shown to be effective with different large language models (LLMs), although GPT-4 produces the best results. The system is designed to be transparent and user-friendly, allowing humans to observe and intervene in the process. While MetaGPT has limitations in areas like UI development and meeting complex real-world requirements, it offers a promising solution for generating code from natural language descriptions.\n",
            "\n",
            "This paper analyzes different aspects of a project, including development time, code size, and cost. It highlights common issues encountered during development, such as missing PNG files, compile bugs, and dependency errors. The paper also presents the average values for various metrics, indicating an average score and cost.\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is a summary of the paper?\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "A novel framework called MetaGPT leverages the capabilities of large language models (LLMs) to enable multi-agent collaboration for software development. Inspired by real-world practices, MetaGPT assigns specialized roles to different agents, such as product managers, architects, and engineers, mimicking a structured software development team. This approach facilitates a more efficient and effective development process, leading to higher-quality code generation. Through standardized operating procedures and communication protocols, MetaGPT streamlines the interaction between agents, resulting in improved code executability and adherence to user requirements. Empirical evaluations demonstrate MetaGPT's superior performance compared to existing methods, highlighting its potential to transform AI-driven software development. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = vertex_gemini.predict_and_call(\n",
        "    [summary_tool, vector_query_tool],\n",
        "    \"What is a summary of the paper?\",\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "007toHpNCd6R"
      },
      "source": [
        "### Task 3: Building an Agent Reasoning Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1lawzddDCkVz"
      },
      "outputs": [],
      "source": [
        "# TODO: abstract all of this into a function that takes in a PDF file name\n",
        "from typing import Optional\n",
        "\n",
        "def get_doc_tools(\n",
        "    file_path: str,\n",
        "    name: str,\n",
        ") -> str:\n",
        "    \"\"\"Get vector query and summary query tools from a document.\"\"\"\n",
        "\n",
        "    # load documents\n",
        "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
        "    splitter = SentenceSplitter(chunk_size=1024)\n",
        "    nodes = splitter.get_nodes_from_documents(documents)\n",
        "    vector_index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
        "    summary_index = SummaryIndex(nodes)\n",
        "\n",
        "    def vector_query(\n",
        "        query: str,\n",
        "        page_numbers: Optional[List[str]] = None\n",
        "    ) -> str:\n",
        "        \"\"\"Use to answer questions over the MetaGPT paper.\n",
        "\n",
        "        Useful if you have specific questions over the MetaGPT paper.\n",
        "        Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
        "\n",
        "        Args:\n",
        "            query (str): the string query to be embedded.\n",
        "            page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE\n",
        "                if we want to perform a vector search\n",
        "                over all pages. Otherwise, filter by the set of specified pages.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        page_numbers = page_numbers or []\n",
        "        metadata_dicts = [\n",
        "            {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
        "        ]\n",
        "\n",
        "        query_engine = vector_index.as_query_engine(\n",
        "            similarity_top_k=2,\n",
        "            filters=MetadataFilters.from_dicts(\n",
        "                metadata_dicts,\n",
        "                condition=FilterCondition.OR\n",
        "            )\n",
        "        )\n",
        "        response = query_engine.query(query)\n",
        "        return response\n",
        "\n",
        "\n",
        "    vector_query_tool = FunctionTool.from_defaults(\n",
        "        name=f\"vector_tool_{name}\",\n",
        "        fn=vector_query\n",
        "    )\n",
        "\n",
        "    def summary_query(\n",
        "        query: str,\n",
        "    ) -> str:\n",
        "        \"\"\"Perform a summary of document\n",
        "        query (str): the string query to be embedded.\n",
        "        \"\"\"\n",
        "        summary_engine = summary_index.as_query_engine(\n",
        "            response_mode=\"tree_summarize\",\n",
        "            use_async=True,\n",
        "        )\n",
        "    \n",
        "        response = summary_engine.query(query)\n",
        "        return response\n",
        "    \n",
        "    \n",
        "    summary_tool = FunctionTool.from_defaults(\n",
        "        \n",
        "        fn=summary_query,\n",
        "        name=f'summary_tool_{name}'\n",
        "        \n",
        "    )\n",
        "\n",
        "    return vector_query_tool, summary_tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obvj0hBjGUIe",
        "outputId": "a54b138a-5f28-4275-ecdc-39232f703554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n"
          ]
        }
      ],
      "source": [
        "vector_query_tool, summary_tool = get_doc_tools(\"metagpt.pdf\", \"metagpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "vertex_gemini = Vertex(model=\"gemini-1.5-pro-preview-0514\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cNXRrhEHquy",
        "outputId": "ccb4431a-8619-43dc-bd86-0f8fc80b1ba6"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [vector_query_tool, summary_tool], \n",
        "    llm=vertex_gemini, \n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_message user: what's the summary of the paper?\n",
            "Function Calling, No Text Content\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_metagpt with args: {\"query\": \"What is this paper about?\"}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "page_label: 1\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "METAGPT: M ETA PROGRAMMING FOR A\n",
            "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
            "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
            "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
            "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
            "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
            "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
            "5Nanjing University,6University of Pennsylvania,\n",
            "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
            "ABSTRACT\n",
            "Remarkable progress has been made on automated problem solving through so-\n",
            "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
            "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
            "complex tasks, however, are complicated through logic inconsistencies due to\n",
            "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
            "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
            "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
            "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
            "streamlined workflows, thus allowing agents with human-like domain expertise\n",
            "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
            "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
            "complex tasks into subtasks involving many agents working together. On col-\n",
            "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
            "solutions than previous chat-based multi-agent systems. Our project can be found\n",
            "at https://github.com/geekan/MetaGPT.\n",
            "1 I NTRODUCTION\n",
            "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
            "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
            "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
            "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
            "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
            "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
            "et al., 2023; Qian et al., 2023).\n",
            "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
            "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
            "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
            "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
            "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
            "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
            "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
            "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
            "(PRDs) using a standardized structure, to guide the developmental process.\n",
            "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
            "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
            "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
            "∗These authors contributed equally to this work.\n",
            "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
            "1\n",
            "\n",
            "page_label: 2\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
            "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
            "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
            "(e.g., Product Manager, Architect, Engineer, etc.).\n",
            "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
            "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
            "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
            "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
            "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
            "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
            "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
            "lunch?” – Bob (Architect).\n",
            "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
            "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
            "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
            "2006; Finn et al., 2017).\n",
            "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
            "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
            "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
            "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
            "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
            "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
            "ing how agent-based techniques can enhance meta-programming.\n",
            "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
            "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
            "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
            "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
            "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
            "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
            "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
            "We summarize our contributions as follows:\n",
            "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
            "2\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "•We introduce MetaGPT, a meta-programming framework for multi-agent collaboration based on\n",
            "LLMs. It is highly convenient and flexible, with well-defined functions like role definition and\n",
            "message sharing, making it a useful platform for developing LLM-based multi-agent systems.\n",
            "•Our innovative integration of human-like SOPs throughout MetaGPT’s design significantly en-\n",
            "hances its robustness, reducing unproductive collaboration among LLM-based agents. Furthermore,\n",
            "we introduce a novel executive feedback mechanism that debugs and executes code during runtime,\n",
            "significantly elevating code generation quality (e.g., 5.4% absolute improvement on MBPP).\n",
            "•We achieve state-of-the-art performance on HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021). Extensive results convincingly validate MetaGPT, suggesting that it is a promising\n",
            "meta-programming framework for developing LLM-based multi-agent systems.\n",
            "2 R ELATED WORK\n",
            "Automatic Programming The roots of automatic programming reach back deep into the previ-\n",
            "ous century. In 1969, Waldinger & Lee (1969) introduced “PROW,” a system designed to accept\n",
            "program specifications written in predicate calculus, generate algorithms, and create LISP imple-\n",
            "mentations (McCarthy, 1978). Balzer (1985) and Soloway (1986) made efforts to advance auto-\n",
            "matic programming and identified potential methods to achieve it. Recent approaches use natural\n",
            "language processing (NLP) techniques (Ni et al., 2023; Skreta et al., 2023; Feng et al., 2020; Li\n",
            "et al., 2022; Chen et al., 2018; 2021b; Zhang et al., 2023). Automatic programming has grown into\n",
            "an industry delivering paid functions such as Microsoft Copilot. Lately, LLMs-based agents (Yao\n",
            "et al., 2022; Shinn et al., 2023; Lin et al., 2023) have advanced automatic programming develop-\n",
            "ment. Among them, ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023) utilize a chain of\n",
            "thought prompts (Wei et al., 2022) to generate reasoning trajectories and action plans with LLMs.\n",
            "Both works demonstrate the effectiveness of the ReAct style loop of reasoning as a design paradigm\n",
            "for empowering automatic programming. Additionally, ToolFormer (Schick et al., 2023) can learn\n",
            "how to use external tools through simple APIs. The research most closely aligned with our work\n",
            "by Li et al. (2023) proposes a straightforward role-play framework for programming that involves\n",
            "communication between agents playing different roles. Qian et al. (2023) utilizes multiple agents for\n",
            "software development. Although existing papers (Li et al., 2023; Qian et al., 2023) have improved\n",
            "productivity, they have not fully tapped into effective workflows with structured output formats.\n",
            "This makes it harder to deal with complex software engineering issues.\n",
            "LLM-Based Multi-Agent Frameworks Recently, LLM-based autonomous agents have gained\n",
            "tremendous interest in both industry and academia (Wang et al., 2023b). Many works (Chen et al.,\n",
            "2024; Wang et al., 2023c; Du et al., 2023; Zhuge et al., 2023; Hao et al., 2023; Akata et al., 2023)\n",
            "have improved the problem-solving abilities of LLMs by integrating discussions among multiple\n",
            "agents. Stable-Alignment (Liu et al., 2023) creates instruction datasets by deriving consensus on\n",
            "value judgments through interactions across a sandbox with LLM agents. Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks.\n",
            "\n",
            "page_label: 3\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Other works focus on\n",
            "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
            "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
            "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
            "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
            "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
            "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
            "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
            "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
            "agents frameworks. Besides, LLM-based agents face the challenges of “assistant repeated instruc-\n",
            "tion” or “infinite loop of message” (Talebirad & Nadiri, 2023; Li et al., 2023). These challenges\n",
            "become more urgent in task-oriented collaborations, which require consistent and mutually benefi-\n",
            "cial interactions (Elazar et al., 2021; Wang et al., 2022; Jiang et al., 2023). This motivates our focus\n",
            "on applying advanced concepts such as Standard Operating Procedures in software development to\n",
            "multi-agent frameworks.\n",
            "3\n",
            "\n",
            "page_label: 4\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 2: An example of the communication protocol (left) and iterative programming with exe-\n",
            "cutable feedback (right). Left: Agents use a shared message pool to publish structured messages.\n",
            "They can also subscribe to relevant messages based on their profiles. Right : After generating the\n",
            "initial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past\n",
            "messages stored in memory and compares them with the PRD, system design, and code files.\n",
            "3 M ETAGPT: A M ETA-PROGRAMMING FRAMEWORK\n",
            "MetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 pro-\n",
            "vides an explanation of role specialization, workflow and structured communication in this frame-\n",
            "work, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2\n",
            "presents a communication protocol that enhances role communication efficiency. We also imple-\n",
            "ment structured communication interfaces and an effective publish-subscribe mechanism. These\n",
            "methods enable agents to obtain directional information from other roles and public information\n",
            "from the environment. Finally, we introduce executable feedback—a self-correction mechanism for\n",
            "further enhancing code generation quality during run-time in Sec. 3.3.\n",
            "3.1 A GENTS IN STANDARD OPERATING PROCEDURES\n",
            "Specialization of Roles Unambiguous role specialization enables the breakdown of complex work\n",
            "into smaller and more specific tasks. Solving complex tasks or problems often requires the collab-\n",
            "oration of agents with diverse skills and expertise, each contributing specialized outputs tailored to\n",
            "specific issues.\n",
            "In a software company, a Product Manager typically conducts business-oriented analysis and derives\n",
            "insights, while a software engineer is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design, the information\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is this paper about?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its sig-\n",
            "nificant dependence on SOPs. The more detailed demonstration can be found in Appendix B.\n",
            "Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager under-\n",
            "takes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement\n",
            "Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to\n",
            "the Architect, who translates the requirements into system design components, such as File Lists,\n",
            "Data Structures, and Interface Definitions. Once captured in the system design, the information is\n",
            "directed towards the Project Manager for task distribution. Engineers proceed to execute the des-\n",
            "ignated classes and functions as outlined (detailed in Figure 2). In the following stage, the QA\n",
            "Engineer formulates test cases to enforce stringent code quality. In the final step, MetaGPT pro-\n",
            "duces a meticulously crafted software solution. We provide a detailed schematic (Figure 3) and a\n",
            "concrete instance (Appendix B) of the SOP workflow in MetaGPT.\n",
            "3.2 C OMMUNICATION PROTOCOL\n",
            "Structured Communication Interfaces Most current LLM-based multi-agent frameworks (Li\n",
            "et al., 2023; Zhuge et al., 2023; Zhang et al., 2023; Park et al., 2023) utilize unconstrained natural\n",
            "language as a communication interface.\n",
            "However, despite the versatility of natural language, a question arises: does pure natural language\n",
            "communication suffice for solving complex tasks? For example, in the telephone game (or Chinese\n",
            "5\n",
            "\n",
            "page_label: 6\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "whispers)2, after several rounds of communication, the original information may be quite distorted.\n",
            "Inspired by human social structures, we propose using structured communication to formulate the\n",
            "communication of agents. We establish a schema and format for each role and request that individ-\n",
            "uals provide the necessary outputs based on their specific role and context.\n",
            "As shown in Figure 3, the Architect agent generates two outputs: the system interface design and a\n",
            "sequence flow diagram. These contain system module design and interaction sequences, which serve\n",
            "as important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT\n",
            "communicate through documents and diagrams (structured outputs) rather than dialogue. These\n",
            "documents contain all necessary information, preventing irrelevant or missing content.\n",
            "Publish-Subscribe Mechanism Sharing information is critical in collaboration. For instance,\n",
            "Architects and Engineers often need to reference PRDs. However, communicating this information\n",
            "each time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023;\n",
            "Zhang et al., 2023), can complicate the communication topology, resulting in inefficiencies.\n",
            "To address this challenge, a viable approach is to store information in a global message pool . As\n",
            "shown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange\n",
            "messages directly. These agents not only publish their structured messages in the pool but also access\n",
            "messages from other entities transparently. Any agent can directly retrieve required information\n",
            "from the shared pool, eliminating the need to inquire about other agents and await their responses.\n",
            "This enhances communication efficiency.\n",
            "Sharing all information with every agent can lead to information overload. During task execution,\n",
            "an agent typically prefers to receive only task-related information and avoid distractions through\n",
            "irrelevant details. Effective management and dissemination of this information play a crucial role.\n",
            "We offer a simple and effective solution- subscription mechanism (in Figure 2 (left)). Instead of\n",
            "relying on dialogue, agents utilize role-specific interests to extract relevant information. They can\n",
            "select information to follow based on their role profiles. In practical implementations, an agent\n",
            "activates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3,\n",
            "the Architect mainly focuses on PRDs provided by the Product Manager, while documents from\n",
            "roles such as the QA Engineer might be of lesser concern.\n",
            "3.3 I TERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK\n",
            "In daily programming tasks, the processes of debugging and optimization play important roles.\n",
            "However, existing methods often lack a self-correction mechanism, which leads to unsuccessful code\n",
            "generation. Previous work introduced non-executable code review and self-reflection (Zhao et al.,\n",
            "2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in\n",
            "ensuring code executability and runtime correctness.\n",
            "Our first MetaGPT implementations overlooked certain errors during the review process, due to\n",
            "LLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we\n",
            "introduce an executable feedback mechanism to improve the code iteratively. More specifically, as\n",
            "shown in Figure 2, the Engineer is asked to write code based on the original product requirements\n",
            "and design.\n",
            "This enables the Engineer to continuously improve code using its own historical execution and\n",
            "debugging memory. To obtain additional information, the Engineer writes and executes the corre-\n",
            "sponding unit test cases, and subsequently receives the test results. If satisfactory, additional devel-\n",
            "opment tasks are initiated. Otherwise the Engineer debugs the code before resuming programming.\n",
            "This iterative testing process continues until the test is passed or a maximum of 3 retries is reached.\n",
            "4 E XPERIMENTS\n",
            "4.1 E XPERIMENTAL SETTING\n",
            "Datasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
            "et al., 2021), and a self-generated, more challenging software development benchmark named Soft-\n",
            "2https://en.wikipedia.org/wiki/Chinese whispers\n",
            "6\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "wareDev: (1) HumanEval includes 164 handwritten programming tasks. These tasks encompass\n",
            "function specifications, descriptions, reference codes, and tests. (2) MBPP consists of 427 Python\n",
            "tasks. These tasks cover core concepts and standard library features and include descriptions, ref-\n",
            "erence codes, and automated tests. (3) Our SoftwareDev dataset is a collection of 70 representa-\n",
            "tive examples of software development tasks, each with its own task prompt (see Table 8). These\n",
            "tasks have diverse scopes (See Figure 5), such as mini-games, image processing algorithms, data\n",
            "visualization. They offer a robust testbed for authentic development tasks. Contrary to previous\n",
            "datasets (Chen et al., 2021a; Austin et al., 2021), SoftwareDev focuses on the engineering aspects.\n",
            "In the comparisons, we randomly select seven representative tasks for evaluation.\n",
            "Evaluation Metrics For HuamnEval and MBPP, we follow the unbiased version of Pass @ kas\n",
            "presented by (Chen et al., 2021a; Dong et al., 2023), to evaluate the functional accuracy of the top-k\n",
            "generated codes: Pass @ k=EProblems\u0014\n",
            "1−(n−c\n",
            "k)\n",
            "(n\n",
            "k)\u0015\n",
            ".\n",
            "For SoftwareDev, we prioritize practical use and evaluate performance through human evaluations\n",
            "(A, E) or statistical analysis (B, C, D): (A)Executability: this metric rates code from 1 (failure/non-\n",
            "functional) to 4 (flawless). ‘1’ is for non-functional, ‘2’ for runnable but imperfect, ‘3’ for nearly\n",
            "perfect, and ‘4’ for flawless code. (B)Cost: the cost evaluations here include the (1) running time,\n",
            "(2) token usage, and (3) expenses. (C)Code Statistics: this includes (1) code files, (2) lines of code\n",
            "per file, and (3) total code lines. (D)Productivity: basically, it is defined as the number of token\n",
            "usage divided by the number of lines of code, which refers to the consumption of tokens per code\n",
            "line. (E)Human Revision Cost: refers to times of manual code corrections, which tackle problems\n",
            "like package import errors, incorrect class names, or incomplete reference paths. Typically, each\n",
            "correction involves up to 3 lines of code.\n",
            "Baselines We compare our method with recent domain-specific LLMs in the code generation field,\n",
            "including AlphaCode (Li et al., 2022), Incoder (Fried et al., 2022), CodeGeeX (Zheng et al., 2023),\n",
            "CodeGen (Nijkamp et al., 2023), CodeX (Chen et al., 2021a), and CodeT (Chen et al., 2022) and\n",
            "general domain LLMs such as PaLM (Chowdhery et al., 2022), and GPT-4 (OpenAI, 2023). Several\n",
            "results of baselines (such as Incoder, CodeGeeX) are provided by Dong et al. (2023). In HumanEval\n",
            "and MBPP, we slightly modified the prompts to align with response format requirements. These\n",
            "modifications aim to address format-specific issues (i.e., Python problems). With the SoftwareDev\n",
            "benchmark, we provide a comprehensive comparison between MetaGPT, AutoGPT (Torantulino\n",
            "et al., 2023), LangChain (Chase, 2022) with Python Read-Eval-Print Loop (REPL) tool3, Agent-\n",
            "Verse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
            "4.2 M AINRESULT\n",
            "AlphaCode(1.1B)\n",
            "Incoder (6.7B)\n",
            "CodeGeeX (13B)17.1\n",
            "—15.2 17.6 18.926.9\n",
            "CodeGeeX-Mono(16.1B)32.938.6\n",
            "GPT-467.0\n",
            "—\n",
            "MetaGPT\n",
            "(w/o Feedback)81.7 82.3Pass@1 of MBPP  and HumanEval (%)\n",
            "PaLM Coder(540B)36.047.0\n",
            "Codex (175B)47.058.1\n",
            "Codex + CodeT65.8 67.7\n",
            "HumanEval\n",
            "MBPP\n",
            "MetaGPT85.9 87.7\n",
            "Figure 4: Pass rates on the MBPP and HumanEval with a single attempt.\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks.\n",
            "\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks. When MetaGPT collaborates with GPT-4, it significantly im-\n",
            "proves the Pass @ kin the HumanEval benchmark compared to GPT-4. It achieves 85.9% and 87.7%\n",
            "3https://en.wikipedia.org/wiki/Read–eval–print loop\n",
            "7\n",
            "\n",
            "page_label: 8\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 5: Demo softwares developed by MetaGPT.\n",
            "in these two public benchmarks. Moreover, as shown in Table 1, MetaGPT outperforms ChatDev on\n",
            "the challenging SoftwareDev dataset in nearly all metrics. For example, considering the executabil-\n",
            "ity, MetaGPT achieves a score of 3.75, which is very close to 4 (flawless). Besides, it takes less time\n",
            "(503 seconds), clearly less than ChatDev. Considering the code statistic and the cost of human revi-\n",
            "sion, it also significantly outperforms ChatDev. Although MetaGPT requires more tokens (24,613\n",
            "or 31,255 compared to 19,292), it needs only 126.5/124.3 tokens to generate one line of code. In\n",
            "contrast, ChatDev uses 248.9 tokens. These results highlight the benefits of SOPs in collabora-\n",
            "tions between multiple agents. Additionally, we demonstrate the autonomous software generation\n",
            "capabilities of MetaGPT through visualization samples (Figure 5). For additional experiments and\n",
            "analysis, please refer to Appendix C.\n",
            "Table 1: The statistical analysis on SoftwareDev.\n",
            "Statistical Index ChatDev MetaGPT w/o Feedback MetaGPT\n",
            "(A)Executability 2.25 3.67 3.75\n",
            "(B)Cost#1: Running Times (s) 762 503 541\n",
            "(B)Cost#2: Token Usage 19,292 24,613 31,255\n",
            "(C)Code Statistic#1: Code Files 1.9 4.6 5.1\n",
            "(C)Code Statistic#2: Lines of Code per File 40.8 42.3 49.3\n",
            "(C)Code Statistic#3: Total Code Lines 77.5 194.6 251.4\n",
            "(D)Productivity 248.9 126.5 124.3\n",
            "(E)Human Revision Cost 2.5 2.25 0.83\n",
            "4.3 C APABILITIES ANALYSIS\n",
            "Compared to open-source baseline methods such as AutoGPT and autonomous agents such as\n",
            "AgentVerse and ChatDev, MetaGPT offers functions for software engineering tasks. As presented\n",
            "in Table 2, our framework encompasses a wide range of abilities to handle complex and specialized\n",
            "development tasks efficiently. Incorporating SOPs (e.g., role-play expertise, structured communi-\n",
            "cation, streamlined workflow) can significantly improve code generation. Other baseline methods\n",
            "8\n",
            "\n",
            "page_label: 9\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 2: Comparison of capabilities for MetaGPT and other approaches. ‘!’ indicates the\n",
            "presence of a specific feature in the corresponding framework, ‘ %’ its absence.\n",
            "Framework Capabiliy AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "PRD generation % % % % !\n",
            "Tenical design genenration % % % % !\n",
            "API interface generation % % % % !\n",
            "Code generation ! ! ! ! !\n",
            "Precompilation execution % % % % !\n",
            "Role-based task management % % % ! !\n",
            "Code review % % ! ! !\n",
            "Table 3: Ablation study on roles. ‘#’ denotes ‘The number of’, ‘Product’ denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass @1 on\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is this paper about?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "denotes ‘Product man-\n",
            "ager’, and ‘Project’ denotes ‘Project manager’. ‘ !’ indicates the addition of a specific role. ‘Revi-\n",
            "sions’ refers to ‘Human Revision Cost’.\n",
            "Engineer Product Architect Project #Agents #Lines Expense Revisions Executability\n",
            "! % % % 1 83.0 $ 0.915 10 1.0\n",
            "! ! % % 2 112.0 $ 1.059 6.5 2.0\n",
            "! ! ! % 3 143.0 $ 1.204 4.0 2.5\n",
            "! ! % ! 3 205.0 $ 1.251 3.5 2.0\n",
            "! ! ! ! 4 191.0 $ 1.385 2.5 4.0\n",
            "can easily integrate SOP-like designs to improve their performance, similar to injecting chain-of-\n",
            "thought (Wei et al., 2022) in LLMs.\n",
            "4.4 A BLATION STUDY\n",
            "The Effectiveness of Roles To understand the impact of different roles on the final results, we\n",
            "perform two tasks that involve generating effective code and calculating average statistics. When we\n",
            "exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles\n",
            "different from just the Engineer consistently improves both revisions and executability. While more\n",
            "roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the\n",
            "effectiveness of the various roles.\n",
            "The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable\n",
            "feedback into MetaGPT leads to a significant improvement of 4.2% and 5.4% in Pass @1 on Hu-\n",
            "manEval and MBPP, respectively. Besides, Table 1 shows that the feedback mechanism improves\n",
            "feasibility (3.67 to 3.75) and reduces the cost of human revisions (2.25 to 0.83). These results\n",
            "illustrate how our designed feedback mechanism can produce higher-quality code. Additional quan-\n",
            "titative results of MetaGPT and MetaGPT without executable feedback are shown in Table 4 and\n",
            "Table 9.\n",
            "5 C ONCLUSION\n",
            "This work introduces MetaGPT, a novel meta-programming framework that leverages SOPs to en-\n",
            "hance the problem-solving capabilities of multi-agent systems based on Large Language Models\n",
            "(LLMs). MetaGPT models a group of agents as a simulated software company, analogous to simu-\n",
            "lated towns (Park et al., 2023) and the Minecraft Sandbox in V oyager (Wang et al., 2023a). MetaGPT\n",
            "leverages role specialization, workflow management, and efficient sharing mechanisms such as mes-\n",
            "sage pools and subscriptions, rendering it a flexible and portable platform for autonomous agents\n",
            "and multi-agent frameworks. It uses an executable feedback mechanism to enhance code generation\n",
            "quality during runtime. In extensive experiments, MetaGPT achieves state-of-the-art performance\n",
            "on multiple benchmarks. The successful integration of human-like SOPs inspires future research\n",
            "on human-inspired techniques for artificial multi-agent systems. We also view our work as an early\n",
            "attempt to regulate LLM-based multi-agent frameworks. See also the outlook (Appendix A) .\n",
            "9\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Acknowledgement\n",
            "We thank Sarah Salhi, the Executive Secretary of KAUST AI Initiative, and Yuhui Wang, Postdoc-\n",
            "toral Fellow at the KAUST AI Initiative, for helping to polish some of the text. We would like to\n",
            "express our gratitude to Wenyi Wang, a PhD student at the KAUST AI Initiative, for providing com-\n",
            "prehensive feedback on the paper and for helping to draft the outlook (Appendix A) with Mingchen.\n",
            "We also thank Zongze Xu, the vice president of DeepWisdom, for providing illustrative materials\n",
            "for AgentStore.\n",
            "Author Contributions\n",
            "Sirui Hong conducted most of the experiments and designed the executable feedback module. She\n",
            "also led the initial version of the write-up, supported by Ceyao Zhang, and also by Jinlin Wang and\n",
            "Zili Wang. Mingchen Zhuge designed the self-improvement module, discussed additional experi-\n",
            "ments, and led the current write-up. Jonathan Chen helped with the MBPP experiments, outlined\n",
            "the methods section, and contributed to the current write-up. Xiawu Zheng provided valuable guid-\n",
            "ance, reviewed and edited the paper. Yuheng Cheng contributed to the evaluation metric design and\n",
            "HumanEval experiments. Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Lingfeng Xiao helped\n",
            "with the MBPP experiments and comparisons to open-source baseline methods. Chenyu Ran cre-\n",
            "ated most of the illustrative figures. Chenglin Wu is the CEO of DeepWisdom, initiated MetaGPT,\n",
            "made the most significant code contributions to it, and advised this project. J ¨urgen Schmidhuber,\n",
            "Director of the AI Initiative at KAUST and Scientific Director of IDSIA, advised this project and\n",
            "helped with the write-up.\n",
            "REFERENCES\n",
            "Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz.\n",
            "Playing repeated games with large language models. arXiv preprint , 2023.\n",
            "Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\n",
            "Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large\n",
            "language models, 2021.\n",
            "Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew\n",
            "Goff, Jonathan Gray, Hengyuan Hu, et al. Human-level play in the game of diplomacy by com-\n",
            "bining language models with strategic reasoning. Science , 2022.\n",
            "Robert Balzer. A 15 year perspective on automatic programming. TSE, 1985.\n",
            "R.M. Belbin. Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "\n",
            "page_label: 10\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Team Roles at Work . Routledge, 2012. URL https://books.google.co.uk/\n",
            "books?id=MHIQBAAAQBAJ .\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as\n",
            "tool makers. arXiv preprint , 2023.\n",
            "Harrison Chase. LangChain. https://github.com/hwchase17/langchain , 2022.\n",
            "Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu\n",
            "Chen. Codet: Code generation with generated tests, 2022.\n",
            "Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended\n",
            "environment. arXiv preprint , 2024.\n",
            "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\n",
            "Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,\n",
            "Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\n",
            "Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,\n",
            "Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-\n",
            "tios Chantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex\n",
            "Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,\n",
            "Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec\n",
            "Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob Mc-\n",
            "Grew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large\n",
            "language models trained on code, 2021a.\n",
            "10\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan,\n",
            "Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facili-\n",
            "tating multi-agent collaboration and exploring emergent behaviors in agents, 2023.\n",
            "Xinyun Chen, Chang Liu, and Dawn Song. Execution-guided neural program synthesis. In ICLR ,\n",
            "2018.\n",
            "Xinyun Chen, Dawn Song, and Yuandong Tian. Latent execution for neural program synthesis\n",
            "beyond domain-specific languages. NeurIPS , 2021b.\n",
            "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\n",
            "Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\n",
            "Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\n",
            "Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\n",
            "Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\n",
            "skaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\n",
            "Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret\n",
            "Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,\n",
            "Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\n",
            "Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\n",
            "nan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas\n",
            "Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,\n",
            "2022.\n",
            "T. DeMarco and T.R. Lister. Peopleware: Productive Projects and Teams . Addison-Wesley, 2013.\n",
            "URLhttps://books.google.co.uk/books?id=DVlsAQAAQBAJ .\n",
            "Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. Self-collaboration code generation via chatgpt. arXiv\n",
            "preprint , 2023.\n",
            "Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving\n",
            "factuality and reasoning in language models through multiagent debate, 2023.\n",
            "Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\n",
            "Sch¨utze, and Yoav Goldberg. Measuring and improving consistency in pretrained language mod-\n",
            "els.TACL , 2021.\n",
            "Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing\n",
            "Qin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained model for programming and natural\n",
            "languages. arXiv preprint , 2020.\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "\n",
            "page_label: 11\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt ¨aschel.\n",
            "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint , 2023.\n",
            "Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n",
            "of deep networks. In ICML , 2017.\n",
            "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\n",
            "Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\n",
            "and synthesis. arXiv preprint , 2022.\n",
            "Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput. , 1965.\n",
            "Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, and Liqiang Nie. Chatllm network:\n",
            "More brains, more intelligence. arXiv preprint , 2023.\n",
            "S. Hochreiter, A. S. Younger, and P. R. Conwell. Learning to learn using gradient descent. In Lecture\n",
            "Notes on Comp. Sci. 2130, Proc. Intl. Conf. on Artificial Neural Networks (ICANN-2001) , pp. 87–\n",
            "94. Springer: Berlin, Heidelberg, 2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang, Chenyan Jia,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is this paper about?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "2001.\n",
            "Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation\n",
            "with large language model. arXiv preprint , 2023.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "Camel: Communicative agents for” mind” exploration of large scale language model society.\n",
            "arXiv preprint , 2023.\n",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R ´emi Leblond, Tom\n",
            "Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation\n",
            "with alphacode. Science , 2022.\n",
            "Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng\n",
            "Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-\n",
            "agent debate. arXiv preprint , 2023.\n",
            "Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang,\n",
            "Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and\n",
            "slow thinking for complex interactive tasks. arXiv preprint , 2023.\n",
            "Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi Yang, and\n",
            "Soroush V osoughi. Training socially aligned language models in simulated human society. arXiv\n",
            "preprint , 2023.\n",
            "Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing\n",
            "Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with\n",
            "evol-instruct. arXiv preprint , 2023.\n",
            "Potsawee Manakul, Adian Liusie, and Mark JF Gales. Selfcheckgpt: Zero-resource black-box hal-\n",
            "lucination detection for generative large language models. arXiv preprint , 2023.\n",
            "Agile Manifesto. Manifesto for agile software development . Snowbird, UT, 2001.\n",
            "John McCarthy. History of lisp. In History of programming languages . 1978.\n",
            "Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-tau Yih, Sida Wang, and Xi Victoria\n",
            "Lin. Lever: Learning to verify language-to-code generation with execution. In ICML , 2023.\n",
            "Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese,\n",
            "and Caiming Xiong. Codegen: An open large language model for code with multi-turn program\n",
            "synthesis, 2023.\n",
            "OpenAI. Gpt-4 technical report, 2023.\n",
            "Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and\n",
            "Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint ,\n",
            "2023.\n",
            "Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and\n",
            "Maosong Sun. Communicative agents for software development, 2023.\n",
            "Baptiste Rozi `ere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi\n",
            "Adi, Jingyu Liu, Tal Remez, J ´er´emy Rapin, et al. Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements.\n",
            "\n",
            "page_label: 12\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Code llama: Open foundation models for code.\n",
            "arXiv preprint , 2023.\n",
            "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
            "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
            "use tools. arXiv preprint , 2023.\n",
            "J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference\n",
            "on Artificial Neural Networks, Amsterdam , pp. 446–451. Springer, 1993a.\n",
            "J. Schmidhuber. G ¨odel machines: self-referential universal problem solvers making provably\n",
            "optimal self-improvements. Technical Report IDSIA-19-03, arXiv:cs.LO/0309048 v3, IDSIA,\n",
            "Manno-Lugano, Switzerland, December 2003.\n",
            "J. Schmidhuber. G ¨odel machines: Fully self-referential optimal universal self-improvers. In B. Go-\n",
            "ertzel and C. Pennachin (eds.), Artificial General Intelligence , pp. 199–226. Springer Verlag,\n",
            "2006. Variant available as arXiv:cs.LO/0309048.\n",
            "12\n",
            "\n",
            "page_label: 13\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "J. Schmidhuber. Ultimate cognition `a laG¨odel. Cognitive Computation , 1(2):177–193, 2009.\n",
            "J¨urgen Schmidhuber. Evolutionary principles in self-referential learning, or on learning how to\n",
            "learn: the meta-meta-... hook . PhD thesis, 1987.\n",
            "J¨urgen Schmidhuber. A ‘self-referential’weight matrix. In ICANN’93: Proceedings of the Interna-\n",
            "tional Conference on Artificial Neural Networks Amsterdam, The Netherlands 13–16 September\n",
            "1993 3 , 1993b.\n",
            "J¨urgen Schmidhuber. On learning to think: Algorithmic information theory for novel combinations\n",
            "of reinforcement learning controllers and recurrent neural world models. arXiv preprint , 2015.\n",
            "J¨urgen Schmidhuber, Jieyu Zhao, and Nicol N Schraudolph. Reinforcement learning with self-\n",
            "modifying policies. In Learning to learn . 1998.\n",
            "Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic\n",
            "memory and self-reflection. arXiv preprint , 2023.\n",
            "Marta Skreta, Naruki Yoshikawa, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen,\n",
            "Kourosh Darvish, Al ´an Aspuru-Guzik, Florian Shkurti, and Animesh Garg. Errors are useful\n",
            "prompts: Instruction guided task programming with verifier-assisted iterative prompting. arXiv\n",
            "preprint , 2023.\n",
            "Elliot Soloway. Learning to program =learning to construct mechanisms and explanations. Com-\n",
            "munications of the ACM , 1986.\n",
            "Yashar Talebirad and Amirhossein Nadiri. Multi-agent collaboration: Harnessing the power of\n",
            "intelligent llm agents, 2023.\n",
            "Torantulino et al. Auto-gpt. https://github.com/Significant-Gravitas/\n",
            "Auto-GPT , 2023.\n",
            "R. J. Waldinger and R. C. T. Lee. PROW: a step toward automatic program writing. In D. E. Walker\n",
            "and L. M. Norton (eds.), Proceedings of the 1st International Joint Conference on Artificial Intel-\n",
            "ligence (IJCAI) , 1969.\n",
            "Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan,\n",
            "and Anima Anandkumar. V oyager: An open-ended embodied agent with large language models.\n",
            "arXiv preprint , 2023a.\n",
            "Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\n",
            "Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\n",
            "arXiv preprint , 2023b.\n",
            "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\n",
            "ery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.\n",
            "arXiv preprint , 2022.\n",
            "Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. Unleashing\n",
            "cognitive synergy in large language models: A task-solving agent through multi-persona self-\n",
            "collaboration. arXiv preprint , 2023c.\n",
            "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\n",
            "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS ,\n",
            "2022.\n",
            "Michael Wooldridge and Nicholas R. Jennings. Pitfalls of agent-oriented development. In Pro-\n",
            "ceedings of the Second International Conference on Autonomous Agents , 1998. URL https:\n",
            "//doi.org/10.1145/280765.280867 .\n",
            "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\n",
            "React: Synergizing reasoning and acting in language models. arXiv preprint , 2022.\n",
            "Eric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. Self-taught optimizer (stop):\n",
            "Recursively self-improving code generation. arXiv preprint , 2023.\n",
            "13\n",
            "\n",
            "page_label: 14\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tian-\n",
            "min Shu, and Chuang Gan. Building cooperative embodied agents modularly with large language\n",
            "models. arXiv preprint , 2023.\n",
            "Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, and Stefan Wermter. Chat\n",
            "with the environment: Interactive multimodal perception using large language models. arXiv\n",
            "preprint , 2023.\n",
            "Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen,\n",
            "Andi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang. Codegeex: A pre-trained model for\n",
            "code generation with multilingual evaluations on humaneval-x, 2023.\n",
            "Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng,\n",
            "Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for building\n",
            "autonomous agents. arXiv preprint , 2023.\n",
            "Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, R ´obert Csord ´as, Anand\n",
            "Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki\n",
            "Irie, et al. Mindstorms in natural language-based societies of mind. arXiv preprint , 2023.\n",
            "14\n",
            "\n",
            "page_label: 15\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "A O UTLOOK\n",
            "A.1 S ELF-IMPROVEMENT MECHANISMS\n",
            "One limitation of the MetaGPT version in the main text of this paper is that each software project is\n",
            "executed independently. However, through active teamwork, a software development team should\n",
            "learn from the experience gained by developing each project, thus becoming more compatible and\n",
            "successful over time.\n",
            "This is somewhat related to the idea of recursive self-improvement, first informally proposed in\n",
            "1965 (Good, 1965), with first concrete implementations since 1987 (Schmidhuber, 1987; 1993b;\n",
            "Schmidhuber et al., 1998), culminating in the concept of mathematically optimal self-referential\n",
            "self-improvers (Schmidhuber, 2003; 2009). Generally speaking, a system should learn from experi-\n",
            "ence in the real world, and meta-learn better learning algorithms from experiences of learning, and\n",
            "meta-meta-learn better meta-learning algorithms from experiences of meta-learning, etc., without\n",
            "any limitations except those of computability and physics.\n",
            "More recent, somewhat related work leverages the reasoning ability of Large Language Models\n",
            "(LLMs) and recursively improves prompts of LLMs, to improve performance on certain downstream\n",
            "tasks (Fernando et al., 2023; Zelikman et al., 2023), analogous to the adaptive prompt engineer of\n",
            "2015 (Schmidhuber, 2015) where one neural network learns to generate sequence of queries or\n",
            "prompts for another pre-trained neural network whose answers may help the first network to learn\n",
            "new tasks more quickly.\n",
            "In our present work, we also explore a self-referential mechanism that recursively modifies the con-\n",
            "straint prompts of agents based on information they observe during software development. Our\n",
            "initial implementation works as follows. Prior to each project, every agent in the software company\n",
            "reviews previous feedback and makes necessary adjustments to their constraint prompts. This en-\n",
            "ables them to continuously learn from past project experiences and enhance the overall multi-agent\n",
            "system by improving each individual in the company. We first establish a handover feedback action\n",
            "for each agent. This action is responsible for critically summarizing the information received dur-\n",
            "ing the development of previous projects and integrating this information in an updated constraint\n",
            "prompt. The summarized information is stored in long-term memory such that it can be inherited\n",
            "by future constraint prompt updates. When initiating a new project, each agent starts with a react\n",
            "action. Each agent evaluates the received feedback and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically, AgentStore allows users to subscribe\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is this paper about?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "and summarizes how they can improve in a\n",
            "constraint prompt.\n",
            "One current limitation is that these summary-based optimizations only modify constraints in the\n",
            "specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\n",
            "protocols (Sec. 3.2). Future advancements are yet to be explored.\n",
            "A.2 M ULTI -AGENT ECONOMIES\n",
            "In real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\n",
            "ware company, the collaboration SOP may change dynamically.\n",
            "One implementation of such self-organization is discussed in the paper on a “Natural Language-\n",
            "Based Society of Mind” (NLSOM) (Zhuge et al., 2023), which introduced the idea of an “Economy\n",
            "of Minds” (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\n",
            "agents. Instead of using standard RL techniques to optimize the total reward of the system through\n",
            "modifications of neural network parameters, EOMs use the principles of supply and demand in free\n",
            "markets to assign credit (money) to those agents that contribute to economic success (reward).\n",
            "The recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\n",
            "signment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\n",
            "costs. A convenient API is provided so that human users or agents in the platform can easily pur-\n",
            "chase services from other agents to accomplish their services. Figure 6 displays the User Interface\n",
            "(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\n",
            "developers can participate in building new agents and enable collaborative development within the\n",
            "community. Specifically, AgentStore allows users to subscribe to agents according to their demands\n",
            "4http://beta.deepwisdom.ai\n",
            "15\n",
            "\n",
            "page_label: 16\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "and pay according to their usage. Moreover, users can purchase additional capabilities to expand the\n",
            "plug-and-play functions of their existing agents. This allows users to gradually upgrade their agents.\n",
            "Within the MetaGPT framework, AgentStore can support the collaboration of various agents. Users\n",
            "can collect several agents together to carry out more complex tasks or projects, and all the agents\n",
            "share and comply with development and communication protocols defined in MetaGPT.\n",
            "Figure 6: AgentStore is a platform dedicated to serving users in the creation and development of\n",
            "agents within the MetaGPT framework. This platform provides users with an operational interface,\n",
            "allowing users to easily manage a variety of agents with different emotions, personalities, and capa-\n",
            "bilities for specific tasks.\n",
            "16\n",
            "\n",
            "page_label: 17\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "B A D EMO OF THE EXECUTION\n",
            "In this section, we outline the complete process of software development using MetaGPT. It begins\n",
            "with a user’s input command (as shown in Appendix B.1) and ends with software designed according\n",
            "to the user’s specifications.\n",
            "B.1 U SERINPUT\n",
            "Upon receiving an instruction from the user, MetaGPT collaborates with a professional development\n",
            "team to fulfill the task. Here is a demo of user input:\n",
            "User input\n",
            "1write a python3 GUI app such that you can draw an image with it\n",
            "B.2 M ETAGPT DEVELOPMENT PROCESS\n",
            "Now we provide a step-by-step explanation of the standardized output process for each agent.\n",
            "Product Manager The Product Manager generates a Product Requirement Document (PRD), as\n",
            "detailed in the specified documentation. This document encompasses goals, user stories, competitive\n",
            "analysis, requirement analysis and requirement pool. Additionally, a competitive quadrant chart is\n",
            "produced (see Figure 7). Subsequently, these documents and charts are handed over to the architect\n",
            "for system design.\n",
            "Product Requirement Document\n",
            "1## Original Requirements\n",
            "2The boss requires a Python3 GUI color meter that outputs the RGB values when it moves.\n",
            "3\n",
            "4## Product Goals\n",
            "5‘‘‘python\n",
            "6[\n",
            "7 \"Create a user-friendly GUI color meter\",\n",
            "8 \"Ensure the color meter accurately outputs RGB values\",\n",
            "9 \"Ensure the color meter updates RGB values in real-time as it moves\"\n",
            "10]\n",
            "11‘‘‘\n",
            "12\n",
            "13## User Stories\n",
            "14‘‘‘python\n",
            "15[\n",
            "16 \"As a user, I want to select any color on the screen, so that I can get its RGB values\",\n",
            "17 \"As a user, I want the RGB values to update in real-time as I move the color meter, so that I\n",
            ",→can get accurate color information\",\n",
            "18 \"As a user, I want a simple and intuitive interface, so that I can easily use the color meter\"\n",
            "19]\n",
            "20‘‘‘\n",
            "21\n",
            "22## Competitive Analysis\n",
            "23‘‘‘python\n",
            "24[\n",
            "25 \"Color Cop: A popular color picker for Windows. It’s simple and easy to use, but lacks real-\n",
            ",→time RGB value updates\",\n",
            "26 \"Just Color Picker: Offers real-time color picking and multiple color code formats. However,\n",
            ",→its interface is cluttered and not very user-friendly\",\n",
            "27 \"Instant Eyedropper: A simple color picker that lives in the system tray. It’s convenient but\n",
            ",→lacks advanced features\",\n",
            "28 \"ColorZilla: A color picker extension for browsers. It’s convenient for web design but not\n",
            ",→suitable for desktop applications\",\n",
            "29 \"ColorPic: Offers color palettes and mixer tools. It’s feature-rich but can be overwhelming\n",
            ",→for simple tasks\"\n",
            "30]\n",
            "31‘‘‘\n",
            "17\n",
            "\n",
            "page_label: 18\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1\n",
            "2## Requirement Analysis\n",
            "3The product should be a Python3 GUI application that serves as a color meter. It should allow\n",
            ",→users to select any color on the screen and display the corresponding RGB values. The RGB\n",
            ",→ values should update in real-time as the color meter moves. The interface should be\n",
            ",→simple and user-friendly.\n",
            "4\n",
            "5## Requirement Pool\n",
            "6‘‘‘python\n",
            "7[\n",
            "8 (\"Design a user-friendly GUI for the color meter\", \"P0\"),\n",
            "9 (\"Implement color selection functionality\", \"P0\"),\n",
            "10 (\"Display RGB values of the selected color\", \"P0\"),\n",
            "11 (\"Update RGB values in real-time as the color meter moves\", \"P0\"),\n",
            "12 (\"Test the application for accuracy and performance\", \"P1\")\n",
            "13]\n",
            "14‘‘‘\n",
            "15\n",
            "16## UI Design draft\n",
            "17The UI should be minimalistic and intuitive. It should primarily consist of a color meter, which\n",
            ",→could be a magnified area of the screen that the user can move around. The RGB values of\n",
            ",→the currently selected color should be prominently displayed, updating in real-time as\n",
            ",→the color meter moves. The layout should be clean and uncluttered, with a focus on\n",
            ",→functionality and ease of use.\n",
            "18\n",
            "19## Anything UNCLEAR\n",
            "20There are no unclear points.\n",
            "Figure 7: The quadrant chart for the “Drawing App” generated by the product manager agent.\n",
            "18\n",
            "\n",
            "page_label: 19\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Architect Based on the requirements in PRD, the Architect agent devises technical specifications\n",
            "including system architecture diagrams and interface definitions. Initially, the Architect defines the\n",
            "overarching technical trajectory. Subsequently, the project’s architecture, including files, classes\n",
            "(Figure 8) and the sequence flow chart (Figure 12), is designed. The Architect’s documentation is\n",
            "then given to the project manager for task allocation and execution.\n",
            "System design\n",
            "1## Implementation approach\n",
            "2We will use Python’s Tkinter library to create the GUI for the color meter. Tkinter is a standard\n",
            ",→Python interface to the Tk GUI toolkit and is included with most Python installations. It\n",
            ",→ is simple to use and powerful enough for our needs.\n",
            "3\n",
            "4The color selection functionality will be implemented using the PIL (Pillow) library, which allows\n",
            ",→ us to capture the screen’s pixel data. By moving the mouse, we can get the RGB values of\n",
            ",→ the pixel under the mouse cursor in real-time.\n",
            "5\n",
            "6The RGB values will be displayed on the GUI using Tkinter’s Label widget. We will use Python’s\n",
            ",→threading library to update the RGB values in real-time as the color meter moves.\n",
            "7\n",
            "8The application will be tested for accuracy and performance using Python’s unittest library.\n",
            "9\n",
            "10## Python package name\n",
            "11‘‘‘python\n",
            "12\"color_meter\"\n",
            "13‘‘‘\n",
            "14\n",
            "15## File list\n",
            "16‘‘‘python\n",
            "17[\n",
            "18 \"main.py\",\n",
            "19 \"color_picker.py\",\n",
            "20 \"gui.py\",\n",
            "21 \"tests.py\"\n",
            "22]\n",
            "23‘‘‘\n",
            "24\n",
            "25## Anything UNCLEAR\n",
            "26The requirement is clear to me.\n",
            "Figure 8: Data structures and interface definitions for the “Drawing App” generated by the architect\n",
            "agent.\n",
            "Project Manager The Project Manager breaks down the project into a task list. Furthermore, each\n",
            "code file is analyzed based on its intended functionality and then treated as a separate task assigned\n",
            "to Engineers.\n",
            "19\n",
            "\n",
            "page_label: 20\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 9: The program call flow for the “Drawing App” generated by the architect agent.\n",
            "Tasks\n",
            "1## Required Python third-party packages\n",
            "2\n",
            "3‘‘‘python\n",
            "4\"\"\"\n",
            "5tkinter==8.6\n",
            "6Pillow==8.3.1\n",
            "7\"\"\"\n",
            "8‘‘‘\n",
            "9\n",
            "10## Required Other language third-party packages\n",
            "11‘‘‘python\n",
            "12\"\"\"\n",
            "13No third-party packages required in other languages.\n",
            "14\"\"\"\n",
            "15‘‘‘\n",
            "16\n",
            "17## Full API spec\n",
            "18‘‘‘python\n",
            "19\"\"\"\n",
            "20No APIs are used in this project.\n",
            "21\"\"\"\n",
            "22‘‘‘\n",
            "23\n",
            "24## Logic Analysis\n",
            "25‘‘‘python\n",
            "26[\n",
            "27 (\"main.py\", \"Contains the main application loop and initializes all the other components.\"),\n",
            "28 (\"canvas.py\", \"Implements the drawing canvas, responds to mouse events, and uses the selected\n",
            ",→tool and color.\"),\n",
            "29 (\"tools.py\", \"Implements the tool selection interface.\"),\n",
            "30 (\"color_picker.py\", \"Implements the color selection interface.\"),\n",
            "31 (\"file_manager.py\", \"Implements the file saving and opening functionality.\")\n",
            "32]\n",
            "33‘‘‘\n",
            "20\n",
            "\n",
            "page_label: 21\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Product Requirement Document\n",
            "1## Task list\n",
            "2‘‘‘python\n",
            "3[\n",
            "4 \"main.py\",\n",
            "5 \"canvas.py\",\n",
            "6 \"tools.py\",\n",
            "7 \"color_picker.py\",\n",
            "8 \"file_manager.py\"\n",
            "9]\n",
            "10‘‘‘\n",
            "11\n",
            "12## Shared Knowledge\n",
            "13‘‘‘python\n",
            "14\"\"\"\n",
            "15The ’Tkinter’ library is used for creating the GUI of the application. It provides various widgets\n",
            ",→ like frames and canvases which are used in this project.\n",
            "16The ’Pillow’ library is used for handling image files. It is used in the ’file_manager.py’ for\n",
            ",→saving and opening image files.\n",
            "17The ’main.py’ file is the entry point of the application. It initializes all the other components\n",
            ",→and starts the application loop.\n",
            "18\"\"\"\n",
            "19‘‘‘\n",
            "20\n",
            "21## Anything UNCLEAR\n",
            "22The project requirements and implementation approach are clear. However, we need to ensure that\n",
            ",→all team members are familiar with the Tkinter and Pillow libraries. If not, they may\n",
            ",→need some time to learn these libraries before starting the development.\n",
            "21\n",
            "\n",
            "page_label: 22\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Engineer Given the provided file structure and function definitions, an Engineer agent requires\n",
            "only fundamental development skills to complete the development tasks. Due to the large number\n",
            "of files, we present only one auto-generated code file here.\n",
            "Generated code (color picker.py)\n",
            "1import tkinter as tk\n",
            "2from tkinter import colorchooser\n",
            "3class ColorPicker:\n",
            "4 def __init__(self, root: tk.Tk, color: str = ’black’):\n",
            "5 self.frame = tk.Frame(root)\n",
            "6 self.color = color\n",
            "7\n",
            "8 self.color_button = tk.Button(self.frame, text=’Color’, command=self.select_color)\n",
            "9 self.color_button.pack(fill=’x’)\n",
            "10\n",
            "11 def select_color(self):\n",
            "12 color = colorchooser.askcolor()[1]\n",
            "13 if color is not None:\n",
            "14 self.color = color\n",
            "15\n",
            "16 def pack(self, **kwargs):\n",
            "17 self.frame.pack( **kwargs)\n",
            "18\n",
            "19 def get_color(self):\n",
            "20 return self.color\n",
            "QA Engineer Upon receiving the code output from the Engineer, the QA Engineer generates unit\n",
            "test code and reviews it to identify and fix any bugs, ensuring high-quality software.\n",
            "Generated Unit tests (test.py)\n",
            "1import unittest\n",
            "2import tkinter as tk\n",
            "3# You might want to move the ColorPicker class to another file, let’s say color_picker.py\n",
            "4# from color_picker import ColorPicker\n",
            "5\n",
            "6class TestColorPicker(unittest.TestCase):\n",
            "7\n",
            "8 def setUp(self):\n",
            "9 self.root = tk.Tk()\n",
            "10 self.cp = ColorPicker(self.root)\n",
            "11\n",
            "12 def tearDown(self):\n",
            "13 # This is important to close the tk window after tests\n",
            "14 self.root.destroy()\n",
            "15\n",
            "16 def test_initial_color(self):\n",
            "17 # Test the default color during initialization\n",
            "18 self.assertEqual(self.cp.get_color(), ’black’)\n",
            "19\n",
            "20 def test_set_and_get_color(self):\n",
            "21 # Test setting a new color and retrieving it\n",
            "22 new_color = ’#ffffff’ # white color\n",
            "23 self.cp.color = new_color\n",
            "24 self.assertEqual(self.cp.get_color(), new_color)\n",
            "25\n",
            "26\n",
            "27if __name__ == ’__main__’:\n",
            "28 unittest.main()\n",
            "Output Ultimately, as shown in Figure 10, MetaGPT generates a functional application named\n",
            "“Drawing App”.\n",
            "22\n",
            "\n",
            "page_label: 23\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 10: The “Drawing App” generated by MetaGPT.\n",
            "C E XPERIMENTS\n",
            "C.1 D ETAILS OF THE SOFTWARE DEVDATASET\n",
            "The SoftwareDev dataset includes 70 diverse software development tasks. Table 8 displays the\n",
            "names and detailed prompts of 11 tasks within the dataset. Note that the first seven tasks listed are\n",
            "used in the main experiments of this paper.\n",
            "C.2 A DDITIONAL RESULTS\n",
            "Quantitative results of MetaGPT As shown in Table 4, MetaGPT achieves an average score\n",
            "of 3.9, surpassing ChatDev’s score of 2.1 Zhao et al. (2023), which is based on the Chat chain.\n",
            "Compare the scores of general intelligent algorithms, including AutoGPT Torantulino et al. (2023),\n",
            "which all score 1.0, failing to generate executable code. We observe that the generated code is often\n",
            "short, lacks comprehensive logic, and tends to fail to handle cross-file dependencies correctly.\n",
            "While models such as AutoGPT (Torantulino et al., 2023), Langchain (Chase, 2022), and Agent-\n",
            "Verse (Chen et al., 2023) display robust general problem-solving capabilities, they lack an essential\n",
            "element for developing complex systems: systematically deconstructing requirements. Conversely,\n",
            "MetaGPT simplifies the process of transforming abstract requirements into detailed class and func-\n",
            "tion designs through a specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1 1 2\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is this paper about?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "specialized division of labor and SOPs workflow. When compared to Chat-\n",
            "Dev (Zhao et al., 2023), MetaGPT’s structured messaging and feedback mechanisms not only reduce\n",
            "loss of communication information but also improve the execution of code.\n",
            "Quantitative results of MetaGPT w/o executable feedback Table 9 presents the performance of\n",
            "MetaGPT with GPT-4 32K on 11 tasks within the SoftwareDev dataset. It also shows the average\n",
            "performance across all 70 tasks (in the last line). Note that the version of MetaGPT used here is the\n",
            "basic version without the executable feedback mechanism.\n",
            "Quantitative results of MetaGPT with different LLMs To verify the performance of MetaGPT\n",
            "on different LLMs, we randomly selected 5 SoftwareDev tasks and conducted experiments using\n",
            "GPT-3.5 and Deepseek Coder 33B5as backends. As shown in Table 5, the results indicate that\n",
            "although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior\n",
            "performance.\n",
            "5https://deepseekcoder.github.io\n",
            "23\n",
            "\n",
            "page_label: 24\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 4: Executability comparison. The executability scores are on a grading system ranging from\n",
            "’1’ to ’4’. A score of ’1’ signifies complete failure, ’2’ denotes executable code, ’3’ represents\n",
            "largely satisfying expected workflow, and ’4’ indicates a perfect match with expectations.\n",
            "Task AutoGPT LangChain AgentVerse ChatDev MetaGPT\n",
            "Flappy bird 1 1 1 2 3\n",
            "Tank battle game 1 1 1 2 4\n",
            "2048 game 1 1 1 1 4\n",
            "Snake game 1 1 1 3 4\n",
            "Brick breaker game 1 1 1 1 4\n",
            "Excel data process 1 1 1 4 4\n",
            "CRUD manage 1 1 1 2 4\n",
            "Average score 1.0 1.0 1.0 2.1 3.9\n",
            "Table 5: Performance of MetaGPT on SoftwareDev using different LLMs as agent backends.\n",
            "Model Open source Time(/s) # Lines Executability Revisions\n",
            "MetaGPT (w/ GPT-3.5) % 75.18 161.6 2.8 2.4\n",
            "MetaGPT (w/ GPT-4) % 552.94 178.2 3.8 1.2\n",
            "MetaGPT (w/ Deepseek Coder 33B) \" 1186.20 120.2 1.4 2.6\n",
            "Impact of Instruction Levels (High-level v.s.Detailed Instructions) Does the variation in the\n",
            "level of initial input from humans significantly influence performance outcomes? For examples:\n",
            "1.High-level prompt : Create a brick breaker game.\n",
            "2.Detailed prompt : Creating a brick breaker game. In a brick breaker game, the player\n",
            "typically controls a paddle at the bottom of the screen to bounce a ball towards a wall of\n",
            "bricks. The goal is to break all the bricks by hitting them with the ball.\n",
            "Additional experiments were conducted to investigate this aspect: we selected 5 tasks from Soft-\n",
            "wareDev, and constructed detailed prompts for them. Here are the experimental results:\n",
            "Table 6: Impact of Instruction Levels. The executability is scored on a grading system ranging\n",
            "from ‘1’ to ‘4’. A score of ‘1’ signifies complete failure, ‘2’ denotes runnable code, ‘3’ represents\n",
            "largely expected workflow, and ‘4’ indicates a perfect match to expectations.\n",
            "Model # Word Time(/s) Token usage # Lines Executability Productivity Reversions\n",
            "High-level 13.2 552.9 28384.2 178.2 3.8 163.8 1.2\n",
            "Detailed 42.2 567.8 29657.0 257.0 4.0 118.0 1.6\n",
            "We observe that: detailed prompts lead to better software projects with lower productivity ratios\n",
            "because of clearer requirements and functions, while simple inputs can still generate good enough\n",
            "software using MetaGPT with an executability rating of 3.8, which is comparable to the detailed\n",
            "prompt scenario. (Note that, Productivity = Token usage / Total Code Lines. The lower this ratio,\n",
            "the better.)\n",
            "The performance of GPT variants in HumanEval benchmark We use the GPT-4’s 67% Hu-\n",
            "manEval score (OpenAI, 2023) as our baseline, acknowledging its acceptance in the HumanEval\n",
            "benchmark. We further extend to experiments(five times) with GPT-4 (gpt-4-0613) and GPT-3.5-\n",
            "Turbo (gpt-3.5-turbo-0613) under various conditions to assess performance. (A)We directly called\n",
            "the OpenAI API with the prompt in HumanEval. (B)We called the OpenAI API and parsed the\n",
            "code with regex in the response. (C)We added an additional system prompt, then called the OpenAI\n",
            "API. The prompt is ”You are an AI that only responds with Python code, NOT ENGLISH. You will\n",
            "24\n",
            "\n",
            "page_label: 25\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "be given a function signature and its docstring by the user. Write your full implementation (restate\n",
            "the function signature).” As shown in Table 7, GPT-4 is more sensitive to prompt, code parser, and\n",
            "post-processing results on the HumanEval data set. It is difficult for GPT-3.5-Turbo to return the\n",
            "correct completion code without prompt words.\n",
            "Table 7: Performance of GPT models on HumanEval. Experiments were conducted five times\n",
            "using gpt-4-0613 and gpt-3.5-turbo-0613 with different settings.\n",
            "Settings Model 1 2 3 4 5 Avg. Std.\n",
            "A gpt-4-0613 0.732 0.707 0.732 0.713 0.738 0.724 0.013\n",
            "A gpt-3.5-turbo-0613 0.360 0.366 0.360 0.348 0.354 0.357 0.007\n",
            "B gpt-4-0613 0.787 0.811 0.817 0.829 0.817 0.812 0.016\n",
            "B gpt-3.5-turbo-0613 0.348 0.354 0.348 0.335 0.348 0.346 0.007\n",
            "C gpt-4-0613 0.805 0.805 0.817 0.793 0.780 0.800 0.014\n",
            "C gpt-3.5-turbo-0613 0.585 0.567 0.573 0.579 0.579 0.577 0.007\n",
            "Qualitative results Figure 11 and Figure 12 illustrate the outcomes of the Architect agent’s ef-\n",
            "forts to design a complex recommender system. These figures showcase the comprehensive system\n",
            "interface design and program call flow. The latter is essential for creating a sophisticated automated\n",
            "system. It is crucial to emphasize the importance of this division of labor in developing an automated\n",
            "software framework.\n",
            "D L IMITATION AND ETHICS CONCERNS\n",
            "D.1 L IMITATION\n",
            "System side At present, our system cannot fully cater to specific scenarios, such as UI and front-\n",
            "end, as we have yet to incorporate such agents and multimodal tools. Furthermore, despite gen-\n",
            "erating the most amount of code among comparable frameworks, it remains challenging to fulfill\n",
            "real-world applications’ diverse and complex requirements.\n",
            "Human user side A key challenge for users is to interrupt the running process of each agent, or\n",
            "set the starting running point (checkpoint) for each agent.\n",
            "D.2 E THICS CONCERNS\n",
            "Unemployment and Skill Obsolescence MetaGPT enables more people to program in natural\n",
            "languages, thereby making it easier for engineers to get started. Over the years, programming\n",
            "languages have evolved from punched cards to assembly, C, Java, Python, and now natural lan-\n",
            "guage. As a result, humans have become more proficient at programming, increasing the demand\n",
            "for programming-related positions. Furthermore, programming with natural language may offer a\n",
            "significantly easier learning curve, making programming more accessible to a broader audience.\n",
            "Transparency and Accountability MetaGPT is an open-source framework that facilitates inter-\n",
            "active communication between multiple agents through natural language. Humans can initiate, ob-\n",
            "serve, and stop running with the highest level of control. It provides real-time interpretation and op-\n",
            "eration of the natural language, displayed on the screen and logs, ensuring transparency. MetaGPT\n",
            "enhances “natural language programming” capabilities, and human engineers are the users and re-\n",
            "sponsible for the outcomes.\n",
            "Privacy and Data Security MetaGPT operates locally, ensuring user data privacy and security. It\n",
            "does not collect user data. For interactions with third-party LLMs, such as those by OpenAI, users\n",
            "are encouraged to refer to the respective privacy policies (e.g., OpenAI Privacy Policy). However,\n",
            "we provide the option of open-source LLMs as backends.\n",
            "25\n",
            "\n",
            "page_label: 26\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 11: The system interface design for “recommendation engine development” is generated by\n",
            "thearchitect agent ( zoom in for a better view ).\n",
            "E M ORE DISCUSSIONS\n",
            "E.1 D EEP-SEATED CHALLENGES\n",
            "MetaGPT also alleviates or solves these challenges with its unique designs:\n",
            "Use Context Efficiently Two sub-challenges are present. First, unfolding short natural language\n",
            "descriptions accurately to eliminate ambiguity. Second, maintaining information validity in lengthy\n",
            "contexts, enables LLMs to concentrate on relevant data without distraction.\n",
            "Reduce Hallucinations Using LLMs to generate entire software programs faces code halluci-\n",
            "nation problems—-including incomplete implementation of functions, missing dependencies, and\n",
            "potential undiscovered bugs, which may be more serious. LLMs often struggle with software gen-\n",
            "eration due to vague task definitions. Focusing on granular tasks like requirement analysis and\n",
            "package selection offers guided thinking, which LLMs lack in broad task solving.\n",
            "E.2 I NFORMATION OVERLOAD\n",
            "In MetaGPT, we use a global message pool and a subscription mechanism to address “information\n",
            "overload,” which refers to the problem of receiving excessive or irrelevant information. This issue\n",
            "is dependent on specific applications. MetaGPT employs a message pool to streamline communi-\n",
            "cation, ensuring efficiency. Additionally, a subscription mechanism filters out irrelevant contexts,\n",
            "enhancing the relevance and utility of the information. This design is particularly crucial in soft-\n",
            "26\n",
            "\n",
            "page_label: 27\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 12: The program call flow for “recommendation engine development” generated by the\n",
            "architect agent ( zoom in for a better view ).\n",
            "ware design scenarios and standard operating procedures (SOPs) where effective communication is\n",
            "essential.\n",
            "27\n",
            "\n",
            "page_label: 28\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 8: Examples of SoftwareDev dataset.\n",
            "Task ID Task Prompt\n",
            "0 Snake game Create a snake game.\n",
            "1 Brick breaker game Create a brick breaker game.\n",
            "2 2048 game Create a 2048 game for the web.\n",
            "3 Flappy bird game Write p5.js code for Flappy Bird where you control a yellow bird continu-\n",
            "ously flying between a series of green pipes. The bird flaps every time you\n",
            "left click the mouse. If it falls to the ground or hits a pipe, you lose. This\n",
            "game goes on indefinitely until you lose; you get points the further you go.\n",
            "4 Tank battle game Create a tank battle game.\n",
            "5 Excel data process Write an excel data processing program based on streamlit and pandas. The\n",
            "screen first shows an excel file upload button. After the excel file is uploaded,\n",
            "use pandas to display its data content. The program is required to be concise,\n",
            "easy to maintain, and not over-designed. It uses streamlit to process web\n",
            "screen displays, and pandas is sufficient to process excel reading and display.\n",
            "Please make sure others can execute directly without introducing additional\n",
            "packages.\n",
            "6 CRUD manage Write a management program based on the crud addition, deletion, modifi-\n",
            "cation and query processing of the customer business entity. The customer\n",
            "needs to save this information: name, birthday, age, sex, and phone. The data\n",
            "is stored in client.db, and there is a judgement whether the customer table ex-\n",
            "ists. If it doesn’t, it needs to be created first. Querying is done by name; same\n",
            "for deleting. The program is required to be concise, easy to maintain, and not\n",
            "over-designed. The screen is realized through streamlit and sqlite—no need\n",
            "to introduce other additional packages.\n",
            "7 Music transcriber Develop a program to transcribe sheet music into a digital format; provid-\n",
            "ing error-free transcribed symbolized sheet music intelligence from audio\n",
            "through signal processing involving pitch and time slicing then training a\n",
            "neural net to run Onset Detected CWT transforming scalograms to chroma-\n",
            "grams decoded with Recursive Neural Network focused networks.\n",
            "8 Custom press releases Create custom press releases; develop a Python script that extracts rele-\n",
            "vant information about company news from external sources, such as social\n",
            "media; extract update interval database for recent changes. The program\n",
            "should create press releases with customizable options and export writings\n",
            "to PDFs, NYTimes API JSONs, media format styled with interlink internal\n",
            "fixed character-length metadata.\n",
            "9 Gomoku game Implement a Gomoku game using Python, incorporating an AI opponent\n",
            "with varying difficulty levels.\n",
            "10 Weather dashboard Create a Python program to develop an interactive weather dashboard.\n",
            "28\n",
            "\n",
            "page_label: 29\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Table 9: Additional results of pure MetaGPT w/o feedback on SoftwareDev. Averages (Avg.) of 70 tasks are calculated and 10 randomly selected tasks are\n",
            "included. ‘#’ denotes ‘The number of’, while ‘ID’ is ‘Task ID’.\n",
            "ID Code statistics Doc statistics Cost statistics Cost of revision Code executability\n",
            "#code files #lines of code #lines per code file #doc files #lines of doc #lines per doc file #prompt tokens #completion tokens time costs money costs\n",
            "0 5.00 196.00 39.20 3.00 210.00 70.00 24087.00 6157.00 582.04 $ 1.09 1. TypeError 4\n",
            "1 6.00 191.00 31.83 3.00 230.00 76.67 32517.00 6238.00 566.30 $ 1.35 1. TypeError 4\n",
            "2 3.00 198.00 66.00 3.00 235.00 78.33 21934.00 6316.00 553.11 $ 1.04 1. lack\n",
            "@app.route(’/’)3\n",
            "3 5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method not\n",
            "implement2\n",
            "9\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is this paper about?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "5.00 164 32.80 3.00 202.00 67.33 22951.00 5312.00 481.34 $ 1.01 1. PNG file miss-\n",
            "ing 2. Compile bug\n",
            "fixes2\n",
            "4 6.00 203.00 33.83 3.00 210.00 70.00 30087.00 6567.00 599.58 $ 1.30 1. PNG file\n",
            "missing 2. Com-\n",
            "pile bug fixes 3.\n",
            "pygame.surface not\n",
            "initialize3\n",
            "5 6.00 219.00 36.50 3.00 294.00 96.00 35590.00 7336.00 585.10 $ 1.51 1. dependency er-\n",
            "ror 2. ModuleNot-\n",
            "FoundError4\n",
            "6 4.00 73.00 18.25 3.00 261.00 87.00 25673.00 5832.00 398.83 $ 0.90 0 4\n",
            "7 4.00 316.00 79.00 3.00 332.00 110.67 29139.00 7104.00 435.83 $ 0.92 0 4\n",
            "8 5.00 215.00 43.00 3.00 301.00 100.33 29372.00 6499.00 621.73 $ 1.27 1. tensorflow ver-\n",
            "sion error 2. model\n",
            "training method not\n",
            "implement2\n",
            "9 5.00 215.00 43.00 3.00 270.00 90.00 24799.00 5734.00 550.88 $ 1.27 1. dependency er-\n",
            "ror 2. URL 403 er-\n",
            "ror3\n",
            "10 3.00 93.00 31.00 3.00 254.00 84.67 24109.00 5363.00 438.50 $ 0.92 1. dependency er-\n",
            "ror 2. missing main\n",
            "func.4\n",
            "Avg. 4.71 191.57 42.98 3.00 240.00 80.00 26626.86 6218.00 516.71 $1.12 0.51 (only consider\n",
            "item scored 2, 3 or\n",
            "4)3.36\n",
            "29\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is this paper about?\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "This paper describes MetaGPT, a new framework designed to improve the problem-solving abilities of large language models (LLMs) by organizing their interactions.  MetaGPT structures the collaboration of multiple specialized LLMs, each assigned a specific role and operating within a defined workflow inspired by human practices like Standardized Operating Procedures (SOPs). This approach aims to reduce errors and inconsistencies often found in less structured LLM interactions, leading to more robust and reliable problem-solving, particularly in domains like software development.\n",
            "\n",
            "This paper introduces a novel framework for autonomous software development that employs multiple agents. This framework leverages the strengths of large language models, specifically their ability to understand and generate human-like text, to perform tasks such as requirement analysis, code generation, and testing.  A key innovation of this framework is the incorporation of structured communication and a clearly defined workflow inspired by the software development life cycle. This structured approach, along with an iterative feedback mechanism, makes the system particularly adept at handling complex, multi-step software development tasks.\n",
            "\n",
            "This paper describes a new framework for building AI agents that can work together like a company to solve problems. This framework uses large language models and a system inspired by standard operating procedures to improve the quality of code generation.  The authors tested their framework on several benchmarks and found that it outperforms existing methods.\n",
            "\n",
            "This paper discusses a system of autonomous agents that collaboratively develop software. The agents learn from past experiences to improve their performance and the overall success of the multi-agent system.  The authors also explore self-improvement mechanisms and the concept of \"Economy of Minds\" where agents are rewarded based on their contribution to the system's success.\n",
            "\n",
            "This paper describes a new framework for developing software applications. The framework uses a team of specialized agents, each responsible for a specific stage of the software development process. This approach aims to improve the efficiency and quality of software development by leveraging the strengths of large language models.\n",
            "\n",
            "This research focuses on the development of a new framework designed to improve the process of software creation. This framework aims to enhance the capabilities of large language models (LLMs) in generating code, ultimately making it easier for people to develop software applications.\n",
            "\n",
            "This paper is about bug reproduction.\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: What is this paper about?\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "This paper introduces an innovative framework that uses a team of specialized AI agents to build software applications. These agents, powered by large language models, collaborate within a structured workflow similar to a company, with each agent responsible for a specific stage of the software development process. This approach aims to enhance the quality and efficiency of software development. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = vertex_gemini.predict_and_call(\n",
        "    [vector_query_tool, summary_tool],\n",
        "    \"what's the summary of the paper?\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbDCflqb9HAx",
        "outputId": "be698774-19d0-4b0a-82ab-d9c98656397e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
            "merged_message user: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
            "Function Calling, No Text Content\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool_metagpt with args: {\"query\": \"What are the roles of agents in MetaGPT and how do they communicate?\"}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information is below.\n",
            "---------------------\n",
            "page_label: 4\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 2: An example of the communication protocol (left) and iterative programming with exe-\n",
            "cutable feedback (right). Left: Agents use a shared message pool to publish structured messages.\n",
            "They can also subscribe to relevant messages based on their profiles. Right : After generating the\n",
            "initial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past\n",
            "messages stored in memory and compares them with the PRD, system design, and code files.\n",
            "3 M ETAGPT: A M ETA-PROGRAMMING FRAMEWORK\n",
            "MetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 pro-\n",
            "vides an explanation of role specialization, workflow and structured communication in this frame-\n",
            "work, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2\n",
            "presents a communication protocol that enhances role communication efficiency. We also imple-\n",
            "ment structured communication interfaces and an effective publish-subscribe mechanism. These\n",
            "methods enable agents to obtain directional information from other roles and public information\n",
            "from the environment. Finally, we introduce executable feedback—a self-correction mechanism for\n",
            "further enhancing code generation quality during run-time in Sec. 3.3.\n",
            "3.1 A GENTS IN STANDARD OPERATING PROCEDURES\n",
            "Specialization of Roles Unambiguous role specialization enables the breakdown of complex work\n",
            "into smaller and more specific tasks. Solving complex tasks or problems often requires the collab-\n",
            "oration of agents with diverse skills and expertise, each contributing specialized outputs tailored to\n",
            "specific issues.\n",
            "In a software company, a Product Manager typically conducts business-oriented analysis and derives\n",
            "insights, while a software engineer is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "\n",
            "page_label: 4\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Preprint\n",
            "Figure 2: An example of the communication protocol (left) and iterative programming with exe-\n",
            "cutable feedback (right). Left: Agents use a shared message pool to publish structured messages.\n",
            "They can also subscribe to relevant messages based on their profiles. Right : After generating the\n",
            "initial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past\n",
            "messages stored in memory and compares them with the PRD, system design, and code files.\n",
            "3 M ETAGPT: A M ETA-PROGRAMMING FRAMEWORK\n",
            "MetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 pro-\n",
            "vides an explanation of role specialization, workflow and structured communication in this frame-\n",
            "work, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2\n",
            "presents a communication protocol that enhances role communication efficiency. We also imple-\n",
            "ment structured communication interfaces and an effective publish-subscribe mechanism. These\n",
            "methods enable agents to obtain directional information from other roles and public information\n",
            "from the environment. Finally, we introduce executable feedback—a self-correction mechanism for\n",
            "further enhancing code generation quality during run-time in Sec. 3.3.\n",
            "3.1 A GENTS IN STANDARD OPERATING PROCEDURES\n",
            "Specialization of Roles Unambiguous role specialization enables the breakdown of complex work\n",
            "into smaller and more specific tasks. Solving complex tasks or problems often requires the collab-\n",
            "oration of agents with diverse skills and expertise, each contributing specialized outputs tailored to\n",
            "specific issues.\n",
            "In a software company, a Product Manager typically conducts business-oriented analysis and derives\n",
            "insights, while a software engineer is responsible for programming. We define five roles in our\n",
            "software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\n",
            "shown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\n",
            "goal, and constraints for each role. We also initialize the specific context and skills for each role.\n",
            "For instance, a Product Manager can use web search tools, while an Engineer can execute code, as\n",
            "shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\n",
            "Every agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\n",
            "servations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\n",
            "assist in finishing the job.\n",
            "Workflow across Agents By defining the agents’ roles and operational skills, we can establish\n",
            "basic workflows. In our work, we follow SOP in software development, which enables all agents to\n",
            "work in a sequential manner.\n",
            "4\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: What are the roles of agents in MetaGPT and how do they communicate?\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "Five roles — a product manager, architect, project manager, engineer, and QA engineer — are defined to represent a software company setting. Each role has a distinct profile that includes their name, goal, constraints, context, and skills. For example, a product manager might use web search tools, while an engineer might execute code.  All agents operate on a 'react-style' behavior, meaning they monitor their environment for important observations, such as messages from other agents, and react accordingly. These messages can either directly trigger actions or provide assistance in completing a task.  These agents communicate through a shared message pool, publishing structured messages and subscribing to relevant ones based on their roles. This structured communication enables agents to access both role-specific instructions and public information from their environment. \n",
            "\n",
            "merged_message user: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
            "merged_message model: \n",
            "merged_message user: Five roles — a product manager, architect, project manager, engineer, and QA engineer — are defined to represent a software company setting. Each role has a distinct profile that includes their name, goal, constraints, context, and skills. For example, a product manager might use web search tools, while an engineer might execute code.  All agents operate on a 'react-style' behavior, meaning they monitor their environment for important observations, such as messages from other agents, and react accordingly. These messages can either directly trigger actions or provide assistance in completing a task.  These agents communicate through a shared message pool, publishing structured messages and subscribing to relevant ones based on their roles. This structured communication enables agents to access both role-specific instructions and public information from their environment. \n",
            "\n",
            "=== LLM Response ===\n",
            "That's a great summary of the agent roles and communication in MetaGPT! You accurately described:\n",
            "\n",
            "* **Distinct Roles:** Each role (product manager, architect, etc.) has a clear purpose and different skills, mimicking a real software development team.\n",
            "* **React-Style Behavior:** Agents are constantly watching for new information (like messages) and take action based on those updates.\n",
            "* **Shared Message Pool:** This acts as a central communication hub. Agents post messages relevant to others and subscribe to topics they care about. \n",
            "\n",
            "This setup allows for a dynamic and collaborative environment where agents work together to achieve a common goal, much like a real software team. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = agent.query(\n",
        "    #\"what's the summary of the paper?\"\n",
        "    \"Tell me about the agent roles in MetaGPT, \"\n",
        "    \"and then how they communicate with each other.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WCz9FC-e8-T3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Tell me about the evaluation datasets used.\n",
            "merged_message user: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
            "merged_message model: \n",
            "merged_message user: Five roles — a product manager, architect, project manager, engineer, and QA engineer — are defined to represent a software company setting. Each role has a distinct profile that includes their name, goal, constraints, context, and skills. For example, a product manager might use web search tools, while an engineer might execute code.  All agents operate on a 'react-style' behavior, meaning they monitor their environment for important observations, such as messages from other agents, and react accordingly. These messages can either directly trigger actions or provide assistance in completing a task.  These agents communicate through a shared message pool, publishing structured messages and subscribing to relevant ones based on their roles. This structured communication enables agents to access both role-specific instructions and public information from their environment. \n",
            "\n",
            "merged_message model: That's a great summary of the agent roles and communication in MetaGPT! You accurately described:\n",
            "\n",
            "* **Distinct Roles:** Each role (product manager, architect, etc.) has a clear purpose and different skills, mimicking a real software development team.\n",
            "* **React-Style Behavior:** Agents are constantly watching for new information (like messages) and take action based on those updates.\n",
            "* **Shared Message Pool:** This acts as a central communication hub. Agents post messages relevant to others and subscribe to topics they care about. \n",
            "\n",
            "This setup allows for a dynamic and collaborative environment where agents work together to achieve a common goal, much like a real software team. \n",
            "\n",
            "merged_message user: Tell me about the evaluation datasets used.\n",
            "Function Calling, No Text Content\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool_metagpt with args: {\"query\": \"What are the evaluation datasets used?\"}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information is below.\n",
            "---------------------\n",
            "source: ['https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/']\n",
            "title: [\"Adversarial Attacks on LLMs | Lil'Log\"]\n",
            "description: ['The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space.']\n",
            "language: ['en']\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: What are the evaluation datasets used?\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "This information is not provided in the context. \n",
            "\n",
            "merged_message user: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
            "merged_message model: \n",
            "merged_message user: Five roles — a product manager, architect, project manager, engineer, and QA engineer — are defined to represent a software company setting. Each role has a distinct profile that includes their name, goal, constraints, context, and skills. For example, a product manager might use web search tools, while an engineer might execute code.  All agents operate on a 'react-style' behavior, meaning they monitor their environment for important observations, such as messages from other agents, and react accordingly. These messages can either directly trigger actions or provide assistance in completing a task.  These agents communicate through a shared message pool, publishing structured messages and subscribing to relevant ones based on their roles. This structured communication enables agents to access both role-specific instructions and public information from their environment. \n",
            "\n",
            "merged_message model: That's a great summary of the agent roles and communication in MetaGPT! You accurately described:\n",
            "\n",
            "* **Distinct Roles:** Each role (product manager, architect, etc.) has a clear purpose and different skills, mimicking a real software development team.\n",
            "* **React-Style Behavior:** Agents are constantly watching for new information (like messages) and take action based on those updates.\n",
            "* **Shared Message Pool:** This acts as a central communication hub. Agents post messages relevant to others and subscribe to topics they care about. \n",
            "\n",
            "This setup allows for a dynamic and collaborative environment where agents work together to achieve a common goal, much like a real software team. \n",
            "\n",
            "merged_message user: Tell me about the evaluation datasets used.\n",
            "merged_message model: \n",
            "merged_message user: This information is not provided in the context. \n",
            "\n",
            "=== LLM Response ===\n",
            "You are right! I apologize for the mistake. I cannot access external websites or specific documents without their content being provided in the context. \n",
            "\n",
            "Could you tell me more about what you'd like to know regarding evaluation datasets? For example, are you interested in:\n",
            "\n",
            "* **The types of tasks MetaGPT is evaluated on?** (e.g., code generation, problem-solving)\n",
            "* **Common benchmark datasets used in this field?** (I might be able to give examples even without knowing the specifics of MetaGPT's evaluation)\n",
            "* **The metrics used to measure performance?** (e.g., accuracy, code quality) \n",
            "\n",
            "Knowing your focus will help me give you a more helpful response! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\n",
        "    \"Tell me about the evaluation datasets used.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmvjfnTq8-XY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feWbCJ358-aN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRWWgbv-8-dg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MZvoeKd8-gh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDif4oYhWfBe",
        "outputId": "4ef4deb6-6bf4-4fd7-8a13-70a841a11752"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade git+https://github.com/wadave/llama_index.git@main\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E_-CSON-Rqm"
      },
      "source": [
        "### Task 4: Multi-document agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "papers = [\n",
        "    \"metagpt.pdf\",\n",
        "    \"longlora.pdf\",\n",
        "    \"loftq.pdf\",\n",
        "    \"swebench.pdf\",\n",
        "    \"selfrag.pdf\",\n",
        "    \"zipformer.pdf\",\n",
        "    \"values.pdf\",\n",
        "    \"finetune_fair_diffusion.pdf\",\n",
        "    \"knowledge_card.pdf\",\n",
        "    \"metra.pdf\",  \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting tools for paper: metagpt.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "Getting tools for paper: longlora.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "Getting tools for paper: loftq.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "Getting tools for paper: swebench.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "Getting tools for paper: selfrag.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "Getting tools for paper: zipformer.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "Getting tools for paper: values.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "Getting tools for paper: finetune_fair_diffusion.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "Getting tools for paper: knowledge_card.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "Getting tools for paper: metra.pdf\n",
            "Upserting datapoints MatchingEngineIndex index: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n",
            "MatchingEngineIndex index Upserted datapoints. Resource name: projects/77923429797/locations/us-central1/indexes/8741403313842421760\n"
          ]
        }
      ],
      "source": [
        "paper_to_tools_dict = {}\n",
        "for paper in papers:\n",
        "    print(f\"Getting tools for paper: {paper}\")\n",
        "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
        "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define an \"object\" index and retriever over these tools\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.objects import ObjectIndex\n",
        "\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    all_tools,\n",
        "    index_cls=VectorStoreIndex,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    tool_retriever=obj_retriever,\n",
        "    llm=vertex_gemini, \n",
        "    system_prompt=\"\"\" \\\n",
        "You are an agent designed to answer queries over a set of given papers.\n",
        "Please use the tools provided to answer a question as possible. Do not rely on prior knowledge. Summarize your answer\\\n",
        "\n",
        "\"\"\",\n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is the evaluation dataset used in MetaGPT? Compare it against SWE-Bench\n",
            "merged_message user:  You are an agent designed to answer queries over a set of given papers.\n",
            "Please use the tools provided to answer a question as possible. Do not rely on prior knowledge. Summarize your answer\n",
            "\n",
            "What is the evaluation dataset used in MetaGPT? Compare it against SWE-Bench\n",
            "Function Calling, No Text Content\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool_swebench with args: {\"query\": \"What is the evaluation dataset used in MetaGPT? Compare it against SWE-Bench\"}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information is below.\n",
            "---------------------\n",
            "page_label: 7\n",
            "file_path: metagpt.pdf\n",
            "\n",
            "Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both\n",
            "HumanEval and MBPP benchmarks. When MetaGPT collaborates with GPT-4, it significantly im-\n",
            "proves the Pass @ kin the HumanEval benchmark compared to GPT-4. It achieves 85.9% and 87.7%\n",
            "3https://en.wikipedia.org/wiki/Read–eval–print loop\n",
            "7\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: What is the evaluation dataset used in MetaGPT? Compare it against SWE-Bench\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "HumanEval and MBPP are two benchmarks used for evaluating code generation. One benchmark focuses on evaluating the functionality of generated code, while the other focuses on its ability to solve complex programming problems. \n",
            "\n",
            "merged_message user:  You are an agent designed to answer queries over a set of given papers.\n",
            "Please use the tools provided to answer a question as possible. Do not rely on prior knowledge. Summarize your answer\n",
            "\n",
            "What is the evaluation dataset used in MetaGPT? Compare it against SWE-Bench\n",
            "merged_message model: \n",
            "merged_message user: HumanEval and MBPP are two benchmarks used for evaluating code generation. One benchmark focuses on evaluating the functionality of generated code, while the other focuses on its ability to solve complex programming problems. \n",
            "\n",
            "=== LLM Response ===\n",
            "You're right! Let's break down HumanEval and MBPP to clarify their focuses:\n",
            "\n",
            "* **HumanEval** focuses on evaluating the **functionality** of generated code. It consists of a set of coding problems described in natural language, and the generated code is executed to check if it produces the expected output. \n",
            "\n",
            "* **MBPP** (Mostly Basic Python Problems) focuses on evaluating the ability of a language model to solve **complex programming problems**. It includes a diverse set of problems that require understanding of algorithms, data structures, and problem-solving techniques.\n",
            "\n",
            "**In essence:**\n",
            "\n",
            "* **HumanEval:**  Is the code functionally correct?\n",
            "* **MBPP:** Can the code solve intricate programming challenges? \n",
            "\n",
            "You're right! Let's break down HumanEval and MBPP to clarify their focuses:\n",
            "\n",
            "* **HumanEval** focuses on evaluating the **functionality** of generated code. It consists of a set of coding problems described in natural language, and the generated code is executed to check if it produces the expected output. \n",
            "\n",
            "* **MBPP** (Mostly Basic Python Problems) focuses on evaluating the ability of a language model to solve **complex programming problems**. It includes a diverse set of problems that require understanding of algorithms, data structures, and problem-solving techniques.\n",
            "\n",
            "**In essence:**\n",
            "\n",
            "* **HumanEval:**  Is the code functionally correct?\n",
            "* **MBPP:** Can the code solve intricate programming challenges? \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = agent.query(\n",
        "    \"What is the evaluation dataset used in MetaGPT? Compare it against SWE-Bench\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Compare and contrast the LoRA papers (LongLoRA, LoftQ). Analyze the approach in each paper first. \n",
            "merged_message user:  You are an agent designed to answer queries over a set of given papers.\n",
            "Please use the tools provided to answer a question as possible. Do not rely on prior knowledge. Summarize your answer\n",
            "\n",
            "Compare and contrast the LoRA papers (LongLoRA, LoftQ). Analyze the approach in each paper first. \n",
            "Function Calling, No Text Content\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_loftq with args: {\"query\": \"Summarize the LoftQ paper.\"}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "page_label: 1\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "LOFTQ: L ORA-F INE-TUNING -AWARE QUANTIZA -\n",
            "TION FOR LARGE LANGUAGE MODELS\n",
            "Yixiao Li1∗Yifan Yu1∗Chen Liang1Pengcheng He2\n",
            "Nikos Karampatziakis2Weizhu Chen2Tuo Zhao1\n",
            "ABSTRACT\n",
            "Quantization is an indispensable technique for serving Large Language Models\n",
            "(LLMs) and has recently found its way into LoRA fine-tuning (Dettmers et al.,\n",
            "2023). In this work we focus on the scenario where quantization and LoRA fine-\n",
            "tuning are applied together on a pre-trained model. In such cases it is common\n",
            "to observe a consistent gap in the performance on downstream tasks between\n",
            "full fine-tuning and quantization plus LoRA fine-tuning approach. In response,\n",
            "we propose LoftQ ( LoRA-Fine-Tuning-aware Quantization), a novel quantiza-\n",
            "tion framework that simultaneously quantizes an LLM and finds a proper low-\n",
            "rank initialization for LoRA fine-tuning. Such an initialization alleviates the dis-\n",
            "crepancy between the quantized and full-precision model and significantly im-\n",
            "proves generalization in downstream tasks. We evaluate our method on nat-\n",
            "ural language understanding, question answering, summarization, and natural\n",
            "language generation tasks. Experiments show that our method is highly ef-\n",
            "fective and outperforms existing quantization methods, especially in the chal-\n",
            "lenging 2-bit and 2/4-bit mixed precision regimes. The code is available on\n",
            "https://github.com/yxli2123/LoftQ .1 2\n",
            "1 I NTRODUCTION\n",
            "The advent of Pre-trained Language Models (PLMs) has marked a transformative shift in the field\n",
            "of Natural Language Processing (NLP), offering versatile solutions across various applications (He\n",
            "et al., 2021b; Lewis et al., 2019; Touvron et al., 2023). They have showcased unparalleled profi-\n",
            "ciency in executing a variety of language tasks, including Natural Language Understanding (NLU)\n",
            "and Natural Language Generation (NLG). These models typically have millions or even billions of\n",
            "parameters, necessitating substantial computational and memory requirements. However, the exten-\n",
            "sive computational and memory demands of these models pose significant challenges, especially for\n",
            "deployments where resources are often constrained and need to be shared among many users.\n",
            "To mitigate the extensive storage requirements of pre-trained models, quantization serves as a piv-\n",
            "otal compression technique (Zafrir et al., 2019; Shen et al., 2020; Bai et al., 2022; Dettmers et al.,\n",
            "2022), converting high-precision numerical values into a discrete set of values. Typically, model\n",
            "parameters, originally stored in a 16-bit float format, are transformed into a 4-bit integer format\n",
            "through quantization, resulting in a substantial 75% reduction in storage overhead. Additionally, to\n",
            "facilitate the adaptation of quantized pre-trained models to downstream tasks efficiently, Low-Rank\n",
            "Adaptation (LoRA) is a viable approach (Hu et al., 2021). This technique is a parameter-efficient\n",
            "fine-tuning method traditionally applied to high-precision pre-trained models. It is based on the\n",
            "hypothesis that the differences between fully fine-tuned weights and pre-trained weights exhibit\n",
            "low-rank properties. This allows these differences to be represented using low-rank matrices. As a\n",
            "result, the original pre-trained weights remain unaltered, with adaptations confined solely to these\n",
            "low-rank matrices, enabling effective task adaptation.\n",
            "∗Equal contribution\n",
            "1Li, Yu, Liang and Zhao are affiliated with Georgia Institute of Technology. Correspondence to\n",
            "yixiaoli@gatech.edu ,yyu429@gatech.edu andtourzhao@gatech.edu .\n",
            "2He, Karampatziakisand and Chen are affiliated with Microsoft Azure.\n",
            "1\n",
            "\n",
            "page_label: 2\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "When quantizing pre-trained models, practitioners often concentrate primarily on the quantization\n",
            "technique, inadvertently neglecting the importance of subsequent LoRA fine-tuning (Dettmers et al.,\n",
            "2023; Diao et al., 2023). For example, QLoRA inherits the fixup initialization (Zhang et al., 2019)\n",
            "used in LoRA, which (Dettmers et al., 2023) attaches zero initialized low-rank adapters (see Section\n",
            "2.3) to the quantized pre-trained model. The inevitable discrepancy introduced by quantization dur-\n",
            "ing the approximation of the original high-precision numbers, a scenario particularly pronounced\n",
            "in low-bit situations such as the 2-bit regime, can adversely impact the initialization of LoRA fine-\n",
            "tuning. As illustrated in Figure 1a, the quantized pre-trained model obtained by QLoRA exhibits\n",
            "severe degradation below the 3-bit level. This deviation in initialization often results in an inferior\n",
            "fine-tuning performance. As illustrated in Figure 1b, the fine-tuning performance drops as the quan-\n",
            "tization bit decreases when applying QLoRA. Moreover, it is noteworthy that QLoRA fails below\n",
            "the 3-bit level.\n",
            "In this paper, we introduce a novel quantization framework, called LoRA-Fine-Tuning-aware\n",
            "Quantization (LoftQ). It is designed specifically for pre-trained models that require quantization\n",
            "and LoRA fine-tuning. This framework actively integrates low-rank approximation, working in tan-\n",
            "dem with quantization to jointly approximate the original high-precision pre-trained weights. This\n",
            "synergy significantly enhances alignment with the original pre-trained weights as illustrated in Fig-\n",
            "ure 2. Consequently, our method provides an advantageous initialization point for subsequent LoRA\n",
            "fine-tuning, leading to improvements in downstream tasks.\n",
            "16 8 4 3 2.5 2.25 2\n",
            "Number of Bits24681012Log of Perplexity\n",
            "2.49 2.50 2.53 2.5311.37 11.48 11.50\n",
            "(a) Pre-trained LLAMA-2-13b on WikiText-2\n",
            "16 8 4 3 2.5 2.25 2\n",
            "Number of Bits0246Log of Perplexity1.63 1.64 1.65 1.652.996.807.19 (b) Fine-tuned LLAMA-2-13b on WikiText-2\n",
            "Figure 1: QLoRA performance with different bits. Left: QLoRA initialization of LLAMA-2-13b\n",
            "on WikiText-2. Right: Apply QLoRA to LLAMA-2-13b on WikiText-2 language modeling task.\n",
            "Smaller perplexity indicates better performance.\n",
            "We evaluate our quantization framework by conducting extensive experiments on downstream tasks,\n",
            "such as NLU, question answering, summarization, and NLG. Experiments show that LoftQ consis-\n",
            "tently outperforms QLoRA across all precision levels. For instance, with 4-bit quantization, we\n",
            "achieve a 1.1 and 0.8 gain in Rouge-1 for XSum (Narayan et al., 2018) and CNN/DailyMail (Her-\n",
            "mann et al., 2015), respectively. LoftQ excels particularly in low-bit scenarios and works effectively\n",
            "with different quantization methods. For example, we achieve over an 8% gain on MNLI (Wang\n",
            "et al., 2019) and more than 10% on SQuADv1.1 (Rajpurkar et al., 2016) with both 2-bit NormalFloat\n",
            "and the 2-bit uniform quantization. We have not seen our approach performs worse than QLoRA.\n",
            "2 B ACKGROUND\n",
            "2.1 T RANSFORMER MODELS\n",
            "A transformer model contains a sequence of layers, where each layer consists of two sub-layers: a\n",
            "multi-head self-attention (MHA) and a fully connected feed forward network (FFN) (Vaswani et al.,\n",
            "2017).\n",
            "\n",
            "page_label: 2\n",
            "file_path: loftq.pdf\n",
            "\n",
            "LoftQ excels particularly in low-bit scenarios and works effectively\n",
            "with different quantization methods. For example, we achieve over an 8% gain on MNLI (Wang\n",
            "et al., 2019) and more than 10% on SQuADv1.1 (Rajpurkar et al., 2016) with both 2-bit NormalFloat\n",
            "and the 2-bit uniform quantization. We have not seen our approach performs worse than QLoRA.\n",
            "2 B ACKGROUND\n",
            "2.1 T RANSFORMER MODELS\n",
            "A transformer model contains a sequence of layers, where each layer consists of two sub-layers: a\n",
            "multi-head self-attention (MHA) and a fully connected feed forward network (FFN) (Vaswani et al.,\n",
            "2017). Given the input X∈Rn×d, where nis the sequence length and dis the hidden dimension of\n",
            "the model, MHA computes the hattention heads in parallel:\n",
            "MHA( X) = Concat(head 1, ...,head h)Wo,\n",
            "where head i=Softmax( XW qi(XW ki)⊤/p\n",
            "dh)XW vifori= 1, ..., h,\n",
            "where Wqi, Wki, Wvi∈Rd×dhare query, key, and value matrices, Wo∈Rd×dis the output matrix,\n",
            "anddh=d/h. FFN comprises two linear transformations and an activation function, and is defined\n",
            "asFFN( X) =σ(XW f1+b1)Wf2+b2,where Wf1∈Rd×dm,Wf2∈Rdm×d, and σ(·)is the\n",
            "activation function. A residual connection is used and followed by layer normalization.\n",
            "2\n",
            "\n",
            "page_label: 3\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Uniform\n",
            "4bitNormalFloat\n",
            "4bitUniform\n",
            "2bitNormalFloat\n",
            "2bit02468101214DiscrepancyLoftQ\n",
            "QLoRA\n",
            "(a) Spectral norm of the initialization difference\n",
            "Uniform\n",
            "4bitNormalFloat\n",
            "4bitUniform\n",
            "2bitNormalFloat\n",
            "2bit0102030405060DiscrepancyLoftQ\n",
            "QLoRA (b) Frobenius norm of the initialization difference\n",
            "Figure 2: Initialization discrepancy between the LoRA initialization and the original pre-trained\n",
            "weight matrix, described by the spectral norm and Frobenius norm of the difference. The weight\n",
            "matrix in the above figures is randomly selected in BART-large. The initialization is obtained by\n",
            "QLoRA and LoftQ, with Uniform and NormalFloat quantization methods applied at both 2-bit and\n",
            "4-bit levels. LoftQ successfully mitigates the discrepancy, especially at the 2-bit level.\n",
            "2.2 Q UANTIZATION\n",
            "Quantization. Given a high-precision number, e.g., such as 32-bit floating point number, XHP∈R,\n",
            "N-bit quantization encodes it to an integer XINT∈ {0,1, ...,2N−1}. This process can be expressed\n",
            "as\n",
            "XINT=round\u0000\n",
            "(2N−1)F\u0000\n",
            "XHP\u0001\u0001\n",
            ", (1)\n",
            "where F(·):R7→[0,1]is a normalization function. Uniform quantization assumes F(X) = (X−\n",
            "Xmin)/(Xmax−Xmin). Dettmers et al. (2023) proposes 4-bit NormalFloat Quantization (NF4). It\n",
            "assumes X∼ N (0, σ2)and hence F(X) = Φ( X/σ), where Φ(·)is the cumulative distribution\n",
            "function of the standard normal distribution.\n",
            "Dequantization. A lookup table T, where\n",
            "T[i] =F−1\u0012i\n",
            "2N−1\u0013\n",
            ", i= 0,1, ...,2N−1, (2)\n",
            "is used to decode the integer XINTto its simulated high-precision counterpart XD∈R. Therefore,\n",
            "the dequantization can be expressed as\n",
            "XD=T[XINT]. (3)\n",
            "Simulated Quantization for Matrices. While it is possible to perform multiplication directly be-\n",
            "tween quantized representations, it is common to apply simulated quantization for matrices (Bai\n",
            "et al., 2020; Shen et al., 2020). There, quantized weight matrices are stored as encoded integers in\n",
            "memory, and are temporarily dequantized to simulated high-precision matrices by the lookup table\n",
            "when engaged in multiplication operations. In simulated quantization, it is only necessary to an-\n",
            "alyze the map from a high-precision matrix to a simulated high-precision matrix. We denote this\n",
            "end-to-end process by qN(·):Rm×n7→Rm×n\n",
            "N , where RN:{T[i]∈R|0≤i <2N}.\n",
            "2.3 L OW-RANK ADAPTATION\n",
            "LoRA (Hu et al., 2021) updates two small weight matrices AandBthat are attached to a frozen\n",
            "pre-trained weight matrix W. Hence, a linear transformation, Y=XW , is reformulated as\n",
            "Y=XW +XAB⊤, (4)\n",
            "where X∈Rn×d1, W∈Rd1×d2, A∈Rd1×r, B∈Rd2×r, andr≪min{d1, d2}. Initially,\n",
            "A∼ N(0, σ2), B= 0, (5)\n",
            "so as to align to the pre-trained weights. During the fine-tuning, Wis fixed while AandBare\n",
            "updated by some SGD-type optimization method.\n",
            "It is worth noting that if low-rank adapters AandBare attached to a quantized backbone Q=\n",
            "qN(W)and are initialized by (5), the starting weight Q+AB⊤is no longer equal to the pre-trained\n",
            "weight Wdue to the discrepancy introduced by the quantization.\n",
            "3\n",
            "\n",
            "page_label: 4\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "3 M ETHOD\n",
            "We propose LoRA-Fine-Tuning-aware Quantization (LoftQ), a quantization framework for LLMs.\n",
            "It alternatively applies quantization and low-rank approximation to approximate original pre-trained\n",
            "weights. This quantization framework provides a promising initialization for LoRA fine-tuning,\n",
            "which alleviates the quantization discrepancy in QLoRA and improves generalization in downstream\n",
            "tasks significantly.\n",
            "3.1 L ORA-A WARE QUANTIZATION\n",
            "We use an N-bit quantized weight Q∈Rd1×d2\n",
            "N and low-rank approximations A∈Rd1×r, B∈\n",
            "Rd2×rto approximate the original high-precision pre-trained weight W∈Rd1×d2as the initializa-\n",
            "tion of LoRA fine-tuning. Specifically, before fine-tuning, we initialize the network by minimizing\n",
            "the following objective:\n",
            "min\n",
            "W−Q−AB⊤\n",
            "F, (6)\n",
            "where ∥·∥Fdenotes the Frobenious norm. This objective in (6) takes LoRA fine-tuning into consid-\n",
            "eration by jointly optimizing the initial values of the quantized backbone Qand low-rank adapters\n",
            "A, B . Contrarily, practitioners typically convert the pre-trained weight Winto a quantized weight\n",
            "Qoutright, neglecting the subsequent LoRA fine-tuning process. This oversight leads to notable\n",
            "performance degradation in downstream tasks arising from the quantization discrepancy.\n",
            "3.2 A LTERNATING OPTIMIZATION\n",
            "We solve the minimization problem in (6) by alternating between quantization and singular value\n",
            "decomposition (SVD). To begin with, we set A0, andB0equal to 0.\n",
            "Quantization . At the t-th step, we quantize the difference between the original pre-trained weight\n",
            "matrix Wand the low-rank approximation At−1B⊤\n",
            "t−1from the previous step to obtain the quantized\n",
            "weight matrix Qtby\n",
            "Qt=qN(W−At−1B⊤\n",
            "t−1), (7)\n",
            "where qN(·)maps a high-precision weight matrix to a quantized matrix.\n",
            "We remark that our algorithm is compatible with different quantization functions qN(·). We apply\n",
            "NF4 and the uniform quantization in Section 4 as examples. We also remark that Qtis not an exact\n",
            "solution of the minimization in (6), given the fixed At−1B⊤\n",
            "t−1, but it is an efficient approximation.\n",
            "SVD . After obtaining the t-th quantized weight\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LoftQ paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "following objective:\n",
            "min\n",
            "W−Q−AB⊤\n",
            "F, (6)\n",
            "where ∥·∥Fdenotes the Frobenious norm. This objective in (6) takes LoRA fine-tuning into consid-\n",
            "eration by jointly optimizing the initial values of the quantized backbone Qand low-rank adapters\n",
            "A, B . Contrarily, practitioners typically convert the pre-trained weight Winto a quantized weight\n",
            "Qoutright, neglecting the subsequent LoRA fine-tuning process. This oversight leads to notable\n",
            "performance degradation in downstream tasks arising from the quantization discrepancy.\n",
            "3.2 A LTERNATING OPTIMIZATION\n",
            "We solve the minimization problem in (6) by alternating between quantization and singular value\n",
            "decomposition (SVD). To begin with, we set A0, andB0equal to 0.\n",
            "Quantization . At the t-th step, we quantize the difference between the original pre-trained weight\n",
            "matrix Wand the low-rank approximation At−1B⊤\n",
            "t−1from the previous step to obtain the quantized\n",
            "weight matrix Qtby\n",
            "Qt=qN(W−At−1B⊤\n",
            "t−1), (7)\n",
            "where qN(·)maps a high-precision weight matrix to a quantized matrix.\n",
            "We remark that our algorithm is compatible with different quantization functions qN(·). We apply\n",
            "NF4 and the uniform quantization in Section 4 as examples. We also remark that Qtis not an exact\n",
            "solution of the minimization in (6), given the fixed At−1B⊤\n",
            "t−1, but it is an efficient approximation.\n",
            "SVD . After obtaining the t-th quantized weight Qt, SVD is applied to the residual of the quantization\n",
            "denoted by Rt=W−Qtby\n",
            "Rt=dX\n",
            "i=1σt,iut,iv⊤\n",
            "t,i, (8)\n",
            "where d= min {d1, d2},σt,1≥σt,2≥...≥σt,dare the singular values of Rt,ut,i’s and vt,i’s are\n",
            "the associated left and right singular vectors of Rt. We then obtain a rank- rapproximation of Rtby\n",
            "AtB⊤\n",
            "t, where\n",
            "At= [√σt,1ut,1, ...,√σt,rut,r],\n",
            "Bt= [√σt,1vt,1, ...,√σt,rvt,r]. (9)\n",
            "We summarize our method in Algorithm 1. It is worth noting that T= 1is a special case where Q1is\n",
            "the exact quantized weight obtained by QLoRA, and low-rank approximations A1, B1are obtained\n",
            "by the SVD of the quantization residual W−Q1.T= 1 is sufficient to mitigate the quantization\n",
            "discrepancy, and alternating optimization helps to find a closer initialization to the pre-trained weight\n",
            "W, which further improves the performance (see Section 3).\n",
            "We remark that the computational cost of LoftQ is negligible because it is applied to individual\n",
            "weight matrices and can be executed in parallel. We also remark one can apply LoftQ only once to\n",
            "a pre-trained model and reuse the initialization obtained by LoftQ for different downstream tasks.\n",
            "3.3 A PPLYING TO LORA F INE-TUNING\n",
            "We store the QT∈Rd1×d2\n",
            "N obtained by LoftQ using an integer matrix Mby (1) and a lookup table\n",
            "Tby (2). We initialize the backbone with the integer matrix Mand initialize the low-rank adapters\n",
            "withAT, BTobtained by LoftQ.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Algorithm 1 LoftQ\n",
            "input Pre-trained weight W, target rank r,N-bit quantization function qN(·), alternating step T\n",
            "1:Initialize A0←0, B0←0\n",
            "2:fort =1toTdo\n",
            "3: Obtain quantized weight Qt←qN(W−At−1B⊤\n",
            "t−1)\n",
            "4: Obtain low-rank approximation At, Bt←SVD(W−Qt)by (9)\n",
            "5:end for\n",
            "output QT, AT, BT\n",
            "During LoRA fine-tuning, we freeze the integer weight Mand optimize the low-rank adapters with\n",
            "an efficient optimization algorithm, e.g., AdamW (Loshchilov & Hutter, 2017). In forward propa-\n",
            "gation, the integer weight Mis temporarily dequantized to the simulated high-precision weight QT\n",
            "by its lookup table, as described in (3). In back propagation, gradients and optimizer state are only\n",
            "related to low-rank adapters A, B , which reduces considerable training cost.\n",
            "4 E XPERIMENTS\n",
            "We evaluate our method on NLU and NLG tasks. We apply LoftQ for quantizing DeBERTaV3-base\n",
            "(He et al., 2021b), BART-large (Lewis et al., 2019), and LLAMA-2 series (Touvron et al., 2023).\n",
            "Implementation Details. Following the prior works of LoRA variants (Zhang et al., 2023; He\n",
            "et al., 2021a), we freeze all the backbone weight matrices and add low-rank adapters to weight\n",
            "matrices in MHA and FFN of all layers. We quantize the weight matrices that are attached by low-\n",
            "rank adapters. All the quantized models and adapters used in this paper are available on https:\n",
            "//huggingface.co/LoftQ . Our implementation is based on publicly available Huggingface\n",
            "Transformers code-base (Paszke et al., 2019). All the experiments are conducted on NVIDIA A100\n",
            "GPUs.\n",
            "Quantization Methods. We apply two quantization methods to demonstrate LoftQ is compatible\n",
            "with different quantization functions:\n",
            "•Uniform quantization is a classic quantization method. It uniformly divides a continuous\n",
            "interval into 2Ncategories and stores a local maximum absolute value for dequantization.\n",
            "•NF4 and its 2-bit variant NF2 are quantization methods used in QLoRA (Dettmers et al.,\n",
            "2023). They assume that the high-precision values are drawn from a Gaussian distribution\n",
            "and map these values to discrete slots that have equal probability.\n",
            "We perform 2-bit and 4-bit quantization on all models, achieving compression ratios of 25-30% and\n",
            "15-20% at the 4-bit and 2-bit levels, respectively. The compression ratios and trainable parameter\n",
            "ratios for all models are detailed in the Appendix A.\n",
            "Baselines. We compare LoftQ with the following baseline methods:\n",
            "•Full fine-tuning is the most common approach for adapting a pre-trained model to down-\n",
            "stream tasks. The model is initialized with pre-trained weights and all parameters are up-\n",
            "dated through an SGD-type optimization method.\n",
            "•Full precision LoRA (LoRA) is a lightweight method for task adaptation, where it stores the\n",
            "backbone using 16-bit numbers and optimizes the low-rank adaptors only. The adaptors\n",
            "are applied to the same matrices as in LoftQ.\n",
            "•QLoRA is similar to LoRA except the backbone is quantized into low-bit regime. The low-\n",
            "rank adapters are initialized using (5) and are applied to the same matrices as in LoftQ.\n",
            "4.1 E NCODER -ONLY MODEL : DEBERT AV3\n",
            "Models and Datasets. We quantize the DeBERTaV3-base (He et al., 2021b) with LoftQ, then fine-\n",
            "tune and evaluate the model on the General Language Understanding Evaluation (GLUE) bench-\n",
            "mark (Wang et al., 2019), SQuADv1.1 (Rajpurkar et al., 2016), and ANLI (Nie et al., 2019). The\n",
            "specific tasks of GLUE are given in Appendix C. Following previous works (Zhang et al., 2023), we\n",
            "exclude WNLI in the experiments.\n",
            "5\n",
            "\n",
            "page_label: 6\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Implementation Details. We select the learning rates from {1×10−5,5×10−5,1×10−45×10−4}.\n",
            "We quantize the entire backbone. Given that GLUE, SQuADv1.1, and ANLI are relatively easy\n",
            "NLU tasks, we also quantize the embedding layer for higher compression efficiency. We apply the\n",
            "NormalFloat and the uniform quantization for LoftQ and QLoRA at both 2-bit and 4-bit levels. We\n",
            "use rank 16 and 32 for low-rank adapters. More implementation details, such as the training epochs\n",
            "and batch sizes, are presented in Appendix D.2.\n",
            "Main Results. Table 1 and Table 2 summarize the results for 2-bit quantization on the GLUE,\n",
            "SQuADv1.1, and ANLI datasets, by NF2 and the uniform quantization, respectively. Our method\n",
            "consistently outperforms QLoRA on all settings with respect to different ranks, quantization meth-\n",
            "ods, and datasets. When using the uniform quantization (Table 2), our method achieves 88.0%\n",
            "accuracy on MNLI-m, surpassing the QLoRA baseline by 8%. For tasks like SST and SQuADv1.1,\n",
            "our method even approaches the full fine-tuning performance at 2-bit level. The 4-bit quantization\n",
            "experiment results are presented in Appendix D.1 as both LoftQ and QLoRA achieve performance\n",
            "close to full fine-tuning.\n",
            "Table 1: Results with 2-bit LoftQ of DeBERTaV3-base models on GLUE development set,\n",
            "SQuADv1.1 development set, ANLI test set using NF2 quantization . We report the median over\n",
            "four seeds. N.A. indicates the model does not converge. The best results on each dataset are shown\n",
            "inbold .\n",
            "Rank Method MNLI QNLI RTE SST MRPC CoLA QQP STSB SQuAD ANLI\n",
            "m / mm Acc Acc Acc Acc Matt Acc P/S Corr EM/F1 Acc\n",
            "- Full FT 90.5/90.6 94.0 82.0 95.3 89.5/93.3 69.2 92.4/89.8 91.6/91.1 88.5/92.8 59.8\n",
            "16 LoRA 90.4/90.5 94.6 85.1 95.1 89.9/93.6 69.9 92.0/89.4 91.7/91.1 87.3/93.1 60.2\n",
            "16QLoRA 75.4/75.6 82.4 55.9 86.5 73.8/82.8 N.A. 86.8/82.3 83.0/82.8 61.5 / 71.2 N.A.\n",
            "LoftQ 84.7/85.1 86.6 61.4 90.2 83.8/88.6 37.4 90.3/86.9 87.1/86.9 81.5/88.6 47.1\n",
            "32QLoRA 78.5/78.7 80.4 56.7 86.9 73.8/82.7 N.A. 87.1/82.7 83.6/83.3 64.6/73.8 N.A.\n",
            "LoftQ 86.0/86.1 89.9 61.7 92.0 83.6/87.2 47.5 91.0/87.9 87.5/87.0 82.9/89.8 49.0\n",
            "Table 2: Results with 2-bit LoftQ of DeBERTaV3-base models on GLUE development set,\n",
            "SQuADv1.1 development set using Uniform quantization . We report the median over four seeds.\n",
            "N.A. indicates the model does not converge. The best results on each task are shown in bold .\n",
            "\n",
            "page_label: 6\n",
            "file_path: loftq.pdf\n",
            "\n",
            "87.1/82.7 83.6/83.3 64.6/73.8 N.A.\n",
            "LoftQ 86.0/86.1 89.9 61.7 92.0 83.6/87.2 47.5 91.0/87.9 87.5/87.0 82.9/89.8 49.0\n",
            "Table 2: Results with 2-bit LoftQ of DeBERTaV3-base models on GLUE development set,\n",
            "SQuADv1.1 development set using Uniform quantization . We report the median over four seeds.\n",
            "N.A. indicates the model does not converge. The best results on each task are shown in bold .\n",
            "Rank Method MNLI QNLI RTE SST MRPC CoLA QQP STSB SQuAD\n",
            "m / mm Acc Acc Acc Acc Matt Acc P/S Corr Em/F1\n",
            "- Full FT 90.5/90.6 94.0 82.0 95.3 89.5/93.3 69.2 92.4/89.8 91.6/91.1 88.5/92.8\n",
            "16 LoRA 90.4/90.5 94.6 85.1 95.1 89.9/93.6 69.9 92.0/89.4 91.7/91.1 87.3/93.1\n",
            "16QLoRA 76.5/76.3 83.8 56.7 86.6 75.7/84.7 N.A. 87.1/82.6 83.5/83.4 69.5/77.6\n",
            "LoftQ 87.3/87.1 90.6 61.1 94.0 87.0/90.6 59.1 90.9/88.0 87.9/87.6 84.4/91.2\n",
            "32QLoRA 79.9/79.5 83.7 57.8 86.9 76.5/84.5 N.A. 88.6/84.7 84.1/84.0 71.6/80.2\n",
            "LoftQ 88.0/88.1 92.2 63.2 94.7 87.5/91.2 60.5 91.3/88.3 89.5/89.2 85.2/91.6\n",
            "Our method is also more stable compared to QLoRA in the low-bit regime. For instance, while\n",
            "QLoRA fails to converge on CoLA for both quantization methods and ranks, LoftQ converges in all\n",
            "cases and achieves a score of 60.5 using uniform quantization at rank 32. LoftQ stands out in its\n",
            "ability to consistently attain robust and improved performance by effectively preserving the starting\n",
            "point of pre-trained weights.\n",
            "4.2 E NCODER -DECODER MODEL : BART\n",
            "Models and Datasets. We quantize BART-large model (Lewis et al., 2020) with LoftQ, then fine-\n",
            "tune and evaluate the model on two commonly used summarization datasets: XSum (Narayan et al.,\n",
            "2018) and CNN/DailyMail(Hermann et al., 2015).\n",
            "Implementation Details. We apply LoftQ to weight matrices in MHA and FFN of both encoder and\n",
            "decoder layers. We report ROUGE 1/2/L scores, which are the metrics for summarization tasks (Lin,\n",
            "2004). We conduct quantization experiments in both 2-bit and 4-bit scenarios. We experiment with\n",
            "both NormalFloat and the uniform quantization in both 2-bit and 4-bit scenarios. In each precision,\n",
            "we choose rank equal to 8 and 16 for a fair comparison with the full precision LoRA baseline (Zhang\n",
            "et al., 2023). Please see Appendix E for detailed configurations.\n",
            "6\n",
            "\n",
            "page_label: 7\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Main Results. Table 3 summarizes our 4-bit quantization experiment results on the XSum and\n",
            "CNN/DailyMail test sets. Our method consistently outperforms QLoRA at both ranks on both\n",
            "datasets. It even surpasses full precision LoRA at both ranks on Xsum. We will discuss this un-\n",
            "expected results in Section 5. The\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LoftQ paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "score of 60.5 using uniform quantization at rank 32. LoftQ stands out in its\n",
            "ability to consistently attain robust and improved performance by effectively preserving the starting\n",
            "point of pre-trained weights.\n",
            "4.2 E NCODER -DECODER MODEL : BART\n",
            "Models and Datasets. We quantize BART-large model (Lewis et al., 2020) with LoftQ, then fine-\n",
            "tune and evaluate the model on two commonly used summarization datasets: XSum (Narayan et al.,\n",
            "2018) and CNN/DailyMail(Hermann et al., 2015).\n",
            "Implementation Details. We apply LoftQ to weight matrices in MHA and FFN of both encoder and\n",
            "decoder layers. We report ROUGE 1/2/L scores, which are the metrics for summarization tasks (Lin,\n",
            "2004). We conduct quantization experiments in both 2-bit and 4-bit scenarios. We experiment with\n",
            "both NormalFloat and the uniform quantization in both 2-bit and 4-bit scenarios. In each precision,\n",
            "we choose rank equal to 8 and 16 for a fair comparison with the full precision LoRA baseline (Zhang\n",
            "et al., 2023). Please see Appendix E for detailed configurations.\n",
            "6\n",
            "\n",
            "page_label: 7\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Main Results. Table 3 summarizes our 4-bit quantization experiment results on the XSum and\n",
            "CNN/DailyMail test sets. Our method consistently outperforms QLoRA at both ranks on both\n",
            "datasets. It even surpasses full precision LoRA at both ranks on Xsum. We will discuss this un-\n",
            "expected results in Section 5. The 2-bit quantization results are shown in Table 4. Our observation\n",
            "is consistent with the NLU experiments, that LoftQ demonstrates the convergence to reasonable\n",
            "results, while QLoRA does not converge. This indicates our method is robuster by narrowing the\n",
            "initialization gap.\n",
            "Table 3: Results with 4-bit LoftQ of BART-large on XSum and CNN/DailyMail. We report ROUGE-\n",
            "1/2/L. Lead-3 means choosing the first 3 sentences as the summary. N.A. indicates the model does\n",
            "not converge. Full FT : full fine-tuning. We report the median over five seeds.\n",
            "Quantization Rank Method XSum CNN/DailyMail\n",
            "Full Precision-Lead-3 16.30/1.60/11.95 40.42/17.62/36.67\n",
            "Full FT 45.14/22.27/37.25 44.16/21.28/40.90\n",
            "8 LoRA 43.40/20.20/35.20 44.72/21.58/41.84\n",
            "16 LoRA 43.95/20.72/35.68 45.03/21.84/42.15\n",
            "NF48QLoRA 42.91/19.72/34.82 43.10/20.22/40.06\n",
            "LoftQ 44.08/20.72/35.89 43.81/20.95/40.84\n",
            "16QLoRA 43.29/20.05/35.15 43.42/20.62/40.44\n",
            "LoftQ 44.51/21.14/36.18 43.96/21.06/40.96\n",
            "Uniform8QLoRA 41.84/18.71/33.74 N.A.\n",
            "LoftQ 43.86/20.51/35.69 43.73/20.91/40.77\n",
            "16QLoRA 42.45/19.36/34.38 43.00/20.19/40.02\n",
            "LoftQ 44.29/20.90/36.00 43.87/20.99/40.92\n",
            "Table 4: Results with 2-bit LoftQ of BART-large on XSum and CNN/DailyMail using NF2 quanti-\n",
            "zation .N.A. indicates the model does not converge. We report ROUGE-1/2/L, the higher the better.\n",
            "We report the median over five seeds.\n",
            "Rank Method XSum CNN/DailyMail\n",
            "8QLoRA N.A. N.A.\n",
            "LoftQ 39.63/16.65/31.62 42.24/19.44/29.04\n",
            "16QLoRA N.A. N.A.\n",
            "LoftQ 40.81/17.85/32.80 42.52/19.81/39.51\n",
            "4.3 D ECODER -ONLY MODEL : LLAMA-2\n",
            "Models and Datasets. We quantize LLAMA-2-7b and LLAMA-2-13b (Touvron et al., 2023) with\n",
            "LoftQ. We then fine-tune and evaluate the models on two NLG datasets: GSM8K (Cobbe et al.,\n",
            "2021) and WikiText-2 (Merity et al., 2016). Please see Appendix F for more details about the\n",
            "datasets.\n",
            "Implementation Details. Similarly, we apply LoftQ to weight matrices in MHA and FFN of all\n",
            "layers. In WikiText-2 evaluation, we report perplexity. In case of overfitting, we apply weight decay\n",
            "to low-rank adapters for all settings. In GSM8K evaluation, we extract numerical answers in the\n",
            "generated solutions and then calculate the accuracy using those numerical answers. We conduct\n",
            "experiments with both NF2 and NF4. Please see Appendix F for detailed configurations.\n",
            "Main Results.\n",
            "\n",
            "page_label: 7\n",
            "file_path: loftq.pdf\n",
            "\n",
            "We then fine-tune and evaluate the models on two NLG datasets: GSM8K (Cobbe et al.,\n",
            "2021) and WikiText-2 (Merity et al., 2016). Please see Appendix F for more details about the\n",
            "datasets.\n",
            "Implementation Details. Similarly, we apply LoftQ to weight matrices in MHA and FFN of all\n",
            "layers. In WikiText-2 evaluation, we report perplexity. In case of overfitting, we apply weight decay\n",
            "to low-rank adapters for all settings. In GSM8K evaluation, we extract numerical answers in the\n",
            "generated solutions and then calculate the accuracy using those numerical answers. We conduct\n",
            "experiments with both NF2 and NF4. Please see Appendix F for detailed configurations.\n",
            "Main Results. Table 5 presents a summary of our experiments on LLAMA-2-7b and LLAMA-2-\n",
            "13b using 2-bit, 4-bit, and mixed-precision NormalFloat quantization methods on WikiText-2 and\n",
            "GSM8K datasets. In WikiText-2, our method consistently outperforms QLoRA across all quantiza-\n",
            "tion precision settings on both models. When dealing with the challenging 2-bit precision, where\n",
            "QLoRA fails to converge, LoftQ manages to achieve a perplexity of 7.85. In GSM8K, our method\n",
            "achieves better or on par performance compared to QLoRA across different model sizes and quanti-\n",
            "zation precision levels. For example, our method achieves 26.5% accuracy using 2-bit precision of\n",
            "LLAMA-2-7b, where QLoRA does not converge.\n",
            "7\n",
            "\n",
            "page_label: 8\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "To provide a customized trade-off between the performance and precision, we also explore mixed-\n",
            "precision (equivalent to 3 bits) quantization where matrices in the first half layers are quantized\n",
            "using 4 bits, and the rest matrices remain 2 bits. We witness a remarkable 4.1% accuracy boost\n",
            "on the GSM8K dataset using LLAMA-2-7b and a 4.7% boost using LLAMA-2-13b. This result\n",
            "underscores the potential of LoftQ for complex mixed-precision quantization scenarios.\n",
            "Table 5: Results of LoftQ using NormalFloat for LLAMA-2 series on WikiText-2 and GSM8K.\n",
            "3/2.5/2.25-bit indicates mixed-precision quantization: 4-bit precision for the first 16/8/4 layers and\n",
            "2-bit precision for the rest of layers. We report the perplexity (the smaller the better) for WikiText-2\n",
            "and accuracy for GSM8K. The rank of low-rank adapters is 64. N.A. indicates the model does not\n",
            "converge. We report the median over five random seeds.\n",
            "Method BitLLAMA-2-7b LLAMA-2-13b\n",
            "WikiText-2 ↓GSM8K ↑WikiText-2 ↓GSM8K ↑\n",
            "LoRA 16 5.08 38.5 5.12 48.8\n",
            "QLoRA 4 5.70 38.2 5.22 48.8\n",
            "LoftQ 4 5.24 38.0 5.16 49.1\n",
            "QLoRA 3 5.73 32.1 5.22 40.7\n",
            "LoftQ 3 5.63 36.2 5.13 45.4\n",
            "QLoRA 2.5 N.A. N.A. 19.39 N.A.\n",
            "LoftQ 2.5 5.78 31.1 5.22 41.1\n",
            "QLoRA 2.25 N.A. N.A. N.A. N.A.\n",
            "LoftQ 2.25 6.13 27.5 5.45 38.1\n",
            "QLoRA 2 N.A N.A. N.A. N.A.\n",
            "LoftQ 2 7.85 26.5 7.69 33.4\n",
            "4.4 A NALYSIS\n",
            "Effectiveness of Alternating Optimization. We conduct experiments with different alternating\n",
            "stepTto verify the effectiveness of the alternating optimization and to find the best value Tas\n",
            "a hyperparameter for different models. Across all tasks and models, we observed that alternating\n",
            "optimization yields substantial improvements even with a minimal alternating step. This suggests\n",
            "that it rapidly narrows the discrepancy between quantized weights and pre-trained weights, making\n",
            "our method easy to apply. For example, LoftQ achieves 21.14 Rouge-2 score on XSum using only\n",
            "1 step. Interestingly, we noticed that increasing the alternating step beyond a certain point tends\n",
            "to result in diminishing returns. We suspect this phenomenon occurs because, as the gap becomes\n",
            "smaller, it becomes more challenging for alternating optimization to consistently minimize the gap\n",
            "at each step. This challenge emerges because of the inherent errors introduced by the quantization\n",
            "method. Nevertheless, results from Figure 3 indicate our method is not sensitive to the alternating\n",
            "stepTand is able to consistently enhance downstream fine-tuning performance.\n",
            "0 1 5 10\n",
            "Alternating Step T7580858890Accuracy79.986.688.0 87.7\n",
            "(a) MNLI\n",
            "20.022.525.027.0\n",
            "22.525.225.5\n",
            "0 1 5 10\n",
            "Alternating Step T011.2Accuracy (b) GSM8k\n",
            "0 1 5 10\n",
            "Alternating Step T19.020.021.021.5ROUGE-220.0521.14 21.09\n",
            "20.83 (c) XSum\n",
            "Figure 3: Comparison of different alternating step Tused in LoftQ. T= 0indicates we use QLoRA\n",
            "method that initializes low-rank adapters by (5). T= 1,5,10indicates we use different Tfor LoftQ\n",
            "described in Algorithm 1. Left: Uniform 2-bit DeBERTaV3-base. Middle : NF2 2-bit LLAMA-2-\n",
            "13b.Right : NF4 BART-large.\n",
            "8\n",
            "\n",
            "page_label: 9\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "5 D ISCUSSION\n",
            "Start with quantization or SVD in the alternating optimization? An alternative algorithm to the\n",
            "alternating optimization is that we first obtain the low-rank approximation At, Btand then obtain the\n",
            "quantized weight Qtby switching Line 3 and Line 4 in Algorithm 1. We note this is a valid alterna-\n",
            "tive method as both still jointly minimize the objective in (6). Table 6 summarizes the performance\n",
            "of this alternative method. It is noteworthy that the alternative method still outperforms QLoRA\n",
            "significantly, even though it is worse than the primary version. This observation underscores the\n",
            "potential for performance improvement by achieving a closer approximation of pre-trained weights\n",
            "within the low-precision regime.\n",
            "LoftQ better than Full-precision LoRA? We find LoftQ outperforms full precision LoRA in XSum\n",
            "and GSM8K (see Table 3 and Table 5). Beside the overfitting caused by lack of regularization,\n",
            "anonther possible explanation for this unexpected phenomenon is that the initial low-rank adapters\n",
            "obtained by LoftQ are non-zero while they are all zero in full precision LoRA as described in (5).\n",
            "Such zero initialization could make the fine-tuning unstable, and therefore it performs worse than\n",
            "LoftQ. We leave the study of the robustness of LoftQ as future work.\n",
            "Table 6: Results of 2-bit uniformly quantized DeBERTaV3-base on part of GLUE. LoftQ(SVD\n",
            "First) indicates the alternative LoftQ that swiches Line 3 and Line 4 in Algorithm 1. We report the\n",
            "median over four random seeds. The best results on each task are shown in bold .\n",
            "Method RankMNLI QNLI SST2\n",
            "m / mm Acc Acc\n",
            "Full FT - 90.5/90.6 94.0 95.3\n",
            "QLoRA 32 79.9/79.5 83.8 86.6\n",
            "LoftQ(SVD First) 32 87.8/87.7 84.9 89.7\n",
            "LoftQ(Quantiztion First) 32 88.0/88.1 92.2 94.7\n",
            "6 R ELATED WORK\n",
            "Quantization-Aware Training (QAT) is often used to obtain quantized models that are adapted\n",
            "in downstream tasks (Peri et al., 2020; Liu et al., 2023). It involves quantization and full model\n",
            "fine-tuning at the same time. However, QAT requires massive training cost, such as the gradient\n",
            "and optimization state. Moreover, it is difficult to compute the gradient of quantized weights. Our\n",
            "method, with the help of LoRA, sidesteps the aforementioned issues, providing a light approach for\n",
            "downstream task adaptation.\n",
            "Post-Training Quantization (PTQ) is a category of popular quantization frameworks (Frantar et al.,\n",
            "2022; Xiao et al., 2023), which can also be used for task adaptation. It calibrates the high-precision\n",
            "model with a small subset of the training dataset. Therefore, the subsequent quantization is guided\n",
            "by the training dataset, providing task-specific quantized models. Besides, it does not involve any\n",
            "gradient backpropagation, so it is cost-efficient. However, it usually results in lower accuracy com-\n",
            "pared to QAT.\n",
            "7 C ONCLUSION\n",
            "We propose LoftQ, a quantization framework for LLMs, which alternatively applies quantization\n",
            "and low-rank approximation to the original high-precision pre-trained weights, to obtain an ini-\n",
            "tialization for the subsequent LoRA fine-tuning. Experiments on natural language understanding,\n",
            "question answering, summarization, and natural language generation show that our framework re-\n",
            "markably surpasses existing methods, e.g., QLoRA, for quantizing encoder-only, encoder-decoder,\n",
            "and decoder-only models. We have not observed our method exhibiting worse performance over\n",
            "QLoRA. Moreover, our quantization framework demonstrates effectiveness and robustness particu-\n",
            "larly in low-bit quantization regimes, e.g., the 2-bit level.\n",
            "9\n",
            "\n",
            "page_label: 10\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "REFERENCES\n",
            "Haoli Bai, Wei Zhang, Lu Hou, Lifeng Shang, Jing Jin, Xin Jiang, Qun Liu, Michael Lyu, and Irwin\n",
            "King. Binarybert: Pushing the limit of bert quantization. arXiv preprint arXiv:2012.15701 , 2020.\n",
            "Haoli Bai, Lu Hou, Lifeng Shang, Xin Jiang, Irwin King, and Michael R Lyu. Towards efficient post-\n",
            "training quantization of pre-trained language models. Advances in Neural Information Processing\n",
            "Systems , 35:1405–1418, 2022.\n",
            "Roy Bar-Haim, Ido Dagan, Bill Dolan,\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LoftQ paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "Besides, it does not involve any\n",
            "gradient backpropagation, so it is cost-efficient. However, it usually results in lower accuracy com-\n",
            "pared to QAT.\n",
            "7 C ONCLUSION\n",
            "We propose LoftQ, a quantization framework for LLMs, which alternatively applies quantization\n",
            "and low-rank approximation to the original high-precision pre-trained weights, to obtain an ini-\n",
            "tialization for the subsequent LoRA fine-tuning. Experiments on natural language understanding,\n",
            "question answering, summarization, and natural language generation show that our framework re-\n",
            "markably surpasses existing methods, e.g., QLoRA, for quantizing encoder-only, encoder-decoder,\n",
            "and decoder-only models. We have not observed our method exhibiting worse performance over\n",
            "QLoRA. Moreover, our quantization framework demonstrates effectiveness and robustness particu-\n",
            "larly in low-bit quantization regimes, e.g., the 2-bit level.\n",
            "9\n",
            "\n",
            "page_label: 10\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "REFERENCES\n",
            "Haoli Bai, Wei Zhang, Lu Hou, Lifeng Shang, Jing Jin, Xin Jiang, Qun Liu, Michael Lyu, and Irwin\n",
            "King. Binarybert: Pushing the limit of bert quantization. arXiv preprint arXiv:2012.15701 , 2020.\n",
            "Haoli Bai, Lu Hou, Lifeng Shang, Xin Jiang, Irwin King, and Michael R Lyu. Towards efficient post-\n",
            "training quantization of pre-trained language models. Advances in Neural Information Processing\n",
            "Systems , 35:1405–1418, 2022.\n",
            "Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and\n",
            "Idan Szpektor. The second pascal recognising textual entailment challenge. 2006.\n",
            "Luisa Bentivogli, Peter Clark, Ido Dagan, and Danilo Giampiccolo. The fifth pascal recognizing\n",
            "textual entailment challenge. In TAC, 2009.\n",
            "Daniel Cer, Mona Diab, Eneko Agirre, I ˜nigo Lopez-Gazpio, and Lucia Specia. SemEval-2017 task\n",
            "1: Semantic textual similarity multilingual and crosslingual focused evaluation. In Proceedings of\n",
            "the 11th International Workshop on Semantic Evaluation (SemEval-2017) , pp. 1–14, Vancouver,\n",
            "Canada, August 2017. Association for Computational Linguistics. doi: 10.18653/v1/S17-2001.\n",
            "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\n",
            "Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to\n",
            "solve math word problems. arXiv preprint arXiv:2110.14168 , 2021.\n",
            "Ido Dagan, Oren Glickman, and Bernardo Magnini. The pascal recognising textual entailment\n",
            "challenge. In Machine Learning Challenges Workshop , 2007.\n",
            "Tim Dettmers, Mike Lewis, Younes Belkada, and Luke Zettlemoyer. Llm. int8 (): 8-bit matrix\n",
            "multiplication for transformers at scale. arXiv preprint arXiv:2208.07339 , 2022.\n",
            "Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning\n",
            "of quantized llms. arXiv preprint arXiv:2305.14314 , 2023.\n",
            "Shizhe Diao, Rui Pan, Hanze Dong, Ka Shun Shum, Jipeng Zhang, Wei Xiong, and Tong Zhang.\n",
            "Lmflow: An extensible toolkit for finetuning and inference of large foundation models. arXiv\n",
            "preprint arXiv:2306.12420 , 2023.\n",
            "William B. Dolan and Chris Brockett. Automatically constructing a corpus of sentential paraphrases.\n",
            "InProceedings of the Third International Workshop on Paraphrasing (IWP2005) , 2005.\n",
            "Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. Gptq: Accurate post-training\n",
            "quantization for generative pre-trained transformers. arXiv preprint arXiv:2210.17323 , 2022.\n",
            "Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. The third PASCAL recognizing\n",
            "textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entail-\n",
            "ment and Paraphrasing , pp. 1–9, Prague, June 2007. Association for Computational Linguistics.\n",
            "Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig. Towards a\n",
            "unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366 , 2021a.\n",
            "Pengcheng He, Jianfeng Gao, and Weizhu Chen. Debertav3: Improving deberta using electra-style\n",
            "pre-training with gradient-disentangled embedding sharing. arXiv preprint arXiv:2111.09543 ,\n",
            "2021b.\n",
            "\n",
            "page_label: 10\n",
            "file_path: loftq.pdf\n",
            "\n",
            "The third PASCAL recognizing\n",
            "textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entail-\n",
            "ment and Paraphrasing , pp. 1–9, Prague, June 2007. Association for Computational Linguistics.\n",
            "Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig. Towards a\n",
            "unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366 , 2021a.\n",
            "Pengcheng He, Jianfeng Gao, and Weizhu Chen. Debertav3: Improving deberta using electra-style\n",
            "pre-training with gradient-disentangled embedding sharing. arXiv preprint arXiv:2111.09543 ,\n",
            "2021b.\n",
            "Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa\n",
            "Suleyman, and Phil Blunsom. Teaching machines to read and comprehend. Advances in neural\n",
            "information processing systems , 28, 2015.\n",
            "Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,\n",
            "and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint\n",
            "arXiv:2106.09685 , 2021.\n",
            "Hector Levesque, Ernest Davis, and Leora Morgenstern. The winograd schema challenge. In Thir-\n",
            "teenth international conference on the principles of knowledge representation and reasoning ,\n",
            "2012.\n",
            "10\n",
            "\n",
            "page_label: 11\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer\n",
            "Levy, Ves Stoyanov, and Luke Zettlemoyer. Bart: Denoising sequence-to-sequence pre-\n",
            "training for natural language generation, translation, and comprehension. arXiv preprint\n",
            "arXiv:1910.13461 , 2019.\n",
            "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer\n",
            "Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-\n",
            "training for natural language generation, translation, and comprehension. In Proceedings of the\n",
            "58th Annual Meeting of the Association for Computational Linguistics , pp. 7871–7880, Online,\n",
            "July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.703.\n",
            "Yixiao Li, Yifan Yu, Qingru Zhang, Chen Liang, Pengcheng He, Weizhu Chen, and Tuo Zhao.\n",
            "Losparse: Structured compression of large language models based on low-rank and sparse ap-\n",
            "proximation. arXiv preprint arXiv:2306.11222 , 2023.\n",
            "Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summarization\n",
            "Branches Out , pp. 74–81, Barcelona, Spain, July 2004. Association for Computational Linguis-\n",
            "tics.\n",
            "Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock, Yashar Mehdad, Yangyang\n",
            "Shi, Raghuraman Krishnamoorthi, and Vikas Chandra. Llm-qat: Data-free quantization aware\n",
            "training for large language models. arXiv preprint arXiv:2305.17888 , 2023.\n",
            "Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint\n",
            "arXiv:1711.05101 , 2017.\n",
            "Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture\n",
            "models, 2016.\n",
            "Shashi Narayan, Shay B. Cohen, and Mirella Lapata. Don’t give me the details, just the summary!\n",
            "topic-aware convolutional neural networks for extreme summarization. ArXiv , abs/1808.08745,\n",
            "2018.\n",
            "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. Adver-\n",
            "sarial nli: A new benchmark for natural language understanding. ArXiv , abs/1910.14599, 2019.\n",
            "URL https://api.semanticscholar.org/CorpusID:207756753 .\n",
            "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\n",
            "Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward\n",
            "Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,\n",
            "Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance\n",
            "deep learning library. In Advances in Neural Information Processing Systems 32 , pp. 8024–8035.\n",
            "Curran Associates, Inc., 2019.\n",
            "Dheeraj Peri, Jhalak Patel, and Josh Park. Deploying quantization-aware trained networks using\n",
            "tensorrt. In GPU Technology Conference , 2020.\n",
            "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions\n",
            "for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods\n",
            "in Natural Language Processing , pp. 2383–2392, Austin, Texas, November 2016. Association for\n",
            "Computational Linguistics. doi: 10.18653/v1/D16-1264.\n",
            "Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami, Michael W Mahoney,\n",
            "and Kurt Keutzer. Q-bert: Hessian based ultra low precision quantization of bert.\n",
            "\n",
            "page_label: 11\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Dheeraj Peri, Jhalak Patel, and Josh Park. Deploying quantization-aware trained networks using\n",
            "tensorrt. In GPU Technology Conference , 2020.\n",
            "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions\n",
            "for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods\n",
            "in Natural Language Processing , pp. 2383–2392, Austin, Texas, November 2016. Association for\n",
            "Computational Linguistics. doi: 10.18653/v1/D16-1264.\n",
            "Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami, Michael W Mahoney,\n",
            "and Kurt Keutzer. Q-bert: Hessian based ultra low precision quantization of bert. In Proceedings\n",
            "of the AAAI Conference on Artificial Intelligence , volume 34, pp. 8815–8821, 2020.\n",
            "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng,\n",
            "and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment\n",
            "treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language\n",
            "Processing , pp. 1631–1642, Seattle, Washington, USA, October 2013. Association for Computa-\n",
            "tional Linguistics.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\n",
            "lay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open founda-\n",
            "tion and fine-tuned chat models. arXiv preprint arXiv:2307.09288 , 2023.\n",
            "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n",
            "Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural informa-\n",
            "tion processing systems , 30, 2017.\n",
            "Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman.\n",
            "GLUE: A multi-task benchmark and analysis platform for natural language understanding. In\n",
            "International Conference on Learning Representations , 2019.\n",
            "Alex Warstadt, Amanpreet Singh, and Samuel R. Bowman. Neural network acceptability judgments.\n",
            "Transactions of the Association for Computational Linguistics , 7:625–641, 2019. doi: 10.1162/\n",
            "tacla00290.\n",
            "Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sen-\n",
            "tence understanding through inference. In Proceedings of the 2018 Conference of the North Amer-\n",
            "ican Chapter of the Association for Computational Linguistics: Human Language Technologies,\n",
            "Volume 1 (Long Papers) , pp. 1112–1122, New Orleans, Louisiana, June 2018. Association for\n",
            "Computational Linguistics. doi: 10.18653/v1/N18-1101.\n",
            "Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han. Smoothquant:\n",
            "Accurate and efficient post-training quantization for large language models. In International\n",
            "Conference on Machine Learning , pp. 38087–38099. PMLR, 2023.\n",
            "Ofir Zafrir, Guy Boudoukh, Peter Izsak, and Moshe Wasserblat. Q8bert: Quantized 8bit bert. In\n",
            "2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing-NeurIPS\n",
            "Edition (EMC2-NIPS) , pp. 36–39. IEEE, 2019.\n",
            "Hongyi Zhang, Yann N Dauphin, and Tengyu Ma. Fixup initialization: Residual learning without\n",
            "normalization. arXiv preprint arXiv:1901.09321 , 2019.\n",
            "Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng He, Yu Cheng, Weizhu Chen,\n",
            "and Tuo Zhao. Adaptive budget allocation for parameter-efficient fine-tuning. arXiv preprint\n",
            "arXiv:2303.10512 , 2023.\n",
            "12\n",
            "\n",
            "page_label: 13\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "A M ODEL COMPRESSION RATIO AND MEMORY FOOTPRINT\n",
            "We report the compression ratio after applying LoftQ in Table 7. It is defined as\n",
            "compression ration =backbone size +LoRA adapter size\n",
            "pre-trained size.\n",
            "We also measure the GPU memory cost during training. Given that GPU memory varies by models,\n",
            "tasks, sequence lengths, batch sizes, etc. We report LLAMA-2 on GSM8K as an example in Table\n",
            "8.\n",
            "Table 7: Compression ratios\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LoftQ paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "and Song Han. Smoothquant:\n",
            "Accurate and efficient post-training quantization for large language models. In International\n",
            "Conference on Machine Learning , pp. 38087–38099. PMLR, 2023.\n",
            "Ofir Zafrir, Guy Boudoukh, Peter Izsak, and Moshe Wasserblat. Q8bert: Quantized 8bit bert. In\n",
            "2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing-NeurIPS\n",
            "Edition (EMC2-NIPS) , pp. 36–39. IEEE, 2019.\n",
            "Hongyi Zhang, Yann N Dauphin, and Tengyu Ma. Fixup initialization: Residual learning without\n",
            "normalization. arXiv preprint arXiv:1901.09321 , 2019.\n",
            "Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng He, Yu Cheng, Weizhu Chen,\n",
            "and Tuo Zhao. Adaptive budget allocation for parameter-efficient fine-tuning. arXiv preprint\n",
            "arXiv:2303.10512 , 2023.\n",
            "12\n",
            "\n",
            "page_label: 13\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "A M ODEL COMPRESSION RATIO AND MEMORY FOOTPRINT\n",
            "We report the compression ratio after applying LoftQ in Table 7. It is defined as\n",
            "compression ration =backbone size +LoRA adapter size\n",
            "pre-trained size.\n",
            "We also measure the GPU memory cost during training. Given that GPU memory varies by models,\n",
            "tasks, sequence lengths, batch sizes, etc. We report LLAMA-2 on GSM8K as an example in Table\n",
            "8.\n",
            "Table 7: Compression ratios of backbones.\n",
            "ModelCompression TrainableRank BitsQuantization\n",
            "ratio (%) ratio (%) method\n",
            "DeBERTaV3-base 15.6 3.1 16 2 Uniform\n",
            "DeBERTaV3-base 18.8 6.3 32 2 Uniform\n",
            "DeBERTaV3-base 17.2 3.1 16 2 NF2\n",
            "DeBERTaV3-base 20.4 6.3 32 2 NF2\n",
            "BART-large 15.3 1.2 8 4 NF2\n",
            "BART-large 16.7 2.5 16 4 NF2\n",
            "BART-large 27.8 1.2 8 4 NF4\n",
            "BART-large 29.0 2.5 16 4 NF4\n",
            "BART-large 26.2 1.2 8 4 Uniform\n",
            "BART-large 27.5 2.5 16 4 Uniform\n",
            "LLAMA-2-7b 16.6 2.4 64 2 Nf2\n",
            "LLAMA-2-7b 29.0 2.4 64 4 Nf4\n",
            "LLAMA-2-13b 16.0 1.9 64 2 Nf2\n",
            "LLAMA-2-13b 28.5 1.9 64 4 Nf4\n",
            "Table 8: GPU memory footprint\n",
            "Model Dataset Seq length Batch size GPU Mem\n",
            "LLAMA-2-7b GSM8K 384 1 15GB\n",
            "LLAMA-2-13b GSM8K 384 1 24GB\n",
            "B Q UANTIZATION TIME\n",
            "We report the execution time of LoftQ applying to a single weight matrix in Table 9. The time is\n",
            "tested on Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz.\n",
            "Table 9: Execution time of LoftQ applying to different weight matrices.\n",
            "Model Size StepTQuantization method Time\n",
            "DeBERTaV3-base 768×768 5 Uniform 1s\n",
            "BART-large 1024×1024 5 NF4 1s\n",
            "LLAMA-2-7b 4096×4096 5 NF4 21s\n",
            "LLAMA-2-13b 5120×5120 5 NF4 43s\n",
            "C GLUE D ATASET STATISTICS\n",
            "We present the dataset statistics of GLUE Wang et al. (2019) in the following table.\n",
            "GLUE includes two single-sentence classification tasks: SST-2 (Socher et al., 2013) and CoLA\n",
            "(Warstadt et al., 2019), and three similarity and paraphrase tasks: MRPC (Dolan & Brockett, 2005),\n",
            "STS-B (Cer et al., 2017), and QQP. GLUE also includes four natural language inference tasks in\n",
            "GLUE: MNLI (Williams et al., 2018), QNLI (Rajpurkar et al., 2016), RTE (Dagan et al., 2007; Bar-\n",
            "Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009), and WNLI (Levesque et al.,\n",
            "2012).\n",
            "13\n",
            "\n",
            "page_label: 14\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Corpus Task #Train #Dev #Test #Label Metrics\n",
            "Single-Sentence Classification (GLUE)\n",
            "CoLA Acceptability 8.5k 1k 1k 2 Matthews corr\n",
            "SST Sentiment 67k 872 1.8k 2 Accuracy\n",
            "Pairwise Text Classification (GLUE)\n",
            "MNLI NLI 393k 20k 20k 3 Accuracy\n",
            "RTE NLI 2.5k 276 3k 2 Accuracy\n",
            "QQP Paraphrase 364k 40k 391k 2 Accuracy/F1\n",
            "MRPC Paraphrase 3.7k 408 1.7k 2 Accuracy/F1\n",
            "QNLI QA/NLI 108k 5.7k 5.7k 2 Accuracy\n",
            "Text Similarity (GLUE)\n",
            "STS-B Similarity 7k 1.5k 1.4k 1 Pearson/Spearman corr\n",
            "Table 10: Summary of the GLUE benchmark.\n",
            "D N ATURAL LANGUAGE UNDERSTANDING\n",
            "D.1 GLUE WITH 4-BIT\n",
            "We show the 4-bits results in the Table 11. Both methods can achieve performance close to full-\n",
            "finetuning.\n",
            "Table 11: Results with 4-bit LoftQ of DeBERTaV3-base models on GLUE development set using\n",
            "NF4 quantization. We report the median over four seeds. Results with N.A. indicate the model does\n",
            "not converge. The best results on each dataset are shown in bold\n",
            "Method RankMNLI SST-2 QNLI ANLI\n",
            "m / mm Acc Acc Acc\n",
            "Full FT - 90.5/90.6 95.3 94.0 59.8\n",
            "QLoRA 32 89.9/89.9 95.3 94.2 59.4\n",
            "LoftQ 32 89.9/90.0 95.3 94.1 59.9\n",
            "D.2 T RAINING DETAILS\n",
            "Implementation Details. The implementation of LoftQ is based on publicly available Huggingface\n",
            "(Paszke et al., 2019) code-base3.\n",
            "Hyper-parameter Details. We select the learning rate of {1×10−5,5×10−5,1×10−4,5×10−4},\n",
            "and use the selected learning rate for both uniform quantization experiments and nf2 quantization\n",
            "experiments. We use batch size of 32 for all GLUE tasks and ANLI. We use batch size of 16 for\n",
            "SQuADv1.1. We use LoftQ of 5 iterations for all GLUE tasks.\n",
            "Table 12 summarizes the detailed hyperparameters for each task used in training DeBERTaV3-base\n",
            "using uniform quantization. Table 13 summarizes the detailed hyperparameters for each task used\n",
            "in training DeBERTaV3-base using nf2 quantization.\n",
            "Table 12: Hyper-parameter setup of LoftQ for GLUE benchmark for training DeBERTaV3-base\n",
            "using Uniform quantization.\n",
            "Hyper-parameter MNLI RTE QNLI MRPC QQP SST-2 CoLA STS-B SQuADv1.1 ANLI\n",
            "# epochs 5 20 10 60 10 10 60 60 10 12\n",
            "Learning rate 1×10−45×10−45×10−51×10−45×10−55×10−55×10−55×10−55×10−55×10−5\n",
            "3https://github.com/huggingface/transformers/tree/main/examples/pytorch\n",
            "14\n",
            "\n",
            "page_label: 15\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Table 13: Hyper-parameter setup of LoftQ for GLUE benchmark for training DeBERTaV3-base\n",
            "using NF2 quantization.\n",
            "Hyper-parameter MNLI RTE QNLI MRPC QQP SST-2 CoLA STS-B SQuADv1.1 ANLI\n",
            "# epochs 5 20 10 60 10 10 60 60 10 12\n",
            "Learning rate 1×10−45×10−55×10−51×10−45×10−55×10−55×10−51×10−45×10−55×10−5\n",
            "E S UMMARIZATION\n",
            "E.1 T RAINING DETAILS\n",
            "We choose Adam as the optimizer and try learning rate from {1×10−5,5×10−5,7×10−5,2×\n",
            "10−4,3×10−4,4×10−4}. We show the optimal learning rate for different settings in Table 14.\n",
            "We use LoftQ of 1 iteration for all BART-large experiments. Table 14 and Table 15 summarize the\n",
            "learning rate and other hyper-parameters for CNN/DailyMail and XSum.\n",
            "Table 14: Hyper-parameter setup of LoftQ BART-large on CNN/DailyMail\n",
            "HyperparameterNF4 4-bit Uniform NF2\n",
            "rank8 rank16 rank8 rank16 rank8 rank16\n",
            "Learning rate 2e-4 2e-4 2e-4 3e-4 2e-4 2e-4\n",
            "Epoch 15 15 15 15 15 15\n",
            "Batch size 64 64 64 64 64 64\n",
            "Table 15: Hyper-parameter setup of LoftQ BART-large on XSum\n",
            "HyperparameterNF4 4-bit Uniform NF2\n",
            "rank8 rank16 rank8 rank16 rank8 rank16\n",
            "Learning rate 2e-4 2e-4 2e-4 2e-4 2e-4 2e-4\n",
            "Epoch 25 25 25 25 25 25\n",
            "Batch size 32 32 32 32 32 32\n",
            "F N ATURAL LANGUAGE GENERATION\n",
            "We set the batch size as 32 for WikiText-2 and 16 for GSM8K. We train 2 epochs on WikiText-2 and\n",
            "6 epochs on GSM8K. We select learning rate from {1×10−5,5×10−5,7×10−5,1×10−4, ,3×\n",
            "10−4,4×10−4}. Specific settings are summarized in Table 16 and Table 17.\n",
            "G C OMPARISON TO PRUNING\n",
            "Pruning is also a widely used compression method. Here we compare LoftQ with the state-of-the-\n",
            "art pruning method Li et al. (2023). We show the comparison in Table 18. We can see our method\n",
            "significantly outperforms the pruning methods on DeBERTaV3-base model. We also remark that\n",
            "LoftQ can consistently reduce the memory of both training and storage. In contrast, pruning requires\n",
            "training the entire full-precision matrix, which implies that it can not achieve any memory savings\n",
            "during the training stage.\n",
            "H E XTENSION TO CONVOLUTIONAL LAYERS\n",
            "Low-rank adapters can also be applied to convolutional layers. Given an input feature map\n",
            "X∈Rh×w×c1andc22D convolutional kernels Ki∈Rc1×d×d, i= 1,2, ..., c 2, the output of\n",
            "the convolutional layer is\n",
            "Y= stack( X⊗K1, ..., X ⊗Kc2), (10)\n",
            "where Y∈Rh×w×c2and⊗denotes the 2D convolution operation.\n",
            "15\n",
            "\n",
            "page_label: 16\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Table 16: Hyper-parameter setup of LoftQ LLAMA-2-series on GSM8K\n",
            "Model Hyperparameter NF4 NF2 Mixed-precision\n",
            "LLAMA-2-7b learning rate 3×10−43×10−43×10−4\n",
            "LLAMA-2-13b learning rate 1×10−41×10−43×10−4\n",
            "Table 17: Hyper-parameter setup of LoftQ LLAMA-2-series on WikiText-2\n",
            "Model Hyperparameter NF4 NF2 Mixed-precision\n",
            "LLAMA-2-7b learning rate 3×10−43×10−43×10−4\n",
            "LLAMA-2-13b learning rate 1×10−41×10−43×10−4\n",
            "Table 18: Results of LoftQ using 2-bits uniform quantization compared with LoSparse with\n",
            "DeBERTaV3-base models on some of GLUE development sets. Here Ratio is the proportion of\n",
            "total remaining weights. Results with N.A. indicate the model does not converge.\n",
            "Method RatioMNLI SST-2 QNLI\n",
            "m / mm Acc Acc\n",
            "Full FT 100% 90.5 / 90.6 95.3 94.0\n",
            "LoSparse15% 83.3/82.9 87.6 90.4\n",
            "20% 84.5/83.8 91.7 88.6\n",
            "LoftQ15.6% 87.3/87.1 94.0 90.6\n",
            "18.8% 88.0/88.1 94.7 92.4\n",
            "We can reformulate Equation (10) into matrix multiplication as\n",
            "Y=Z×H⊤,\n",
            "where Z∈Rhw×c1d2, H∈Rc2×c1d2, by extending and flattening the input Xtogether with con-\n",
            "catenating and flattening kernels. We first extend a vector xi,j∈Rc1by its neighbor vectors within\n",
            "the kernel window:\n",
            "x′\n",
            "i,j= Concat(xi−d\n",
            "2,j−d\n",
            "2, ...,xi+d\n",
            "2,j+d\n",
            "2).\n",
            "Now, Xbecomes X′∈Rh×w×c1d2. We then flatten X′intoZ∈Rhw×c1d2. For kernels, we first\n",
            "concatenate {K1, ..., K c2}intoH′∈Rc2×c1×d×d. We then flatten H′intoH.\n",
            "Note that Hcan be approximated by a low-rank matrix\n",
            "R=UV⊤,\n",
            "where U∈Rc2×r, V∈Rc1d2×r, r≪min{c2, c1d2}by SVD. Therefore, the original convolution\n",
            "layer can be approximated as\n",
            "bY=Z×(UV⊤)⊤(11)\n",
            "= (Z×V)×U⊤(12)\n",
            "=M×U⊤. (13)\n",
            "Note that Z×Vcan be restored into a convolution operation where we have rkernels Di∈\n",
            "Rc1×d×d, i= 1,2, , ..., r andM×U⊤can also be restored into a convolution operation where\n",
            "we have c2kernels Ui∈Rr×1×1, i= 1,2, , ..., c 2.\n",
            "16\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LoftQ paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "LoftQ is a new quantization framework designed for large language models that addresses the performance gap often observed when combining standard quantization with LoRA fine-tuning. It works by jointly optimizing the quantized model weights and the initialization of low-rank adapters, leading to a better starting point for fine-tuning and improved performance on downstream tasks. This method consistently outperforms standard quantization techniques, especially in low-bit scenarios, and is compatible with various quantization methods.\n",
            "\n",
            "LoftQ is a novel quantization method for large language models that addresses the performance degradation caused by quantization discrepancy in LoRA fine-tuning. Unlike traditional methods that quantize pre-trained weights directly, LoftQ jointly optimizes quantized weights and low-rank adapters, leading to superior performance in downstream tasks. This method alternates between quantization and singular value decomposition to find a closer initialization to the pre-trained weights, effectively mitigating quantization discrepancy. Experiments on various natural language understanding and generation tasks demonstrate that LoftQ consistently outperforms existing methods like QLoRA, achieving comparable or even superior results to full-precision models, particularly in low-bit quantization settings.\n",
            "\n",
            "LoftQ is a novel quantization framework for Large Language Models (LLMs) that applies quantization and low-rank approximation to pre-trained weights. This process generates an initialization for Low-Rank Adaptation (LoRA) fine-tuning.  Experiments demonstrate that LoftQ consistently surpasses other methods, such as QLoRA, in quantizing various LLM architectures, including encoder-only, encoder-decoder, and decoder-only models. Notably, LoftQ exhibits robustness and effectiveness in low-bit quantization settings, achieving superior results compared to existing techniques.\n",
            "\n",
            "LoftQ is a novel quantization framework for Large Language Models (LLMs) that applies quantization and low-rank approximation to pretrained weights. This approach generates an initialization for subsequent LoRA fine-tuning.  Experimental results demonstrate that LoftQ outperforms existing methods, such as QLoRA, in quantizing various LLM architectures, including encoder-only, encoder-decoder, and decoder-only models. Notably, LoftQ exhibits superior effectiveness and robustness, especially in low-bit quantization settings like 2-bit quantization.\n",
            "\n",
            "LoftQ is a new model compression method that uses low-rank adaptation with quantized backbones. It achieves significant compression ratios with minimal performance degradation. For instance, LoftQ achieves a 15.6% compression ratio on DeBERTaV3-base with only a 3.1% decrease in trainable parameters, using 2-bit uniform quantization. This method consistently reduces memory usage in both training and storage, unlike pruning methods that require training the entire full-precision matrix. LoftQ can be applied to various tasks, including natural language understanding, summarization, and generation, with results comparable to full-finetuning methods. Additionally, it can be extended to convolutional layers, further demonstrating its versatility.\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LoftQ paper.\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "LoftQ is a new quantization framework for Large Language Models (LLMs) that improves performance by jointly optimizing quantized model weights and the initialization of low-rank adapters. This approach results in a better starting point for fine-tuning and addresses the performance gap often observed when combining standard quantization with LoRA fine-tuning. It consistently outperforms standard quantization techniques, especially in low-bit scenarios, and is compatible with various quantization methods. It achieves significant compression ratios with minimal performance degradation and can be applied to various tasks, including natural language understanding, summarization, and generation, with results comparable to full-finetuning methods. \n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_loftq with args: {\"query\": \"Summarize the LongLoRA paper.\"}\n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "page_label: 1\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "LOFTQ: L ORA-F INE-TUNING -AWARE QUANTIZA -\n",
            "TION FOR LARGE LANGUAGE MODELS\n",
            "Yixiao Li1∗Yifan Yu1∗Chen Liang1Pengcheng He2\n",
            "Nikos Karampatziakis2Weizhu Chen2Tuo Zhao1\n",
            "ABSTRACT\n",
            "Quantization is an indispensable technique for serving Large Language Models\n",
            "(LLMs) and has recently found its way into LoRA fine-tuning (Dettmers et al.,\n",
            "2023). In this work we focus on the scenario where quantization and LoRA fine-\n",
            "tuning are applied together on a pre-trained model. In such cases it is common\n",
            "to observe a consistent gap in the performance on downstream tasks between\n",
            "full fine-tuning and quantization plus LoRA fine-tuning approach. In response,\n",
            "we propose LoftQ ( LoRA-Fine-Tuning-aware Quantization), a novel quantiza-\n",
            "tion framework that simultaneously quantizes an LLM and finds a proper low-\n",
            "rank initialization for LoRA fine-tuning. Such an initialization alleviates the dis-\n",
            "crepancy between the quantized and full-precision model and significantly im-\n",
            "proves generalization in downstream tasks. We evaluate our method on nat-\n",
            "ural language understanding, question answering, summarization, and natural\n",
            "language generation tasks. Experiments show that our method is highly ef-\n",
            "fective and outperforms existing quantization methods, especially in the chal-\n",
            "lenging 2-bit and 2/4-bit mixed precision regimes. The code is available on\n",
            "https://github.com/yxli2123/LoftQ .1 2\n",
            "1 I NTRODUCTION\n",
            "The advent of Pre-trained Language Models (PLMs) has marked a transformative shift in the field\n",
            "of Natural Language Processing (NLP), offering versatile solutions across various applications (He\n",
            "et al., 2021b; Lewis et al., 2019; Touvron et al., 2023). They have showcased unparalleled profi-\n",
            "ciency in executing a variety of language tasks, including Natural Language Understanding (NLU)\n",
            "and Natural Language Generation (NLG). These models typically have millions or even billions of\n",
            "parameters, necessitating substantial computational and memory requirements. However, the exten-\n",
            "sive computational and memory demands of these models pose significant challenges, especially for\n",
            "deployments where resources are often constrained and need to be shared among many users.\n",
            "To mitigate the extensive storage requirements of pre-trained models, quantization serves as a piv-\n",
            "otal compression technique (Zafrir et al., 2019; Shen et al., 2020; Bai et al., 2022; Dettmers et al.,\n",
            "2022), converting high-precision numerical values into a discrete set of values. Typically, model\n",
            "parameters, originally stored in a 16-bit float format, are transformed into a 4-bit integer format\n",
            "through quantization, resulting in a substantial 75% reduction in storage overhead. Additionally, to\n",
            "facilitate the adaptation of quantized pre-trained models to downstream tasks efficiently, Low-Rank\n",
            "Adaptation (LoRA) is a viable approach (Hu et al., 2021). This technique is a parameter-efficient\n",
            "fine-tuning method traditionally applied to high-precision pre-trained models. It is based on the\n",
            "hypothesis that the differences between fully fine-tuned weights and pre-trained weights exhibit\n",
            "low-rank properties. This allows these differences to be represented using low-rank matrices. As a\n",
            "result, the original pre-trained weights remain unaltered, with adaptations confined solely to these\n",
            "low-rank matrices, enabling effective task adaptation.\n",
            "∗Equal contribution\n",
            "1Li, Yu, Liang and Zhao are affiliated with Georgia Institute of Technology. Correspondence to\n",
            "yixiaoli@gatech.edu ,yyu429@gatech.edu andtourzhao@gatech.edu .\n",
            "2He, Karampatziakisand and Chen are affiliated with Microsoft Azure.\n",
            "1\n",
            "\n",
            "page_label: 2\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "When quantizing pre-trained models, practitioners often concentrate primarily on the quantization\n",
            "technique, inadvertently neglecting the importance of subsequent LoRA fine-tuning (Dettmers et al.,\n",
            "2023; Diao et al., 2023). For example, QLoRA inherits the fixup initialization (Zhang et al., 2019)\n",
            "used in LoRA, which (Dettmers et al., 2023) attaches zero initialized low-rank adapters (see Section\n",
            "2.3) to the quantized pre-trained model. The inevitable discrepancy introduced by quantization dur-\n",
            "ing the approximation of the original high-precision numbers, a scenario particularly pronounced\n",
            "in low-bit situations such as the 2-bit regime, can adversely impact the initialization of LoRA fine-\n",
            "tuning. As illustrated in Figure 1a, the quantized pre-trained model obtained by QLoRA exhibits\n",
            "severe degradation below the 3-bit level. This deviation in initialization often results in an inferior\n",
            "fine-tuning performance. As illustrated in Figure 1b, the fine-tuning performance drops as the quan-\n",
            "tization bit decreases when applying QLoRA. Moreover, it is noteworthy that QLoRA fails below\n",
            "the 3-bit level.\n",
            "In this paper, we introduce a novel quantization framework, called LoRA-Fine-Tuning-aware\n",
            "Quantization (LoftQ). It is designed specifically for pre-trained models that require quantization\n",
            "and LoRA fine-tuning. This framework actively integrates low-rank approximation, working in tan-\n",
            "dem with quantization to jointly approximate the original high-precision pre-trained weights. This\n",
            "synergy significantly enhances alignment with the original pre-trained weights as illustrated in Fig-\n",
            "ure 2. Consequently, our method provides an advantageous initialization point for subsequent LoRA\n",
            "fine-tuning, leading to improvements in downstream tasks.\n",
            "16 8 4 3 2.5 2.25 2\n",
            "Number of Bits24681012Log of Perplexity\n",
            "2.49 2.50 2.53 2.5311.37 11.48 11.50\n",
            "(a) Pre-trained LLAMA-2-13b on WikiText-2\n",
            "16 8 4 3 2.5 2.25 2\n",
            "Number of Bits0246Log of Perplexity1.63 1.64 1.65 1.652.996.807.19 (b) Fine-tuned LLAMA-2-13b on WikiText-2\n",
            "Figure 1: QLoRA performance with different bits. Left: QLoRA initialization of LLAMA-2-13b\n",
            "on WikiText-2. Right: Apply QLoRA to LLAMA-2-13b on WikiText-2 language modeling task.\n",
            "Smaller perplexity indicates better performance.\n",
            "We evaluate our quantization framework by conducting extensive experiments on downstream tasks,\n",
            "such as NLU, question answering, summarization, and NLG. Experiments show that LoftQ consis-\n",
            "tently outperforms QLoRA across all precision levels. For instance, with 4-bit quantization, we\n",
            "achieve a 1.1 and 0.8 gain in Rouge-1 for XSum (Narayan et al., 2018) and CNN/DailyMail (Her-\n",
            "mann et al., 2015), respectively. LoftQ excels particularly in low-bit scenarios and works effectively\n",
            "with different quantization methods. For example, we achieve over an 8% gain on MNLI (Wang\n",
            "et al., 2019) and more than 10% on SQuADv1.1 (Rajpurkar et al., 2016) with both 2-bit NormalFloat\n",
            "and the 2-bit uniform quantization. We have not seen our approach performs worse than QLoRA.\n",
            "2 B ACKGROUND\n",
            "2.1 T RANSFORMER MODELS\n",
            "A transformer model contains a sequence of layers, where each layer consists of two sub-layers: a\n",
            "multi-head self-attention (MHA) and a fully connected feed forward network (FFN) (Vaswani et al.,\n",
            "2017).\n",
            "\n",
            "page_label: 2\n",
            "file_path: loftq.pdf\n",
            "\n",
            "LoftQ excels particularly in low-bit scenarios and works effectively\n",
            "with different quantization methods. For example, we achieve over an 8% gain on MNLI (Wang\n",
            "et al., 2019) and more than 10% on SQuADv1.1 (Rajpurkar et al., 2016) with both 2-bit NormalFloat\n",
            "and the 2-bit uniform quantization. We have not seen our approach performs worse than QLoRA.\n",
            "2 B ACKGROUND\n",
            "2.1 T RANSFORMER MODELS\n",
            "A transformer model contains a sequence of layers, where each layer consists of two sub-layers: a\n",
            "multi-head self-attention (MHA) and a fully connected feed forward network (FFN) (Vaswani et al.,\n",
            "2017). Given the input X∈Rn×d, where nis the sequence length and dis the hidden dimension of\n",
            "the model, MHA computes the hattention heads in parallel:\n",
            "MHA( X) = Concat(head 1, ...,head h)Wo,\n",
            "where head i=Softmax( XW qi(XW ki)⊤/p\n",
            "dh)XW vifori= 1, ..., h,\n",
            "where Wqi, Wki, Wvi∈Rd×dhare query, key, and value matrices, Wo∈Rd×dis the output matrix,\n",
            "anddh=d/h. FFN comprises two linear transformations and an activation function, and is defined\n",
            "asFFN( X) =σ(XW f1+b1)Wf2+b2,where Wf1∈Rd×dm,Wf2∈Rdm×d, and σ(·)is the\n",
            "activation function. A residual connection is used and followed by layer normalization.\n",
            "2\n",
            "\n",
            "page_label: 3\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Uniform\n",
            "4bitNormalFloat\n",
            "4bitUniform\n",
            "2bitNormalFloat\n",
            "2bit02468101214DiscrepancyLoftQ\n",
            "QLoRA\n",
            "(a) Spectral norm of the initialization difference\n",
            "Uniform\n",
            "4bitNormalFloat\n",
            "4bitUniform\n",
            "2bitNormalFloat\n",
            "2bit0102030405060DiscrepancyLoftQ\n",
            "QLoRA (b) Frobenius norm of the initialization difference\n",
            "Figure 2: Initialization discrepancy between the LoRA initialization and the original pre-trained\n",
            "weight matrix, described by the spectral norm and Frobenius norm of the difference. The weight\n",
            "matrix in the above figures is randomly selected in BART-large. The initialization is obtained by\n",
            "QLoRA and LoftQ, with Uniform and NormalFloat quantization methods applied at both 2-bit and\n",
            "4-bit levels. LoftQ successfully mitigates the discrepancy, especially at the 2-bit level.\n",
            "2.2 Q UANTIZATION\n",
            "Quantization. Given a high-precision number, e.g., such as 32-bit floating point number, XHP∈R,\n",
            "N-bit quantization encodes it to an integer XINT∈ {0,1, ...,2N−1}. This process can be expressed\n",
            "as\n",
            "XINT=round\u0000\n",
            "(2N−1)F\u0000\n",
            "XHP\u0001\u0001\n",
            ", (1)\n",
            "where F(·):R7→[0,1]is a normalization function. Uniform quantization assumes F(X) = (X−\n",
            "Xmin)/(Xmax−Xmin). Dettmers et al. (2023) proposes 4-bit NormalFloat Quantization (NF4). It\n",
            "assumes X∼ N (0, σ2)and hence F(X) = Φ( X/σ), where Φ(·)is the cumulative distribution\n",
            "function of the standard normal distribution.\n",
            "Dequantization. A lookup table T, where\n",
            "T[i] =F−1\u0012i\n",
            "2N−1\u0013\n",
            ", i= 0,1, ...,2N−1, (2)\n",
            "is used to decode the integer XINTto its simulated high-precision counterpart XD∈R. Therefore,\n",
            "the dequantization can be expressed as\n",
            "XD=T[XINT]. (3)\n",
            "Simulated Quantization for Matrices. While it is possible to perform multiplication directly be-\n",
            "tween quantized representations, it is common to apply simulated quantization for matrices (Bai\n",
            "et al., 2020; Shen et al., 2020). There, quantized weight matrices are stored as encoded integers in\n",
            "memory, and are temporarily dequantized to simulated high-precision matrices by the lookup table\n",
            "when engaged in multiplication operations. In simulated quantization, it is only necessary to an-\n",
            "alyze the map from a high-precision matrix to a simulated high-precision matrix. We denote this\n",
            "end-to-end process by qN(·):Rm×n7→Rm×n\n",
            "N , where RN:{T[i]∈R|0≤i <2N}.\n",
            "2.3 L OW-RANK ADAPTATION\n",
            "LoRA (Hu et al., 2021) updates two small weight matrices AandBthat are attached to a frozen\n",
            "pre-trained weight matrix W. Hence, a linear transformation, Y=XW , is reformulated as\n",
            "Y=XW +XAB⊤, (4)\n",
            "where X∈Rn×d1, W∈Rd1×d2, A∈Rd1×r, B∈Rd2×r, andr≪min{d1, d2}. Initially,\n",
            "A∼ N(0, σ2), B= 0, (5)\n",
            "so as to align to the pre-trained weights. During the fine-tuning, Wis fixed while AandBare\n",
            "updated by some SGD-type optimization method.\n",
            "It is worth noting that if low-rank adapters AandBare attached to a quantized backbone Q=\n",
            "qN(W)and are initialized by (5), the starting weight Q+AB⊤is no longer equal to the pre-trained\n",
            "weight Wdue to the discrepancy introduced by the quantization.\n",
            "3\n",
            "\n",
            "page_label: 4\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "3 M ETHOD\n",
            "We propose LoRA-Fine-Tuning-aware Quantization (LoftQ), a quantization framework for LLMs.\n",
            "It alternatively applies quantization and low-rank approximation to approximate original pre-trained\n",
            "weights. This quantization framework provides a promising initialization for LoRA fine-tuning,\n",
            "which alleviates the quantization discrepancy in QLoRA and improves generalization in downstream\n",
            "tasks significantly.\n",
            "3.1 L ORA-A WARE QUANTIZATION\n",
            "We use an N-bit quantized weight Q∈Rd1×d2\n",
            "N and low-rank approximations A∈Rd1×r, B∈\n",
            "Rd2×rto approximate the original high-precision pre-trained weight W∈Rd1×d2as the initializa-\n",
            "tion of LoRA fine-tuning. Specifically, before fine-tuning, we initialize the network by minimizing\n",
            "the following objective:\n",
            "min\n",
            "W−Q−AB⊤\n",
            "F, (6)\n",
            "where ∥·∥Fdenotes the Frobenious norm. This objective in (6) takes LoRA fine-tuning into consid-\n",
            "eration by jointly optimizing the initial values of the quantized backbone Qand low-rank adapters\n",
            "A, B . Contrarily, practitioners typically convert the pre-trained weight Winto a quantized weight\n",
            "Qoutright, neglecting the subsequent LoRA fine-tuning process. This oversight leads to notable\n",
            "performance degradation in downstream tasks arising from the quantization discrepancy.\n",
            "3.2 A LTERNATING OPTIMIZATION\n",
            "We solve the minimization problem in (6) by alternating between quantization and singular value\n",
            "decomposition (SVD). To begin with, we set A0, andB0equal to 0.\n",
            "Quantization . At the t-th step, we quantize the difference between the original pre-trained weight\n",
            "matrix Wand the low-rank approximation At−1B⊤\n",
            "t−1from the previous step to obtain the quantized\n",
            "weight matrix Qtby\n",
            "Qt=qN(W−At−1B⊤\n",
            "t−1), (7)\n",
            "where qN(·)maps a high-precision weight matrix to a quantized matrix.\n",
            "We remark that our algorithm is compatible with different quantization functions qN(·). We apply\n",
            "NF4 and the uniform quantization in Section 4 as examples. We also remark that Qtis not an exact\n",
            "solution of the minimization in (6), given the fixed At−1B⊤\n",
            "t−1, but it is an efficient approximation.\n",
            "SVD . After obtaining the t-th quantized weight\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LongLoRA paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "following objective:\n",
            "min\n",
            "W−Q−AB⊤\n",
            "F, (6)\n",
            "where ∥·∥Fdenotes the Frobenious norm. This objective in (6) takes LoRA fine-tuning into consid-\n",
            "eration by jointly optimizing the initial values of the quantized backbone Qand low-rank adapters\n",
            "A, B . Contrarily, practitioners typically convert the pre-trained weight Winto a quantized weight\n",
            "Qoutright, neglecting the subsequent LoRA fine-tuning process. This oversight leads to notable\n",
            "performance degradation in downstream tasks arising from the quantization discrepancy.\n",
            "3.2 A LTERNATING OPTIMIZATION\n",
            "We solve the minimization problem in (6) by alternating between quantization and singular value\n",
            "decomposition (SVD). To begin with, we set A0, andB0equal to 0.\n",
            "Quantization . At the t-th step, we quantize the difference between the original pre-trained weight\n",
            "matrix Wand the low-rank approximation At−1B⊤\n",
            "t−1from the previous step to obtain the quantized\n",
            "weight matrix Qtby\n",
            "Qt=qN(W−At−1B⊤\n",
            "t−1), (7)\n",
            "where qN(·)maps a high-precision weight matrix to a quantized matrix.\n",
            "We remark that our algorithm is compatible with different quantization functions qN(·). We apply\n",
            "NF4 and the uniform quantization in Section 4 as examples. We also remark that Qtis not an exact\n",
            "solution of the minimization in (6), given the fixed At−1B⊤\n",
            "t−1, but it is an efficient approximation.\n",
            "SVD . After obtaining the t-th quantized weight Qt, SVD is applied to the residual of the quantization\n",
            "denoted by Rt=W−Qtby\n",
            "Rt=dX\n",
            "i=1σt,iut,iv⊤\n",
            "t,i, (8)\n",
            "where d= min {d1, d2},σt,1≥σt,2≥...≥σt,dare the singular values of Rt,ut,i’s and vt,i’s are\n",
            "the associated left and right singular vectors of Rt. We then obtain a rank- rapproximation of Rtby\n",
            "AtB⊤\n",
            "t, where\n",
            "At= [√σt,1ut,1, ...,√σt,rut,r],\n",
            "Bt= [√σt,1vt,1, ...,√σt,rvt,r]. (9)\n",
            "We summarize our method in Algorithm 1. It is worth noting that T= 1is a special case where Q1is\n",
            "the exact quantized weight obtained by QLoRA, and low-rank approximations A1, B1are obtained\n",
            "by the SVD of the quantization residual W−Q1.T= 1 is sufficient to mitigate the quantization\n",
            "discrepancy, and alternating optimization helps to find a closer initialization to the pre-trained weight\n",
            "W, which further improves the performance (see Section 3).\n",
            "We remark that the computational cost of LoftQ is negligible because it is applied to individual\n",
            "weight matrices and can be executed in parallel. We also remark one can apply LoftQ only once to\n",
            "a pre-trained model and reuse the initialization obtained by LoftQ for different downstream tasks.\n",
            "3.3 A PPLYING TO LORA F INE-TUNING\n",
            "We store the QT∈Rd1×d2\n",
            "N obtained by LoftQ using an integer matrix Mby (1) and a lookup table\n",
            "Tby (2). We initialize the backbone with the integer matrix Mand initialize the low-rank adapters\n",
            "withAT, BTobtained by LoftQ.\n",
            "4\n",
            "\n",
            "page_label: 5\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Algorithm 1 LoftQ\n",
            "input Pre-trained weight W, target rank r,N-bit quantization function qN(·), alternating step T\n",
            "1:Initialize A0←0, B0←0\n",
            "2:fort =1toTdo\n",
            "3: Obtain quantized weight Qt←qN(W−At−1B⊤\n",
            "t−1)\n",
            "4: Obtain low-rank approximation At, Bt←SVD(W−Qt)by (9)\n",
            "5:end for\n",
            "output QT, AT, BT\n",
            "During LoRA fine-tuning, we freeze the integer weight Mand optimize the low-rank adapters with\n",
            "an efficient optimization algorithm, e.g., AdamW (Loshchilov & Hutter, 2017). In forward propa-\n",
            "gation, the integer weight Mis temporarily dequantized to the simulated high-precision weight QT\n",
            "by its lookup table, as described in (3). In back propagation, gradients and optimizer state are only\n",
            "related to low-rank adapters A, B , which reduces considerable training cost.\n",
            "4 E XPERIMENTS\n",
            "We evaluate our method on NLU and NLG tasks. We apply LoftQ for quantizing DeBERTaV3-base\n",
            "(He et al., 2021b), BART-large (Lewis et al., 2019), and LLAMA-2 series (Touvron et al., 2023).\n",
            "Implementation Details. Following the prior works of LoRA variants (Zhang et al., 2023; He\n",
            "et al., 2021a), we freeze all the backbone weight matrices and add low-rank adapters to weight\n",
            "matrices in MHA and FFN of all layers. We quantize the weight matrices that are attached by low-\n",
            "rank adapters. All the quantized models and adapters used in this paper are available on https:\n",
            "//huggingface.co/LoftQ . Our implementation is based on publicly available Huggingface\n",
            "Transformers code-base (Paszke et al., 2019). All the experiments are conducted on NVIDIA A100\n",
            "GPUs.\n",
            "Quantization Methods. We apply two quantization methods to demonstrate LoftQ is compatible\n",
            "with different quantization functions:\n",
            "•Uniform quantization is a classic quantization method. It uniformly divides a continuous\n",
            "interval into 2Ncategories and stores a local maximum absolute value for dequantization.\n",
            "•NF4 and its 2-bit variant NF2 are quantization methods used in QLoRA (Dettmers et al.,\n",
            "2023). They assume that the high-precision values are drawn from a Gaussian distribution\n",
            "and map these values to discrete slots that have equal probability.\n",
            "We perform 2-bit and 4-bit quantization on all models, achieving compression ratios of 25-30% and\n",
            "15-20% at the 4-bit and 2-bit levels, respectively. The compression ratios and trainable parameter\n",
            "ratios for all models are detailed in the Appendix A.\n",
            "Baselines. We compare LoftQ with the following baseline methods:\n",
            "•Full fine-tuning is the most common approach for adapting a pre-trained model to down-\n",
            "stream tasks. The model is initialized with pre-trained weights and all parameters are up-\n",
            "dated through an SGD-type optimization method.\n",
            "•Full precision LoRA (LoRA) is a lightweight method for task adaptation, where it stores the\n",
            "backbone using 16-bit numbers and optimizes the low-rank adaptors only. The adaptors\n",
            "are applied to the same matrices as in LoftQ.\n",
            "•QLoRA is similar to LoRA except the backbone is quantized into low-bit regime. The low-\n",
            "rank adapters are initialized using (5) and are applied to the same matrices as in LoftQ.\n",
            "4.1 E NCODER -ONLY MODEL : DEBERT AV3\n",
            "Models and Datasets. We quantize the DeBERTaV3-base (He et al., 2021b) with LoftQ, then fine-\n",
            "tune and evaluate the model on the General Language Understanding Evaluation (GLUE) bench-\n",
            "mark (Wang et al., 2019), SQuADv1.1 (Rajpurkar et al., 2016), and ANLI (Nie et al., 2019). The\n",
            "specific tasks of GLUE are given in Appendix C. Following previous works (Zhang et al., 2023), we\n",
            "exclude WNLI in the experiments.\n",
            "5\n",
            "\n",
            "page_label: 6\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Implementation Details. We select the learning rates from {1×10−5,5×10−5,1×10−45×10−4}.\n",
            "We quantize the entire backbone. Given that GLUE, SQuADv1.1, and ANLI are relatively easy\n",
            "NLU tasks, we also quantize the embedding layer for higher compression efficiency. We apply the\n",
            "NormalFloat and the uniform quantization for LoftQ and QLoRA at both 2-bit and 4-bit levels. We\n",
            "use rank 16 and 32 for low-rank adapters. More implementation details, such as the training epochs\n",
            "and batch sizes, are presented in Appendix D.2.\n",
            "Main Results. Table 1 and Table 2 summarize the results for 2-bit quantization on the GLUE,\n",
            "SQuADv1.1, and ANLI datasets, by NF2 and the uniform quantization, respectively. Our method\n",
            "consistently outperforms QLoRA on all settings with respect to different ranks, quantization meth-\n",
            "ods, and datasets. When using the uniform quantization (Table 2), our method achieves 88.0%\n",
            "accuracy on MNLI-m, surpassing the QLoRA baseline by 8%. For tasks like SST and SQuADv1.1,\n",
            "our method even approaches the full fine-tuning performance at 2-bit level. The 4-bit quantization\n",
            "experiment results are presented in Appendix D.1 as both LoftQ and QLoRA achieve performance\n",
            "close to full fine-tuning.\n",
            "Table 1: Results with 2-bit LoftQ of DeBERTaV3-base models on GLUE development set,\n",
            "SQuADv1.1 development set, ANLI test set using NF2 quantization . We report the median over\n",
            "four seeds. N.A. indicates the model does not converge. The best results on each dataset are shown\n",
            "inbold .\n",
            "Rank Method MNLI QNLI RTE SST MRPC CoLA QQP STSB SQuAD ANLI\n",
            "m / mm Acc Acc Acc Acc Matt Acc P/S Corr EM/F1 Acc\n",
            "- Full FT 90.5/90.6 94.0 82.0 95.3 89.5/93.3 69.2 92.4/89.8 91.6/91.1 88.5/92.8 59.8\n",
            "16 LoRA 90.4/90.5 94.6 85.1 95.1 89.9/93.6 69.9 92.0/89.4 91.7/91.1 87.3/93.1 60.2\n",
            "16QLoRA 75.4/75.6 82.4 55.9 86.5 73.8/82.8 N.A. 86.8/82.3 83.0/82.8 61.5 / 71.2 N.A.\n",
            "LoftQ 84.7/85.1 86.6 61.4 90.2 83.8/88.6 37.4 90.3/86.9 87.1/86.9 81.5/88.6 47.1\n",
            "32QLoRA 78.5/78.7 80.4 56.7 86.9 73.8/82.7 N.A. 87.1/82.7 83.6/83.3 64.6/73.8 N.A.\n",
            "LoftQ 86.0/86.1 89.9 61.7 92.0 83.6/87.2 47.5 91.0/87.9 87.5/87.0 82.9/89.8 49.0\n",
            "Table 2: Results with 2-bit LoftQ of DeBERTaV3-base models on GLUE development set,\n",
            "SQuADv1.1 development set using Uniform quantization . We report the median over four seeds.\n",
            "N.A. indicates the model does not converge. The best results on each task are shown in bold .\n",
            "\n",
            "page_label: 6\n",
            "file_path: loftq.pdf\n",
            "\n",
            "87.1/82.7 83.6/83.3 64.6/73.8 N.A.\n",
            "LoftQ 86.0/86.1 89.9 61.7 92.0 83.6/87.2 47.5 91.0/87.9 87.5/87.0 82.9/89.8 49.0\n",
            "Table 2: Results with 2-bit LoftQ of DeBERTaV3-base models on GLUE development set,\n",
            "SQuADv1.1 development set using Uniform quantization . We report the median over four seeds.\n",
            "N.A. indicates the model does not converge. The best results on each task are shown in bold .\n",
            "Rank Method MNLI QNLI RTE SST MRPC CoLA QQP STSB SQuAD\n",
            "m / mm Acc Acc Acc Acc Matt Acc P/S Corr Em/F1\n",
            "- Full FT 90.5/90.6 94.0 82.0 95.3 89.5/93.3 69.2 92.4/89.8 91.6/91.1 88.5/92.8\n",
            "16 LoRA 90.4/90.5 94.6 85.1 95.1 89.9/93.6 69.9 92.0/89.4 91.7/91.1 87.3/93.1\n",
            "16QLoRA 76.5/76.3 83.8 56.7 86.6 75.7/84.7 N.A. 87.1/82.6 83.5/83.4 69.5/77.6\n",
            "LoftQ 87.3/87.1 90.6 61.1 94.0 87.0/90.6 59.1 90.9/88.0 87.9/87.6 84.4/91.2\n",
            "32QLoRA 79.9/79.5 83.7 57.8 86.9 76.5/84.5 N.A. 88.6/84.7 84.1/84.0 71.6/80.2\n",
            "LoftQ 88.0/88.1 92.2 63.2 94.7 87.5/91.2 60.5 91.3/88.3 89.5/89.2 85.2/91.6\n",
            "Our method is also more stable compared to QLoRA in the low-bit regime. For instance, while\n",
            "QLoRA fails to converge on CoLA for both quantization methods and ranks, LoftQ converges in all\n",
            "cases and achieves a score of 60.5 using uniform quantization at rank 32. LoftQ stands out in its\n",
            "ability to consistently attain robust and improved performance by effectively preserving the starting\n",
            "point of pre-trained weights.\n",
            "4.2 E NCODER -DECODER MODEL : BART\n",
            "Models and Datasets. We quantize BART-large model (Lewis et al., 2020) with LoftQ, then fine-\n",
            "tune and evaluate the model on two commonly used summarization datasets: XSum (Narayan et al.,\n",
            "2018) and CNN/DailyMail(Hermann et al., 2015).\n",
            "Implementation Details. We apply LoftQ to weight matrices in MHA and FFN of both encoder and\n",
            "decoder layers. We report ROUGE 1/2/L scores, which are the metrics for summarization tasks (Lin,\n",
            "2004). We conduct quantization experiments in both 2-bit and 4-bit scenarios. We experiment with\n",
            "both NormalFloat and the uniform quantization in both 2-bit and 4-bit scenarios. In each precision,\n",
            "we choose rank equal to 8 and 16 for a fair comparison with the full precision LoRA baseline (Zhang\n",
            "et al., 2023). Please see Appendix E for detailed configurations.\n",
            "6\n",
            "\n",
            "page_label: 7\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Main Results. Table 3 summarizes our 4-bit quantization experiment results on the XSum and\n",
            "CNN/DailyMail test sets. Our method consistently outperforms QLoRA at both ranks on both\n",
            "datasets. It even surpasses full precision LoRA at both ranks on Xsum. We will discuss this un-\n",
            "expected results in Section 5. The\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LongLoRA paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "score of 60.5 using uniform quantization at rank 32. LoftQ stands out in its\n",
            "ability to consistently attain robust and improved performance by effectively preserving the starting\n",
            "point of pre-trained weights.\n",
            "4.2 E NCODER -DECODER MODEL : BART\n",
            "Models and Datasets. We quantize BART-large model (Lewis et al., 2020) with LoftQ, then fine-\n",
            "tune and evaluate the model on two commonly used summarization datasets: XSum (Narayan et al.,\n",
            "2018) and CNN/DailyMail(Hermann et al., 2015).\n",
            "Implementation Details. We apply LoftQ to weight matrices in MHA and FFN of both encoder and\n",
            "decoder layers. We report ROUGE 1/2/L scores, which are the metrics for summarization tasks (Lin,\n",
            "2004). We conduct quantization experiments in both 2-bit and 4-bit scenarios. We experiment with\n",
            "both NormalFloat and the uniform quantization in both 2-bit and 4-bit scenarios. In each precision,\n",
            "we choose rank equal to 8 and 16 for a fair comparison with the full precision LoRA baseline (Zhang\n",
            "et al., 2023). Please see Appendix E for detailed configurations.\n",
            "6\n",
            "\n",
            "page_label: 7\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Main Results. Table 3 summarizes our 4-bit quantization experiment results on the XSum and\n",
            "CNN/DailyMail test sets. Our method consistently outperforms QLoRA at both ranks on both\n",
            "datasets. It even surpasses full precision LoRA at both ranks on Xsum. We will discuss this un-\n",
            "expected results in Section 5. The 2-bit quantization results are shown in Table 4. Our observation\n",
            "is consistent with the NLU experiments, that LoftQ demonstrates the convergence to reasonable\n",
            "results, while QLoRA does not converge. This indicates our method is robuster by narrowing the\n",
            "initialization gap.\n",
            "Table 3: Results with 4-bit LoftQ of BART-large on XSum and CNN/DailyMail. We report ROUGE-\n",
            "1/2/L. Lead-3 means choosing the first 3 sentences as the summary. N.A. indicates the model does\n",
            "not converge. Full FT : full fine-tuning. We report the median over five seeds.\n",
            "Quantization Rank Method XSum CNN/DailyMail\n",
            "Full Precision-Lead-3 16.30/1.60/11.95 40.42/17.62/36.67\n",
            "Full FT 45.14/22.27/37.25 44.16/21.28/40.90\n",
            "8 LoRA 43.40/20.20/35.20 44.72/21.58/41.84\n",
            "16 LoRA 43.95/20.72/35.68 45.03/21.84/42.15\n",
            "NF48QLoRA 42.91/19.72/34.82 43.10/20.22/40.06\n",
            "LoftQ 44.08/20.72/35.89 43.81/20.95/40.84\n",
            "16QLoRA 43.29/20.05/35.15 43.42/20.62/40.44\n",
            "LoftQ 44.51/21.14/36.18 43.96/21.06/40.96\n",
            "Uniform8QLoRA 41.84/18.71/33.74 N.A.\n",
            "LoftQ 43.86/20.51/35.69 43.73/20.91/40.77\n",
            "16QLoRA 42.45/19.36/34.38 43.00/20.19/40.02\n",
            "LoftQ 44.29/20.90/36.00 43.87/20.99/40.92\n",
            "Table 4: Results with 2-bit LoftQ of BART-large on XSum and CNN/DailyMail using NF2 quanti-\n",
            "zation .N.A. indicates the model does not converge. We report ROUGE-1/2/L, the higher the better.\n",
            "We report the median over five seeds.\n",
            "Rank Method XSum CNN/DailyMail\n",
            "8QLoRA N.A. N.A.\n",
            "LoftQ 39.63/16.65/31.62 42.24/19.44/29.04\n",
            "16QLoRA N.A. N.A.\n",
            "LoftQ 40.81/17.85/32.80 42.52/19.81/39.51\n",
            "4.3 D ECODER -ONLY MODEL : LLAMA-2\n",
            "Models and Datasets. We quantize LLAMA-2-7b and LLAMA-2-13b (Touvron et al., 2023) with\n",
            "LoftQ. We then fine-tune and evaluate the models on two NLG datasets: GSM8K (Cobbe et al.,\n",
            "2021) and WikiText-2 (Merity et al., 2016). Please see Appendix F for more details about the\n",
            "datasets.\n",
            "Implementation Details. Similarly, we apply LoftQ to weight matrices in MHA and FFN of all\n",
            "layers. In WikiText-2 evaluation, we report perplexity. In case of overfitting, we apply weight decay\n",
            "to low-rank adapters for all settings. In GSM8K evaluation, we extract numerical answers in the\n",
            "generated solutions and then calculate the accuracy using those numerical answers. We conduct\n",
            "experiments with both NF2 and NF4. Please see Appendix F for detailed configurations.\n",
            "Main Results.\n",
            "\n",
            "page_label: 7\n",
            "file_path: loftq.pdf\n",
            "\n",
            "We then fine-tune and evaluate the models on two NLG datasets: GSM8K (Cobbe et al.,\n",
            "2021) and WikiText-2 (Merity et al., 2016). Please see Appendix F for more details about the\n",
            "datasets.\n",
            "Implementation Details. Similarly, we apply LoftQ to weight matrices in MHA and FFN of all\n",
            "layers. In WikiText-2 evaluation, we report perplexity. In case of overfitting, we apply weight decay\n",
            "to low-rank adapters for all settings. In GSM8K evaluation, we extract numerical answers in the\n",
            "generated solutions and then calculate the accuracy using those numerical answers. We conduct\n",
            "experiments with both NF2 and NF4. Please see Appendix F for detailed configurations.\n",
            "Main Results. Table 5 presents a summary of our experiments on LLAMA-2-7b and LLAMA-2-\n",
            "13b using 2-bit, 4-bit, and mixed-precision NormalFloat quantization methods on WikiText-2 and\n",
            "GSM8K datasets. In WikiText-2, our method consistently outperforms QLoRA across all quantiza-\n",
            "tion precision settings on both models. When dealing with the challenging 2-bit precision, where\n",
            "QLoRA fails to converge, LoftQ manages to achieve a perplexity of 7.85. In GSM8K, our method\n",
            "achieves better or on par performance compared to QLoRA across different model sizes and quanti-\n",
            "zation precision levels. For example, our method achieves 26.5% accuracy using 2-bit precision of\n",
            "LLAMA-2-7b, where QLoRA does not converge.\n",
            "7\n",
            "\n",
            "page_label: 8\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "To provide a customized trade-off between the performance and precision, we also explore mixed-\n",
            "precision (equivalent to 3 bits) quantization where matrices in the first half layers are quantized\n",
            "using 4 bits, and the rest matrices remain 2 bits. We witness a remarkable 4.1% accuracy boost\n",
            "on the GSM8K dataset using LLAMA-2-7b and a 4.7% boost using LLAMA-2-13b. This result\n",
            "underscores the potential of LoftQ for complex mixed-precision quantization scenarios.\n",
            "Table 5: Results of LoftQ using NormalFloat for LLAMA-2 series on WikiText-2 and GSM8K.\n",
            "3/2.5/2.25-bit indicates mixed-precision quantization: 4-bit precision for the first 16/8/4 layers and\n",
            "2-bit precision for the rest of layers. We report the perplexity (the smaller the better) for WikiText-2\n",
            "and accuracy for GSM8K. The rank of low-rank adapters is 64. N.A. indicates the model does not\n",
            "converge. We report the median over five random seeds.\n",
            "Method BitLLAMA-2-7b LLAMA-2-13b\n",
            "WikiText-2 ↓GSM8K ↑WikiText-2 ↓GSM8K ↑\n",
            "LoRA 16 5.08 38.5 5.12 48.8\n",
            "QLoRA 4 5.70 38.2 5.22 48.8\n",
            "LoftQ 4 5.24 38.0 5.16 49.1\n",
            "QLoRA 3 5.73 32.1 5.22 40.7\n",
            "LoftQ 3 5.63 36.2 5.13 45.4\n",
            "QLoRA 2.5 N.A. N.A. 19.39 N.A.\n",
            "LoftQ 2.5 5.78 31.1 5.22 41.1\n",
            "QLoRA 2.25 N.A. N.A. N.A. N.A.\n",
            "LoftQ 2.25 6.13 27.5 5.45 38.1\n",
            "QLoRA 2 N.A N.A. N.A. N.A.\n",
            "LoftQ 2 7.85 26.5 7.69 33.4\n",
            "4.4 A NALYSIS\n",
            "Effectiveness of Alternating Optimization. We conduct experiments with different alternating\n",
            "stepTto verify the effectiveness of the alternating optimization and to find the best value Tas\n",
            "a hyperparameter for different models. Across all tasks and models, we observed that alternating\n",
            "optimization yields substantial improvements even with a minimal alternating step. This suggests\n",
            "that it rapidly narrows the discrepancy between quantized weights and pre-trained weights, making\n",
            "our method easy to apply. For example, LoftQ achieves 21.14 Rouge-2 score on XSum using only\n",
            "1 step. Interestingly, we noticed that increasing the alternating step beyond a certain point tends\n",
            "to result in diminishing returns. We suspect this phenomenon occurs because, as the gap becomes\n",
            "smaller, it becomes more challenging for alternating optimization to consistently minimize the gap\n",
            "at each step. This challenge emerges because of the inherent errors introduced by the quantization\n",
            "method. Nevertheless, results from Figure 3 indicate our method is not sensitive to the alternating\n",
            "stepTand is able to consistently enhance downstream fine-tuning performance.\n",
            "0 1 5 10\n",
            "Alternating Step T7580858890Accuracy79.986.688.0 87.7\n",
            "(a) MNLI\n",
            "20.022.525.027.0\n",
            "22.525.225.5\n",
            "0 1 5 10\n",
            "Alternating Step T011.2Accuracy (b) GSM8k\n",
            "0 1 5 10\n",
            "Alternating Step T19.020.021.021.5ROUGE-220.0521.14 21.09\n",
            "20.83 (c) XSum\n",
            "Figure 3: Comparison of different alternating step Tused in LoftQ. T= 0indicates we use QLoRA\n",
            "method that initializes low-rank adapters by (5). T= 1,5,10indicates we use different Tfor LoftQ\n",
            "described in Algorithm 1. Left: Uniform 2-bit DeBERTaV3-base. Middle : NF2 2-bit LLAMA-2-\n",
            "13b.Right : NF4 BART-large.\n",
            "8\n",
            "\n",
            "page_label: 9\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "5 D ISCUSSION\n",
            "Start with quantization or SVD in the alternating optimization? An alternative algorithm to the\n",
            "alternating optimization is that we first obtain the low-rank approximation At, Btand then obtain the\n",
            "quantized weight Qtby switching Line 3 and Line 4 in Algorithm 1. We note this is a valid alterna-\n",
            "tive method as both still jointly minimize the objective in (6). Table 6 summarizes the performance\n",
            "of this alternative method. It is noteworthy that the alternative method still outperforms QLoRA\n",
            "significantly, even though it is worse than the primary version. This observation underscores the\n",
            "potential for performance improvement by achieving a closer approximation of pre-trained weights\n",
            "within the low-precision regime.\n",
            "LoftQ better than Full-precision LoRA? We find LoftQ outperforms full precision LoRA in XSum\n",
            "and GSM8K (see Table 3 and Table 5). Beside the overfitting caused by lack of regularization,\n",
            "anonther possible explanation for this unexpected phenomenon is that the initial low-rank adapters\n",
            "obtained by LoftQ are non-zero while they are all zero in full precision LoRA as described in (5).\n",
            "Such zero initialization could make the fine-tuning unstable, and therefore it performs worse than\n",
            "LoftQ. We leave the study of the robustness of LoftQ as future work.\n",
            "Table 6: Results of 2-bit uniformly quantized DeBERTaV3-base on part of GLUE. LoftQ(SVD\n",
            "First) indicates the alternative LoftQ that swiches Line 3 and Line 4 in Algorithm 1. We report the\n",
            "median over four random seeds. The best results on each task are shown in bold .\n",
            "Method RankMNLI QNLI SST2\n",
            "m / mm Acc Acc\n",
            "Full FT - 90.5/90.6 94.0 95.3\n",
            "QLoRA 32 79.9/79.5 83.8 86.6\n",
            "LoftQ(SVD First) 32 87.8/87.7 84.9 89.7\n",
            "LoftQ(Quantiztion First) 32 88.0/88.1 92.2 94.7\n",
            "6 R ELATED WORK\n",
            "Quantization-Aware Training (QAT) is often used to obtain quantized models that are adapted\n",
            "in downstream tasks (Peri et al., 2020; Liu et al., 2023). It involves quantization and full model\n",
            "fine-tuning at the same time. However, QAT requires massive training cost, such as the gradient\n",
            "and optimization state. Moreover, it is difficult to compute the gradient of quantized weights. Our\n",
            "method, with the help of LoRA, sidesteps the aforementioned issues, providing a light approach for\n",
            "downstream task adaptation.\n",
            "Post-Training Quantization (PTQ) is a category of popular quantization frameworks (Frantar et al.,\n",
            "2022; Xiao et al., 2023), which can also be used for task adaptation. It calibrates the high-precision\n",
            "model with a small subset of the training dataset. Therefore, the subsequent quantization is guided\n",
            "by the training dataset, providing task-specific quantized models. Besides, it does not involve any\n",
            "gradient backpropagation, so it is cost-efficient. However, it usually results in lower accuracy com-\n",
            "pared to QAT.\n",
            "7 C ONCLUSION\n",
            "We propose LoftQ, a quantization framework for LLMs, which alternatively applies quantization\n",
            "and low-rank approximation to the original high-precision pre-trained weights, to obtain an ini-\n",
            "tialization for the subsequent LoRA fine-tuning. Experiments on natural language understanding,\n",
            "question answering, summarization, and natural language generation show that our framework re-\n",
            "markably surpasses existing methods, e.g., QLoRA, for quantizing encoder-only, encoder-decoder,\n",
            "and decoder-only models. We have not observed our method exhibiting worse performance over\n",
            "QLoRA. Moreover, our quantization framework demonstrates effectiveness and robustness particu-\n",
            "larly in low-bit quantization regimes, e.g., the 2-bit level.\n",
            "9\n",
            "\n",
            "page_label: 10\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "REFERENCES\n",
            "Haoli Bai, Wei Zhang, Lu Hou, Lifeng Shang, Jing Jin, Xin Jiang, Qun Liu, Michael Lyu, and Irwin\n",
            "King. Binarybert: Pushing the limit of bert quantization. arXiv preprint arXiv:2012.15701 , 2020.\n",
            "Haoli Bai, Lu Hou, Lifeng Shang, Xin Jiang, Irwin King, and Michael R Lyu. Towards efficient post-\n",
            "training quantization of pre-trained language models. Advances in Neural Information Processing\n",
            "Systems , 35:1405–1418, 2022.\n",
            "Roy Bar-Haim, Ido Dagan, Bill\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LongLoRA paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "quantized models. Besides, it does not involve any\n",
            "gradient backpropagation, so it is cost-efficient. However, it usually results in lower accuracy com-\n",
            "pared to QAT.\n",
            "7 C ONCLUSION\n",
            "We propose LoftQ, a quantization framework for LLMs, which alternatively applies quantization\n",
            "and low-rank approximation to the original high-precision pre-trained weights, to obtain an ini-\n",
            "tialization for the subsequent LoRA fine-tuning. Experiments on natural language understanding,\n",
            "question answering, summarization, and natural language generation show that our framework re-\n",
            "markably surpasses existing methods, e.g., QLoRA, for quantizing encoder-only, encoder-decoder,\n",
            "and decoder-only models. We have not observed our method exhibiting worse performance over\n",
            "QLoRA. Moreover, our quantization framework demonstrates effectiveness and robustness particu-\n",
            "larly in low-bit quantization regimes, e.g., the 2-bit level.\n",
            "9\n",
            "\n",
            "page_label: 10\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "REFERENCES\n",
            "Haoli Bai, Wei Zhang, Lu Hou, Lifeng Shang, Jing Jin, Xin Jiang, Qun Liu, Michael Lyu, and Irwin\n",
            "King. Binarybert: Pushing the limit of bert quantization. arXiv preprint arXiv:2012.15701 , 2020.\n",
            "Haoli Bai, Lu Hou, Lifeng Shang, Xin Jiang, Irwin King, and Michael R Lyu. Towards efficient post-\n",
            "training quantization of pre-trained language models. Advances in Neural Information Processing\n",
            "Systems , 35:1405–1418, 2022.\n",
            "Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and\n",
            "Idan Szpektor. The second pascal recognising textual entailment challenge. 2006.\n",
            "Luisa Bentivogli, Peter Clark, Ido Dagan, and Danilo Giampiccolo. The fifth pascal recognizing\n",
            "textual entailment challenge. In TAC, 2009.\n",
            "Daniel Cer, Mona Diab, Eneko Agirre, I ˜nigo Lopez-Gazpio, and Lucia Specia. SemEval-2017 task\n",
            "1: Semantic textual similarity multilingual and crosslingual focused evaluation. In Proceedings of\n",
            "the 11th International Workshop on Semantic Evaluation (SemEval-2017) , pp. 1–14, Vancouver,\n",
            "Canada, August 2017. Association for Computational Linguistics. doi: 10.18653/v1/S17-2001.\n",
            "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\n",
            "Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to\n",
            "solve math word problems. arXiv preprint arXiv:2110.14168 , 2021.\n",
            "Ido Dagan, Oren Glickman, and Bernardo Magnini. The pascal recognising textual entailment\n",
            "challenge. In Machine Learning Challenges Workshop , 2007.\n",
            "Tim Dettmers, Mike Lewis, Younes Belkada, and Luke Zettlemoyer. Llm. int8 (): 8-bit matrix\n",
            "multiplication for transformers at scale. arXiv preprint arXiv:2208.07339 , 2022.\n",
            "Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning\n",
            "of quantized llms. arXiv preprint arXiv:2305.14314 , 2023.\n",
            "Shizhe Diao, Rui Pan, Hanze Dong, Ka Shun Shum, Jipeng Zhang, Wei Xiong, and Tong Zhang.\n",
            "Lmflow: An extensible toolkit for finetuning and inference of large foundation models. arXiv\n",
            "preprint arXiv:2306.12420 , 2023.\n",
            "William B. Dolan and Chris Brockett. Automatically constructing a corpus of sentential paraphrases.\n",
            "InProceedings of the Third International Workshop on Paraphrasing (IWP2005) , 2005.\n",
            "Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. Gptq: Accurate post-training\n",
            "quantization for generative pre-trained transformers. arXiv preprint arXiv:2210.17323 , 2022.\n",
            "Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. The third PASCAL recognizing\n",
            "textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entail-\n",
            "ment and Paraphrasing , pp. 1–9, Prague, June 2007. Association for Computational Linguistics.\n",
            "Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig. Towards a\n",
            "unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366 , 2021a.\n",
            "Pengcheng He, Jianfeng Gao, and Weizhu Chen. Debertav3: Improving deberta using electra-style\n",
            "pre-training with gradient-disentangled embedding sharing. arXiv preprint arXiv:2111.09543 ,\n",
            "2021b.\n",
            "\n",
            "page_label: 10\n",
            "file_path: loftq.pdf\n",
            "\n",
            "The third PASCAL recognizing\n",
            "textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entail-\n",
            "ment and Paraphrasing , pp. 1–9, Prague, June 2007. Association for Computational Linguistics.\n",
            "Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig. Towards a\n",
            "unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366 , 2021a.\n",
            "Pengcheng He, Jianfeng Gao, and Weizhu Chen. Debertav3: Improving deberta using electra-style\n",
            "pre-training with gradient-disentangled embedding sharing. arXiv preprint arXiv:2111.09543 ,\n",
            "2021b.\n",
            "Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa\n",
            "Suleyman, and Phil Blunsom. Teaching machines to read and comprehend. Advances in neural\n",
            "information processing systems , 28, 2015.\n",
            "Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,\n",
            "and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint\n",
            "arXiv:2106.09685 , 2021.\n",
            "Hector Levesque, Ernest Davis, and Leora Morgenstern. The winograd schema challenge. In Thir-\n",
            "teenth international conference on the principles of knowledge representation and reasoning ,\n",
            "2012.\n",
            "10\n",
            "\n",
            "page_label: 11\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer\n",
            "Levy, Ves Stoyanov, and Luke Zettlemoyer. Bart: Denoising sequence-to-sequence pre-\n",
            "training for natural language generation, translation, and comprehension. arXiv preprint\n",
            "arXiv:1910.13461 , 2019.\n",
            "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer\n",
            "Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-\n",
            "training for natural language generation, translation, and comprehension. In Proceedings of the\n",
            "58th Annual Meeting of the Association for Computational Linguistics , pp. 7871–7880, Online,\n",
            "July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.703.\n",
            "Yixiao Li, Yifan Yu, Qingru Zhang, Chen Liang, Pengcheng He, Weizhu Chen, and Tuo Zhao.\n",
            "Losparse: Structured compression of large language models based on low-rank and sparse ap-\n",
            "proximation. arXiv preprint arXiv:2306.11222 , 2023.\n",
            "Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summarization\n",
            "Branches Out , pp. 74–81, Barcelona, Spain, July 2004. Association for Computational Linguis-\n",
            "tics.\n",
            "Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock, Yashar Mehdad, Yangyang\n",
            "Shi, Raghuraman Krishnamoorthi, and Vikas Chandra. Llm-qat: Data-free quantization aware\n",
            "training for large language models. arXiv preprint arXiv:2305.17888 , 2023.\n",
            "Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint\n",
            "arXiv:1711.05101 , 2017.\n",
            "Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture\n",
            "models, 2016.\n",
            "Shashi Narayan, Shay B. Cohen, and Mirella Lapata. Don’t give me the details, just the summary!\n",
            "topic-aware convolutional neural networks for extreme summarization. ArXiv , abs/1808.08745,\n",
            "2018.\n",
            "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. Adver-\n",
            "sarial nli: A new benchmark for natural language understanding. ArXiv , abs/1910.14599, 2019.\n",
            "URL https://api.semanticscholar.org/CorpusID:207756753 .\n",
            "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\n",
            "Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward\n",
            "Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,\n",
            "Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance\n",
            "deep learning library. In Advances in Neural Information Processing Systems 32 , pp. 8024–8035.\n",
            "Curran Associates, Inc., 2019.\n",
            "Dheeraj Peri, Jhalak Patel, and Josh Park. Deploying quantization-aware trained networks using\n",
            "tensorrt. In GPU Technology Conference , 2020.\n",
            "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions\n",
            "for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods\n",
            "in Natural Language Processing , pp. 2383–2392, Austin, Texas, November 2016. Association for\n",
            "Computational Linguistics. doi: 10.18653/v1/D16-1264.\n",
            "Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami, Michael W Mahoney,\n",
            "and Kurt Keutzer. Q-bert: Hessian based ultra low precision quantization of bert.\n",
            "\n",
            "page_label: 11\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Dheeraj Peri, Jhalak Patel, and Josh Park. Deploying quantization-aware trained networks using\n",
            "tensorrt. In GPU Technology Conference , 2020.\n",
            "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions\n",
            "for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods\n",
            "in Natural Language Processing , pp. 2383–2392, Austin, Texas, November 2016. Association for\n",
            "Computational Linguistics. doi: 10.18653/v1/D16-1264.\n",
            "Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami, Michael W Mahoney,\n",
            "and Kurt Keutzer. Q-bert: Hessian based ultra low precision quantization of bert. In Proceedings\n",
            "of the AAAI Conference on Artificial Intelligence , volume 34, pp. 8815–8821, 2020.\n",
            "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng,\n",
            "and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment\n",
            "treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language\n",
            "Processing , pp. 1631–1642, Seattle, Washington, USA, October 2013. Association for Computa-\n",
            "tional Linguistics.\n",
            "11\n",
            "\n",
            "page_label: 12\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\n",
            "lay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open founda-\n",
            "tion and fine-tuned chat models. arXiv preprint arXiv:2307.09288 , 2023.\n",
            "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n",
            "Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural informa-\n",
            "tion processing systems , 30, 2017.\n",
            "Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman.\n",
            "GLUE: A multi-task benchmark and analysis platform for natural language understanding. In\n",
            "International Conference on Learning Representations , 2019.\n",
            "Alex Warstadt, Amanpreet Singh, and Samuel R. Bowman. Neural network acceptability judgments.\n",
            "Transactions of the Association for Computational Linguistics , 7:625–641, 2019. doi: 10.1162/\n",
            "tacla00290.\n",
            "Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sen-\n",
            "tence understanding through inference. In Proceedings of the 2018 Conference of the North Amer-\n",
            "ican Chapter of the Association for Computational Linguistics: Human Language Technologies,\n",
            "Volume 1 (Long Papers) , pp. 1112–1122, New Orleans, Louisiana, June 2018. Association for\n",
            "Computational Linguistics. doi: 10.18653/v1/N18-1101.\n",
            "Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han. Smoothquant:\n",
            "Accurate and efficient post-training quantization for large language models. In International\n",
            "Conference on Machine Learning , pp. 38087–38099. PMLR, 2023.\n",
            "Ofir Zafrir, Guy Boudoukh, Peter Izsak, and Moshe Wasserblat. Q8bert: Quantized 8bit bert. In\n",
            "2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing-NeurIPS\n",
            "Edition (EMC2-NIPS) , pp. 36–39. IEEE, 2019.\n",
            "Hongyi Zhang, Yann N Dauphin, and Tengyu Ma. Fixup initialization: Residual learning without\n",
            "normalization. arXiv preprint arXiv:1901.09321 , 2019.\n",
            "Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng He, Yu Cheng, Weizhu Chen,\n",
            "and Tuo Zhao. Adaptive budget allocation for parameter-efficient fine-tuning. arXiv preprint\n",
            "arXiv:2303.10512 , 2023.\n",
            "12\n",
            "\n",
            "page_label: 13\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "A M ODEL COMPRESSION RATIO AND MEMORY FOOTPRINT\n",
            "We report the compression ratio after applying LoftQ in Table 7. It is defined as\n",
            "compression ration =backbone size +LoRA adapter size\n",
            "pre-trained size.\n",
            "We also measure the GPU memory cost during training. Given that GPU memory varies by models,\n",
            "tasks, sequence lengths, batch sizes, etc. We report LLAMA-2 on GSM8K as an example in Table\n",
            "8.\n",
            "Table\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LongLoRA paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "Wu, Julien Demouth, and Song Han. Smoothquant:\n",
            "Accurate and efficient post-training quantization for large language models. In International\n",
            "Conference on Machine Learning , pp. 38087–38099. PMLR, 2023.\n",
            "Ofir Zafrir, Guy Boudoukh, Peter Izsak, and Moshe Wasserblat. Q8bert: Quantized 8bit bert. In\n",
            "2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing-NeurIPS\n",
            "Edition (EMC2-NIPS) , pp. 36–39. IEEE, 2019.\n",
            "Hongyi Zhang, Yann N Dauphin, and Tengyu Ma. Fixup initialization: Residual learning without\n",
            "normalization. arXiv preprint arXiv:1901.09321 , 2019.\n",
            "Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng He, Yu Cheng, Weizhu Chen,\n",
            "and Tuo Zhao. Adaptive budget allocation for parameter-efficient fine-tuning. arXiv preprint\n",
            "arXiv:2303.10512 , 2023.\n",
            "12\n",
            "\n",
            "page_label: 13\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "A M ODEL COMPRESSION RATIO AND MEMORY FOOTPRINT\n",
            "We report the compression ratio after applying LoftQ in Table 7. It is defined as\n",
            "compression ration =backbone size +LoRA adapter size\n",
            "pre-trained size.\n",
            "We also measure the GPU memory cost during training. Given that GPU memory varies by models,\n",
            "tasks, sequence lengths, batch sizes, etc. We report LLAMA-2 on GSM8K as an example in Table\n",
            "8.\n",
            "Table 7: Compression ratios of backbones.\n",
            "ModelCompression TrainableRank BitsQuantization\n",
            "ratio (%) ratio (%) method\n",
            "DeBERTaV3-base 15.6 3.1 16 2 Uniform\n",
            "DeBERTaV3-base 18.8 6.3 32 2 Uniform\n",
            "DeBERTaV3-base 17.2 3.1 16 2 NF2\n",
            "DeBERTaV3-base 20.4 6.3 32 2 NF2\n",
            "BART-large 15.3 1.2 8 4 NF2\n",
            "BART-large 16.7 2.5 16 4 NF2\n",
            "BART-large 27.8 1.2 8 4 NF4\n",
            "BART-large 29.0 2.5 16 4 NF4\n",
            "BART-large 26.2 1.2 8 4 Uniform\n",
            "BART-large 27.5 2.5 16 4 Uniform\n",
            "LLAMA-2-7b 16.6 2.4 64 2 Nf2\n",
            "LLAMA-2-7b 29.0 2.4 64 4 Nf4\n",
            "LLAMA-2-13b 16.0 1.9 64 2 Nf2\n",
            "LLAMA-2-13b 28.5 1.9 64 4 Nf4\n",
            "Table 8: GPU memory footprint\n",
            "Model Dataset Seq length Batch size GPU Mem\n",
            "LLAMA-2-7b GSM8K 384 1 15GB\n",
            "LLAMA-2-13b GSM8K 384 1 24GB\n",
            "B Q UANTIZATION TIME\n",
            "We report the execution time of LoftQ applying to a single weight matrix in Table 9. The time is\n",
            "tested on Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz.\n",
            "Table 9: Execution time of LoftQ applying to different weight matrices.\n",
            "Model Size StepTQuantization method Time\n",
            "DeBERTaV3-base 768×768 5 Uniform 1s\n",
            "BART-large 1024×1024 5 NF4 1s\n",
            "LLAMA-2-7b 4096×4096 5 NF4 21s\n",
            "LLAMA-2-13b 5120×5120 5 NF4 43s\n",
            "C GLUE D ATASET STATISTICS\n",
            "We present the dataset statistics of GLUE Wang et al. (2019) in the following table.\n",
            "GLUE includes two single-sentence classification tasks: SST-2 (Socher et al., 2013) and CoLA\n",
            "(Warstadt et al., 2019), and three similarity and paraphrase tasks: MRPC (Dolan & Brockett, 2005),\n",
            "STS-B (Cer et al., 2017), and QQP. GLUE also includes four natural language inference tasks in\n",
            "GLUE: MNLI (Williams et al., 2018), QNLI (Rajpurkar et al., 2016), RTE (Dagan et al., 2007; Bar-\n",
            "Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009), and WNLI (Levesque et al.,\n",
            "2012).\n",
            "13\n",
            "\n",
            "page_label: 14\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Corpus Task #Train #Dev #Test #Label Metrics\n",
            "Single-Sentence Classification (GLUE)\n",
            "CoLA Acceptability 8.5k 1k 1k 2 Matthews corr\n",
            "SST Sentiment 67k 872 1.8k 2 Accuracy\n",
            "Pairwise Text Classification (GLUE)\n",
            "MNLI NLI 393k 20k 20k 3 Accuracy\n",
            "RTE NLI 2.5k 276 3k 2 Accuracy\n",
            "QQP Paraphrase 364k 40k 391k 2 Accuracy/F1\n",
            "MRPC Paraphrase 3.7k 408 1.7k 2 Accuracy/F1\n",
            "QNLI QA/NLI 108k 5.7k 5.7k 2 Accuracy\n",
            "Text Similarity (GLUE)\n",
            "STS-B Similarity 7k 1.5k 1.4k 1 Pearson/Spearman corr\n",
            "Table 10: Summary of the GLUE benchmark.\n",
            "D N ATURAL LANGUAGE UNDERSTANDING\n",
            "D.1 GLUE WITH 4-BIT\n",
            "We show the 4-bits results in the Table 11. Both methods can achieve performance close to full-\n",
            "finetuning.\n",
            "Table 11: Results with 4-bit LoftQ of DeBERTaV3-base models on GLUE development set using\n",
            "NF4 quantization. We report the median over four seeds. Results with N.A. indicate the model does\n",
            "not converge. The best results on each dataset are shown in bold\n",
            "Method RankMNLI SST-2 QNLI ANLI\n",
            "m / mm Acc Acc Acc\n",
            "Full FT - 90.5/90.6 95.3 94.0 59.8\n",
            "QLoRA 32 89.9/89.9 95.3 94.2 59.4\n",
            "LoftQ 32 89.9/90.0 95.3 94.1 59.9\n",
            "D.2 T RAINING DETAILS\n",
            "Implementation Details. The implementation of LoftQ is based on publicly available Huggingface\n",
            "(Paszke et al., 2019) code-base3.\n",
            "Hyper-parameter Details. We select the learning rate of {1×10−5,5×10−5,1×10−4,5×10−4},\n",
            "and use the selected learning rate for both uniform quantization experiments and nf2 quantization\n",
            "experiments. We use batch size of 32 for all GLUE tasks and ANLI. We use batch size of 16 for\n",
            "SQuADv1.1. We use LoftQ of 5 iterations for all GLUE tasks.\n",
            "Table 12 summarizes the detailed hyperparameters for each task used in training DeBERTaV3-base\n",
            "using uniform quantization. Table 13 summarizes the detailed hyperparameters for each task used\n",
            "in training DeBERTaV3-base using nf2 quantization.\n",
            "Table 12: Hyper-parameter setup of LoftQ for GLUE benchmark for training DeBERTaV3-base\n",
            "using Uniform quantization.\n",
            "Hyper-parameter MNLI RTE QNLI MRPC QQP SST-2 CoLA STS-B SQuADv1.1 ANLI\n",
            "# epochs 5 20 10 60 10 10 60 60 10 12\n",
            "Learning rate 1×10−45×10−45×10−51×10−45×10−55×10−55×10−55×10−55×10−55×10−5\n",
            "3https://github.com/huggingface/transformers/tree/main/examples/pytorch\n",
            "14\n",
            "\n",
            "page_label: 15\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Table 13: Hyper-parameter setup of LoftQ for GLUE benchmark for training DeBERTaV3-base\n",
            "using NF2 quantization.\n",
            "Hyper-parameter MNLI RTE QNLI MRPC QQP SST-2 CoLA STS-B SQuADv1.1 ANLI\n",
            "# epochs 5 20 10 60 10 10 60 60 10 12\n",
            "Learning rate 1×10−45×10−55×10−51×10−45×10−55×10−55×10−51×10−45×10−55×10−5\n",
            "E S UMMARIZATION\n",
            "E.1 T RAINING DETAILS\n",
            "We choose Adam as the optimizer and try learning rate from {1×10−5,5×10−5,7×10−5,2×\n",
            "10−4,3×10−4,4×10−4}. We show the optimal learning rate for different settings in Table 14.\n",
            "We use LoftQ of 1 iteration for all BART-large experiments. Table 14 and Table 15 summarize the\n",
            "learning rate and other hyper-parameters for CNN/DailyMail and XSum.\n",
            "Table 14: Hyper-parameter setup of LoftQ BART-large on CNN/DailyMail\n",
            "HyperparameterNF4 4-bit Uniform NF2\n",
            "rank8 rank16 rank8 rank16 rank8 rank16\n",
            "Learning rate 2e-4 2e-4 2e-4 3e-4 2e-4 2e-4\n",
            "Epoch 15 15 15 15 15 15\n",
            "Batch size 64 64 64 64 64 64\n",
            "Table 15: Hyper-parameter setup of LoftQ BART-large on XSum\n",
            "HyperparameterNF4 4-bit Uniform NF2\n",
            "rank8 rank16 rank8 rank16 rank8 rank16\n",
            "Learning rate 2e-4 2e-4 2e-4 2e-4 2e-4 2e-4\n",
            "Epoch 25 25 25 25 25 25\n",
            "Batch size 32 32 32 32 32 32\n",
            "F N ATURAL LANGUAGE GENERATION\n",
            "We set the batch size as 32 for WikiText-2 and 16 for GSM8K. We train 2 epochs on WikiText-2 and\n",
            "6 epochs on GSM8K. We select learning rate from {1×10−5,5×10−5,7×10−5,1×10−4, ,3×\n",
            "10−4,4×10−4}. Specific settings are summarized in Table 16 and Table 17.\n",
            "G C OMPARISON TO PRUNING\n",
            "Pruning is also a widely used compression method. Here we compare LoftQ with the state-of-the-\n",
            "art pruning method Li et al. (2023). We show the comparison in Table 18. We can see our method\n",
            "significantly outperforms the pruning methods on DeBERTaV3-base model. We also remark that\n",
            "LoftQ can consistently reduce the memory of both training and storage. In contrast, pruning requires\n",
            "training the entire full-precision matrix, which implies that it can not achieve any memory savings\n",
            "during the training stage.\n",
            "H E XTENSION TO CONVOLUTIONAL LAYERS\n",
            "Low-rank adapters can also be applied to convolutional layers. Given an input feature map\n",
            "X∈Rh×w×c1andc22D convolutional kernels Ki∈Rc1×d×d, i= 1,2, ..., c 2, the output of\n",
            "the convolutional layer is\n",
            "Y= stack( X⊗K1, ..., X ⊗Kc2), (10)\n",
            "where Y∈Rh×w×c2and⊗denotes the 2D convolution operation.\n",
            "15\n",
            "\n",
            "page_label: 16\n",
            "file_path: loftq.pdf\n",
            "\n",
            "Published as a conference paper at ICLR 2024\n",
            "Table 16: Hyper-parameter setup of LoftQ LLAMA-2-series on GSM8K\n",
            "Model Hyperparameter NF4 NF2 Mixed-precision\n",
            "LLAMA-2-7b learning rate 3×10−43×10−43×10−4\n",
            "LLAMA-2-13b learning rate 1×10−41×10−43×10−4\n",
            "Table 17: Hyper-parameter setup of LoftQ LLAMA-2-series on WikiText-2\n",
            "Model Hyperparameter NF4 NF2 Mixed-precision\n",
            "LLAMA-2-7b learning rate 3×10−43×10−43×10−4\n",
            "LLAMA-2-13b learning rate 1×10−41×10−43×10−4\n",
            "Table 18: Results of LoftQ using 2-bits uniform quantization compared with LoSparse with\n",
            "DeBERTaV3-base models on some of GLUE development sets. Here Ratio is the proportion of\n",
            "total remaining weights. Results with N.A. indicate the model does not converge.\n",
            "Method RatioMNLI SST-2 QNLI\n",
            "m / mm Acc Acc\n",
            "Full FT 100% 90.5 / 90.6 95.3 94.0\n",
            "LoSparse15% 83.3/82.9 87.6 90.4\n",
            "20% 84.5/83.8 91.7 88.6\n",
            "LoftQ15.6% 87.3/87.1 94.0 90.6\n",
            "18.8% 88.0/88.1 94.7 92.4\n",
            "We can reformulate Equation (10) into matrix multiplication as\n",
            "Y=Z×H⊤,\n",
            "where Z∈Rhw×c1d2, H∈Rc2×c1d2, by extending and flattening the input Xtogether with con-\n",
            "catenating and flattening kernels. We first extend a vector xi,j∈Rc1by its neighbor vectors within\n",
            "the kernel window:\n",
            "x′\n",
            "i,j= Concat(xi−d\n",
            "2,j−d\n",
            "2, ...,xi+d\n",
            "2,j+d\n",
            "2).\n",
            "Now, Xbecomes X′∈Rh×w×c1d2. We then flatten X′intoZ∈Rhw×c1d2. For kernels, we first\n",
            "concatenate {K1, ..., K c2}intoH′∈Rc2×c1×d×d. We then flatten H′intoH.\n",
            "Note that Hcan be approximated by a low-rank matrix\n",
            "R=UV⊤,\n",
            "where U∈Rc2×r, V∈Rc1d2×r, r≪min{c2, c1d2}by SVD. Therefore, the original convolution\n",
            "layer can be approximated as\n",
            "bY=Z×(UV⊤)⊤(11)\n",
            "= (Z×V)×U⊤(12)\n",
            "=M×U⊤. (13)\n",
            "Note that Z×Vcan be restored into a convolution operation where we have rkernels Di∈\n",
            "Rc1×d×d, i= 1,2, , ..., r andM×U⊤can also be restored into a convolution operation where\n",
            "we have c2kernels Ui∈Rr×1×1, i= 1,2, , ..., c 2.\n",
            "16\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LongLoRA paper.\n",
            "Answer: \n",
            "merged_message user: You are an expert Q&A system that is trusted around the world.\n",
            "Always answer the query using the provided context information, and not prior knowledge.\n",
            "Some rules to follow:\n",
            "1. Never directly reference the given context in your answer.\n",
            "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
            "Context information from multiple sources is below.\n",
            "---------------------\n",
            "The LongLoRA method enhances the performance of Large Language Models (LLMs) on long-sequence tasks by combining low-rank adaptation (LoRA) with techniques like delayed gradient propagation, weight decay, and adaptable learning rates. This approach enables efficient fine-tuning of LLMs for improved accuracy in various downstream tasks.\n",
            "\n",
            "LongLoRA is a novel quantization method that improves upon the performance and stability of quantized Low-Rank Adaptation (LoRA) fine-tuning for large language models. It addresses the issue of quantization discrepancy, which arises from directly quantizing pre-trained weights without considering the subsequent fine-tuning process. LongLoRA tackles this by jointly optimizing both the quantized base model and the low-rank adapters. This approach ensures a closer initialization to the original pre-trained weights, leading to enhanced performance in downstream tasks. Experimental results demonstrate that LongLoRA consistently outperforms existing methods like QLoRA, particularly in low-bit quantization settings, and exhibits greater stability across various tasks.\n",
            "\n",
            "LongLoRA is a novel quantization framework for Large Language Models (LLMs) that applies quantization and low-rank approximation to pre-trained weights. This process creates an initialization for Low-Rank Adaptation (LoRA) fine-tuning.  \n",
            "\n",
            "Empirical evidence from various natural language processing tasks, including natural language understanding, question answering, summarization, and natural language generation, demonstrates that this framework outperforms existing methods, especially in low-bit quantization scenarios. Notably, this method has not shown inferior performance to existing methods and exhibits robustness and effectiveness, particularly in 2-bit quantization settings.\n",
            "\n",
            "The authors propose a new quantization framework for LLMs called LoftQ. This framework alternates between applying quantization and low-rank approximation to the initial high-precision pre-trained weights. The resulting output is then used as an initialization for LoRA fine-tuning. Experiments on various tasks, including natural language understanding, question answering, summarization, and natural language generation, show that LoftQ significantly outperforms existing methods, especially in low-bit quantization settings. Notably, the authors observed no performance degradation compared to QLoRA.\n",
            "\n",
            "The LongLoRA method compresses large language models by combining low-rank adaptation (LoRA) with quantization, achieving high compression ratios without significant performance degradation. It employs a low-rank approximation of weight matrices and applies quantization techniques like NF4 for further compression. This approach significantly reduces memory footprint during training, enabling the training of larger models or the use of larger batch sizes. Experimental results demonstrate its effectiveness across various tasks, including natural language understanding, summarization, and natural language generation, showing comparable or even superior performance to full-precision models while achieving significant compression ratios. Notably, LongLoRA outperforms pruning methods in terms of memory savings during both training and storage. Moreover, the paper discusses the extension of LongLoRA to convolutional layers, further broadening its applicability.\n",
            "---------------------\n",
            "Given the information from multiple sources and not prior knowledge, answer the query.\n",
            "Query: Summarize the LongLoRA paper.\n",
            "Answer: \n",
            "=== Function Output ===\n",
            "LongLoRA is a novel framework that enhances the efficiency and performance of Large Language Models (LLMs) for long-sequence tasks. \n",
            "\n",
            "This framework leverages a combination of quantization and low-rank approximation techniques applied to the initial pre-trained weights. This process results in an optimized initialization for Low-Rank Adaptation (LoRA) fine-tuning. \n",
            "\n",
            "Evaluations across a range of natural language processing tasks, including question answering and summarization, demonstrate that this method surpasses existing techniques, particularly in low-bit quantization scenarios. Notably, it maintains superior performance, especially in 2-bit quantization settings, without any degradation compared to other methods. \n",
            "\n",
            "merged_message user:  You are an agent designed to answer queries over a set of given papers.\n",
            "Please use the tools provided to answer a question as possible. Do not rely on prior knowledge. Summarize your answer\n",
            "\n",
            "Compare and contrast the LoRA papers (LongLoRA, LoftQ). Analyze the approach in each paper first. \n",
            "merged_message model: \n",
            "merged_message user: LoftQ is a new quantization framework for Large Language Models (LLMs) that improves performance by jointly optimizing quantized model weights and the initialization of low-rank adapters. This approach results in a better starting point for fine-tuning and addresses the performance gap often observed when combining standard quantization with LoRA fine-tuning. It consistently outperforms standard quantization techniques, especially in low-bit scenarios, and is compatible with various quantization methods. It achieves significant compression ratios with minimal performance degradation and can be applied to various tasks, including natural language understanding, summarization, and generation, with results comparable to full-finetuning methods. \n",
            "\n",
            "LongLoRA is a novel framework that enhances the efficiency and performance of Large Language Models (LLMs) for long-sequence tasks. \n",
            "\n",
            "This framework leverages a combination of quantization and low-rank approximation techniques applied to the initial pre-trained weights. This process results in an optimized initialization for Low-Rank Adaptation (LoRA) fine-tuning. \n",
            "\n",
            "Evaluations across a range of natural language processing tasks, including question answering and summarization, demonstrate that this method surpasses existing techniques, particularly in low-bit quantization scenarios. Notably, it maintains superior performance, especially in 2-bit quantization settings, without any degradation compared to other methods. \n",
            "\n",
            "=== LLM Response ===\n",
            "Both LoftQ and LongLoRA are designed to improve the efficiency and performance of Large Language Models (LLMs) by combining quantization and Low-Rank Adaptation (LoRA). \n",
            "\n",
            "LoftQ focuses on jointly optimizing quantized model weights and LoRA adapter initialization, leading to a better starting point for fine-tuning and addressing the performance gap often seen when combining standard quantization with LoRA. It excels in low-bit scenarios and achieves high compression ratios with minimal performance loss. \n",
            "\n",
            "LongLoRA, on the other hand, applies quantization and low-rank approximation to the initial pre-trained weights to optimize LoRA fine-tuning initialization. It demonstrates superior performance, particularly in low-bit quantization settings, especially 2-bit, without compromising performance.\n",
            "\n",
            "In essence, both methods leverage quantization and LoRA but differ in their application points and optimization targets. LoftQ focuses on joint optimization during quantization, while LongLoRA targets pre-trained weight optimization for enhanced LoRA initialization. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = agent.query(\n",
        "    \"Compare and contrast the LoRA papers (LongLoRA, LoftQ). \"\n",
        "    \"Analyze the approach in each paper first. \"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.-1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
