{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Initiate llama-index OCI client"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7356951c0a79f014"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from llama_index.llms.oci_genai import OCIGenAI\n",
    "\n",
    "llm = OCIGenAI(\n",
    "    model=\"cohere.command-r-plus\", # Switch to different models for testing\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.tenancy.oc1..aaaaaaaaumuuscymm6yb3wsbaicfx3mjhesghplvrvamvbypyehh5pgaasna\",\n",
    "    auth_type=\"SECURITY_TOKEN\",\n",
    "    auth_profile=\"BoatOc1\", # Please update here with your own profile name\n",
    "    additional_kwargs={\"max_tokens\": 300}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T23:44:52.244744Z",
     "start_time": "2024-11-04T23:44:51.082511Z"
    }
   },
   "id": "29f1ea43785173a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simple Chat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7df8b4644fcb1eb"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Arrrr, me heartie! Do ye want to hear a tale that'll make yer heart race and yer blood boil? \n",
      "\n",
      "Once upon a time, there was a fearsome pirate captain named Mad Morgan. She was known far and wide for her cunning and her skill with a cutlass. Her ship, the *Black Raven*, was a terror on the high seas, striking fear into the hearts of merchants and sailors alike. \n",
      "\n",
      "One day, Captain Morgan heard a tale that set her heart aflame. It was said that a legendary treasure, known as the *Golden Monkey*, was hidden on a remote island in the Caribbean. This treasure was said to be worth a king's ransom, and it was guarded by a host of deadly traps and curses. \n",
      "\n",
      "Captain Morgan was undeterred. She gathered her crew and set sail for the island, determined to claim the *Golden Monkey* for herself. As they drew closer to their destination, the seas grew rough and the sky turned an ominous shade of purple. It was clear that this quest would not be an easy one. \n",
      "\n",
      "The *Black Raven* dropped anchor off the coast of the island, and Captain Morgan led a small band of her most trusted crewmates ashore. They hacked their way through the dense jungle, fighting off poisonous snakes and swarms of bloodthirsty mosquitoes. Finally, they reached the ancient temple where the *Golden Monkey* was said to be hidden. \n",
      "\n",
      "The temple was filled with all\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n",
    "]\n",
    "response = llm.chat(messages)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T23:45:03.281392Z",
     "start_time": "2024-11-04T23:44:54.444032Z"
    }
   },
   "id": "bb2ab1f196c87f21"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 200, 'headers': {'content-type': 'application/json', 'opc-request-id': 'DECC0712EDC1440D9A9932C1A15B51DC/F47B6E48B5F73694D62A0D5E934B2000/99924C41E77B807AED7DF5D4BEFE4CC0', 'content-encoding': 'gzip', 'content-length': '912'}, 'data': {\n",
      "  \"chat_response\": {\n",
      "    \"api_format\": \"COHERE\",\n",
      "    \"chat_history\": [\n",
      "      {\n",
      "        \"message\": \"You are a pirate with a colorful personality\",\n",
      "        \"role\": \"SYSTEM\"\n",
      "      },\n",
      "      {\n",
      "        \"message\": \"Tell me a story\",\n",
      "        \"role\": \"USER\"\n",
      "      },\n",
      "      {\n",
      "        \"message\": \"Arrrr, me heartie! Do ye want to hear a tale that'll make yer heart race and yer blood boil? \\n\\nOnce upon a time, there was a fearsome pirate captain named Mad Morgan. She was known far and wide for her cunning and her skill with a cutlass. Her ship, the *Black Raven*, was a terror on the high seas, striking fear into the hearts of merchants and sailors alike. \\n\\nOne day, Captain Morgan heard a tale that set her heart aflame. It was said that a legendary treasure, known as the *Golden Monkey*, was hidden on a remote island in the Caribbean. This treasure was said to be worth a king's ransom, and it was guarded by a host of deadly traps and curses. \\n\\nCaptain Morgan was undeterred. She gathered her crew and set sail for the island, determined to claim the *Golden Monkey* for herself. As they drew closer to their destination, the seas grew rough and the sky turned an ominous shade of purple. It was clear that this quest would not be an easy one. \\n\\nThe *Black Raven* dropped anchor off the coast of the island, and Captain Morgan led a small band of her most trusted crewmates ashore. They hacked their way through the dense jungle, fighting off poisonous snakes and swarms of bloodthirsty mosquitoes. Finally, they reached the ancient temple where the *Golden Monkey* was said to be hidden. \\n\\nThe temple was filled with all\",\n",
      "        \"role\": \"CHATBOT\",\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    ],\n",
      "    \"citations\": null,\n",
      "    \"documents\": null,\n",
      "    \"error_message\": null,\n",
      "    \"finish_reason\": \"MAX_TOKENS\",\n",
      "    \"is_search_required\": null,\n",
      "    \"prompt\": null,\n",
      "    \"search_queries\": null,\n",
      "    \"text\": \"Arrrr, me heartie! Do ye want to hear a tale that'll make yer heart race and yer blood boil? \\n\\nOnce upon a time, there was a fearsome pirate captain named Mad Morgan. She was known far and wide for her cunning and her skill with a cutlass. Her ship, the *Black Raven*, was a terror on the high seas, striking fear into the hearts of merchants and sailors alike. \\n\\nOne day, Captain Morgan heard a tale that set her heart aflame. It was said that a legendary treasure, known as the *Golden Monkey*, was hidden on a remote island in the Caribbean. This treasure was said to be worth a king's ransom, and it was guarded by a host of deadly traps and curses. \\n\\nCaptain Morgan was undeterred. She gathered her crew and set sail for the island, determined to claim the *Golden Monkey* for herself. As they drew closer to their destination, the seas grew rough and the sky turned an ominous shade of purple. It was clear that this quest would not be an easy one. \\n\\nThe *Black Raven* dropped anchor off the coast of the island, and Captain Morgan led a small band of her most trusted crewmates ashore. They hacked their way through the dense jungle, fighting off poisonous snakes and swarms of bloodthirsty mosquitoes. Finally, they reached the ancient temple where the *Golden Monkey* was said to be hidden. \\n\\nThe temple was filled with all\",\n",
      "    \"tool_calls\": null\n",
      "  },\n",
      "  \"model_id\": \"cohere.command-r-plus\",\n",
      "  \"model_version\": \"1.2\"\n",
      "}, 'request': <oci.request.Request object at 0x1268f41f0>, 'next_page': None, 'request_id': 'DECC0712EDC1440D9A9932C1A15B51DC/F47B6E48B5F73694D62A0D5E934B2000/99924C41E77B807AED7DF5D4BEFE4CC0'}\n"
     ]
    }
   ],
   "source": [
    "print(response.raw)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T23:45:09.364475Z",
     "start_time": "2024-11-04T23:45:09.362173Z"
    }
   },
   "id": "2e03c8934545e7f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat Streaming"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c080eb754c4867c8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrr, me heartie! Do ye want to hear a tale that'll make yer heart race and yer blood boil? \n",
      "\n",
      "Once upon a time, there was a fearsome pirate captain named Redbeard. He sailed the seven seas with his loyal crew, searching for treasure and glory. One day, Redbeard heard a tale of a legendary island hidden far away in the uncharted waters of the Great Ocean. It was said that this island held a fortune in gold and jewels beyond imagination. \n",
      "\n",
      "Redbeard was determined to find this island and claim its riches for himself. He set sail at once, his heart full of adventure and his eyes gleaming with greed. The journey was long and treacherous, filled with storms and sea monsters, but Redbeard and his crew were undaunted. They battled their way through the perils of the sea, their spirits high and their swords at the ready. \n",
      "\n",
      "Finally, after months of sailing, they spotted the island looming on the horizon. It was a wild and rugged place, surrounded by treacherous reefs and towering cliffs. Redbeard ordered his crew to anchor the ship, and they rowed to shore with eager anticipation. As they explored the island, they found it was filled with mysterious caves and hidden coves. \n",
      "\n",
      "Redbeard and his men searched high and low for the treasure, their excitement growing with each passing moment. Then, in a hidden cave deep within the island, they found itâ€”a pile of gold and jewels"
     ]
    }
   ],
   "source": [
    "resp = llm.stream_chat(messages)\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T23:45:22.328108Z",
     "start_time": "2024-11-04T23:45:14.427163Z"
    }
   },
   "id": "ae769aecf046976a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat Chaining (Chat Prompt with a Template)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5a434473ee1c511"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do dogs make terrible dance partners? \n",
      "\n",
      "Because they have two left feet!\n"
     ]
    }
   ],
   "source": [
    "# Set up a chat prompt with a template\n",
    "prompt_text = \"Tell me a joke about {topic}\"\n",
    "formatted_prompt = prompt_text.format(topic=\"dogs\")\n",
    "\n",
    "# Send the prompt to OCIGenAI\n",
    "response = llm.chat([ChatMessage(role=\"user\", content=formatted_prompt)])\n",
    "print(response.message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T23:45:25.442033Z",
     "start_time": "2024-11-04T23:45:24.699752Z"
    }
   },
   "id": "c9c6522e7b03f161"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat with Documents \n",
    "\n",
    "* Note: supported in Cohere command models "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba78d178325ad6c8"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Oracle is a provider of database services and products. It offers customers high-performance and cost-optimized versions of Oracle Database, a converged, multi-model database management system. Oracle Autonomous Database is available on-premises via Oracle Cloud@Customer and in the Oracle Cloud Infrastructure.\n",
      "[{\n",
      "  \"document_ids\": [\n",
      "    \"doc_0\"\n",
      "  ],\n",
      "  \"end\": 55,\n",
      "  \"start\": 12,\n",
      "  \"text\": \"provider of database services and products.\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"doc_0\"\n",
      "  ],\n",
      "  \"end\": 120,\n",
      "  \"start\": 76,\n",
      "  \"text\": \"high-performance and cost-optimized versions\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"doc_0\"\n",
      "  ],\n",
      "  \"end\": 139,\n",
      "  \"start\": 124,\n",
      "  \"text\": \"Oracle Database\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"doc_0\"\n",
      "  ],\n",
      "  \"end\": 193,\n",
      "  \"start\": 143,\n",
      "  \"text\": \"converged, multi-model database management system.\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"doc_0\"\n",
      "  ],\n",
      "  \"end\": 220,\n",
      "  \"start\": 194,\n",
      "  \"text\": \"Oracle Autonomous Database\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"doc_0\"\n",
      "  ],\n",
      "  \"end\": 271,\n",
      "  \"start\": 234,\n",
      "  \"text\": \"on-premises via Oracle Cloud@Customer\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"doc_0\"\n",
      "  ],\n",
      "  \"end\": 311,\n",
      "  \"start\": 283,\n",
      "  \"text\": \"Oracle Cloud Infrastructure.\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "documents = [\n",
    "    {\n",
    "        \"title\": \"Oracle\",\n",
    "        \"snippet\": \"Oracle database services and products offer customers cost-optimized and high-performance versions of Oracle Database, the world's leading converged, multi-model database management system, as well as in-memory, NoSQL and MySQL databases. Oracle Autonomous Database, available on premises via Oracle Cloud@Customer or in the Oracle Cloud Infrastructure, enables customers to simplify relational database environments and reduce management workloads.\",\n",
    "        \"website\": \"https://www.oracle.com/database\"\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=\"You are an AI assistant.\"),\n",
    "    ChatMessage(role=MessageRole.USER, content=\"Tell me something about Oracle.\"),\n",
    "    ChatMessage(role=MessageRole.ASSISTANT, content=\"Oracle is a leading provider of database solutions.\"),\n",
    "]\n",
    "\n",
    "response = llm.chat(messages=messages, documents=documents)\n",
    "print(response)\n",
    "print(response.message.additional_kwargs['citations'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T00:10:15.823805Z",
     "start_time": "2024-11-05T00:10:10.758936Z"
    }
   },
   "id": "965dc2c77d334287"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic tool calling in llamaindex \n",
    "\n",
    "only Cohere supports tool calling for now"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "682c1e174c6ca7a6"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: I will use the multiply tool to calculate 3 * 12 and the add tool to calculate 11 + 49.\n",
      "[{'toolUseId': 'd28117f35b374389a343d103f22feef4', 'name': 'multiply', 'input': '{\"a\": 12, \"b\": 3}'}, {'toolUseId': '45a73237c2f642d8bdf3921155731840', 'name': 'add', 'input': '{\"a\": 11, \"b\": 49}'}]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Addition function on two integers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "response = llm.chat_with_tools(\n",
    "    tools=[add_tool, multiply_tool],\n",
    "    user_msg=\"What is 3 * 12? Also, what is 11 + 49?\",\n",
    ")\n",
    "\n",
    "print(response)\n",
    "tool_calls = response.message.additional_kwargs.get('tool_calls', [])\n",
    "print(tool_calls)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T00:14:37.008301Z",
     "start_time": "2024-11-05T00:14:33.634005Z"
    }
   },
   "id": "4ac5510e464e4e80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat streaming with tools"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "125cba17b0d7ff32"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: I\n",
      "Content: I will\n",
      "Content: I will use\n",
      "Content: I will use the\n",
      "Content: I will use the multiply\n",
      "Content: I will use the multiply tool\n",
      "Content: I will use the multiply tool to\n",
      "Content: I will use the multiply tool to find\n",
      "Content: I will use the multiply tool to find the\n",
      "Content: I will use the multiply tool to find the answer\n",
      "Content: I will use the multiply tool to find the answer to\n",
      "Content: I will use the multiply tool to find the answer to the\n",
      "Content: I will use the multiply tool to find the answer to the user\n",
      "Content: I will use the multiply tool to find the answer to the user's\n",
      "Content: I will use the multiply tool to find the answer to the user's request\n",
      "Content: I will use the multiply tool to find the answer to the user's request.\n",
      "Content: I will use the multiply tool to find the answer to the user's request.I will use the multiply tool to find the answer to the user's request.\n",
      "Tool Calls: [{'toolUseId': '5caab4e07bd14a47826aab681f53a8be', 'name': 'multiply', 'input': '{\"a\": 23, \"b\": 45}'}]\n",
      "Content: I will use the multiply tool to find the answer to the user's request.I will use the multiply tool to find the answer to the user's request.\n",
      "Tool Calls: [{'toolUseId': '9b6ed77c533d42d6b96b39f2dd9a8403', 'name': 'multiply', 'input': '{\"a\": 23, \"b\": 45}'}]\n"
     ]
    }
   ],
   "source": [
    "# Use streaming with tools\n",
    "gen = llm.stream_chat_with_tools(\n",
    "    tools=[multiply_tool, add_tool],\n",
    "    user_msg=\"What is 23 * 45?\",\n",
    ")\n",
    "\n",
    "# Process the stream\n",
    "try:\n",
    "    for response in gen:\n",
    "        # Print content as it arrives\n",
    "        if response.message.content:\n",
    "            print(f\"Content: {response.message.content}\")\n",
    "\n",
    "        # Check for tool calls\n",
    "        if \"tool_calls\" in response.message.additional_kwargs:\n",
    "            tool_calls = response.message.additional_kwargs[\"tool_calls\"]\n",
    "            print(f\"Tool Calls: {tool_calls}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in stream processing: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T00:15:19.311221Z",
     "start_time": "2024-11-05T00:15:17.170237Z"
    }
   },
   "id": "6b865f544a43b6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Invoking tools and passing tool outputs back to model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2daf408eebe8f866"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will use the multiply and add tools to answer this question.\n",
      "assistant: 3 * 12 = **36** and 11 + 49 = **60**.\n"
     ]
    }
   ],
   "source": [
    "# Initial user query\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "user_message = ChatMessage(role=MessageRole.USER, content=query)\n",
    "\n",
    "# Pass initial message to the LLM with tool calling enabled\n",
    "response = llm.chat_with_tools(tools=[add_tool, multiply_tool], user_msg=user_message.content)\n",
    "print(response.message.content)  # Initial assistant response about using tools\n",
    "\n",
    "# Extract tool calls and invoke each tool based on the response\n",
    "messages = [user_message, response.message]  # Start with user message and initial assistant response\n",
    "\n",
    "for tool_call in response.message.additional_kwargs.get(\"tool_calls\", []):\n",
    "    # Select the tool based on the tool call name\n",
    "    selected_tool = {\"add\": add_tool, \"multiply\": multiply_tool}[tool_call[\"name\"].lower()]\n",
    "    tool_input = eval(tool_call[\"input\"])  # Convert input JSON string to dict\n",
    "    tool_output = selected_tool(**tool_input)  # Invoke tool\n",
    "\n",
    "    # Add the tool's output as a new message in the conversation\n",
    "    tool_output_message = ChatMessage(\n",
    "        role=MessageRole.TOOL,\n",
    "        content=str(tool_output),  # Format tool output as string\n",
    "        additional_kwargs={\"tool_call_id\": tool_call.get(\"toolUseId\")}\n",
    "    )\n",
    "    messages.append(tool_output_message)\n",
    "\n",
    "# Pass the messages back to the LLM for a final response using the tool outputs\n",
    "final_response = llm.chat(messages)\n",
    "print(final_response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T00:27:27.662615Z",
     "start_time": "2024-11-05T00:27:20.407071Z"
    }
   },
   "id": "9e9c1d54094babdc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Few-shot tool prompting & basic agent-like tool looping"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cec514e673f6897a"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will use the multiply tool to multiply 119 and 7, then use the add tool to add 30 to the result.\n",
      "119 x 7 = 833. I will now add 30 to this number.\n",
      "The answer is: 863\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Define initial few-shot messages\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=\"What's the product of 317253 and 128472 plus four\"\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.ASSISTANT,\n",
    "        content=\"\",\n",
    "        additional_kwargs={\n",
    "            \"tool_calls\": [{\"name\": \"multiply\", \"input\": {\"x\": 317253, \"y\": 128472}, \"toolUseId\": \"1\"}]\n",
    "        }\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.TOOL,\n",
    "        content=\"16505054784\",\n",
    "        additional_kwargs={\"tool_call_id\": \"1\"}\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.ASSISTANT,\n",
    "        content=\"\",\n",
    "        additional_kwargs={\n",
    "            \"tool_calls\": [{\"name\": \"add\", \"input\": {\"x\": 16505054784, \"y\": 4}, \"toolUseId\": \"2\"}]\n",
    "        }\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.TOOL,\n",
    "        content=\"16505054788\",\n",
    "        additional_kwargs={\"tool_call_id\": \"2\"}\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.ASSISTANT,\n",
    "        content=\"The product of 317253 and 128472 plus four is 16505054788\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Define the query\n",
    "query = \"Whats 119 times 7 plus 30. Don't do any math yourself, only use tools for math. Respect order of operations. when you have the answer output 'the answer is: <answer>'\"\n",
    "messages.append(ChatMessage(role=MessageRole.USER, content=query))\n",
    "\n",
    "# Start agent-like tool looping\n",
    "while True:\n",
    "    ai_response = llm.chat_with_tools(messages=messages, tools=[multiply_tool, add_tool])\n",
    "    print(ai_response.message.content)\n",
    "\n",
    "    if \"the answer is:\" in ai_response.message.content.lower():\n",
    "        break\n",
    "\n",
    "    messages.append(ai_response.message)\n",
    "\n",
    "    # Execute tools based on tool calls and append tool responses\n",
    "    if ai_response.message.additional_kwargs.get(\"tool_calls\"):\n",
    "        for tool_call in ai_response.message.additional_kwargs[\"tool_calls\"]:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_input = tool_call[\"input\"]\n",
    "\n",
    "            # If tool_input is a string, parse it as JSON\n",
    "            if isinstance(tool_input, str):\n",
    "                tool_input = json.loads(tool_input)\n",
    "\n",
    "            # Select tool and invoke it\n",
    "            if tool_name == \"multiply\":\n",
    "                result = multiply(**tool_input)\n",
    "            elif tool_name == \"add\":\n",
    "                result = add(**tool_input)\n",
    "\n",
    "            # Append the tool result as a tool message\n",
    "            messages.append(\n",
    "                ChatMessage(\n",
    "                    role=MessageRole.TOOL,\n",
    "                    content=str(result),\n",
    "                    additional_kwargs={\"tool_call_id\": tool_call[\"toolUseId\"]}\n",
    "                )\n",
    "            )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T00:29:54.622612Z",
     "start_time": "2024-11-05T00:29:47.696059Z"
    }
   },
   "id": "4b9a59c4a783c025"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a llama-index agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c245da335beb23f"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 51daca26-1dc3-40a5-ba0d-ce9dbdee7074. Step input: Whats 119 times 7 plus 30. Don't do any math yourself, only use tools for math. Respect order of operations.\n",
      "\u001B[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: multiply\n",
      "Action Input: {'a': 119, 'b': 7}\n",
      "\u001B[0m\u001B[1;3;34mObservation: 833\n",
      "\u001B[0m> Running step 36e440fa-27b6-4c95-b0e2-dc3a0e1d6d00. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The answer is **863**.\n",
      "\u001B[0mThe answer is **863**.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Set the LLM in the global settings\n",
    "# Settings.llm = llm\n",
    "\n",
    "# # Define your tools\n",
    "# def multiply(a: int, b: int) -> int:\n",
    "#     \"\"\"Multiply two integers and return the result.\"\"\"\n",
    "#     return a * b\n",
    "# \n",
    "# def add(a: int, b: int) -> int:\n",
    "#     \"\"\"Add two integers and return the result.\"\"\"\n",
    "#     return a + b\n",
    "# \n",
    "# # Create FunctionTool instances\n",
    "# multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "# add_tool = FunctionTool.from_defaults(fn=add)\n",
    "# tools = [multiply_tool, add_tool]\n",
    "\n",
    "# Create the ReActAgent\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[multiply_tool, add_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "response = agent.chat(\n",
    "    \"Whats 119 times 7 plus 30. Don't do any math yourself, only use tools for math. Respect order of operations.\"\n",
    ")\n",
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T00:31:29.851456Z",
     "start_time": "2024-11-05T00:31:24.431071Z"
    }
   },
   "id": "6b4e7d9c12f15c00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "967734e1f7aec641"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
