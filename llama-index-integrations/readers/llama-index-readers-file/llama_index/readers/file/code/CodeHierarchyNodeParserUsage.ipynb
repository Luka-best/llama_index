{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Hierarchy Node Parser\n",
    "\n",
    "The `CodeHierarchyNodeParser` is useful to split long code files into more reasonable chunks. What this will do is create a \"Hierarchy\" of sorts, where sections of the code are made more reasonable by replacing the scope body with short comments telling the LLM to search for a referenced node if it wants to read that context body. This is called skeletonization, and is toggled by setting `skeleton` to `True` which it is by default. Nodes in this hierarchy will be split based on scope, like function, class, or method scope, and will have links to their children and parents so the LLM can traverse the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Import\n",
    "\n",
    "First be sure to install the necessary [tree-sitter](https://tree-sitter.github.io/tree-sitter/) libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tree-sitter in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (0.20.2)\n",
      "Requirement already satisfied: tree-sitter-languages in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (1.10.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tree-sitter tree-sitter-languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1m/43h2nghx5sn30cnmx7xwxnfw0000gp/T/ipykernel_57021/2227626717.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) download_loader. (`download_loader()` is deprecated. Please install tool using pip install directly instead.)\n",
      "  CodeHierarchyNodeParser = download_loader(\"CodeHierarchyNodeParser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-file in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-readers-file) (4.0.1)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-readers-file) (1.23.22)\n",
      "Requirement already satisfied: tree-sitter==0.20.2 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-readers-file) (0.20.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-readers-file) (0.0.2)\n",
      "Requirement already satisfied: tree-sitter-languages<2.0.0,>=1.8.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-readers-file) (1.10.2)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-readers-file) (0.10.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.5)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.11.1)\n",
      "Requirement already satisfied: dataclasses-json in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.5.14)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.66.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.8.1)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.2.14)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.8.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.8.6)\n",
      "Requirement already satisfied: httpx in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.26.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.5.1)\n",
      "Requirement already satisfied: numpy in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.26.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.31.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.2.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (6.0.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (8.2.3)\n",
      "Requirement already satisfied: pandas in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.1.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.9.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.8)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.0.22)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (10.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.5.8)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file) (1.23.22)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (23.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.4.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.15.0)\n",
      "Requirement already satisfied: joblib in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.10.3)\n",
      "Requirement already satisfied: click in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (8.1.7)\n",
      "Requirement already satisfied: sniffio in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.4.2)\n",
      "Requirement already satisfied: certifi in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.14.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.20.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.8.2)\n",
      "Requirement already satisfied: exceptiongroup in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.1.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (23.2)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ryan.peach/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to import CodeHierarchyNodeParser",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama-index-core/llama_index/core/download/integration.py:21\u001b[0m, in \u001b[0;36mdownload_integration\u001b[0;34m(module_str, module_import_str, cls_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrom \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_import_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m import \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcls_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     module_spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mfind_spec(module_import_str)\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/__init__.py:19\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XMLReader\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeHierarchyNodeParser, CodeHierarchyKeywordQueryEngine\n\u001b[1;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocxReader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHWPReader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeHierarchyKeywordQueryEngine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/code/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_hierarchy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeHierarchyNodeParser\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeHierarchyKeywordQueryEngine\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeHierarchyNodeParser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeHierarchyKeywordQueryEngine\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama-index-integrations/readers/llama-index-readers-file/llama_index/readers/file/code/index.py:4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain_helpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaIndexTool\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomQueryEngine\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama-index-core/llama_index/core/langchain_helpers/agents/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Llama integration with Langchain agents.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain_helpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     create_llama_agent,\n\u001b[1;32m      5\u001b[0m     create_llama_chat_agent,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain_helpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoolkits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaToolkit\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama-index-core/llama_index/core/langchain_helpers/agents/agents.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Optional\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbridge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     AgentExecutor,\n\u001b[1;32m      7\u001b[0m     AgentType,\n\u001b[1;32m      8\u001b[0m     BaseCallbackManager,\n\u001b[1;32m      9\u001b[0m     BaseLLM,\n\u001b[1;32m     10\u001b[0m     initialize_agent,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain_helpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoolkits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaToolkit\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama-index-core/llama_index/core/bridge/langchain.py:50\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTool, StructuredTool, Tool\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatAnyscale, ChatOpenAI\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     52\u001b[0m     HuggingFaceBgeEmbeddings,\n\u001b[1;32m     53\u001b[0m     HuggingFaceEmbeddings,\n\u001b[1;32m     54\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader, download_loader\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 4\u001b[0m CodeHierarchyNodeParser \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCodeHierarchyNodeParser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/llama_index2/lib/python3.10/site-packages/deprecated/classic.py:285\u001b[0m, in \u001b[0;36mdeprecated.<locals>.wrapper_function\u001b[0;34m(wrapped_, instance_, args_, kwargs_)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, category\u001b[38;5;241m=\u001b[39mcategory, stacklevel\u001b[38;5;241m=\u001b[39m_routine_stacklevel)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama-index-core/llama_index/core/readers/download.py:67\u001b[0m, in \u001b[0;36mdownload_loader\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find python package for class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloader_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m reader_cls \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_integration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_install_parent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_import_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_import_parent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcls_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(reader_cls, BaseReader):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoader class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloader_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be a subclass of BaseReader.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/OnScale/llama_index/llama-index-core/llama_index/core/download/integration.py:27\u001b[0m, in \u001b[0;36mdownload_integration\u001b[0;34m(module_str, module_import_str, cls_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m     pack_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, cls_name)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_cls\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import CodeHierarchyNodeParser"
     ]
    }
   ],
   "source": [
    "from llama_index.core.text_splitter import CodeSplitter\n",
    "from llama_index.core import SimpleDirectoryReader, download_loader\n",
    "from pathlib import Path\n",
    "\n",
    "CodeHierarchyNodeParser = download_loader(\"CodeHierarchyNodeParser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def print_python(python_text):\n",
    "    \"\"\"This function prints python text in ipynb nicely formatted.\"\"\"\n",
    "    display(Markdown(\"```python\\n\" + python_text + \"```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a directory you want to scan, and glob for all the code files you want to import.\n",
    "\n",
    "In this case I'm going to glob all \"*.py\" files in the `llama_index/node_parser` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\n",
    "    input_files=[Path(\"./code_hierarchy.py\")],\n",
    "    file_metadata=lambda x: {\"filepath\": x},\n",
    ")\n",
    "nodes = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be the code hierarchy node parser itself. Lets have it parse itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 33247\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    \"\"\"\n",
       "    Unfortunately some languages need special options for how to make a signature.\n",
       "\n",
       "    For example, html element signatures should include their closing >, there is no\n",
       "    easy way to include this using an always-exclusive system.\n",
       "\n",
       "    However, using an always-inclusive system, python decorators don't work,\n",
       "    as there isn't an easy to define terminator for decorators that is inclusive\n",
       "    to their signature.\n",
       "    \"\"\"\n",
       "\n",
       "    type: str = Field(description=\"The type string to match on.\")\n",
       "    inclusive: bool = Field(\n",
       "        description=(\n",
       "            \"Whether to include the text of the node matched by this type or not.\"\n",
       "        ),\n",
       "    )\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    start_signature_types: Optional[List[_SignatureCaptureType]] = Field(\n",
       "\n",
       "# ...```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Length of text: {len(nodes[0].text)}\")\n",
    "print_python(nodes[0].text[:1500] + \"\\n\\n# ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is way too long to fit into the context of our LLM. So what are we to do? Well we will split it. We are going to use the `CodeHierarchyNodeParser` to split the nodes into more reasonable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes after splitting: 87\n"
     ]
    }
   ],
   "source": [
    "split_nodes = CodeHierarchyNodeParser(\n",
    "    language=\"python\",\n",
    "    # You can further parameterize the CodeSplitter to split the code\n",
    "    # into \"chunks\" that match your context window size using\n",
    "    # chunck_lines and max_chars parameters, here we just use the defaults\n",
    "    code_splitter=CodeSplitter(language=\"python\", max_chars=1000, chunk_lines=10),\n",
    ").get_nodes_from_documents(nodes)\n",
    "print(\"Number of nodes after splitting:\", len(split_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So that split up our data from 1 node into 86 nodes! Whats the max length of any of these nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest text in nodes: 1160\n"
     ]
    }
   ],
   "source": [
    "print(f\"Longest text in nodes: {max(len(n.text) for n in split_nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much shorter than before! Let's look at a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    # Code replaced for brevity. See node_id 9fc27450-8dd7-4459-a67b-d35266d949be\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    # Code replaced for brevity. See node_id d79396a6-bc83-4115-a748-37173ac792c2\n",
       "    # Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(split_nodes[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without even needing a long printout we can see everything this module imported in the first document (which is at the module level) and some classes it defines.\n",
    "\n",
    "We also see that it has put comments in place of code that was removed to make the text size more reasonable.\n",
    "These can appear at the beginning or end of a chunk, or at a new scope level, like a class or function declaration.\n",
    "\n",
    "`# Code replaced for brevity. See node_id {node_id}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Hierarchy\n",
    "\n",
    "These scopes can be listed by the `CodeHierarchyNodeParser`, giving a \"repo map\" of sorts.\n",
    "The namesake of this node parser, it creates a tree of scope names to use to search the code.\n",
    "Put this in your context to give the LLM a default search hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruct an LLM using the KeywordQueryEngine (shown later) as a tool to:\n",
    "\n",
    "```\n",
    "\"Search the tool by any element in this list, or any uuid found in the resulting code, to get more information about that element.\"\n",
    "```\n",
    "\n",
    "Then append this to your context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- code_hierarchy\n",
      "  - _SignatureCaptureType\n",
      "  - _SignatureCaptureOptions\n",
      "  - _ScopeMethod\n",
      "  - _CommentOptions\n",
      "  - _ScopeItem\n",
      "  - _ChunkNodeOutput\n",
      "  - CodeHierarchyNodeParser\n",
      "    - class_name\n",
      "    - __init__\n",
      "    - _get_node_name\n",
      "      - recur\n",
      "    - _get_node_signature\n",
      "      - find_start\n",
      "      - find_end\n",
      "    - _chunk_node\n",
      "    - get_code_hierarchy_from_nodes\n",
      "      - get_subdict\n",
      "      - recur_inclusive_scope\n",
      "      - dict_to_markdown\n",
      "    - _parse_nodes\n",
      "    - _get_indentation\n",
      "    - _get_comment_text\n",
      "    - _create_comment_line\n",
      "    - _get_replacement_text\n",
      "    - _skeletonize\n",
      "    - _skeletonize_list\n",
      "      - recur\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(CodeHierarchyNodeParser.get_code_hierarchy_from_nodes(split_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration by the Programmer\n",
    "\n",
    "So that we understand what is going on under the hood, what if we go to that node_id we found above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to print the node with UUID: 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 1165ccf1-7954-4350-847e-8677ae49a5a0\n",
       "\"\"\"\n",
       "Maps language -> Node Type -> SignatureCaptureOptions\n",
       "\n",
       "The best way for a developer to discover these is to put a breakpoint at the TIP\n",
       "tag in _chunk_node, and then create a unit test for some code, and then iterate\n",
       "through the code discovering the node names.\n",
       "\"\"\"\n",
       "    # Code replaced for brevity. See node_id 13c351a9-fa3c-4d91-8e4a-bfde2b7d4f6c```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_nodes_by_id = {n.node_id: n for n in split_nodes}\n",
    "uuid_from_text = split_nodes[0].text.splitlines()[-1].split(\" \")[-1]\n",
    "print(\"Going to print the node with UUID:\", uuid_from_text)\n",
    "print_python(split_nodes_by_id[uuid_from_text].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the next split in the file. It is prepended with the node before it and appended with the node after it as a comment.\n",
    "\n",
    "We can also see the relationships on this node programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 1165ccf1-7954-4350-847e-8677ae49a5a0\n",
       "\"\"\"\n",
       "Maps language -> Node Type -> SignatureCaptureOptions\n",
       "\n",
       "The best way for a developer to discover these is to put a breakpoint at the TIP\n",
       "tag in _chunk_node, and then create a unit test for some code, and then iterate\n",
       "through the code discovering the node names.\n",
       "\"\"\"\n",
       "    # Code replaced for brevity. See node_id 13c351a9-fa3c-4d91-8e4a-bfde2b7d4f6c```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(split_nodes_by_id[uuid_from_text].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NEXT` `PREV` relationships come from the `CodeSplitter` which is a component of the `CodeHierarchyNodeParser`. It is responsible for cutting up the nodes into chunks that are a certain character length. For more information about the `CodeSplitter` read this:\n",
    "\n",
    "[Code Splitter](https://docs.llamaindex.ai/en/latest/api/llama_index.node_parser.CodeSplitter.html)\n",
    "\n",
    "The `PARENT` and `CHILD` relationships come from the `CodeHierarchyNodeParser` which is responsible for creating the hierarchy of nodes. Things like classes, functions, and methods are nodes in this hierarchy.\n",
    "\n",
    "The `SOURCE` is the original file that this node came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311\n",
       "_DEFAULT_SIGNATURE_IDENTIFIERS: Dict[str, Dict[str, _SignatureCaptureOptions]] =\n",
       "    # Code replaced for brevity. See node_id 04a96f73-8399-4ec6-8db7-ae18cd18127d```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.schema import NodeRelationship\n",
    "\n",
    "node_id = uuid_from_text\n",
    "if NodeRelationship.NEXT not in split_nodes_by_id[node_id].relationships:\n",
    "    print(\"No next node found!\")\n",
    "else:\n",
    "    next_node_relationship_info = split_nodes_by_id[node_id].relationships[\n",
    "        NodeRelationship.NEXT\n",
    "    ]\n",
    "    next_node = split_nodes_by_id[next_node_relationship_info.node_id]\n",
    "    print_python(next_node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Table and Usage by the LLM\n",
    "\n",
    "Lets explore the use of this node parser in an index. We will be able to use any index which allows search by keyword, which should enable us to search for any node by it's uuid, or by any scope name.\n",
    "\n",
    "We have created a `CodeHierarchyKeywordQueryEngine` which will allow us to search for nodes by their uuid, or by their scope name. It's `.query` method can be used as a simple search tool for any LLM. Given the repo map we created earlier, or the text of a split file, the LLM should be able to figure out what to search for very naturally.\n",
    "\n",
    "Lets create the KeywordQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index import CodeHierarchyKeywordQueryEngine\n",
    "\n",
    "idx = CodeHierarchyKeywordQueryEngine(\n",
    "    nodes=split_nodes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the same code as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    # Code replaced for brevity. See node_id 9fc27450-8dd7-4459-a67b-d35266d949be\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    # Code replaced for brevity. See node_id d79396a6-bc83-4115-a748-37173ac792c2\n",
       "    # Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(idx.query(split_nodes[0].node_id).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we can also search for any node by it's common sense name.\n",
    "\n",
    "For example, the class `_SignatureCaptureOptions` is a node in the hierarchy. We can search for it by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    \"\"\"\n",
       "    Unfortunately some languages need special options for how to make a signature.\n",
       "\n",
       "    For example, html element signatures should include their closing >, there is no\n",
       "    easy way to include this using an always-exclusive system.\n",
       "\n",
       "    However, using an always-inclusive system, python decorators don't work,\n",
       "    as there isn't an easy to define terminator for decorators that is inclusive\n",
       "    to their signature.\n",
       "    \"\"\"\n",
       "\n",
       "    type: str = Field(description=\"The type string to match on.\")\n",
       "    inclusive: bool = Field(\n",
       "        description=(\n",
       "            \"Whether to include the text of the node matched by this type or not.\"\n",
       "        ),\n",
       "    )```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(idx.query(\"_SignatureCaptureType\").response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by module name, in case the LLM sees something in an import statement and wants to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    # Code replaced for brevity. See node_id 9fc27450-8dd7-4459-a67b-d35266d949be\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    # Code replaced for brevity. See node_id d79396a6-bc83-4115-a748-37173ac792c2\n",
       "    # Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(idx.query(\"code_hierarchy\").response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As a Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the langchain tool, just use `as_langchain_tool` on the `CodeHierarchyKeywordQueryEngine` and it will be ready to use in the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from collections import defaultdict\n",
       "from enum import Enum\n",
       "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
       "\n",
       "from llama_index.extractors.metadata_extractors import BaseExtractor\n",
       "from llama_index.node_parser.interface import NodeParser\n",
       "\n",
       "try:\n",
       "    from pydantic.v1 import BaseModel, Field\n",
       "except ImportError:\n",
       "    from pydantic import BaseModel, Field\n",
       "\n",
       "\n",
       "from tree_sitter import Node\n",
       "\n",
       "from llama_index.callbacks.base import CallbackManager\n",
       "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
       "from llama_index.schema import BaseNode, Document, NodeRelationship, TextNode\n",
       "from llama_index.text_splitter import CodeSplitter\n",
       "from llama_index.utils import get_tqdm_iterable\n",
       "\n",
       "\n",
       "class _SignatureCaptureType(BaseModel):\n",
       "    # Code replaced for brevity. See node_id 9fc27450-8dd7-4459-a67b-d35266d949be\n",
       "\n",
       "\n",
       "class _SignatureCaptureOptions(BaseModel):\n",
       "    # Code replaced for brevity. See node_id d79396a6-bc83-4115-a748-37173ac792c2\n",
       "    # Code replaced for brevity. See node_id 1bccb6a2-cb81-4dd8-b2ca-60de94fb4311```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_python(idx.as_langchain_tool().run(\"code_hierarchy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description for your LLM to read to learn the tool is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Code Search\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Description: \n",
       "        Search the tool by any element in this list,\n",
       "        or any uuid found in the code,\n",
       "        to get more information about that element.\n",
       "\n",
       "        - code_hierarchy\n",
       "  - _SignatureCaptureType\n",
       "  - _SignatureCaptureOptions\n",
       "  - _ScopeMethod\n",
       "  - _CommentOptions\n",
       "  - _ScopeItem\n",
       "  - _ChunkNodeOutput\n",
       "  - CodeHierarchyNodeParser\n",
       "    - class_name\n",
       "    - __init__\n",
       "    - _get_node_name\n",
       "      - recur\n",
       "    - _get_node_signature\n",
       "      - find_start\n",
       "      - find_end\n",
       "    - _chunk_node\n",
       "    - get_code_hierarchy_from_nodes\n",
       "      - get_subdict\n",
       "      - recur_inclusive_scope\n",
       "      - dict_to_markdown\n",
       "    - _parse_nodes\n",
       "    - _get_indentation\n",
       "    - _get_comment_text\n",
       "    - _create_comment_line\n",
       "    - _get_replacement_text\n",
       "    - _skeletonize\n",
       "    - _skeletonize_list\n",
       "      - recur\n",
       "\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Name: \" + idx.as_langchain_tool().name)\n",
    "display(Markdown(\"Description: \" + idx.as_langchain_tool().description))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
