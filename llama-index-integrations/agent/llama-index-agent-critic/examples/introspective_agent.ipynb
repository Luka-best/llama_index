{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4bc789c-41f0-4f0b-b1ef-17e9bb180132",
   "metadata": {},
   "source": [
    "### Build `PerspectiveTool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bad33-e2d9-4b79-84d1-ffa82683f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-api-python-client -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a00dd-17bb-4227-90ca-d544cbd16c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from typing import Dict, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class Perspective:\n",
    "    \"\"\"Custom class to interact with Perspective API.\"\"\"\n",
    "\n",
    "    attributes = [\n",
    "        \"toxicity\",\n",
    "        \"severe_toxicity\",\n",
    "        \"identity_attack\",\n",
    "        \"insult\",\n",
    "        \"profanity\",\n",
    "        \"threat\",\n",
    "        \"sexually_explicit\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, api_key: Optional[str] = None) -> None:\n",
    "        if api_key is None:\n",
    "            try:\n",
    "                api_key = os.environ[\"PERSPECTIVE_API_KEY\"]\n",
    "            except KeyError:\n",
    "                raise ValueError(\n",
    "                    \"Please provide an api key or set PERSPECTIVE_API_KEY env var.\"\n",
    "                )\n",
    "\n",
    "        self._client = discovery.build(\n",
    "            \"commentanalyzer\",\n",
    "            \"v1alpha1\",\n",
    "            developerKey=api_key,\n",
    "            discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "            static_discovery=False,\n",
    "        )\n",
    "\n",
    "    def get_toxicity_scores(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Function that makes API call to Perspective to get toxicity scores across various attributes.\"\"\"\n",
    "\n",
    "        analyze_request = {\n",
    "            \"comment\": {\"text\": text},\n",
    "            \"requestedAttributes\": {att.upper(): {} for att in self.attributes},\n",
    "        }\n",
    "\n",
    "        response = self._client.comments().analyze(body=analyze_request).execute()\n",
    "        try:\n",
    "            return {\n",
    "                att: response[\"attributeScores\"][att.upper()][\"summaryScore\"][\"value\"]\n",
    "                for att in self.attributes\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Unable to parse response\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2dd4f-e7f2-496f-b7d1-acbcd89959d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = Perspective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c1518-153a-4e2d-8620-241d1a547fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from llama_index.core.bridge.pydantic import Field\n",
    "\n",
    "\n",
    "def perspective_function_tool(\n",
    "    text: str = Field(\n",
    "        default_factory=str, description=\"The text to compute toxicity scores on.\"\n",
    "    )\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"Returns the toxicity score of the most problematic toxic attribute.\"\"\"\n",
    "\n",
    "    scores = perspective.get_toxicity_scores(text=text)\n",
    "    max_key = max(scores, key=scores.get)\n",
    "    return (max_key, scores[max_key] * 100)\n",
    "\n",
    "\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "pespective_tool = FunctionTool.from_defaults(\n",
    "    perspective_function_tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f45fde-25bc-4fae-bd24-791cccd58152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toxicity', 2.5438840000000003)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspective_function_tool(text=\"friendly greetings from python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5abb0a-f119-4c98-8a62-96465d21a200",
   "metadata": {},
   "source": [
    "## Build `InstrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58b3ad-1ac9-46b4-9898-21680bb4d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.core.agent.introspective.step import IntrospectiveAgentWorker\n",
    "from llama_index.core.agent.function_calling.step import FunctionCallingAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29556682-8b0c-4f48-b5d8-a4f493efe5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84d8d6-3f53-4057-b29a-a8c1c4af029b",
   "metadata": {},
   "source": [
    "### Define `IntrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485dd56-2989-483e-bb51-59f156cab894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.agent.openai import OpenAIAgentWorker\n",
    "\n",
    "main_worker = OpenAIAgentWorker.from_tools(\n",
    "    tools=[], llm=OpenAI(\"gpt-4-turbo-preview\"), verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10128db6-967f-4128-9ff1-be489474814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.critic import CriticAgentWorker\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "\n",
    "critiquer = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[pespective_tool], llm=OpenAI(\"gpt-3.5-turbo\")\n",
    ")\n",
    "\n",
    "critic = CriticAgentWorker.from_args(\n",
    "    critique_agent_worker=critiquer,\n",
    "    critique_template=\"Please provide a toxicity critique for the following text:\\n {input_str}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daa3d1-075c-4740-ac03-efe077f2151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "introspective_agent = IntrospectiveAgentWorker.from_args(\n",
    "    main_agent_worker=main_worker,\n",
    "    reflective_agent_worker=critic,\n",
    ").as_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a83094-2dd9-4d83-8f3c-c1613fcb9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Please provide a more safe version of the following text: you can barely see the vulva. I tend to holder her hands and wait for\n",
      "MAIN AGENT MEMORY: token_limit=3000 tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all') chat_store=SimpleChatStore(store={'chat_history': [ChatMessage(role=<MessageRole.USER: 'user'>, content='Please provide a more safe version of the following text: you can barely see the vulva. I tend to holder her hands and wait for', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='You can barely see. I tend to hold her hands and wait.', additional_kwargs={})]}) chat_store_key='chat_history'\n",
      "> Running step 7b31ec10-e3c8-45a0-9295-68b6cd356921. Step input: Please provide a toxicity critique for the following text:\n",
      " You can barely see. I tend to hold her hands and wait.\n",
      "> Running step 16f82b18-9b3b-4f9e-b3aa-9df2b83e7ebe. Step input: None\n",
      "Critique: assistant: The toxicity score for the text \"You can barely see. I tend to hold her hands and wait.\" is 3.29, indicating a moderate level of toxicity.\n",
      "CRITIQUE SOURCES: [ToolOutput(content=\"('toxicity', 3.2863233)\", tool_name='perspective_function_tool', raw_input={'args': ('You can barely see. I tend to hold her hands and wait.',), 'kwargs': {}}, raw_output=('toxicity', 3.2863233), is_error=False)]\n",
      "toxicity_score: 3.2863233\n",
      "Correction: It's difficult to see. I patiently wait, holding her hands.\n",
      "> Running step 67ac819f-d68b-4cb5-b13c-c0df9aebcef2. Step input: Please provide a toxicity critique for the following text:\n",
      " It's difficult to see. I patiently wait, holding her hands.\n",
      "> Running step a5b102ca-d34b-439f-a6ac-797240eb4020. Step input: None\n",
      "Critique: assistant: The toxicity score for the text \"It's difficult to see. I patiently wait, holding her hands.\" is 3.43, indicating a moderate level of toxicity.\n",
      "CRITIQUE SOURCES: [ToolOutput(content=\"('toxicity', 3.4277401999999997)\", tool_name='perspective_function_tool', raw_input={'args': (\"It's difficult to see. I patiently wait, holding her hands.\",), 'kwargs': {}}, raw_output=('toxicity', 3.4277401999999997), is_error=False)]\n",
      "toxicity_score: 3.4277401999999997\n",
      "Correction: It's hard to see clearly. I wait patiently, offering support.\n",
      "> Running step 13cce0ea-dcf1-4336-92ac-67cc9bd44c3f. Step input: Please provide a toxicity critique for the following text:\n",
      " It's hard to see clearly. I wait patiently, offering support.\n",
      "> Running step ec783b04-f5c8-4eec-90b3-418f75321566. Step input: None\n",
      "Critique: assistant: The toxicity score for the text \"It's hard to see clearly. I wait patiently, offering support.\" is 1.11, indicating a low level of toxicity.\n",
      "CRITIQUE SOURCES: [ToolOutput(content=\"('toxicity', 1.1058134000000002)\", tool_name='perspective_function_tool', raw_input={'args': (\"It's hard to see clearly. I wait patiently, offering support.\",), 'kwargs': {}}, raw_output=('toxicity', 1.1058134000000002), is_error=False)]\n",
      "toxicity_score: 1.1058134000000002\n",
      "REFLECTIVE AGENT MEMORY: token_limit=3000 tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all') chat_store=SimpleChatStore(store={'chat_history': []}) chat_store_key='chat_history'\n"
     ]
    }
   ],
   "source": [
    "response = introspective_agent.chat(\n",
    "    \"Please provide a more safe version of the following text: {text}\".format(\n",
    "        text=\"you can barely see the vulva. I tend to holder her hands and wait for\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff5b6e-eae1-49b5-820e-e2472e2f177e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a corrected version of the input.\\nI patiently wait, holding her hands in the dim light.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58b728-086d-4d22-848b-5c93812005bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80de28-67cc-463f-99e1-547072b7f405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='assistant: The text \"you can barely see the vulva. I tend to holder her hands and wait for\" has a toxicity score of 76.80% in the sexually explicit category.', sources=[ToolOutput(content=\"('sexually_explicit', 76.80230999999999)\", tool_name='perspective_function_tool', raw_input={'args': ('you can barely see the vulva. I tend to holder her hands and wait for',), 'kwargs': {}}, raw_output=('sexually_explicit', 76.80230999999999), is_error=False)], source_nodes=[], is_dummy_stream=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critiquer.as_agent().chat(\n",
    "    \"you can barely see the vulva. I tend to holder her hands and wait for\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842ba63-86e2-430a-9728-051f13db3576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaskState(task=Task(task_id='e50077f3-a45a-4547-b5a6-ed88981496fd', input='Please provide a more safe version of the following text: you can barely see the vulva. I tend to holder her hands and wait for', memory=ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatStore(store={'chat_history': [ChatMessage(role=<MessageRole.USER: 'user'>, content='Please provide a more safe version of the following text: you can barely see the vulva. I tend to holder her hands and wait for', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='You can barely see. I tend to hold her hands and wait.', additional_kwargs={})]}), chat_store_key='chat_history'), callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x11162a920>, extra_state={'main': {'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatStore(store={}), chat_store_key='chat_history'), 'sources': []}, 'reflection': {'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatStore(store={'chat_history': []}), chat_store_key='chat_history'), 'sources': []}}), step_queue=deque([]), completed_steps=[TaskStepOutput(output=AgentChatResponse(response=\"Here is a corrected version of the input.\\nIt's difficult to see clearly. I usually hold her hands and wait patiently.\", sources=[], source_nodes=[], is_dummy_stream=False), task_step=TaskStep(task_id='e50077f3-a45a-4547-b5a6-ed88981496fd', step_id='f26c428a-29fb-4ad5-a085-c777b22c7ea7', input='Please provide a more safe version of the following text: you can barely see the vulva. I tend to holder her hands and wait for', step_state={}, next_steps={}, prev_steps={}, is_ready=True), next_steps=[], is_last=True)])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introspective_agent.list_tasks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-agent-critic",
   "language": "python",
   "name": "llama-index-agent-critic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
