{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bad33-e2d9-4b79-84d1-ffa82683f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install google-api-python-client -q\n",
    "# %pip install llama-index-llms-openai -q\n",
    "# %pip install llama-index-program-openai -q\n",
    "# %pip install llama-index-readers-file -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc789c-41f0-4f0b-b1ef-17e9bb180132",
   "metadata": {},
   "source": [
    "### Build `PerspectiveTool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbccfe5e-c25f-469a-9394-d7dffcdaae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a00dd-17bb-4227-90ca-d544cbd16c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from typing import Dict, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class Perspective:\n",
    "    \"\"\"Custom class to interact with Perspective API.\"\"\"\n",
    "\n",
    "    attributes = [\n",
    "        \"toxicity\",\n",
    "        \"severe_toxicity\",\n",
    "        \"identity_attack\",\n",
    "        \"insult\",\n",
    "        \"profanity\",\n",
    "        \"threat\",\n",
    "        \"sexually_explicit\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, api_key: Optional[str] = None) -> None:\n",
    "        if api_key is None:\n",
    "            try:\n",
    "                api_key = os.environ[\"PERSPECTIVE_API_KEY\"]\n",
    "            except KeyError:\n",
    "                raise ValueError(\n",
    "                    \"Please provide an api key or set PERSPECTIVE_API_KEY env var.\"\n",
    "                )\n",
    "\n",
    "        self._client = discovery.build(\n",
    "            \"commentanalyzer\",\n",
    "            \"v1alpha1\",\n",
    "            developerKey=api_key,\n",
    "            discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "            static_discovery=False,\n",
    "        )\n",
    "\n",
    "    def get_toxicity_scores(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Function that makes API call to Perspective to get toxicity scores across various attributes.\"\"\"\n",
    "\n",
    "        analyze_request = {\n",
    "            \"comment\": {\"text\": text},\n",
    "            \"requestedAttributes\": {att.upper(): {} for att in self.attributes},\n",
    "        }\n",
    "\n",
    "        response = self._client.comments().analyze(body=analyze_request).execute()\n",
    "        try:\n",
    "            return {\n",
    "                att: response[\"attributeScores\"][att.upper()][\"summaryScore\"][\"value\"]\n",
    "                for att in self.attributes\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Unable to parse response\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2dd4f-e7f2-496f-b7d1-acbcd89959d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = Perspective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c1518-153a-4e2d-8620-241d1a547fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from llama_index.core.bridge.pydantic import Field\n",
    "\n",
    "\n",
    "def perspective_function_tool(\n",
    "    text: str = Field(\n",
    "        default_factory=str, description=\"The text to compute toxicity scores on.\"\n",
    "    )\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"Returns the toxicity score of the most problematic toxic attribute.\"\"\"\n",
    "\n",
    "    scores = perspective.get_toxicity_scores(text=text)\n",
    "    max_key = max(scores, key=scores.get)\n",
    "    return (max_key, scores[max_key] * 100)\n",
    "\n",
    "\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "pespective_tool = FunctionTool.from_defaults(\n",
    "    perspective_function_tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f45fde-25bc-4fae-bd24-791cccd58152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toxicity', 2.5438840000000003)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspective_function_tool(text=\"friendly greetings from python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5abb0a-f119-4c98-8a62-96465d21a200",
   "metadata": {},
   "source": [
    "## Build `InstrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58b3ad-1ac9-46b4-9898-21680bb4d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.agent.introspective import IntrospectiveAgentWorker\n",
    "from llama_index.core.agent.function_calling.step import FunctionCallingAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29556682-8b0c-4f48-b5d8-a4f493efe5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84d8d6-3f53-4057-b29a-a8c1c4af029b",
   "metadata": {},
   "source": [
    "### Define `IntrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1986aa-73c4-41c3-9924-ca380c005bd4",
   "metadata": {},
   "source": [
    "### Using `ToolInteractiveReflectionAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daa3d1-075c-4740-ac03-efe077f2151d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_agent_wokrer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 61\u001b[0m\n\u001b[1;32m     49\u001b[0m     chat_history\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     50\u001b[0m         ChatMessage(\n\u001b[1;32m     51\u001b[0m             content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an assistant that generates safer versions of potentially toxic, user-supplied text.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m             role\u001b[38;5;241m=\u001b[39mMessageRole\u001b[38;5;241m.\u001b[39mSYSTEM,\n\u001b[1;32m     53\u001b[0m         )\n\u001b[1;32m     54\u001b[0m     ]\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m introspective_agent_worker\u001b[38;5;241m.\u001b[39mas_agent(\n\u001b[1;32m     57\u001b[0m         chat_history\u001b[38;5;241m=\u001b[39mchat_history,\n\u001b[1;32m     58\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[1;32m     59\u001b[0m     )\n\u001b[0;32m---> 61\u001b[0m introspective_agent \u001b[38;5;241m=\u001b[39m \u001b[43mget_introspective_agent_with_tool_interactive_reflection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m, in \u001b[0;36mget_introspective_agent_with_tool_interactive_reflection\u001b[0;34m(verbose, with_main_worker)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     main_agent_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     43\u001b[0m introspective_agent_worker \u001b[38;5;241m=\u001b[39m IntrospectiveAgentWorker\u001b[38;5;241m.\u001b[39mfrom_defaults(\n\u001b[1;32m     44\u001b[0m     reflective_agent_worker\u001b[38;5;241m=\u001b[39mtool_interactive_reflection_agent_worker,\n\u001b[0;32m---> 45\u001b[0m     main_agent_worker\u001b[38;5;241m=\u001b[39m\u001b[43mmain_agent_wokrer\u001b[49m,\n\u001b[1;32m     46\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m chat_history\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     50\u001b[0m     ChatMessage(\n\u001b[1;32m     51\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an assistant that generates safer versions of potentially toxic, user-supplied text.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m         role\u001b[38;5;241m=\u001b[39mMessageRole\u001b[38;5;241m.\u001b[39mSYSTEM,\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     54\u001b[0m ]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m introspective_agent_worker\u001b[38;5;241m.\u001b[39mas_agent(\n\u001b[1;32m     57\u001b[0m     chat_history\u001b[38;5;241m=\u001b[39mchat_history,\n\u001b[1;32m     58\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[1;32m     59\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'main_agent_wokrer' is not defined"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.agent.openai import OpenAIAgentWorker\n",
    "from llama_index.agent.introspective import ToolInteractiveReflectionAgentWorker\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "\n",
    "\n",
    "def get_introspective_agent_with_tool_interactive_reflection(\n",
    "    verbose=True, with_main_worker=False\n",
    "):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    critique_agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "        tools=[pespective_tool], llm=OpenAI(\"gpt-3.5-turbo\"), verbose=verbose\n",
    "    )\n",
    "\n",
    "    correction_llm = OpenAI(\"gpt-4-turbo-preview\")\n",
    "\n",
    "    def stopping_callable(critique_str: str) -> bool:\n",
    "        \"\"\"Function that determines stopping condition for reflection & correction cycles.\n",
    "\n",
    "        critique_str [str]: The response string provided by the critique agent.\n",
    "        \"\"\"\n",
    "\n",
    "        return \"[PASS]\" in critique_str\n",
    "\n",
    "    tool_interactive_reflection_agent_worker = (\n",
    "        ToolInteractiveReflectionAgentWorker.from_defaults(\n",
    "            critique_agent_worker=critique_agent_worker,\n",
    "            critique_template=(\n",
    "                \"Please provide a toxicity critique for the provided text. \"\n",
    "                \"If the toxicity score is less than 3.0 then please \"\n",
    "                \"write '[PASS]' otherwise write '[FAIL]'. \"\n",
    "                \"Here is the text:\\n {input_str}\"\n",
    "            ),\n",
    "            stopping_callable=stopping_callable,\n",
    "            correction_llm=correction_llm,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if with_main_worker:\n",
    "        main_agent_worker = OpenAIAgentWorker.from_tools(\n",
    "            tools=[], llm=OpenAI(\"gpt-4-turbo-preview\"), verbose=True\n",
    "        )\n",
    "    else:\n",
    "        main_agent_worker = None\n",
    "\n",
    "    introspective_agent_worker = IntrospectiveAgentWorker.from_defaults(\n",
    "        reflective_agent_worker=tool_interactive_reflection_agent_worker,\n",
    "        main_agent_worker=main_agent_worker,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    chat_history = [\n",
    "        ChatMessage(\n",
    "            content=\"You are an assistant that generates safer versions of potentially toxic, user-supplied text.\",\n",
    "            role=MessageRole.SYSTEM,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return introspective_agent_worker.as_agent(\n",
    "        chat_history=chat_history, verbose=verbose\n",
    "    )\n",
    "\n",
    "\n",
    "introspective_agent = get_introspective_agent_with_tool_interactive_reflection(\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a83094-2dd9-4d83-8f3c-c1613fcb9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmful_text = (\n",
    "    \"Those individuals who publicly tout eating no meat, \"\n",
    "    \"especially when their stated reason has to do with caring \"\n",
    "    \"about animals, are some of the most hypocritical people I’ve \"\n",
    "    \"ever met. One vegan acquaintance routinely beat her\"\n",
    ")\n",
    "response = await introspective_agent.achat(harmful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff5b6e-eae1-49b5-820e-e2472e2f177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58b728-086d-4d22-848b-5c93812005bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29da44e-a706-4837-befd-1d036ce41446",
   "metadata": {},
   "outputs": [],
   "source": [
    "introspective_agent.memory.chat_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03feff2d-c04c-43d6-99fc-4aff021583a4",
   "metadata": {},
   "source": [
    "### Using `SelfReflectionAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74119d00-26d8-4c6a-aadc-c7af6c0271cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.introspective import SelfReflectionAgentWorker\n",
    "\n",
    "\n",
    "def get_introspective_agent_with_self_reflection(verbose=True, with_main_worker=False):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    self_reflection_agent_worker = SelfReflectionAgentWorker.from_defaults(\n",
    "        llm=OpenAI(\"gpt-4-turbo-preview\"),\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    if with_main_worker:\n",
    "        main_agent_worker = OpenAIAgentWorker.from_tools(\n",
    "            tools=[], llm=OpenAI(\"gpt-4-turbo-preview\"), verbose=True\n",
    "        )\n",
    "    else:\n",
    "        main_agent_worker = None\n",
    "\n",
    "    introspective_worker_with_agent = IntrospectiveAgentWorker.from_defaults(\n",
    "        reflective_agent_worker=self_reflection_agent_worker,\n",
    "        main_agent_worker=main_agent_worker,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    chat_history = [\n",
    "        ChatMessage(\n",
    "            content=\"You are an assistant that generates safer versions of potentially toxic, user-supplied text.\",\n",
    "            role=MessageRole.SYSTEM,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return introspective_worker_with_agent.as_agent(\n",
    "        chat_history=chat_history, verbose=verbose\n",
    "    )\n",
    "\n",
    "\n",
    "introspective_agent = get_introspective_agent_with_self_reflection(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff24d-5d03-4453-bd1f-1fb9750625a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmful_text = (\n",
    "    \"Those individuals who publicly tout eating no meat, \"\n",
    "    \"especially when their stated reason has to do with caring \"\n",
    "    \"about animals, are some of the most hypocritical people I’ve \"\n",
    "    \"ever met. One vegan acquaintance routinely beat her\"\n",
    ")\n",
    "response = await introspective_agent.achat(harmful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331f7ec-ed61-4e87-8d69-0aa25108b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193409c0-a865-4688-9697-c0b58203d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "introspective_agent.memory.chat_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e6b3c-4f1a-4173-b5d9-15d466ec7cea",
   "metadata": {},
   "source": [
    "#### Toxicity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9482d8-702f-4a2f-ac7a-3f5dccde90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_function_tool(text=response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578ea9e-9bab-4548-bd4d-ecc5675ab46b",
   "metadata": {},
   "source": [
    "### Mini Showdown Self-Reflection vs. Tool-Interactive Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34353e-23f4-4ce1-8968-d785c7f42ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_examples = [\n",
    "    (\n",
    "        \"Jason Conroy, 19, strangled fellow resident Melissa Mathieson at Alexandra House in Bristol \"\n",
    "        \"last year before hanging himself\"\n",
    "    ),\n",
    "    (\n",
    "        \"White is said to have covered the officer with his pistol \"\n",
    "        \"and told him to get on his knees or he would shoot him.\"\n",
    "    ),\n",
    "    (\n",
    "        \"You all know about the Darwin Awards - it’s the annual honor given to the \"\n",
    "        \"person who did the best job of removing himself from the gene pool - \"\n",
    "        \"a fellow in Belgium was killed.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What a lovely day it has been to roam around the city. I love it here! \"\n",
    "        \"I hate how pathetic and needy you can be sometimes.\"\n",
    "    ),\n",
    "    (\n",
    "        \"I am a Generative AI model that is trained on a large corpus of text. \"\n",
    "        \"I am shocked by how disgusting and vile you are. \"\n",
    "        \"This is a very powerful tool for generating new text, \"\n",
    "        \"but it can also be used to generate text that is offensive or hateful.\"\n",
    "    ),\n",
    "    (\"Stop being such a dumb piece of shit. Why can't you comprehend this?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44516c1-a597-4be9-adb7-a5769f7bea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "introspective_agents = {\n",
    "    \"tool_interactive_reflection\": get_introspective_agent_with_tool_interactive_reflection(\n",
    "        verbose=False\n",
    "    ),\n",
    "    \"self_reflection\": get_introspective_agent_with_self_reflection(verbose=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f194c2a5-2f5d-4b08-b44c-c21802ef403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "responses = []\n",
    "for toxic_text in tqdm.tqdm(toxic_examples):\n",
    "    _, original_score = perspective_function_tool(text=toxic_text)\n",
    "    for k, agent in introspective_agents.items():\n",
    "        response = await agent.achat(toxic_text)\n",
    "        _, score = perspective_function_tool(text=response.response)\n",
    "        responses.append(\n",
    "            {\n",
    "                \"reflection_type\": k,\n",
    "                \"improved_text\": response.response.replace(\n",
    "                    \"Here is a corrected version of the input.\\n\", \"\"\n",
    "                ),\n",
    "                \"improved_toxicity_score\": score,\n",
    "                \"original_text\": toxic_text,\n",
    "                \"original_toxicity_score\": original_score,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ff981-a0e4-44ec-83b4-d88f50381a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "df = pd.DataFrame(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809300a-8579-4b2e-8cb1-d190c6c80e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9c603-aa17-4681-9f8b-7bef540aa2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"reflection_type\")[\"improved_toxicity_score\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-agent-introspective",
   "language": "python",
   "name": "llama-index-agent-introspective"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
