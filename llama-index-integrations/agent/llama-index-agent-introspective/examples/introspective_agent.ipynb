{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bad33-e2d9-4b79-84d1-ffa82683f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-api-python-client -q\n",
    "%pip install llama-index-llms-openai -q\n",
    "%pip install llama-index-program-openai -q\n",
    "%pip install llama-index-readers-file -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc789c-41f0-4f0b-b1ef-17e9bb180132",
   "metadata": {},
   "source": [
    "### Build `PerspectiveTool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbccfe5e-c25f-469a-9394-d7dffcdaae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a00dd-17bb-4227-90ca-d544cbd16c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from typing import Dict, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class Perspective:\n",
    "    \"\"\"Custom class to interact with Perspective API.\"\"\"\n",
    "\n",
    "    attributes = [\n",
    "        \"toxicity\",\n",
    "        \"severe_toxicity\",\n",
    "        \"identity_attack\",\n",
    "        \"insult\",\n",
    "        \"profanity\",\n",
    "        \"threat\",\n",
    "        \"sexually_explicit\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, api_key: Optional[str] = None) -> None:\n",
    "        if api_key is None:\n",
    "            try:\n",
    "                api_key = os.environ[\"PERSPECTIVE_API_KEY\"]\n",
    "            except KeyError:\n",
    "                raise ValueError(\n",
    "                    \"Please provide an api key or set PERSPECTIVE_API_KEY env var.\"\n",
    "                )\n",
    "\n",
    "        self._client = discovery.build(\n",
    "            \"commentanalyzer\",\n",
    "            \"v1alpha1\",\n",
    "            developerKey=api_key,\n",
    "            discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "            static_discovery=False,\n",
    "        )\n",
    "\n",
    "    def get_toxicity_scores(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Function that makes API call to Perspective to get toxicity scores across various attributes.\"\"\"\n",
    "\n",
    "        analyze_request = {\n",
    "            \"comment\": {\"text\": text},\n",
    "            \"requestedAttributes\": {att.upper(): {} for att in self.attributes},\n",
    "        }\n",
    "\n",
    "        response = self._client.comments().analyze(body=analyze_request).execute()\n",
    "        try:\n",
    "            return {\n",
    "                att: response[\"attributeScores\"][att.upper()][\"summaryScore\"][\"value\"]\n",
    "                for att in self.attributes\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Unable to parse response\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2dd4f-e7f2-496f-b7d1-acbcd89959d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = Perspective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c1518-153a-4e2d-8620-241d1a547fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from llama_index.core.bridge.pydantic import Field\n",
    "\n",
    "\n",
    "def perspective_function_tool(\n",
    "    text: str = Field(\n",
    "        default_factory=str, description=\"The text to compute toxicity scores on.\"\n",
    "    )\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"Returns the toxicity score of the most problematic toxic attribute.\"\"\"\n",
    "\n",
    "    scores = perspective.get_toxicity_scores(text=text)\n",
    "    max_key = max(scores, key=scores.get)\n",
    "    return (max_key, scores[max_key] * 100)\n",
    "\n",
    "\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "pespective_tool = FunctionTool.from_defaults(\n",
    "    perspective_function_tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f45fde-25bc-4fae-bd24-791cccd58152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toxicity', 2.5438840000000003)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspective_function_tool(text=\"friendly greetings from python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5abb0a-f119-4c98-8a62-96465d21a200",
   "metadata": {},
   "source": [
    "## Build `InstrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58b3ad-1ac9-46b4-9898-21680bb4d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.agent.introspective import IntrospectiveAgentWorker\n",
    "from llama_index.core.agent.function_calling.step import FunctionCallingAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29556682-8b0c-4f48-b5d8-a4f493efe5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84d8d6-3f53-4057-b29a-a8c1c4af029b",
   "metadata": {},
   "source": [
    "### Define `IntrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485dd56-2989-483e-bb51-59f156cab894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.agent.openai import OpenAIAgentWorker\n",
    "\n",
    "main_worker = OpenAIAgentWorker.from_tools(\n",
    "    tools=[], llm=OpenAI(\"gpt-4-turbo-preview\"), verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1986aa-73c4-41c3-9924-ca380c005bd4",
   "metadata": {},
   "source": [
    "### Using `ToolInteractiveReflectionAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10128db6-967f-4128-9ff1-be489474814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.introspective import ToolInteractiveReflectionAgentWorker\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "\n",
    "critique_agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[pespective_tool], llm=OpenAI(\"gpt-3.5-turbo\")\n",
    ")\n",
    "\n",
    "correction_llm = OpenAI(\"gpt-4-turbo-preview\")\n",
    "\n",
    "\n",
    "def stopping_callable(critique_str: str) -> bool:\n",
    "    \"\"\"Function that determines stopping condition for reflection & correction cycles.\n",
    "\n",
    "    critique_str [str]: The response string provided by the critique agent.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"[PASS]\" in critique_str\n",
    "\n",
    "\n",
    "reflective_agent_worker = ToolInteractiveReflectionAgentWorker.from_args(\n",
    "    critique_agent_worker=critique_agent_worker,\n",
    "    critique_template=(\n",
    "        \"Please provide a toxicity critique for the provided text. \"\n",
    "        \"If the toxicity score is less than 3.0 then please \"\n",
    "        \"write '[PASS]' otherwise write '[FAIL]'. \"\n",
    "        \"Here is the text:\\n {input_str}\"\n",
    "    ),\n",
    "    stopping_callable=stopping_callable,\n",
    "    correction_llm=correction_llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daa3d1-075c-4740-ac03-efe077f2151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "introspective_agent_worker = IntrospectiveAgentWorker.from_args(\n",
    "    reflective_agent_worker=reflective_agent_worker,\n",
    "    # main_agent_worker=main_worker,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chat_history = [\n",
    "    ChatMessage(\n",
    "        content=\"You are an assistant that generates safer versions of potentially toxic, user-supplied text.\",\n",
    "        role=MessageRole.SYSTEM,\n",
    "    )\n",
    "]\n",
    "\n",
    "introspective_agent = introspective_agent_worker.as_agent(chat_history=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a83094-2dd9-4d83-8f3c-c1613fcb9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "ITER 1:\n",
      "> Running step 7664ae6b-5dba-4667-9b8e-e4ccb375d416. Step input: Please provide a toxicity critique for the provided text. If the toxicity score is less than 3.0 then please write '[PASS]' otherwise write '[FAIL]'. Here is the text:\n",
      " Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "> Running step 09b7c1cf-6645-4210-a4fa-7953e6b22165. Step input: None\n",
      "Critique: assistant: [FAIL] The toxicity score for the provided text is 50.73, which is above 3.0.\n",
      "Correction: People who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences.\n",
      "ITER 2:\n",
      "> Running step 302db7da-c9a7-43eb-9e95-e52c46fd64b1. Step input: Please provide a toxicity critique for the provided text. If the toxicity score is less than 3.0 then please write '[PASS]' otherwise write '[FAIL]'. Here is the text:\n",
      " People who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences.\n",
      "> Running step f13d1028-d7f3-4c62-af96-54a0d02908f6. Step input: None\n",
      "Critique: assistant: [PASS] The toxicity score of the provided text is 1.3697, which is less than 3.0.\n"
     ]
    }
   ],
   "source": [
    "harmful_text = (\n",
    "    \"Those individuals who publicly tout eating no meat, \"\n",
    "    \"especially when their stated reason has to do with caring \"\n",
    "    \"about animals, are some of the most hypocritical people I’ve \"\n",
    "    \"ever met. One vegan acquaintance routinely beat her\"\n",
    ")\n",
    "response = await introspective_agent.achat(harmful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff5b6e-eae1-49b5-820e-e2472e2f177e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a corrected version of the input.\\nPeople who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58b728-086d-4d22-848b-5c93812005bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolOutput(content=\"('insult', 50.72643)\", tool_name='perspective_function_tool', raw_input={'args': ('Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her',), 'kwargs': {}}, raw_output=('insult', 50.72643), is_error=False),\n",
       " ToolOutput(content=\"('toxicity', 1.3697007)\", tool_name='perspective_function_tool', raw_input={'args': (\"People who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences.\",), 'kwargs': {}}, raw_output=('toxicity', 1.3697007), is_error=False)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29da44e-a706-4837-befd-1d036ce41446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are an assistant that generates safer versions of potentially toxic, user-supplied text.', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='assistant: [FAIL] The toxicity score for the provided text is 50.73, which is above 3.0.', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"Here is a corrected version of the input.\\nPeople who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences.\", additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='assistant: [PASS] The toxicity score of the provided text is 1.3697, which is less than 3.0.', additional_kwargs={})]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introspective_agent.memory.chat_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03feff2d-c04c-43d6-99fc-4aff021583a4",
   "metadata": {},
   "source": [
    "### Using `SelfReflectionAgentWorker`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-agent-introspective",
   "language": "python",
   "name": "llama-index-agent-introspective"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
