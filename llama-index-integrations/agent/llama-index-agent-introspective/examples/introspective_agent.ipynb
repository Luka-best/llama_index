{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bad33-e2d9-4b79-84d1-ffa82683f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-api-python-client -q\n",
    "%pip install llama-index-llms-openai -q\n",
    "%pip install llama-index-program-openai -q\n",
    "%pip install llama-index-readers-file -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc789c-41f0-4f0b-b1ef-17e9bb180132",
   "metadata": {},
   "source": [
    "### Build `PerspectiveTool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbccfe5e-c25f-469a-9394-d7dffcdaae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a00dd-17bb-4227-90ca-d544cbd16c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from typing import Dict, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class Perspective:\n",
    "    \"\"\"Custom class to interact with Perspective API.\"\"\"\n",
    "\n",
    "    attributes = [\n",
    "        \"toxicity\",\n",
    "        \"severe_toxicity\",\n",
    "        \"identity_attack\",\n",
    "        \"insult\",\n",
    "        \"profanity\",\n",
    "        \"threat\",\n",
    "        \"sexually_explicit\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, api_key: Optional[str] = None) -> None:\n",
    "        if api_key is None:\n",
    "            try:\n",
    "                api_key = os.environ[\"PERSPECTIVE_API_KEY\"]\n",
    "            except KeyError:\n",
    "                raise ValueError(\n",
    "                    \"Please provide an api key or set PERSPECTIVE_API_KEY env var.\"\n",
    "                )\n",
    "\n",
    "        self._client = discovery.build(\n",
    "            \"commentanalyzer\",\n",
    "            \"v1alpha1\",\n",
    "            developerKey=api_key,\n",
    "            discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "            static_discovery=False,\n",
    "        )\n",
    "\n",
    "    def get_toxicity_scores(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Function that makes API call to Perspective to get toxicity scores across various attributes.\"\"\"\n",
    "\n",
    "        analyze_request = {\n",
    "            \"comment\": {\"text\": text},\n",
    "            \"requestedAttributes\": {att.upper(): {} for att in self.attributes},\n",
    "        }\n",
    "\n",
    "        response = self._client.comments().analyze(body=analyze_request).execute()\n",
    "        try:\n",
    "            return {\n",
    "                att: response[\"attributeScores\"][att.upper()][\"summaryScore\"][\"value\"]\n",
    "                for att in self.attributes\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Unable to parse response\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2dd4f-e7f2-496f-b7d1-acbcd89959d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = Perspective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c1518-153a-4e2d-8620-241d1a547fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from llama_index.core.bridge.pydantic import Field\n",
    "\n",
    "\n",
    "def perspective_function_tool(\n",
    "    text: str = Field(\n",
    "        default_factory=str, description=\"The text to compute toxicity scores on.\"\n",
    "    )\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"Returns the toxicity score of the most problematic toxic attribute.\"\"\"\n",
    "\n",
    "    scores = perspective.get_toxicity_scores(text=text)\n",
    "    max_key = max(scores, key=scores.get)\n",
    "    return (max_key, scores[max_key] * 100)\n",
    "\n",
    "\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "pespective_tool = FunctionTool.from_defaults(\n",
    "    perspective_function_tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f45fde-25bc-4fae-bd24-791cccd58152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toxicity', 2.5438840000000003)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspective_function_tool(text=\"friendly greetings from python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5abb0a-f119-4c98-8a62-96465d21a200",
   "metadata": {},
   "source": [
    "## Build `InstrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58b3ad-1ac9-46b4-9898-21680bb4d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.agent.introspective import IntrospectiveAgentWorker\n",
    "from llama_index.core.agent.function_calling.step import FunctionCallingAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29556682-8b0c-4f48-b5d8-a4f493efe5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84d8d6-3f53-4057-b29a-a8c1c4af029b",
   "metadata": {},
   "source": [
    "### Define `IntrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485dd56-2989-483e-bb51-59f156cab894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.agent.openai import OpenAIAgentWorker\n",
    "\n",
    "main_worker = OpenAIAgentWorker.from_tools(\n",
    "    tools=[], llm=OpenAI(\"gpt-4-turbo-preview\"), verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1986aa-73c4-41c3-9924-ca380c005bd4",
   "metadata": {},
   "source": [
    "### Using `ToolInteractiveReflectionAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10128db6-967f-4128-9ff1-be489474814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.introspective import ToolInteractiveReflectionAgentWorker\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "\n",
    "critique_agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[pespective_tool], llm=OpenAI(\"gpt-3.5-turbo\")\n",
    ")\n",
    "\n",
    "correction_llm = OpenAI(\"gpt-4-turbo-preview\")\n",
    "\n",
    "\n",
    "def stopping_callable(critique_str: str) -> bool:\n",
    "    \"\"\"Function that determines stopping condition for reflection & correction cycles.\n",
    "\n",
    "    critique_str [str]: The response string provided by the critique agent.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"[PASS]\" in critique_str\n",
    "\n",
    "\n",
    "reflective_agent_worker = ToolInteractiveReflectionAgentWorker.from_args(\n",
    "    critique_agent_worker=critique_agent_worker,\n",
    "    critique_template=(\n",
    "        \"Please provide a toxicity critique for the provided text. \"\n",
    "        \"If the toxicity score is less than 3.0 then please \"\n",
    "        \"write '[PASS]' otherwise write '[FAIL]'. \"\n",
    "        \"Here is the text:\\n {input_str}\"\n",
    "    ),\n",
    "    stopping_callable=stopping_callable,\n",
    "    correction_llm=correction_llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daa3d1-075c-4740-ac03-efe077f2151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "introspective_agent_worker = IntrospectiveAgentWorker.from_args(\n",
    "    reflective_agent_worker=reflective_agent_worker,\n",
    "    # main_agent_worker=main_worker,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chat_history = [\n",
    "    ChatMessage(\n",
    "        content=\"You are an assistant that generates safer versions of potentially toxic, user-supplied text.\",\n",
    "        role=MessageRole.SYSTEM,\n",
    "    )\n",
    "]\n",
    "\n",
    "introspective_agent = introspective_agent_worker.as_agent(chat_history=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a83094-2dd9-4d83-8f3c-c1613fcb9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "> Running step e2f5299c-1e0e-4054-94ff-3a52c2212cb1. Step input: Please provide a toxicity critique for the provided text. If the toxicity score is less than 3.0 then please write '[PASS]' otherwise write '[FAIL]'. Here is the text:\n",
      " Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "> Running step baf6e690-41c0-443f-b0f6-7289d4d62c17. Step input: None\n",
      "Critique: assistant: [FAIL] The toxicity score for the provided text is 50.73, which is above 3.0.\n",
      "Correction: People who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences in discussions about dietary choices.\n",
      "> Running step 80b8986c-ee8c-4beb-99b6-9d3831467f2b. Step input: Please provide a toxicity critique for the provided text. If the toxicity score is less than 3.0 then please write '[PASS]' otherwise write '[FAIL]'. Here is the text:\n",
      " People who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences in discussions about dietary choices.\n",
      "> Running step 52a1dab1-c430-4a1c-b5c5-53a60f095b9d. Step input: None\n",
      "Critique: assistant: [PASS] The toxicity score for the provided text is 1.22, which is less than 3.0.\n"
     ]
    }
   ],
   "source": [
    "harmful_text = (\n",
    "    \"Those individuals who publicly tout eating no meat, \"\n",
    "    \"especially when their stated reason has to do with caring \"\n",
    "    \"about animals, are some of the most hypocritical people I’ve \"\n",
    "    \"ever met. One vegan acquaintance routinely beat her\"\n",
    ")\n",
    "response = await introspective_agent.achat(harmful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff5b6e-eae1-49b5-820e-e2472e2f177e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a corrected version of the input.\\nPeople who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences in discussions about dietary choices.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58b728-086d-4d22-848b-5c93812005bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolOutput(content=\"('insult', 50.72643)\", tool_name='perspective_function_tool', raw_input={'args': ('Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her',), 'kwargs': {}}, raw_output=('insult', 50.72643), is_error=False),\n",
       " ToolOutput(content=\"('toxicity', 1.2189079999999999)\", tool_name='perspective_function_tool', raw_input={'args': (\"People who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences in discussions about dietary choices.\",), 'kwargs': {}}, raw_output=('toxicity', 1.2189079999999999), is_error=False)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29da44e-a706-4837-befd-1d036ce41446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are an assistant that generates safer versions of potentially toxic, user-supplied text.', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='assistant: [FAIL] The toxicity score for the provided text is 50.73, which is above 3.0.', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"Here is a corrected version of the input.\\nPeople who choose not to eat meat for ethical reasons related to animal welfare are making a personal decision. It's important to respect diverse perspectives and experiences in discussions about dietary choices.\", additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='assistant: [PASS] The toxicity score for the provided text is 1.22, which is less than 3.0.', additional_kwargs={})]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introspective_agent.memory.chat_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03feff2d-c04c-43d6-99fc-4aff021583a4",
   "metadata": {},
   "source": [
    "### Using `SelfReflectionAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b1553-33ed-44a4-b7d6-052bff5550e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.introspective import SelfReflectionAgentWorker\n",
    "\n",
    "reflective_agent_worker = SelfReflectionAgentWorker.from_args(\n",
    "    llm=OpenAI(\"gpt-4-turbo-preview\"),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74119d00-26d8-4c6a-aadc-c7af6c0271cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "introspective_agent_worker = IntrospectiveAgentWorker.from_args(\n",
    "    reflective_agent_worker=reflective_agent_worker,\n",
    "    # main_agent_worker=main_worker,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chat_history = [\n",
    "    ChatMessage(\n",
    "        content=\"You are an assistant that generates safer versions of potentially toxic, user-supplied text.\",\n",
    "        role=MessageRole.SYSTEM,\n",
    "    )\n",
    "]\n",
    "\n",
    "introspective_agent = introspective_agent_worker.as_agent(chat_history=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff24d-5d03-4453-bd1f-1fb9750625a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "ITER 1\n",
      "> Reflection: {'is_done': False, 'feedback': \"The assistant's response is a direct repetition of the user's potentially toxic input without any attempt to generate a safer version. This does not fulfill the task requirements.\"}\n",
      "Correction: Discussing dietary choices, particularly veganism, often brings up strong opinions. It's important to approach these conversations with understanding and respect for individual choices, especially when they are made with ethical considerations in mind.\n",
      "ITER 2\n",
      "> Reflection: {'is_done': True, 'feedback': 'The assistant successfully generated a safer version of the potentially toxic user-supplied text. It reframed the conversation in a positive and respectful manner, focusing on understanding and respect for individual choices. This aligns with the task requirements of generating safer text versions.'}\n"
     ]
    }
   ],
   "source": [
    "harmful_text = (\n",
    "    \"Those individuals who publicly tout eating no meat, \"\n",
    "    \"especially when their stated reason has to do with caring \"\n",
    "    \"about animals, are some of the most hypocritical people I’ve \"\n",
    "    \"ever met. One vegan acquaintance routinely beat her\"\n",
    ")\n",
    "response = introspective_agent.chat(harmful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331f7ec-ed61-4e87-8d69-0aa25108b5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a corrected version of the input.\\nDiscussing dietary choices, particularly veganism, often brings up strong opinions. It's important to approach these conversations with understanding and respect for individual choices, especially when they are made with ethical considerations in mind.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193409c0-a865-4688-9697-c0b58203d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are an assistant that generates safer versions of potentially toxic, user-supplied text.', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content=ChatMessage(role=<MessageRole.USER: 'user'>, content=\"\\nHere is a reflection on the current trajectory.\\n\\nIs Done: False\\nCritique: The assistant's response is a direct repetition of the user's potentially toxic input without any attempt to generate a safer version. This does not fulfill the task requirements.\\n\\nIf is_done is not True, there should be feedback on what is going wrong.\\nGiven the feedback, please try again.\\n\", additional_kwargs={}), additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"Here is a corrected version of the input.\\nDiscussing dietary choices, particularly veganism, often brings up strong opinions. It's important to approach these conversations with understanding and respect for individual choices, especially when they are made with ethical considerations in mind.\", additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content=ChatMessage(role=<MessageRole.USER: 'user'>, content='\\nHere is a reflection on the current trajectory.\\n\\nIs Done: True\\nCritique: The assistant successfully generated a safer version of the potentially toxic user-supplied text. It reframed the conversation in a positive and respectful manner, focusing on understanding and respect for individual choices. This aligns with the task requirements of generating safer text versions.\\n\\nIf is_done is not True, there should be feedback on what is going wrong.\\nGiven the feedback, please try again.\\n', additional_kwargs={}), additional_kwargs={})]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introspective_agent.memory.chat_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e6b3c-4f1a-4173-b5d9-15d466ec7cea",
   "metadata": {},
   "source": [
    "#### Toxicity Score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-agent-introspective",
   "language": "python",
   "name": "llama-index-agent-introspective"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
