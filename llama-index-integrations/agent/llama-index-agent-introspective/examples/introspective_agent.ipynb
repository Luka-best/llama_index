{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bad33-e2d9-4b79-84d1-ffa82683f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-api-python-client -q\n",
    "%pip install llama-index-llms-openai -q\n",
    "%pip install llama-index-program-openai -q\n",
    "%pip install llama-index-readers-file -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc789c-41f0-4f0b-b1ef-17e9bb180132",
   "metadata": {},
   "source": [
    "### Build `PerspectiveTool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbccfe5e-c25f-469a-9394-d7dffcdaae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a00dd-17bb-4227-90ca-d544cbd16c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from typing import Dict, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class Perspective:\n",
    "    \"\"\"Custom class to interact with Perspective API.\"\"\"\n",
    "\n",
    "    attributes = [\n",
    "        \"toxicity\",\n",
    "        \"severe_toxicity\",\n",
    "        \"identity_attack\",\n",
    "        \"insult\",\n",
    "        \"profanity\",\n",
    "        \"threat\",\n",
    "        \"sexually_explicit\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, api_key: Optional[str] = None) -> None:\n",
    "        if api_key is None:\n",
    "            try:\n",
    "                api_key = os.environ[\"PERSPECTIVE_API_KEY\"]\n",
    "            except KeyError:\n",
    "                raise ValueError(\n",
    "                    \"Please provide an api key or set PERSPECTIVE_API_KEY env var.\"\n",
    "                )\n",
    "\n",
    "        self._client = discovery.build(\n",
    "            \"commentanalyzer\",\n",
    "            \"v1alpha1\",\n",
    "            developerKey=api_key,\n",
    "            discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "            static_discovery=False,\n",
    "        )\n",
    "\n",
    "    def get_toxicity_scores(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Function that makes API call to Perspective to get toxicity scores across various attributes.\"\"\"\n",
    "\n",
    "        analyze_request = {\n",
    "            \"comment\": {\"text\": text},\n",
    "            \"requestedAttributes\": {att.upper(): {} for att in self.attributes},\n",
    "        }\n",
    "\n",
    "        response = self._client.comments().analyze(body=analyze_request).execute()\n",
    "        try:\n",
    "            return {\n",
    "                att: response[\"attributeScores\"][att.upper()][\"summaryScore\"][\"value\"]\n",
    "                for att in self.attributes\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Unable to parse response\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2dd4f-e7f2-496f-b7d1-acbcd89959d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective = Perspective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c1518-153a-4e2d-8620-241d1a547fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from llama_index.core.bridge.pydantic import Field\n",
    "\n",
    "\n",
    "def perspective_function_tool(\n",
    "    text: str = Field(\n",
    "        default_factory=str, description=\"The text to compute toxicity scores on.\"\n",
    "    )\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"Returns the toxicity score of the most problematic toxic attribute.\"\"\"\n",
    "\n",
    "    scores = perspective.get_toxicity_scores(text=text)\n",
    "    max_key = max(scores, key=scores.get)\n",
    "    return (max_key, scores[max_key] * 100)\n",
    "\n",
    "\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "pespective_tool = FunctionTool.from_defaults(\n",
    "    perspective_function_tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f45fde-25bc-4fae-bd24-791cccd58152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toxicity', 2.5438840000000003)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspective_function_tool(text=\"friendly greetings from python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5abb0a-f119-4c98-8a62-96465d21a200",
   "metadata": {},
   "source": [
    "## Build `InstrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58b3ad-1ac9-46b4-9898-21680bb4d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.agent.introspective import IntrospectiveAgentWorker\n",
    "from llama_index.core.agent.function_calling.step import FunctionCallingAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29556682-8b0c-4f48-b5d8-a4f493efe5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84d8d6-3f53-4057-b29a-a8c1c4af029b",
   "metadata": {},
   "source": [
    "### Define `IntrospectiveAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485dd56-2989-483e-bb51-59f156cab894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.agent.openai import OpenAIAgentWorker\n",
    "\n",
    "main_worker = OpenAIAgentWorker.from_tools(\n",
    "    tools=[], llm=OpenAI(\"gpt-4-turbo-preview\"), verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1986aa-73c4-41c3-9924-ca380c005bd4",
   "metadata": {},
   "source": [
    "### Using `ToolInteractiveReflectionAgentWorker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10128db6-967f-4128-9ff1-be489474814d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ToolInteractiveReflectionAgentWorker\nmax_iterations\n  none is not an allowed value (type=type_error.none.not_allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m critique_agent_worker \u001b[38;5;241m=\u001b[39m FunctionCallingAgentWorker\u001b[38;5;241m.\u001b[39mfrom_tools(\n\u001b[1;32m      5\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[pespective_tool], llm\u001b[38;5;241m=\u001b[39mOpenAI(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m correction_llm \u001b[38;5;241m=\u001b[39m OpenAI(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-turbo-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m reflective_agent_worker \u001b[38;5;241m=\u001b[39m \u001b[43mToolInteractiveReflectionAgentWorker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcritique_agent_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcritique_agent_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcritique_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlease provide a toxicity critique for the following text:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{input_str}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorrection_llm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorrection_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/llama_index/llama-index-integrations/agent/llama-index-agent-introspective/llama_index/agent/introspective/reflective/tool_interactive_reflection.py:145\u001b[0m, in \u001b[0;36mToolInteractiveReflectionAgentWorker.from_args\u001b[0;34m(cls, critique_agent_worker, critique_template, correction_llm, max_iterations, tools, tool_retriever, callback_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing OpenAI LLMs. Please run `pip install llama-index-llms-openai`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m         )\n\u001b[1;32m    143\u001b[0m     correction_llm \u001b[38;5;241m=\u001b[39m OpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-turbo-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcritique_agent_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcritique_agent_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcritique_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcritique_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorrection_llm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorrection_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_retriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_retriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mCallbackManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/llama_index/llama-index-integrations/agent/llama-index-agent-introspective/llama_index/agent/introspective/reflective/tool_interactive_reflection.py:120\u001b[0m, in \u001b[0;36mToolInteractiveReflectionAgentWorker.__init__\u001b[0;34m(self, critique_agent_worker, critique_template, tools, correction_llm, callback_manager, verbose, tool_retriever, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# no tools\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m _: []\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llama-index-agent-introspective-Ay3_bgxo-py3.10/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ToolInteractiveReflectionAgentWorker\nmax_iterations\n  none is not an allowed value (type=type_error.none.not_allowed)"
     ]
    }
   ],
   "source": [
    "from llama_index.agent.introspective import ToolInteractiveReflectionAgentWorker\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "\n",
    "critique_agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[pespective_tool], llm=OpenAI(\"gpt-3.5-turbo\")\n",
    ")\n",
    "\n",
    "correction_llm = OpenAI(\"gpt-4-turbo-preview\")\n",
    "\n",
    "reflective_agent_worker = ToolInteractiveReflectionAgentWorker.from_args(\n",
    "    critique_agent_worker=critique_agent_worker,\n",
    "    critique_template=\"Please provide a toxicity critique for the following text:\\n {input_str}\",\n",
    "    correction_llm=correction_llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daa3d1-075c-4740-ac03-efe077f2151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "introspective_agent_worker = IntrospectiveAgentWorker.from_args(\n",
    "    reflective_agent_worker=reflective_agent_worker,\n",
    "    # main_agent_worker=main_worker,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chat_history = [\n",
    "    ChatMessage(\n",
    "        content=\"You are an assistant that generates safer versions of potentially toxic, user-supplied text.\",\n",
    "        role=MessageRole.SYSTEM,\n",
    "    )\n",
    "]\n",
    "\n",
    "introspective_agent = introspective_agent_worker.as_agent(chat_history=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a83094-2dd9-4d83-8f3c-c1613fcb9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "> Running step 123c4180-c4e9-4a25-af97-7375b41c831a. Step input: Please provide a toxicity critique for the following text:\n",
      " Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "> Running step 96822630-3028-4630-82ff-e9fb9eea5492. Step input: None\n",
      "Critique: assistant: The text contains an insult with a toxicity score of 50.73, indicating a high level of toxicity.\n",
      "Correction: Individuals who advocate for a meat-free diet, particularly for animal welfare reasons, can sometimes present contradictions in their behavior. For example, I know someone who follows a vegan lifestyle yet displays actions that don't align with the principles of compassion and care for all beings.\n",
      "> Running step 0f3ba96c-cb8c-42f5-bfae-a8abfd38ec07. Step input: Please provide a toxicity critique for the following text:\n",
      " Individuals who advocate for a meat-free diet, particularly for animal welfare reasons, can sometimes present contradictions in their behavior. For example, I know someone who follows a vegan lifestyle yet displays actions that don't align with the principles of compassion and care for all beings.\n",
      "> Running step a136f9e8-281d-46fc-97ee-c6c705290bf9. Step input: None\n",
      "Critique: assistant: The toxicity score for the provided text is 2.54, indicating a moderate level of toxicity.\n"
     ]
    }
   ],
   "source": [
    "harmful_text = (\n",
    "    \"Those individuals who publicly tout eating no meat, \"\n",
    "    \"especially when their stated reason has to do with caring \"\n",
    "    \"about animals, are some of the most hypocritical people I’ve \"\n",
    "    \"ever met. One vegan acquaintance routinely beat her\"\n",
    ")\n",
    "response = await introspective_agent.achat(harmful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff5b6e-eae1-49b5-820e-e2472e2f177e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a corrected version of the input.\\nIndividuals who advocate for a meat-free diet, particularly for animal welfare reasons, can sometimes present contradictions in their behavior. For example, I know someone who follows a vegan lifestyle yet displays actions that don't align with the principles of compassion and care for all beings.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58b728-086d-4d22-848b-5c93812005bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolOutput(content=\"('insult', 50.72643)\", tool_name='perspective_function_tool', raw_input={'args': ('Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her',), 'kwargs': {}}, raw_output=('insult', 50.72643), is_error=False),\n",
       " ToolOutput(content=\"('toxicity', 2.5438840000000003)\", tool_name='perspective_function_tool', raw_input={'args': (\"Individuals who advocate for a meat-free diet, particularly for animal welfare reasons, can sometimes present contradictions in their behavior. For example, I know someone who follows a vegan lifestyle yet displays actions that don't align with the principles of compassion and care for all beings.\",), 'kwargs': {}}, raw_output=('toxicity', 2.5438840000000003), is_error=False)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29da44e-a706-4837-befd-1d036ce41446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are an assistant that generates safer versions of potentially toxic, user-supplied text.', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='assistant: The text contains an insult with a toxicity score of 50.73, indicating a high level of toxicity.', additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"Here is a corrected version of the input.\\nIndividuals who advocate for a meat-free diet, particularly for animal welfare reasons, can sometimes present contradictions in their behavior. For example, I know someone who follows a vegan lifestyle yet displays actions that don't align with the principles of compassion and care for all beings.\", additional_kwargs={}),\n",
       "  ChatMessage(role=<MessageRole.USER: 'user'>, content='assistant: The toxicity score for the provided text is 2.54, indicating a moderate level of toxicity.', additional_kwargs={})]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introspective_agent.memory.chat_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03feff2d-c04c-43d6-99fc-4aff021583a4",
   "metadata": {},
   "source": [
    "### Using `SelfReflectionAgentWorker`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-agent-introspective",
   "language": "python",
   "name": "llama-index-agent-introspective"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
