{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b2b1e4",
   "metadata": {},
   "source": [
    "# Async TreeSummarizeQuery Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9331cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes. \n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.  \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1d2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gpt_index import GPTListIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4466dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What is Paul Graham's biggest achievement?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6948df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader('../paul_graham_essay/data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466c3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTListIndex(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9115d1",
   "metadata": {},
   "source": [
    "#### By default, `response_mode=tree_summarize` makes blocking LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ef0fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> Building index from nodes: 5 chunks\n",
      "INFO:root:> [query] Total LLM token usage: 19799 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "index.query(query_str, response_mode='tree_summarize')\n",
    "elapsed_time = time.perf_counter() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392d573",
   "metadata": {},
   "source": [
    "It takes ~26s to finish query with response_mode=tree_summarize from 5 text chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f82d1",
   "metadata": {},
   "source": [
    "#### Pass in `use_async=True` to enable asynchronous LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a02987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> Building index from nodes: 5 chunks\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2873 request_id=10074dbaadddd2c5eeeb684cff0f28fb response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2877 request_id=c01cb4b32eaba25540535d5239f5d58a response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2970 request_id=472f6dd817ee5a13cd38e1a4d125e51c response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=4149 request_id=2840b384b52a09b6ad8363deeabe7194 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=4523 request_id=6327001f34ada72f0a3b40ea80b2920c response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=4897 request_id=5a5db6d32d23ba091aa02e0fd936aa51 response_code=200\n",
      "INFO:root:> [query] Total LLM token usage: 19799 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "index.query(query_str, response_mode='tree_summarize', use_async=True)\n",
    "elapsed_time = time.perf_counter() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23469128",
   "metadata": {},
   "source": [
    "It takes ~8s to finish building the GPTTreeIndex from 5 text chunks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
