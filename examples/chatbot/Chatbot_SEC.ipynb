{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19301a65",
   "metadata": {},
   "source": [
    "# ðŸ’¬ðŸ¤– How to Build a Chatbot\n",
    "\n",
    "LlamaIndex serves as a bridge between your data and Language Learning Models (LLMs), providing a toolkit that enables you to establish a query interface around your data for a variety of tasks, such as question-answering and summarization.\n",
    "\n",
    "In this tutorial, we'll walk you through building a context-augmented chatbot using a [Data Agent](https://gpt-index.readthedocs.io/en/stable/core_modules/agent_modules/agents/root.html). This agent, powered by LLMs, is capable of intelligently executing tasks over your data. The end result is a chatbot agent equipped with a robust set of data interface tools provided by LlamaIndex to answer queries about your data.\n",
    "\n",
    "**Note**: TThis tutorial builds upon initial work on creating a query interface over SEC 10-K filings - [check it out here](https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-bring-the-power-of-llms-to-your-own-data-3657d063e30d).\n",
    "\n",
    "### Context\n",
    "\n",
    "In this guide, weâ€™ll build a \"10-K Chatbot\" that uses raw UBER 10-K HTML filings from Dropbox. Users can interact with the chatbot to ask questions related to the 10-K filings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3649d068",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "CuHeyb224pI2",
   "metadata": {
    "id": "CuHeyb224pI2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6220b01",
   "metadata": {},
   "source": [
    "### Ingest Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9082f6e5",
   "metadata": {},
   "source": [
    "Initially, download the raw 10-K files for the years 2019-2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "YC4R6nkCp91d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YC4R6nkCp91d",
    "outputId": "1792fab3-0a0c-48c1-c3ce-f07091a06d3e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-21 11:50:24--  https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 2620:100:601f:18::a27d:912, 162.125.5.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|2620:100:601f:18::a27d:912|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/dl/948jr9cfs7fgj99/UBER.zip [following]\n",
      "--2023-09-21 11:50:24--  https://www.dropbox.com/s/dl/948jr9cfs7fgj99/UBER.zip\n",
      "Reusing existing connection to [www.dropbox.com]:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc9e507d0bd66c9c8517dd2ae40b.dl.dropboxusercontent.com/cd/0/get/CEI8MX7vh9-J19AfP4ZTviya5YKFOfIxk3yIxcKkFqbXI9BsdGxZ7aGauWWtw6O27iLISfZePukWEJOiQ2DPM79lWnVhMkrNGHvEy9zzau4qot7SsLua4ge1MvIuVO0xRGbGl2ql_qQmExdDsywx12HW/file?dl=1# [following]\n",
      "--2023-09-21 11:50:24--  https://uc9e507d0bd66c9c8517dd2ae40b.dl.dropboxusercontent.com/cd/0/get/CEI8MX7vh9-J19AfP4ZTviya5YKFOfIxk3yIxcKkFqbXI9BsdGxZ7aGauWWtw6O27iLISfZePukWEJOiQ2DPM79lWnVhMkrNGHvEy9zzau4qot7SsLua4ge1MvIuVO0xRGbGl2ql_qQmExdDsywx12HW/file?dl=1\n",
      "Resolving uc9e507d0bd66c9c8517dd2ae40b.dl.dropboxusercontent.com (uc9e507d0bd66c9c8517dd2ae40b.dl.dropboxusercontent.com)... 2620:100:601f:15::a27d:90f, 162.125.5.15\n",
      "Connecting to uc9e507d0bd66c9c8517dd2ae40b.dl.dropboxusercontent.com (uc9e507d0bd66c9c8517dd2ae40b.dl.dropboxusercontent.com)|2620:100:601f:15::a27d:90f|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1820227 (1,7M) [application/binary]\n",
      "Saving to: â€˜data/UBER.zipâ€™\n",
      "\n",
      "data/UBER.zip       100%[===================>]   1,74M  3,58MB/s    in 0,5s    \n",
      "\n",
      "2023-09-21 11:50:26 (3,58 MB/s) - â€˜data/UBER.zipâ€™ saved [1820227/1820227]\n",
      "\n",
      "Archive:  data/UBER.zip\n",
      "   creating: data/UBER/\n",
      "  inflating: data/UBER/UBER_2021.html  \n",
      "  inflating: data/__MACOSX/UBER/._UBER_2021.html  \n",
      "  inflating: data/UBER/UBER_2020.html  \n",
      "  inflating: data/__MACOSX/UBER/._UBER_2020.html  \n",
      "  inflating: data/UBER/UBER_2019.html  \n",
      "  inflating: data/__MACOSX/UBER/._UBER_2019.html  \n",
      "  inflating: data/UBER/UBER_2022.html  \n",
      "  inflating: data/__MACOSX/UBER/._UBER_2022.html  \n"
     ]
    }
   ],
   "source": [
    "# download files\n",
    "!mkdir data\n",
    "!wget \"https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\" -O data/UBER.zip\n",
    "!unzip data/UBER.zip -d data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "354ddbdf-0045-474b-b6f2-1b4c22ad360a",
   "metadata": {
    "id": "354ddbdf-0045-474b-b6f2-1b4c22ad360a",
    "tags": []
   },
   "source": [
    "To parse the HTML files into formatted text, we use the [Unstructured](https://github.com/Unstructured-IO/unstructured) library. Thanks to [LlamaHub](https://llamahub.ai/), we can directly integrate with Unstructured, allowing conversion of any text into a Document format that LlamaIndex can ingest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a5cb155-cfe0-4c89-a2b4-c61d5b7cbe61",
   "metadata": {
    "id": "3a5cb155-cfe0-4c89-a2b4-c61d5b7cbe61"
   },
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    download_loader,\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fed4f1-8cca-4d98-b916-a3184279e256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years = [2022, 2021, 2020, 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0371970e-c11c-4534-aa22-7cfdfe411bb3",
   "metadata": {
    "id": "0371970e-c11c-4534-aa22-7cfdfe411bb3"
   },
   "outputs": [],
   "source": [
    "UnstructuredReader = download_loader(\"UnstructuredReader\", refresh_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29084a11-f3da-428d-ae17-27b85a365e84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29084a11-f3da-428d-ae17-27b85a365e84",
    "outputId": "819e4c48-0bb0-4e22-a84c-3021fbedbc4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jtorres/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jtorres/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "loader = UnstructuredReader()\n",
    "doc_set = {}\n",
    "all_docs = []\n",
    "for year in years:\n",
    "    year_docs = loader.load_data(\n",
    "        file=Path(f\"./data/UBER/UBER_{year}.html\"), split_documents=False\n",
    "    )\n",
    "    # insert year metadata into each year\n",
    "    for d in year_docs:\n",
    "        d.metadata = {\"year\": year}\n",
    "    doc_set[year] = year_docs\n",
    "    all_docs.extend(year_docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08b367eb-f9cc-449a-99c5-dfcfbef20a9d",
   "metadata": {
    "id": "08b367eb-f9cc-449a-99c5-dfcfbef20a9d"
   },
   "source": [
    "### Setting up Vector Indices for each year\n",
    "\n",
    "We first setup a vector index for each year. Each vector index allows us\n",
    "to ask questions about the 10-K filing of a given year.\n",
    "\n",
    "We build each index and save it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fbe18a6-4a08-441d-adae-a6195f2cdcb1",
   "metadata": {
    "id": "8fbe18a6-4a08-441d-adae-a6195f2cdcb1",
    "outputId": "bdc1d207-efb2-4f82-bf6c-668cfb7ca98f"
   },
   "outputs": [],
   "source": [
    "# initialize simple vector indices\n",
    "# NOTE: don't run this cell if the indices are already loaded!\n",
    "index_set = {}\n",
    "service_context = ServiceContext.from_defaults(chunk_size=512)\n",
    "for year in years:\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    cur_index = VectorStoreIndex.from_documents(\n",
    "        doc_set[year],\n",
    "        service_context=service_context,\n",
    "        storage_context=storage_context,\n",
    "    )\n",
    "    index_set[year] = cur_index\n",
    "    storage_context.persist(persist_dir=f\"./storage/{year}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83df9e1f",
   "metadata": {},
   "source": [
    "To load an index from disk, do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a5e993-99ae-445a-bcae-e2d415d84e34",
   "metadata": {
    "id": "d3a5e993-99ae-445a-bcae-e2d415d84e34"
   },
   "outputs": [],
   "source": [
    "# Load indices from disk\n",
    "index_set = {}\n",
    "for year in years:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=f\"./storage/{year}\")\n",
    "    cur_index = load_index_from_storage(storage_context=storage_context)\n",
    "    index_set[year] = cur_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "007a99d7-4f63-44bf-957b-c9f5669bce28",
   "metadata": {
    "id": "007a99d7-4f63-44bf-957b-c9f5669bce28"
   },
   "source": [
    "### Setting up a Sub Question Query Engine to Synthesize Answers Across 10-K Filings\n",
    "\n",
    "Since we have access to documents of 4 years, we may not only want to ask questions regarding the 10-K document of a given year, but ask questions that require analysis over all 10-K filings.\n",
    "\n",
    "To address this, we can use a [Sub Question Query Engine](https://gpt-index.readthedocs.io/en/stable/examples/query_engine/sub_question_query_engine.html). It decomposes a query into subqueries, each answered by an individual vector index, and synthesizes the results to answer the overall query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3fb341a-19a3-4e4a-9369-7ddc46b8c2a6",
   "metadata": {
    "id": "f3fb341a-19a3-4e4a-9369-7ddc46b8c2a6"
   },
   "outputs": [],
   "source": [
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.query_engine import SubQuestionQueryEngine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24e7cd09",
   "metadata": {},
   "source": [
    "LlamaIndex provides some wrappers around indices (and query engines) so that they can be used by query engines and agents. First we define a `QueryEngineTool` for each vector index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "966388cb-2fe4-4427-ad2e-cea6a0375233",
   "metadata": {
    "id": "966388cb-2fe4-4427-ad2e-cea6a0375233"
   },
   "outputs": [],
   "source": [
    "# setup individual query engines as tools\n",
    "individual_query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=index_set[year].as_query_engine(),\n",
    "        metadata=ToolMetadata(\n",
    "            name=f\"vector_index_{year}\",\n",
    "            description=f\"useful for when you want to answer queries about the {year} SEC 10-K for Uber\",\n",
    "        ),\n",
    "    )\n",
    "    for year in years\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4b1e343",
   "metadata": {},
   "source": [
    "Now we can create the Sub Question Query Engine, which will allow us to synthesize answers across the 10-K filings. We pass in the `individual_query_engine_tools` we defined above, as well as a `service_context` that will be used to run the subqueries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95b12f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=individual_query_engine_tools,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e2edef1-005f-4733-b64c-5987efa4c88d",
   "metadata": {
    "id": "e46dd052-ab34-4974-b696-16ff217970e0"
   },
   "source": [
    "## Setting up the Chatbot Agent\n",
    "\n",
    "We use a LlamaIndex Data Agent to setup the outer chatbot agent, which has access to a set of Tools. Specifically, we will use an OpenAIAgent, that takes advantage of OpenAI API function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b25cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57c9c946",
   "metadata": {},
   "source": [
    "We want to use the separate Tools we defined previously for each index (corresponding to a given year), as well as a tool for the sub question query engine we defined above.\n",
    "\n",
    "First we define a `QueryEngineTool` for the sub question query engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60568717",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tool = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"sub_question_query_engine\",\n",
    "        description=\"useful for when you want to answer queries that require analyzing multiple SEC 10-K documents for Uber\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e7a5c9d",
   "metadata": {},
   "source": [
    "Then, we combine the Tools we defined above into a single list of tools for the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a5424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = individual_query_engine_tools + [query_engine_tool]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0eb1845",
   "metadata": {},
   "source": [
    "Finally, we call `OpenAIAgent.from_tools` to create the agent, passing in the list of tools we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c2de0f3-9ec3-4f80-bd36-a509f8bfd4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = OpenAIAgent.from_tools(tools, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5aa73510",
   "metadata": {},
   "source": [
    "### Testing the Agent\n",
    "\n",
    "We can now test the agent with various queries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23e4b155",
   "metadata": {},
   "source": [
    "If we test it with a simple \"hello\" query, the agent does not use any Tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ef8138e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Bob! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"hi, i am bob\")\n",
    "print(str(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68dff3bd",
   "metadata": {},
   "source": [
    "If we test it with a query regarding the 10-k of a given year, the agent will use\n",
    "the relevant vector index Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19ca8476-bfeb-4c88-a0ff-15424e2d91c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_index_2020 with args: {\n",
      "  \"input\": \"biggest risk factors\"\n",
      "}\n",
      "Got output: The biggest risk factors mentioned in the context are:\n",
      "1. The adverse impact of the COVID-19 pandemic and actions taken to mitigate it on the business.\n",
      "2. The potential reclassification of drivers as employees, workers, or quasi-employees instead of independent contractors.\n",
      "3. Intense competition in the mobility, delivery, and logistics industries, with low-cost alternatives and well-capitalized competitors.\n",
      "4. The need to lower fares or service fees and offer driver incentives and consumer discounts to remain competitive.\n",
      "5. Significant losses incurred and the uncertainty of achieving profitability.\n",
      "6. The risk of not attracting or maintaining a critical mass of platform users.\n",
      "7. Operational, compliance, and cultural challenges related to the workplace culture and forward-leaning approach.\n",
      "8. The potential negative impact of international investments and the challenges of conducting business in foreign countries.\n",
      "9. Risks associated with operational and compliance challenges, localization, laws and regulations, competition, social acceptance, technological compatibility, improper business practices, liability uncertainty, managing international operations, currency fluctuations, cash transactions, tax consequences, and payment fraud.\n",
      "========================\n",
      "Some of the biggest risk factors for Uber in 2020 were:\n",
      "\n",
      "1. The adverse impact of the COVID-19 pandemic and actions taken to mitigate it on the business.\n",
      "2. The potential reclassification of drivers as employees, workers, or quasi-employees instead of independent contractors.\n",
      "3. Intense competition in the mobility, delivery, and logistics industries, with low-cost alternatives and well-capitalized competitors.\n",
      "4. The need to lower fares or service fees and offer driver incentives and consumer discounts to remain competitive.\n",
      "5. Significant losses incurred and the uncertainty of achieving profitability.\n",
      "6. The risk of not attracting or maintaining a critical mass of platform users.\n",
      "7. Operational, compliance, and cultural challenges related to the workplace culture and forward-leaning approach.\n",
      "8. The potential negative impact of international investments and the challenges of conducting business in foreign countries.\n",
      "9. Risks associated with operational and compliance challenges, localization, laws and regulations, competition, social acceptance, technological compatibility, improper business practices, liability uncertainty, managing international operations, currency fluctuations, cash transactions, tax consequences, and payment fraud.\n",
      "\n",
      "These risk factors highlight the challenges and uncertainties that Uber faced in 2020.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What were some of the biggest risk factors in 2020 for Uber?\")\n",
    "print(str(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75cc4b35",
   "metadata": {},
   "source": [
    "Finally, if we test it with a query to compare/contrast risk factors across years,\n",
    "the agent will use the Sub Question Query Engine Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05b5cd50-cf28-4ad1-b1c2-067f626bad93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: sub_question_query_engine with args: {\n",
      "  \"input\": \"Compare/contrast the risk factors described in the Uber 10-K across years\"\n",
      "}\n",
      "Generated 4 sub questions.\n",
      "\u001b[36;1m\u001b[1;3m[vector_index_2022] Q: What are the risk factors described in the 2022 SEC 10-K for Uber?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[vector_index_2021] Q: What are the risk factors described in the 2021 SEC 10-K for Uber?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[vector_index_2020] Q: What are the risk factors described in the 2020 SEC 10-K for Uber?\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m[vector_index_2019] Q: What are the risk factors described in the 2019 SEC 10-K for Uber?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[vector_index_2021] A: The risk factors described in the 2021 SEC 10-K for Uber include the adverse impact of the COVID-19 pandemic on their business, the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses incurred by the company, the importance of attracting and maintaining a critical mass of platform users, and the ongoing legal challenges regarding driver classification.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[vector_index_2020] A: The risk factors described in the 2020 SEC 10-K for Uber include the adverse impact of the COVID-19 pandemic on their business, the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses and the uncertainty of achieving profitability, the importance of attracting and retaining a critical mass of drivers and users, and the challenges associated with their workplace culture and operational compliance.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[vector_index_2022] A: The risk factors described in the 2022 SEC 10-K for Uber include the potential adverse effect on their business if drivers were classified as employees instead of independent contractors, the highly competitive nature of the mobility, delivery, and logistics industries, the need to lower fares or service fees to remain competitive in certain markets, the company's history of significant losses and the expectation of increased operating expenses in the future, and the potential impact on their platform if they are unable to attract or maintain a critical mass of drivers, consumers, merchants, shippers, and carriers.\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m[vector_index_2019] A: The risk factors described in the 2019 SEC 10-K for Uber include the loss of their license to operate in London, the complexity of their business and operating model due to regulatory uncertainties, the potential for additional regulations for their other products in the Other Bets segment, the evolving laws and regulations regarding the development and deployment of autonomous vehicles, and the increasing number of data protection and privacy laws around the world. Additionally, there are legal proceedings, litigation, claims, and government investigations that Uber is involved in, which could impose a burden on management and employees and come with defense costs or unfavorable rulings.\n",
      "\u001b[0mGot output: The risk factors described in the Uber 10-K reports across the years include the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses incurred by the company, the importance of attracting and maintaining a critical mass of platform users, and the ongoing legal challenges regarding driver classification. Additionally, there are specific risk factors mentioned in each year's report, such as the adverse impact of the COVID-19 pandemic in 2020 and 2021, the loss of their license to operate in London in 2019, and the evolving laws and regulations regarding autonomous vehicles in 2019. Overall, while there are some similarities in the risk factors mentioned, there are also specific factors that vary across the years.\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: vector_index_2022 with args: {\n",
      "  \"input\": \"risk factors\"\n",
      "}\n",
      "Got output: Some of the risk factors mentioned in the context include the potential adverse effect on the business if drivers were classified as employees instead of independent contractors, the highly competitive nature of the mobility, delivery, and logistics industries, the need to lower fares or service fees to remain competitive, the company's history of significant losses and the expectation of increased operating expenses, the impact of future pandemics or disease outbreaks on the business and financial results, and the potential harm to the business due to economic conditions and their effect on discretionary consumer spending.\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: vector_index_2021 with args: {\n",
      "  \"input\": \"risk factors\"\n",
      "}\n",
      "Got output: The COVID-19 pandemic and the impact of actions to mitigate the pandemic have adversely affected and may continue to adversely affect parts of our business. Our business would be adversely affected if Drivers were classified as employees, workers or quasi-employees instead of independent contractors. The mobility, delivery, and logistics industries are highly competitive, with well-established and low-cost alternatives that have been available for decades, low barriers to entry, low switching costs, and well-capitalized competitors in nearly every major geographic region. To remain competitive in certain markets, we have in the past lowered, and may continue to lower, fares or service fees, and we have in the past offered, and may continue to offer, significant Driver incentives and consumer discounts and promotions. We have incurred significant losses since inception, including in the United States and other major markets. We expect our operating expenses to increase significantly in the foreseeable future, and we may not achieve or maintain profitability. If we are unable to attract or maintain a critical mass of Drivers, consumers, merchants, shippers, and carriers, whether as a result of competition or other factors, our platform will become less appealing to platform users.\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: vector_index_2020 with args: {\n",
      "  \"input\": \"risk factors\"\n",
      "}\n",
      "Got output: The risk factors mentioned in the context include the adverse impact of the COVID-19 pandemic on the business, the potential reclassification of drivers as employees, the highly competitive nature of the mobility, delivery, and logistics industries, the need to lower fares or service fees to remain competitive, the company's history of significant losses and potential future expenses, the importance of attracting and maintaining a critical mass of platform users, and the operational and cultural challenges faced by the company.\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: vector_index_2019 with args: {\n",
      "  \"input\": \"risk factors\"\n",
      "}\n",
      "Got output: The risk factors mentioned in the context include competition with local companies, differing levels of social acceptance, technological compatibility issues, exposure to improper business practices, legal uncertainty, difficulties in managing international operations, fluctuations in currency exchange rates, regulations governing local currencies, tax consequences, financial accounting burdens, difficulties in implementing financial systems, import and export restrictions, political and economic instability, public health concerns, reduced protection for intellectual property rights, limited influence over minority-owned affiliates, and regulatory complexities. These risk factors could adversely affect the international operations, business, financial condition, and operating results of the company.\n",
      "========================\n",
      "Here is a comparison of the risk factors described in the Uber 10-K reports across years:\n",
      "\n",
      "2022 Risk Factors:\n",
      "- Potential adverse effect if drivers were classified as employees instead of independent contractors.\n",
      "- Highly competitive nature of the mobility, delivery, and logistics industries.\n",
      "- Need to lower fares or service fees to remain competitive.\n",
      "- History of significant losses and expectation of increased operating expenses.\n",
      "- Impact of future pandemics or disease outbreaks on the business and financial results.\n",
      "- Potential harm to the business due to economic conditions and their effect on discretionary consumer spending.\n",
      "\n",
      "2021 Risk Factors:\n",
      "- Adverse impact of the COVID-19 pandemic and actions to mitigate it on the business.\n",
      "- Potential reclassification of drivers as employees instead of independent contractors.\n",
      "- Highly competitive nature of the mobility, delivery, and logistics industries.\n",
      "- Need to lower fares or service fees and offer incentives to remain competitive.\n",
      "- History of significant losses and uncertainty of achieving profitability.\n",
      "- Importance of attracting and maintaining a critical mass of platform users.\n",
      "\n",
      "2020 Risk Factors:\n",
      "- Adverse impact of the COVID-19 pandemic on the business.\n",
      "- Potential reclassification of drivers as employees.\n",
      "- Highly competitive nature of the mobility, delivery, and logistics industries.\n",
      "- Need to lower fares or service fees to remain competitive.\n",
      "- History of significant losses and potential future expenses.\n",
      "- Importance of attracting and maintaining a critical mass of platform users.\n",
      "- Operational and cultural challenges faced by the company.\n",
      "\n",
      "2019 Risk Factors:\n",
      "- Competition with local companies.\n",
      "- Differing levels of social acceptance.\n",
      "- Technological compatibility issues.\n",
      "- Exposure to improper business practices.\n",
      "- Legal uncertainty.\n",
      "- Difficulties in managing international operations.\n",
      "- Fluctuations in currency exchange rates.\n",
      "- Regulations governing local currencies.\n",
      "- Tax consequences.\n",
      "- Financial accounting burdens.\n",
      "- Difficulties in implementing financial systems.\n",
      "- Import and export restrictions.\n",
      "- Political and economic instability.\n",
      "- Public health concerns.\n",
      "- Reduced protection for intellectual property rights.\n",
      "- Limited influence over minority-owned affiliates.\n",
      "- Regulatory complexities.\n",
      "\n",
      "These comparisons highlight both common and unique risk factors that Uber faced in different years.\n"
     ]
    }
   ],
   "source": [
    "cross_query_str = \"Compare/contrast the risk factors described in the Uber 10-K across years. Give answer in bullet points.\"\n",
    "\n",
    "response = agent.chat(cross_query_str)\n",
    "print(str(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a066a1c8-2108-447a-ab9a-b82b4f35696e",
   "metadata": {},
   "source": [
    "### Setting up the Chatbot Loop\n",
    "\n",
    "Now that we have the chatbot setup, it only takes a few more steps to setup a basic interactive loop to chat with our SEC-augmented chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edf6b5a9-bac5-4599-93f8-21c2fc44fa4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: In 2022, Uber faced several legal proceedings. Some of the notable ones include:\n",
      "\n",
      "1. Petition against Proposition 22: A petition was filed in California alleging that Proposition 22, which classifies app-based drivers as independent contractors, is unconstitutional.\n",
      "\n",
      "2. Lawsuit by Massachusetts Attorney General: The Massachusetts Attorney General filed a lawsuit against Uber, claiming that drivers should be classified as employees and entitled to protections under wage and labor laws.\n",
      "\n",
      "3. Allegations by New York Attorney General: The New York Attorney General made allegations against Uber regarding the misclassification of drivers and related employment violations.\n",
      "\n",
      "4. Swiss social security rulings: Swiss social security rulings classified Uber drivers as employees, which could have implications for Uber's operations in Switzerland.\n",
      "\n",
      "5. Class action lawsuits in Australia: Uber faced class action lawsuits in Australia, with allegations that the company conspired to harm participants in the taxi, hire-car, and limousine industries.\n",
      "\n",
      "It's important to note that the outcomes of these legal proceedings are uncertain and may vary.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     text_input \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUser: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     response \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mchat(text_input)\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAgent: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/llama_index/llama_index/callbacks/utils.py:38\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m callback_manager \u001b[39m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     37\u001b[0m \u001b[39mwith\u001b[39;00m callback_manager\u001b[39m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llama_index/llama_index/agent/openai_agent.py:344\u001b[0m, in \u001b[0;36mBaseOpenAIAgent.chat\u001b[0;34m(self, message, chat_history, function_call)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m@trace_method\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mchat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchat\u001b[39m(\n\u001b[1;32m    335\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     function_call: Union[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    339\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AgentChatResponse:\n\u001b[1;32m    340\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[1;32m    341\u001b[0m         CBEventType\u001b[39m.\u001b[39mAGENT_STEP,\n\u001b[1;32m    342\u001b[0m         payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mMESSAGES: [message]},\n\u001b[1;32m    343\u001b[0m     ) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 344\u001b[0m         chat_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chat(\n\u001b[1;32m    345\u001b[0m             message, chat_history, function_call, mode\u001b[39m=\u001b[39;49mChatResponseMode\u001b[39m.\u001b[39;49mWAIT\n\u001b[1;32m    346\u001b[0m         )\n\u001b[1;32m    347\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[1;32m    348\u001b[0m         e\u001b[39m.\u001b[39mon_end(payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mRESPONSE: chat_response})\n",
      "File \u001b[0;32m~/llama_index/llama_index/agent/openai_agent.py:295\u001b[0m, in \u001b[0;36mBaseOpenAIAgent._chat\u001b[0;34m(self, message, chat_history, function_call, mode)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_function_call, \u001b[39mdict\u001b[39m)\n\u001b[0;32m--> 295\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_function(tools, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlatest_function_call)\n\u001b[1;32m    296\u001b[0m \u001b[39m# change function call to the default value, if a custom function was given\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m# as an argument (none and auto are predefined by OpenAI)\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m current_func \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/llama_index/llama_index/agent/openai_agent.py:220\u001b[0m, in \u001b[0;36mBaseOpenAIAgent._call_function\u001b[0;34m(self, tools, function_call)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_function\u001b[39m(\u001b[39mself\u001b[39m, tools: List[BaseTool], function_call: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[1;32m    212\u001b[0m         CBEventType\u001b[39m.\u001b[39mFUNCTION_CALL,\n\u001b[1;32m    213\u001b[0m         payload\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m         },\n\u001b[1;32m    219\u001b[0m     ) \u001b[39mas\u001b[39;00m event:\n\u001b[0;32m--> 220\u001b[0m         function_message, tool_output \u001b[39m=\u001b[39m call_function(\n\u001b[1;32m    221\u001b[0m             tools, function_call, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_verbose\n\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m         event\u001b[39m.\u001b[39mon_end(payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mFUNCTION_OUTPUT: \u001b[39mstr\u001b[39m(tool_output)})\n\u001b[1;32m    224\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msources\u001b[39m.\u001b[39mappend(tool_output)\n",
      "File \u001b[0;32m~/llama_index/llama_index/agent/openai_agent.py:55\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(tools, function_call, verbose)\u001b[0m\n\u001b[1;32m     53\u001b[0m tool \u001b[39m=\u001b[39m get_function_by_name(tools, name)\n\u001b[1;32m     54\u001b[0m argument_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(arguments_str)\n\u001b[0;32m---> 55\u001b[0m output \u001b[39m=\u001b[39m tool(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margument_dict)\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m     57\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot output: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(output)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/llama_index/llama_index/tools/types.py:125\u001b[0m, in \u001b[0;36mAsyncBaseTool.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToolOutput:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llama_index/llama_index/tools/query_engine.py:54\u001b[0m, in \u001b[0;36mQueryEngineTool.call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToolOutput:\n\u001b[1;32m     53\u001b[0m     query_str \u001b[39m=\u001b[39m cast(\u001b[39mstr\u001b[39m, \u001b[39minput\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_engine\u001b[39m.\u001b[39;49mquery(query_str)\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m ToolOutput(\n\u001b[1;32m     56\u001b[0m         content\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(response),\n\u001b[1;32m     57\u001b[0m         tool_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mname,\n\u001b[1;32m     58\u001b[0m         raw_input\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39minput\u001b[39m},\n\u001b[1;32m     59\u001b[0m         raw_output\u001b[39m=\u001b[39mresponse,\n\u001b[1;32m     60\u001b[0m     )\n",
      "File \u001b[0;32m~/llama_index/llama_index/indices/query/base.py:23\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(str_or_query_bundle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     22\u001b[0m     str_or_query_bundle \u001b[39m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 23\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(str_or_query_bundle)\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/llama_index/llama_index/query_engine/retriever_query_engine.py:178\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    172\u001b[0m         nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve(query_bundle)\n\u001b[1;32m    174\u001b[0m         retrieve_event\u001b[39m.\u001b[39mon_end(\n\u001b[1;32m    175\u001b[0m             payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mNODES: nodes},\n\u001b[1;32m    176\u001b[0m         )\n\u001b[0;32m--> 178\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_response_synthesizer\u001b[39m.\u001b[39;49msynthesize(\n\u001b[1;32m    179\u001b[0m         query\u001b[39m=\u001b[39;49mquery_bundle,\n\u001b[1;32m    180\u001b[0m         nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    183\u001b[0m     query_event\u001b[39m.\u001b[39mon_end(payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mRESPONSE: response})\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/llama_index/llama_index/response_synthesizers/base.py:125\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[0;34m(self, query, nodes, additional_source_nodes)\u001b[0m\n\u001b[1;32m    120\u001b[0m     query \u001b[39m=\u001b[39m QueryBundle(query_str\u001b[39m=\u001b[39mquery)\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_manager\u001b[39m.\u001b[39mevent(\n\u001b[1;32m    123\u001b[0m     CBEventType\u001b[39m.\u001b[39mSYNTHESIZE, payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mQUERY_STR: query\u001b[39m.\u001b[39mquery_str}\n\u001b[1;32m    124\u001b[0m ) \u001b[39mas\u001b[39;00m event:\n\u001b[0;32m--> 125\u001b[0m     response_str \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_response(\n\u001b[1;32m    126\u001b[0m         query_str\u001b[39m=\u001b[39;49mquery\u001b[39m.\u001b[39;49mquery_str,\n\u001b[1;32m    127\u001b[0m         text_chunks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m    128\u001b[0m             n\u001b[39m.\u001b[39;49mnode\u001b[39m.\u001b[39;49mget_content(metadata_mode\u001b[39m=\u001b[39;49mMetadataMode\u001b[39m.\u001b[39;49mLLM) \u001b[39mfor\u001b[39;49;00m n \u001b[39min\u001b[39;49;00m nodes\n\u001b[1;32m    129\u001b[0m         ],\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    132\u001b[0m     additional_source_nodes \u001b[39m=\u001b[39m additional_source_nodes \u001b[39mor\u001b[39;00m []\n\u001b[1;32m    133\u001b[0m     source_nodes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(nodes) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[0;32m~/llama_index/llama_index/response_synthesizers/compact_and_refine.py:34\u001b[0m, in \u001b[0;36mCompactAndRefine.get_response\u001b[0;34m(self, query_str, text_chunks, **response_kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m new_texts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[0;32m---> 34\u001b[0m response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_response(\n\u001b[1;32m     35\u001b[0m     query_str\u001b[39m=\u001b[39;49mquery_str, text_chunks\u001b[39m=\u001b[39;49mnew_texts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kwargs\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/llama_index/llama_index/response_synthesizers/refine.py:116\u001b[0m, in \u001b[0;36mRefine.get_response\u001b[0;34m(self, query_str, text_chunks, **response_kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mfor\u001b[39;00m text_chunk \u001b[39min\u001b[39;00m text_chunks:\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m prev_response_obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m         \u001b[39m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[1;32m    115\u001b[0m         \u001b[39m# is an answer, then return it\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_give_response_single(\n\u001b[1;32m    117\u001b[0m             query_str,\n\u001b[1;32m    118\u001b[0m             text_chunk,\n\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    120\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m         \u001b[39m# refine response if possible\u001b[39;00m\n\u001b[1;32m    122\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_refine_response_single(\n\u001b[1;32m    123\u001b[0m             prev_response_obj, query_str, text_chunk\n\u001b[1;32m    124\u001b[0m         )\n",
      "File \u001b[0;32m~/llama_index/llama_index/response_synthesizers/refine.py:175\u001b[0m, in \u001b[0;36mRefine._give_response_single\u001b[0;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_streaming:\n\u001b[1;32m    173\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m         structured_response \u001b[39m=\u001b[39m cast(\n\u001b[0;32m--> 175\u001b[0m             StructuredRefineResponse, program(context_str\u001b[39m=\u001b[39;49mcur_text_chunk)\n\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    177\u001b[0m         query_satisfied \u001b[39m=\u001b[39m structured_response\u001b[39m.\u001b[39mquery_satisfied\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m query_satisfied:\n",
      "File \u001b[0;32m~/llama_index/llama_index/response_synthesizers/refine.py:56\u001b[0m, in \u001b[0;36mDefaultRefineProgram.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m StructuredRefineResponse:\n\u001b[0;32m---> 56\u001b[0m     answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_llm_predictor\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m     57\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prompt,\n\u001b[1;32m     58\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m StructuredRefineResponse(answer\u001b[39m=\u001b[39manswer, query_satisfied\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/llama_index/llama_index/llm_predictor/base.py:142\u001b[0m, in \u001b[0;36mLLMPredictor.predict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    140\u001b[0m messages \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mformat_messages(llm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_llm, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprompt_args)\n\u001b[1;32m    141\u001b[0m messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_messages(messages)\n\u001b[0;32m--> 142\u001b[0m chat_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_llm\u001b[39m.\u001b[39;49mchat(messages)\n\u001b[1;32m    143\u001b[0m output \u001b[39m=\u001b[39m chat_response\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m \u001b[39m# NOTE: this is an approximation, only for token counting\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_index/llama_index/llms/base.py:151\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mwith\u001b[39;00m wrapper_logic(_self) \u001b[39mas\u001b[39;00m callback_manager:\n\u001b[1;32m    143\u001b[0m     event_id \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_event_start(\n\u001b[1;32m    144\u001b[0m         CBEventType\u001b[39m.\u001b[39mLLM,\n\u001b[1;32m    145\u001b[0m         payload\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m         },\n\u001b[1;32m    150\u001b[0m     )\n\u001b[0;32m--> 151\u001b[0m     f_return_val \u001b[39m=\u001b[39m f(_self, messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    153\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f_return_val, Generator):\n\u001b[1;32m    154\u001b[0m         \u001b[39m# intercept the generator and add a callback to the end\u001b[39;00m\n\u001b[1;32m    155\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_gen\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatResponseGen:\n",
      "File \u001b[0;32m~/llama_index/llama_index/llms/openai.py:126\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     chat_fn \u001b[39m=\u001b[39m completion_to_chat_decorator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_complete)\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m chat_fn(messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llama_index/llama_index/llms/openai.py:194\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m message_dicts \u001b[39m=\u001b[39m to_openai_message_dicts(messages)\n\u001b[1;32m    193\u001b[0m all_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_all_kwargs(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 194\u001b[0m response \u001b[39m=\u001b[39m completion_with_retry(\n\u001b[1;32m    195\u001b[0m     is_chat_model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_is_chat_model,\n\u001b[1;32m    196\u001b[0m     max_retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    197\u001b[0m     messages\u001b[39m=\u001b[39;49mmessage_dicts,\n\u001b[1;32m    198\u001b[0m     stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    199\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs,\n\u001b[1;32m    200\u001b[0m )\n\u001b[1;32m    201\u001b[0m message_dict \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    202\u001b[0m message \u001b[39m=\u001b[39m from_openai_message_dict(message_dict)\n",
      "File \u001b[0;32m~/llama_index/llama_index/llms/openai_utils.py:142\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(is_chat_model, max_retries, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     client \u001b[39m=\u001b[39m get_completion_endpoint(is_chat_model)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 142\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_index/llama_index/llms/openai_utils.py:140\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    139\u001b[0m     client \u001b[39m=\u001b[39m get_completion_endpoint(is_chat_model)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[1;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    597\u001b[0m         method,\n\u001b[1;32m    598\u001b[0m         abs_url,\n\u001b[1;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/llama_index/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = OpenAIAgent.from_tools(tools)  # verbose=False by default\n",
    "\n",
    "while True:\n",
    "    text_input = input(\"User: \")\n",
    "    response = agent.chat(text_input)\n",
    "    print(f\"Agent: {response}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a8d7bc06ed646b78956101c5c62fb1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_112ef61e952444369d6c0dce1d1098a8",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afe741aff3f54ae6a89b5965888599f4",
      "value": 456318
     }
    },
    "0cccb700fc264051abc0b7458716054f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0cd2bf060b4c4daeaf9156705ae409ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c4ce2ec8ae54042864d1d0261355166",
       "IPY_MODEL_2e27352e29354001b53bc4d07bd4c1ed",
       "IPY_MODEL_709f853d0ae846e7945c74ff83cae52e"
      ],
      "layout": "IPY_MODEL_54a3bafa2af54475abe57e37e2399a45"
     }
    },
    "0dc1dea99b774b74a84c9c02b6335b94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b4a5130401a44daa116828b9fa8d17b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_21efd9c072db42bf89ad5dbd96b52a01",
      "value": "Downloading (â€¦)lve/main/config.json: 100%"
     }
    },
    "10420e2dba3244f48c8fcd7d35904e41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "112ef61e952444369d6c0dce1d1098a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a259e1a45bc4043b81243d033b79752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f0963a05a29d4e6f8a2ab48fc8a26a1d",
       "IPY_MODEL_0a8d7bc06ed646b78956101c5c62fb1f",
       "IPY_MODEL_ef339a504f984cc2ac07c8252aa2f6d5"
      ],
      "layout": "IPY_MODEL_3d3c2d54cdf44a06a99c35d0e1b33b0a"
     }
    },
    "21efd9c072db42bf89ad5dbd96b52a01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d7895836c814084be531103d0218650": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e27352e29354001b53bc4d07bd4c1ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_792a299872704c10af8061175db96031",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d7895836c814084be531103d0218650",
      "value": 1355256
     }
    },
    "37cf19bcc68d41d7bc6b411cd273a88c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e1f2102db184538a35ed9c8498d5bbc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0cccb700fc264051abc0b7458716054f",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 3.35MB/s]"
     }
    },
    "387d0ca6bf2c4341804cfa43a71b6451": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b4a5130401a44daa116828b9fa8d17b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c4ce2ec8ae54042864d1d0261355166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94343417f60a4f9d9a745dfa2c967893",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f6331afe201d49319b76e528e01a9b4b",
      "value": "Downloading (â€¦)/main/tokenizer.json: 100%"
     }
    },
    "3d3c2d54cdf44a06a99c35d0e1b33b0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e45628539864cd2b1297c2be1d35c98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4539f47e9e4c444e9f610dea60db5eb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "548c125bc716475ba6708fa80f5b1b61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_387d0ca6bf2c4341804cfa43a71b6451",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1c406aebffa49f48c3457a9482a47a3",
      "value": 1042301
     }
    },
    "54a3bafa2af54475abe57e37e2399a45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5edb09d55e7b45c881bbf6a38de92f60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d75f60b7f0b94b3d88046ac990446ad4",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_609d29b907424f049de6ef0b86a6541d",
      "value": 665
     }
    },
    "609d29b907424f049de6ef0b86a6541d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6dc9a8ca9270413893e28e3a3807dd51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "709f853d0ae846e7945c74ff83cae52e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10420e2dba3244f48c8fcd7d35904e41",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d7b1b50d3f6843be90e00d3352139b2f",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 3.65MB/s]"
     }
    },
    "755797e4682642399c367962ba737504": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb486eb0dc2f44eabcac46a18b711ff1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3e45628539864cd2b1297c2be1d35c98",
      "value": "Downloading (â€¦)olve/main/vocab.json: 100%"
     }
    },
    "792a299872704c10af8061175db96031": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bd8740ee12a486fbb3d3ae0a2c493b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dc9a8ca9270413893e28e3a3807dd51",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4539f47e9e4c444e9f610dea60db5eb0",
      "value": " 665/665 [00:00&lt;00:00, 18.8kB/s]"
     }
    },
    "7e96275c58434a04a49e56598b12656a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e1f2102db184538a35ed9c8498d5bbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94343417f60a4f9d9a745dfa2c967893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bf6e3e259cd4bc0bd4c714c725d0782": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a292f2af029c4340813e63370bf73f12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_755797e4682642399c367962ba737504",
       "IPY_MODEL_548c125bc716475ba6708fa80f5b1b61",
       "IPY_MODEL_37cf19bcc68d41d7bc6b411cd273a88c"
      ],
      "layout": "IPY_MODEL_ebc4716ea8d849c58c43c26f5caf18fe"
     }
    },
    "a8bae11fb1aa40348e611a1592e0ff0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afe741aff3f54ae6a89b5965888599f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1c406aebffa49f48c3457a9482a47a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2653a474569425ebb546f93241a465e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbdfb7b736f546fea9f2a56a815a8e8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dc1dea99b774b74a84c9c02b6335b94",
       "IPY_MODEL_5edb09d55e7b45c881bbf6a38de92f60",
       "IPY_MODEL_7bd8740ee12a486fbb3d3ae0a2c493b8"
      ],
      "layout": "IPY_MODEL_fa9eff66d6084f0a970408b620afa686"
     }
    },
    "d75f60b7f0b94b3d88046ac990446ad4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7b1b50d3f6843be90e00d3352139b2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb486eb0dc2f44eabcac46a18b711ff1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebc4716ea8d849c58c43c26f5caf18fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef339a504f984cc2ac07c8252aa2f6d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8bae11fb1aa40348e611a1592e0ff0a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9bf6e3e259cd4bc0bd4c714c725d0782",
      "value": " 456k/456k [00:00&lt;00:00, 1.84MB/s]"
     }
    },
    "f0963a05a29d4e6f8a2ab48fc8a26a1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e96275c58434a04a49e56598b12656a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b2653a474569425ebb546f93241a465e",
      "value": "Downloading (â€¦)olve/main/merges.txt: 100%"
     }
    },
    "f6331afe201d49319b76e528e01a9b4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa9eff66d6084f0a970408b620afa686": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
