{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9c48213d-6e6a-4c10-838a-2a7c710c3a05",
      "metadata": {
        "id": "9c48213d-6e6a-4c10-838a-2a7c710c3a05"
      },
      "source": [
        "# Simple Index Demo + ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e34da56e-bc3b-433e-b65c-96edea4db5dd",
      "metadata": {
        "id": "e34da56e-bc3b-433e-b65c-96edea4db5dd"
      },
      "source": [
        "Use a very simple wrapper around the ChatGPT API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "o5RdGwW2Mcya",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5RdGwW2Mcya",
        "outputId": "d54ebbca-012c-48e7-9505-b27931e92dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.9/dist-packages (0.4.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from llama-index) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from llama-index) (1.4.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.9/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.9/dist-packages (from llama-index) (0.5.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.9/dist-packages (from llama-index) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in /usr/local/lib/python3.9/dist-packages (from llama-index) (0.27.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (from llama-index) (0.0.109)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai>=0.26.4->llama-index) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai>=0.26.4->llama-index) (2.28.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json->llama-index) (3.19.0)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json->llama-index) (0.8.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json->llama-index) (1.5.1)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.9/dist-packages (from langchain->llama-index) (6.0)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain->llama-index) (1.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain->llama-index) (1.4.46)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->llama-index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken->llama-index) (2022.6.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (3.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai>=0.26.4->llama-index) (6.0.4)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain->llama-index) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai>=0.26.4->llama-index) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai>=0.26.4->llama-index) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai>=0.26.4->llama-index) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain->llama-index) (2.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json->llama-index) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d3b817-b70e-4667-be4f-d3a0fe4bd119",
      "metadata": {
        "id": "50d3b817-b70e-4667-be4f-d3a0fe4bd119"
      },
      "source": [
        "#### Load documents, build the GPTSimpleVectorIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "690a6918-7c75-4f95-9ccc-d2c4a1fe00d7",
      "metadata": {
        "id": "690a6918-7c75-4f95-9ccc-d2c4a1fe00d7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader, LLMPredictor\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "03d1691e-544b-454f-825b-5ee12f7faa8a",
      "metadata": {
        "id": "03d1691e-544b-454f-825b-5ee12f7faa8a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader('../paul_graham_essay/data').load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ad144ee7-96da-4dd6-be00-fd6cf0c78e58",
      "metadata": {
        "id": "ad144ee7-96da-4dd6-be00-fd6cf0c78e58",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# My OpenAI Key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"INPUT YOUR OPENAI_API_KEY\"\n",
        "\n",
        "index = GPTSimpleVectorIndex(documents, chunk_size_limit=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6cc980e8-f4e1-4fad-93f8-ab1bbaa874f3",
      "metadata": {
        "id": "6cc980e8-f4e1-4fad-93f8-ab1bbaa874f3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# LLM Predictor (gpt-3.5-turbo)\n",
        "llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6caf93b-6345-4c65-a346-a95b0f1746c4",
      "metadata": {
        "id": "b6caf93b-6345-4c65-a346-a95b0f1746c4"
      },
      "source": [
        "#### Query Index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83e2905e-3789-4793-82b9-0ac488246824",
      "metadata": {
        "id": "83e2905e-3789-4793-82b9-0ac488246824"
      },
      "source": [
        "By default, with the help of langchain's PromptSelector abstraction, we use \n",
        "a modified refine prompt tailored for ChatGPT-use if the ChatGPT model is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "85466fdf-93f3-4cb1-a5f9-0056a8245a6f",
      "metadata": {
        "id": "85466fdf-93f3-4cb1-a5f9-0056a8245a6f",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = index.query(\n",
        "    \"What did the author do growing up?\", \n",
        "    llm_predictor=llm_predictor,\n",
        "    similarity_top_k=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bdda1b2c-ae46-47cf-91d7-3153e8d0473b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "bdda1b2c-ae46-47cf-91d7-3153e8d0473b",
        "outputId": "2a3c5f3e-93b6-4903-c799-4fbcf3a2ff4d",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>Before college, the author worked on writing essays and programming. They wrote short stories and essays on various topics they had stacked up. However, in late 2015, the author stopped writing essays to focus on working on Bel, an interpreter written in itself. They worked on it intensively, often having a decent chunk of the code in their head at any given time. The author also worked on Bel while living in England, where they moved with their family in the summer of 2016. In the fall of 2019, Bel was finally finished, and the author resumed writing essays.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ec88df57",
      "metadata": {
        "id": "ec88df57",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = index.query(\n",
        "    \"What did the author do during his time at RISD?\", \n",
        "    llm_predictor=llm_predictor,\n",
        "    similarity_top_k=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "67e8e675-1b03-423a-b53e-23ab278ba03b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "67e8e675-1b03-423a-b53e-23ab278ba03b",
        "outputId": "220feff0-a02f-4890-c9c6-c2fb28b9913e",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>The author took foundation classes in fundamental subjects like drawing, color, and design at RISD while in a PhD program in computer science at Harvard. He also painted during his free time and imagined himself living frugally off the royalties from a popular Lisp book he was writing and spending all his time painting. Additionally, he became a de facto studio assistant for a painter named Idelle Weber in New York. After learning a lot in the color class he took at RISD, he dropped out in 1993 and moved to New York to become a painter. He lived in a rent-controlled apartment in Yorkville and worked as a freelance Lisp hacker to support himself.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88ca1808-d112-4c28-b110-b65dcc9b7207",
      "metadata": {
        "id": "88ca1808-d112-4c28-b110-b65dcc9b7207"
      },
      "source": [
        "**Refine Prompt**: Here is the chat refine prompt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "2f0c270d-9de5-40bf-88fc-83a360523db0",
      "metadata": {
        "id": "2f0c270d-9de5-40bf-88fc-83a360523db0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.prompts.chat_prompts import CHAT_REFINE_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4db38651-9790-4a61-ac3d-689ce6dfa369",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4db38651-9790-4a61-ac3d-689ce6dfa369",
        "outputId": "011b69e7-d6cf-4daf-92ba-37d1fdb315e7",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_variables': ['context_msg', 'existing_answer', 'query_str'],\n",
              " 'output_parser': None,\n",
              " 'partial_variables': {},\n",
              " 'messages': [HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query_str'], output_parser=None, partial_variables={}, template='{query_str}', template_format='f-string', validate_template=True), additional_kwargs={}),\n",
              "  AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['existing_answer'], output_parser=None, partial_variables={}, template='{existing_answer}', template_format='f-string', validate_template=True), additional_kwargs={}),\n",
              "  HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context_msg'], output_parser=None, partial_variables={}, template=\"We have the opportunity to refine the above answer (only if needed) with some more context below.\\n------------\\n{context_msg}\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, output the original answer again.\", template_format='f-string', validate_template=True), additional_kwargs={})]}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(CHAT_REFINE_PROMPT.prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb664e8-f53f-4d6c-a086-1f2784cc1dc8",
      "metadata": {
        "id": "6cb664e8-f53f-4d6c-a086-1f2784cc1dc8"
      },
      "source": [
        "#### Query Index (Using the standard Refine Prompt)\n",
        "\n",
        "If we use the \"standard\" refine prompt (where the prompt is one text template instead of multiple messages), we find that the results over ChatGPT are worse. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "29c416f8-d5ab-47d6-8b16-f615bfa58219",
      "metadata": {
        "id": "29c416f8-d5ab-47d6-8b16-f615bfa58219",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.prompts.default_prompts import DEFAULT_REFINE_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3df1acc4-735a-48ac-9fb4-73d9d7eabc02",
      "metadata": {
        "id": "3df1acc4-735a-48ac-9fb4-73d9d7eabc02",
        "tags": []
      },
      "outputs": [],
      "source": [
        "response = index.query(\n",
        "    \"What did the author do during his time at RISD?\", \n",
        "    llm_predictor=llm_predictor,\n",
        "    refine_template=DEFAULT_REFINE_PROMPT,\n",
        "    similarity_top_k=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b8938077-6527-4008-8d0c-af7a8178ff10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "b8938077-6527-4008-8d0c-af7a8178ff10",
        "outputId": "c116be9f-248a-434b-f627-4abc47159d1a",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>The original answer is not sufficient to answer the question with the new context provided. There is no direct mention of what the author did during his time at RISD in the new context.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e024521-97b5-417f-8c27-950983f52cda",
      "metadata": {
        "id": "2e024521-97b5-417f-8c27-950983f52cda"
      },
      "source": [
        "### [Beta] Use ChatGPTLLMPredictor【Deprecated】\n",
        "\n",
        "> The ChatGPTLLMPredictor is deprecated anyways, please check [issue/709](https://github.com/jerryjliu/llama_index/issues/709)\n",
        "\n",
        "Very simple GPT-Index-native ChatGPT wrapper. Note: this is a beta feature. If this doesn't work please\n",
        "use the suggested flow above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a49d9a1b-21fb-4153-ad24-191a13513d64",
      "metadata": {
        "id": "a49d9a1b-21fb-4153-ad24-191a13513d64"
      },
      "outputs": [],
      "source": [
        "# use ChatGPT [beta]\n",
        "# from llama_index.langchain_helpers.chatgpt import ChatGPTLLMPredictor\n",
        "\n",
        "# llm_predictor = ChatGPTLLMPredictor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "596af2aa-7ddf-41f2-801b-4a24a4980dd8",
      "metadata": {
        "id": "596af2aa-7ddf-41f2-801b-4a24a4980dd8"
      },
      "outputs": [],
      "source": [
        "# response = index.query(\n",
        "#     \"What did the author do during his time at RISD?\", \n",
        "#     llm_predictor=llm_predictor\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Nn0IEB5sc1yT",
      "metadata": {
        "id": "Nn0IEB5sc1yT"
      },
      "source": [
        "### Query Index (Using the ChatGPT Refine Prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "3xtLNcqdcAMb",
      "metadata": {
        "id": "3xtLNcqdcAMb"
      },
      "outputs": [],
      "source": [
        "from llama_index.prompts.chat_prompts import CHAT_REFINE_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "bxbF1XcGcHzi",
      "metadata": {
        "id": "bxbF1XcGcHzi"
      },
      "outputs": [],
      "source": [
        "# LLM Predictor (gpt-3.5-turbo)\n",
        "llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"))\n",
        "\n",
        "response = index.query(\n",
        "    \"What did the author do during his time at RISD?\", \n",
        "    llm_predictor=llm_predictor,\n",
        "    refine_template=CHAT_REFINE_PROMPT,\n",
        "    similarity_top_k=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "J3mN2V99cw18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "J3mN2V99cw18",
        "outputId": "a0bfb064-a4ea-4016-ffb6-516aa1156f16"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>The author attended RISD to learn how to paint and improve his skills. He took a color class and taught himself to paint, but ultimately dropped out in 1993. He then moved to New York City to pursue his career as an artist and lived in a rent-controlled apartment in Yorkville.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llama_index",
      "language": "python",
      "name": "llama_index"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
