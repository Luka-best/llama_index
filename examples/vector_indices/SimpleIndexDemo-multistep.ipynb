{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c48213d-6e6a-4c10-838a-2a7c710c3a05",
   "metadata": {},
   "source": [
    "# Simple Index Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3b817-b70e-4667-be4f-d3a0fe4bd119",
   "metadata": {},
   "source": [
    "#### Load documents, build the GPTSimpleVectorIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690a6918-7c75-4f95-9ccc-d2c4a1fe00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from gpt_index import (\n",
    "    GPTSimpleVectorIndex, \n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48da73f-aadb-480c-8db1-99c915b7cc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM Predictor (gpt-3)\n",
    "llm_predictor_gpt3 = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\"))\n",
    "\n",
    "# LLMPredictor (gpt-4)\n",
    "llm_predictor_gpt4 = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d1691e-544b-454f-825b-5ee12f7faa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader('../paul_graham_essay/data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad144ee7-96da-4dd6-be00-fd6cf0c78e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 17598 tokens\n",
      "> [build_index_from_documents] Total embedding token usage: 17598 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bbccf1d-ac39-427c-b3a3-f8e9d1d12348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "index.save_to_disk('index_simple.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197ca78e-1310-474d-91e3-877c3636b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "index = GPTSimpleVectorIndex.load_from_disk('index_simple.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6caf93b-6345-4c65-a346-a95b0f1746c4",
   "metadata": {},
   "source": [
    "#### Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d989ba-0c1d-43b6-a1d3-0ea7135f43a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gpt_index.indices.query.query_transform.base import StepDecomposeQueryTransform\n",
    "# gpt-4\n",
    "step_decompose_transform = StepDecomposeQueryTransform(\n",
    "    llm_predictor_gpt4, verbose=True\n",
    ")\n",
    "\n",
    "# gpt-3\n",
    "step_decompose_transform_gpt3 = StepDecomposeQueryTransform(\n",
    "    llm_predictor_gpt3, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a124db0-e2d7-4566-bcec-1d41cf669ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index.set_text(\"Used to answer questions about the author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85466fdf-93f3-4cb1-a5f9-0056a8245a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: Who was in the first batch of the accelerator program the author started?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: Who was in the first batch of the accelerator program the author started?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: Who was in the first batch of the accelerator program the author started?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: None\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: What accelerator program did the author start?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3633 tokens\n",
      "> [query] Total LLM token usage: 3633 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# set Logging to DEBUG for more detailed outputs\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m response_gpt4 \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWho was in the first batch of the accelerator program the author started?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_decompose_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_predictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_predictor_gpt4\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/gpt_index/indices/base.py:417\u001b[0m, in \u001b[0;36mBaseGPTIndex.query\u001b[0;34m(self, query_str, mode, query_transform, use_async, **query_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m query_config \u001b[38;5;241m=\u001b[39m QueryConfig(\n\u001b[1;32m    402\u001b[0m     index_struct_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct\u001b[38;5;241m.\u001b[39mget_type(),\n\u001b[1;32m    403\u001b[0m     query_mode\u001b[38;5;241m=\u001b[39mmode_enum,\n\u001b[1;32m    404\u001b[0m     query_kwargs\u001b[38;5;241m=\u001b[39mquery_kwargs,\n\u001b[1;32m    405\u001b[0m )\n\u001b[1;32m    406\u001b[0m query_runner \u001b[38;5;241m=\u001b[39m QueryRunner(\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm_predictor,\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prompt_helper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     use_async\u001b[38;5;241m=\u001b[39muse_async,\n\u001b[1;32m    416\u001b[0m )\n\u001b[0;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_struct\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/gpt_index/indices/query/query_runner.py:189\u001b[0m, in \u001b[0;36mQueryRunner.query\u001b[0;34m(self, query_str_or_bundle, index_struct)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     query_bundle \u001b[38;5;241m=\u001b[39m query_str_or_bundle\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_combiner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/gpt_index/gpt_index/indices/query/query_combiner/base.py:170\u001b[0m, in \u001b[0;36mMultiStepQueryCombiner.run\u001b[0;34m(self, query_obj, query_bundle)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_builder\u001b[38;5;241m.\u001b[39madd_source_node(source_node)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# update extra info\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m \u001b[43mfinal_response_extra_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubresponses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m prev_reasoning \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupdated_query_bundle\u001b[38;5;241m.\u001b[39mquery_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcur_response\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m )\n\u001b[1;32m    175\u001b[0m cur_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "response_gpt4 = index.query(\n",
    "    \"Who was in the first batch of the accelerator program the author started?\",\n",
    "    query_transform=step_decompose_transform,\n",
    "    llm_predictor=llm_predictor_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdda1b2c-ae46-47cf-91d7-3153e8d0473b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "\n",
       "Answer: The first batch of Y Combinator in 2005 included startups like Reddit, founded by Steve Huffman and Alexis Ohanian; Kiko, founded by Justin Kan and Emmett Shear (who later founded Twitch); Infogami, founded by Aaron Swartz (who had already helped write the RSS spec and would later become a martyr for open access); and Loopt, founded by Sam Altman (who would later become the second president of YC). These founders and their startups were part of the initial group that helped shape the future of Y Combinator and the startup ecosystem, and are widely considered to be the pioneers of the accelerator program.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response_gpt4}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec88df57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: None\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: Who is the author that founded Viaweb?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3684 tokens\n",
      "> [query] Total LLM token usage: 3684 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "- Who is the author that founded Viaweb?\n",
      "- Paul Graham is the author who founded Viaweb.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: In which city did Paul Graham found his first company, Viaweb?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3698 tokens\n",
      "> [query] Total LLM token usage: 3698 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "- Who is the author that founded Viaweb?\n",
      "- Paul Graham is the author who founded Viaweb.\n",
      "- In which city did Paul Graham found his first company, Viaweb?\n",
      "- Paul Graham founded his first company, Viaweb, in Cambridge.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: None\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response_gpt4 = index.query(\n",
    "    \"In which city did the author found his first company, Viaweb?\",\n",
    "    query_transform=step_decompose_transform,\n",
    "    llm_predictor=llm_predictor_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653508f1-b2b0-479a-85b3-113cda507231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer: Paul Graham founded his first company, Viaweb, in Cambridge, Massachusetts.\n"
     ]
    }
   ],
   "source": [
    "print(response_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fa93cdb-7007-4664-853a-5c81c6c17560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: None\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  Where was the author located when he founded his first company, Viaweb?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3724 tokens\n",
      "> [query] Total LLM token usage: 3724 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "-  Where was the author located when he founded his first company, Viaweb?\n",
      "- \n",
      "\n",
      "The author was located in Cambridge, Massachusetts when he founded his first company, Viaweb.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query:  Where is Cambridge, Massachusetts located?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3778 tokens\n",
      "> [query] Total LLM token usage: 3778 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n",
      "\u001b[33;1m\u001b[1;3m> Current query: In which city did the author found his first company, Viaweb?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> Formatted prompt: The original question is as follows: In which city did the author found his first company, Viaweb?\n",
      "We have an opportunity to answer some, or all of the question from a knowledge source. Context information for the knowledge source is provided below, as well as previous reasoning steps.\n",
      "Given the context and previous reasoning, return a question that can be answered from the context. This question can be the same as the original question, or this question can represent a subcomponent of the overall question.It should not be irrelevant to the original question.\n",
      "If we cannot extract more information from the context, provide 'None' as the answer. Some examples are given below: \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None\n",
      "Next question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: Who was the winner of the 2020 Australian Open?\n",
      "Knowledge source context: Provides names of the winners of the 2020 Australian Open\n",
      "Previous reasoning: None.\n",
      "New question: Who was the winner of the 2020 Australian Open? \n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: None\n",
      "\n",
      "Question: How many Grand Slam titles does the winner of the 2020 Australian Open have?\n",
      "Knowledge source context: Provides information about the winners of the 2020 Australian Open - includes biographical information for each winner\n",
      "Previous reasoning:\n",
      "- Who was the winner of the 2020 Australian Open? \n",
      "- The winner of the 2020 Australian Open was Novak Djokovic.\n",
      "New question: How many Grand Slam titles does Novak Djokovic have? \n",
      "\n",
      "Question: In which city did the author found his first company, Viaweb?\n",
      "Knowledge source context: Used to answer questions about the author\n",
      "Previous reasoning: \n",
      "-  Where was the author located when he founded his first company, Viaweb?\n",
      "- \n",
      "\n",
      "The author was located in Cambridge, Massachusetts when he founded his first company, Viaweb.\n",
      "-  Where is Cambridge, Massachusetts located?\n",
      "- \n",
      "\n",
      "Cambridge, Massachusetts is located in the Greater Boston area of the northeastern United States. It is situated directly north of Boston, across the Charles River. Paul Graham, the creator of the Lisp programming language, bought a house in Cambridge in the late 1990s and used it as a base for his work on the language.\n",
      "\n",
      "New question: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m> New query: \n",
      "Where is Paul Graham's house located in Cambridge, Massachusetts?\n",
      "\u001b[0mINFO:root:> [query] Total LLM token usage: 3719 tokens\n",
      "> [query] Total LLM token usage: 3719 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 14 tokens\n",
      "> [query] Total embedding token usage: 14 tokens\n"
     ]
    }
   ],
   "source": [
    "response_gpt3 = index.query(\n",
    "    \"In which city did the author found his first company, Viaweb?\",\n",
    "    query_transform=step_decompose_transform_gpt3,\n",
    "    llm_predictor=llm_predictor_gpt3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05899fcf-7a04-4d21-9e6d-04983755d175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The author founded his first company, Viaweb, in Cambridge, Massachusetts, which is located in the Greater Boston area of the northeastern United States, directly north of Boston, across the Charles River. Paul Graham, the creator of the Lisp programming language, bought a house in Cambridge in the spring of 1995 to work on a new dialect of Lisp called Arc, and used it as a base for his work on the language.\n"
     ]
    }
   ],
   "source": [
    "print(response_gpt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43c659-ffd0-40df-b52b-032e6647cf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
