{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "from gpt_index import GPTDeepLakeIndex, GPTVectorStoreIndex, SimpleDirectoryReader, Document\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-********************************\"\n",
    "os.environ[\n",
    "    \"ACTIVELOOP_TOKEN\"\n",
    "] = \"********************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeplake in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (3.2.22)\n",
      "Requirement already satisfied: numpy in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (1.24.2)\n",
      "Requirement already satisfied: pillow in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (9.5.0)\n",
      "Requirement already satisfied: boto3 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (1.24.59)\n",
      "Requirement already satisfied: click in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (8.1.3)\n",
      "Requirement already satisfied: pathos in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (0.3.0)\n",
      "Requirement already satisfied: humbug>=0.3.1 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (0.3.1)\n",
      "Requirement already satisfied: tqdm in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (4.65.0)\n",
      "Requirement already satisfied: numcodecs in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (0.11.0)\n",
      "Requirement already satisfied: pyjwt in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (2.6.0)\n",
      "Requirement already satisfied: aioboto3==10.4.0 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (10.4.0)\n",
      "Requirement already satisfied: nest_asyncio in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from deeplake) (1.5.6)\n",
      "Requirement already satisfied: aiobotocore[boto3]==2.4.2 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aioboto3==10.4.0->deeplake) (2.4.2)\n",
      "Requirement already satisfied: aiohttp>=3.3.1 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (3.8.4)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (0.11.0)\n",
      "Requirement already satisfied: botocore<1.27.60,>=1.27.59 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.27.59)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.15.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (22.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from aioitertools>=0.5.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (4.5.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from boto3->deeplake) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from boto3->deeplake) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.26.15)\n",
      "Requirement already satisfied: requests in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from humbug>=0.3.1->deeplake) (2.28.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (3.4)\n",
      "Requirement already satisfied: entrypoints in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from numcodecs->deeplake) (0.4)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from pathos->deeplake) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from pathos->deeplake) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from pathos->deeplake) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from pathos->deeplake) (0.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/lib/python3.9/site-packages (from requests->humbug>=0.3.1->deeplake) (2022.12.7)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Users/adilkhansarsen/Documents/work/LlamaIndex/llama_index/GPTIndex/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "zsh:1: parse error near `>'\n"
     ]
    }
   ],
   "source": [
    "!pip install deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you don't export token in your environment alternativalay you can use deeplake CLI to loging to deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !activeloop login -t <TOKEN> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 14935662-4884-4c57-ac2e-fa62da019665 Document Hash: 77ae91ab542f3abb308c4d7c77c9bc4c9ad0ccd63144802b7cbe7e1bb3a4094e\n"
     ]
    }
   ],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader('../paul_graham_essay/data').load_data()\n",
    "print('Document ID:', documents[0].doc_id, 'Document Hash:', documents[0].doc_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "The dataset is private so make sure you are logged in!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/adilkhan/paul_graham_essay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://adilkhan/paul_graham_essay loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████| 1/1 [00:21<00:00\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 17617 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://adilkhan/paul_graham_essay', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (6, 1536)   None     None   \n",
      "    ids      text     (6, 1)      str     None   \n",
      " metadata    json     (6, 1)      str     None   \n",
      "   text      text     (6, 1)      str     None   \n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"hub://adilkhan/paul_graham_essay\" # if we comment this out and don't pass the path then GPTDeepLakeIndex will create dataset in memory\n",
    "\n",
    "# Create an index over the documnts\n",
    "index = GPTDeepLakeIndex.from_documents(documents, dataset_path=dataset_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we decide to not pass the path then GPTDeepLakeIndex will create dataset locally called llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_index loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████| 1/1 [00:04<00:00\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 17617 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='llama_index', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (6, 1536)   None     None   \n",
      "    ids      text     (6, 1)      str     None   \n",
      " metadata    json     (6, 1)      str     None   \n",
      "   text      text     (6, 1)      str     None   \n"
     ]
    }
   ],
   "source": [
    "# Create an index over the documnts\n",
    "# index = GPTDeepLakeIndex.from_documents(documents, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 4028 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 6 tokens\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What did the author learn?\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The author learned that working on things that are not prestigious can be a good thing, as it can\n",
      "lead to discovering something real and avoiding the wrong track. The author also learned that\n",
      "ignorance can be beneficial, as it can lead to discovering something new and unexpected. The author\n",
      "also learned the importance of working hard, even at the parts of the job they don't like, in order\n",
      "to set an example for others. The author also learned the value of unsolicited advice, as it can be\n",
      "beneficial in unexpected ways, such as when Robert Morris suggested that the author should make sure\n",
      "Y Combinator wasn't the last cool thing they did.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 4072 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What was a hard moment for the author?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A hard moment for the author was when he was dealing with urgent problems during YC and about 60%\n",
      "of them had to do with Hacker News, a news aggregator he had created. He was overwhelmed by the\n",
      "amount of work he had to do to keep Hacker News running, and it was taking away from his ability to\n",
      "focus on other projects. He was also haunted by the idea that his own work ethic set the upper bound\n",
      "for how hard everyone else worked, so he felt he had to work very hard. He was also dealing with\n",
      "disputes between cofounders, figuring out when people were lying to them, and fighting with people\n",
      "who maltreated the startups. On top of this, he was given unsolicited advice from Robert Morris to\n",
      "make sure Y Combinator wasn't the last cool thing he did, which made him consider quitting.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading GPTDeepLakeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_index = index.save_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/adilkhan/paul_graham_essay\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://adilkhan/paul_graham_essay loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpt_index.vector_stores.deeplake:Deep Lake Dataset in hub://adilkhan/paul_graham_essay already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://adilkhan/paul_graham_essay', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (6, 1536)   None     None   \n",
      "    ids      text     (6, 1)      str     None   \n",
      " metadata    json     (6, 1)      str     None   \n",
      "   text      text     (6, 1)      str     None   \n"
     ]
    }
   ],
   "source": [
    "index = GPTVectorStoreIndex.load_from_dict(saved_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 4072 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A hard moment for the author was when he was dealing with urgent problems during YC and about 60%\n",
      "of them had to do with Hacker News, a news aggregator he had created. He was overwhelmed by the\n",
      "amount of work he had to do to keep Hacker News running, and it was taking away from his ability to\n",
      "focus on other projects. He was also haunted by the idea that his own work ethic set the upper bound\n",
      "for how hard everyone else worked, so he felt he had to work very hard. He was also dealing with\n",
      "disputes between cofounders, figuring out when people were lying to them, and fighting with people\n",
      "who maltreated the startups. On top of this, he was given unsolicited advice from Robert Morris to\n",
      "make sure Y Combinator wasn't the last cool thing he did, which made him consider quitting.\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What was a hard moment for the author?\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting items from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/adilkhan/paul_graham_essay\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://adilkhan/paul_graham_essay loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "import deeplake as dp\n",
    "\n",
    "\n",
    "ds = dp.load(\"hub://adilkhan/paul_graham_essay\")\n",
    "\n",
    "idx = ds.ids[0].numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 4501.13it/s]\n",
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://adilkhan/paul_graham_essay', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (5, 1536)   None     None   \n",
      "    ids      text     (5, 1)      str     None   \n",
      " metadata    json     (5, 1)      str     None   \n",
      "   text      text     (5, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "index.delete(idx[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('GPTIndex': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e44765f40d39e4c6e3d7a9b35e5b42b8711c1c0fb3c237b84fa62e4b3e35e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
